{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/me.png","path":"images/me.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/LICENSE","path":"lib/pdf/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/README.md","path":"lib/pdf/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/build/pdf.js","path":"lib/pdf/build/pdf.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/build/pdf.js.map","path":"lib/pdf/build/pdf.js.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/build/pdf.worker.js","path":"lib/pdf/build/pdf.worker.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/build/pdf.worker.js.map","path":"lib/pdf/build/pdf.worker.js.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/compressed.tracemonkey-pldi-09.pdf","path":"lib/pdf/web/compressed.tracemonkey-pldi-09.pdf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/debugger.js","path":"lib/pdf/web/debugger.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/viewer.css","path":"lib/pdf/web/viewer.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/viewer.html","path":"lib/pdf/web/viewer.html","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/viewer.js","path":"lib/pdf/web/viewer.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/viewer.js.map","path":"lib/pdf/web/viewer.js.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-EUC-H.bcmap","path":"lib/pdf/web/cmaps/78-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-EUC-V.bcmap","path":"lib/pdf/web/cmaps/78-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-H.bcmap","path":"lib/pdf/web/cmaps/78-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/78-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/78-RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-V.bcmap","path":"lib/pdf/web/cmaps/78-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78ms-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/78ms-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/78ms-RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/78ms-RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/83pv-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/83pv-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/90ms-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/90ms-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/90ms-RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/90ms-RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/90msp-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/90msp-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/90msp-RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/90msp-RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/90pv-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/90pv-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/90pv-RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/90pv-RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-H.bcmap","path":"lib/pdf/web/cmaps/Add-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/Add-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/Add-RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-V.bcmap","path":"lib/pdf/web/cmaps/Add-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-0.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-0.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-1.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-1.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-2.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-3.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-3.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-4.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-4.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-5.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-5.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-6.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-6.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-UCS2.bcmap","path":"lib/pdf/web/cmaps/Adobe-CNS1-UCS2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-0.bcmap","path":"lib/pdf/web/cmaps/Adobe-GB1-0.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-1.bcmap","path":"lib/pdf/web/cmaps/Adobe-GB1-1.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-2.bcmap","path":"lib/pdf/web/cmaps/Adobe-GB1-2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-3.bcmap","path":"lib/pdf/web/cmaps/Adobe-GB1-3.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-4.bcmap","path":"lib/pdf/web/cmaps/Adobe-GB1-4.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-5.bcmap","path":"lib/pdf/web/cmaps/Adobe-GB1-5.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-UCS2.bcmap","path":"lib/pdf/web/cmaps/Adobe-GB1-UCS2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-0.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-0.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-1.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-1.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-2.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-3.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-3.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-4.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-4.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-5.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-5.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-6.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-6.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-UCS2.bcmap","path":"lib/pdf/web/cmaps/Adobe-Japan1-UCS2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-0.bcmap","path":"lib/pdf/web/cmaps/Adobe-Korea1-0.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-1.bcmap","path":"lib/pdf/web/cmaps/Adobe-Korea1-1.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-2.bcmap","path":"lib/pdf/web/cmaps/Adobe-Korea1-2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-UCS2.bcmap","path":"lib/pdf/web/cmaps/Adobe-Korea1-UCS2.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5-H.bcmap","path":"lib/pdf/web/cmaps/B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5-V.bcmap","path":"lib/pdf/web/cmaps/B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5pc-H.bcmap","path":"lib/pdf/web/cmaps/B5pc-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5pc-V.bcmap","path":"lib/pdf/web/cmaps/B5pc-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS-EUC-H.bcmap","path":"lib/pdf/web/cmaps/CNS-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS-EUC-V.bcmap","path":"lib/pdf/web/cmaps/CNS-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS1-H.bcmap","path":"lib/pdf/web/cmaps/CNS1-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS1-V.bcmap","path":"lib/pdf/web/cmaps/CNS1-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS2-H.bcmap","path":"lib/pdf/web/cmaps/CNS2-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS2-V.bcmap","path":"lib/pdf/web/cmaps/CNS2-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETHK-B5-H.bcmap","path":"lib/pdf/web/cmaps/ETHK-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETHK-B5-V.bcmap","path":"lib/pdf/web/cmaps/ETHK-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETen-B5-H.bcmap","path":"lib/pdf/web/cmaps/ETen-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETen-B5-V.bcmap","path":"lib/pdf/web/cmaps/ETen-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETenms-B5-H.bcmap","path":"lib/pdf/web/cmaps/ETenms-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETenms-B5-V.bcmap","path":"lib/pdf/web/cmaps/ETenms-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/EUC-H.bcmap","path":"lib/pdf/web/cmaps/EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/EUC-V.bcmap","path":"lib/pdf/web/cmaps/EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-H.bcmap","path":"lib/pdf/web/cmaps/Ext-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/Ext-RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/Ext-RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-V.bcmap","path":"lib/pdf/web/cmaps/Ext-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-EUC-H.bcmap","path":"lib/pdf/web/cmaps/GB-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-EUC-V.bcmap","path":"lib/pdf/web/cmaps/GB-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-H.bcmap","path":"lib/pdf/web/cmaps/GB-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-V.bcmap","path":"lib/pdf/web/cmaps/GB-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK-EUC-H.bcmap","path":"lib/pdf/web/cmaps/GBK-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK-EUC-V.bcmap","path":"lib/pdf/web/cmaps/GBK-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK2K-H.bcmap","path":"lib/pdf/web/cmaps/GBK2K-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK2K-V.bcmap","path":"lib/pdf/web/cmaps/GBK2K-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBKp-EUC-H.bcmap","path":"lib/pdf/web/cmaps/GBKp-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBKp-EUC-V.bcmap","path":"lib/pdf/web/cmaps/GBKp-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-EUC-H.bcmap","path":"lib/pdf/web/cmaps/GBT-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-EUC-V.bcmap","path":"lib/pdf/web/cmaps/GBT-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-H.bcmap","path":"lib/pdf/web/cmaps/GBT-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-V.bcmap","path":"lib/pdf/web/cmaps/GBT-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBTpc-EUC-H.bcmap","path":"lib/pdf/web/cmaps/GBTpc-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBTpc-EUC-V.bcmap","path":"lib/pdf/web/cmaps/GBTpc-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBpc-EUC-H.bcmap","path":"lib/pdf/web/cmaps/GBpc-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBpc-EUC-V.bcmap","path":"lib/pdf/web/cmaps/GBpc-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/H.bcmap","path":"lib/pdf/web/cmaps/H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdla-B5-H.bcmap","path":"lib/pdf/web/cmaps/HKdla-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdla-B5-V.bcmap","path":"lib/pdf/web/cmaps/HKdla-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdlb-B5-H.bcmap","path":"lib/pdf/web/cmaps/HKdlb-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdlb-B5-V.bcmap","path":"lib/pdf/web/cmaps/HKdlb-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKgccs-B5-H.bcmap","path":"lib/pdf/web/cmaps/HKgccs-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKgccs-B5-V.bcmap","path":"lib/pdf/web/cmaps/HKgccs-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm314-B5-H.bcmap","path":"lib/pdf/web/cmaps/HKm314-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm314-B5-V.bcmap","path":"lib/pdf/web/cmaps/HKm314-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm471-B5-H.bcmap","path":"lib/pdf/web/cmaps/HKm471-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm471-B5-V.bcmap","path":"lib/pdf/web/cmaps/HKm471-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKscs-B5-H.bcmap","path":"lib/pdf/web/cmaps/HKscs-B5-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKscs-B5-V.bcmap","path":"lib/pdf/web/cmaps/HKscs-B5-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Hankaku.bcmap","path":"lib/pdf/web/cmaps/Hankaku.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Hiragana.bcmap","path":"lib/pdf/web/cmaps/Hiragana.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-EUC-H.bcmap","path":"lib/pdf/web/cmaps/KSC-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-EUC-V.bcmap","path":"lib/pdf/web/cmaps/KSC-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-H.bcmap","path":"lib/pdf/web/cmaps/KSC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-Johab-H.bcmap","path":"lib/pdf/web/cmaps/KSC-Johab-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-Johab-V.bcmap","path":"lib/pdf/web/cmaps/KSC-Johab-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-V.bcmap","path":"lib/pdf/web/cmaps/KSC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-H.bcmap","path":"lib/pdf/web/cmaps/KSCms-UHC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-HW-H.bcmap","path":"lib/pdf/web/cmaps/KSCms-UHC-HW-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-HW-V.bcmap","path":"lib/pdf/web/cmaps/KSCms-UHC-HW-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-V.bcmap","path":"lib/pdf/web/cmaps/KSCms-UHC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCpc-EUC-H.bcmap","path":"lib/pdf/web/cmaps/KSCpc-EUC-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCpc-EUC-V.bcmap","path":"lib/pdf/web/cmaps/KSCpc-EUC-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Katakana.bcmap","path":"lib/pdf/web/cmaps/Katakana.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/LICENSE","path":"lib/pdf/web/cmaps/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/NWP-H.bcmap","path":"lib/pdf/web/cmaps/NWP-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/NWP-V.bcmap","path":"lib/pdf/web/cmaps/NWP-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/RKSJ-H.bcmap","path":"lib/pdf/web/cmaps/RKSJ-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/RKSJ-V.bcmap","path":"lib/pdf/web/cmaps/RKSJ-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/Roman.bcmap","path":"lib/pdf/web/cmaps/Roman.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UCS2-H.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UCS2-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UCS2-V.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UCS2-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF16-H.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UTF16-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF16-V.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UTF16-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF32-H.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UTF32-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF32-V.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UTF32-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF8-H.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UTF8-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF8-V.bcmap","path":"lib/pdf/web/cmaps/UniCNS-UTF8-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UCS2-H.bcmap","path":"lib/pdf/web/cmaps/UniGB-UCS2-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UCS2-V.bcmap","path":"lib/pdf/web/cmaps/UniGB-UCS2-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF16-H.bcmap","path":"lib/pdf/web/cmaps/UniGB-UTF16-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF16-V.bcmap","path":"lib/pdf/web/cmaps/UniGB-UTF16-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF32-H.bcmap","path":"lib/pdf/web/cmaps/UniGB-UTF32-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF32-V.bcmap","path":"lib/pdf/web/cmaps/UniGB-UTF32-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF8-H.bcmap","path":"lib/pdf/web/cmaps/UniGB-UTF8-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF8-V.bcmap","path":"lib/pdf/web/cmaps/UniGB-UTF8-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UCS2-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-HW-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UCS2-HW-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-HW-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UCS2-HW-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UCS2-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF16-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UTF16-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF16-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UTF16-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF32-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UTF32-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF32-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UTF32-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF8-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UTF8-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF8-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS-UTF8-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF16-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS2004-UTF16-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF16-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS2004-UTF16-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF32-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS2004-UTF32-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF32-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS2004-UTF32-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF8-H.bcmap","path":"lib/pdf/web/cmaps/UniJIS2004-UTF8-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF8-V.bcmap","path":"lib/pdf/web/cmaps/UniJIS2004-UTF8-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISPro-UCS2-HW-V.bcmap","path":"lib/pdf/web/cmaps/UniJISPro-UCS2-HW-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISPro-UCS2-V.bcmap","path":"lib/pdf/web/cmaps/UniJISPro-UCS2-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISPro-UTF8-V.bcmap","path":"lib/pdf/web/cmaps/UniJISPro-UTF8-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX0213-UTF32-H.bcmap","path":"lib/pdf/web/cmaps/UniJISX0213-UTF32-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX0213-UTF32-V.bcmap","path":"lib/pdf/web/cmaps/UniJISX0213-UTF32-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX02132004-UTF32-H.bcmap","path":"lib/pdf/web/cmaps/UniJISX02132004-UTF32-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX02132004-UTF32-V.bcmap","path":"lib/pdf/web/cmaps/UniJISX02132004-UTF32-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UCS2-H.bcmap","path":"lib/pdf/web/cmaps/UniKS-UCS2-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UCS2-V.bcmap","path":"lib/pdf/web/cmaps/UniKS-UCS2-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF16-H.bcmap","path":"lib/pdf/web/cmaps/UniKS-UTF16-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF16-V.bcmap","path":"lib/pdf/web/cmaps/UniKS-UTF16-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF32-H.bcmap","path":"lib/pdf/web/cmaps/UniKS-UTF32-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF32-V.bcmap","path":"lib/pdf/web/cmaps/UniKS-UTF32-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF8-H.bcmap","path":"lib/pdf/web/cmaps/UniKS-UTF8-H.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF8-V.bcmap","path":"lib/pdf/web/cmaps/UniKS-UTF8-V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/V.bcmap","path":"lib/pdf/web/cmaps/V.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/cmaps/WP-Symbol.bcmap","path":"lib/pdf/web/cmaps/WP-Symbol.bcmap","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-check.svg","path":"lib/pdf/web/images/annotation-check.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-comment.svg","path":"lib/pdf/web/images/annotation-comment.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-help.svg","path":"lib/pdf/web/images/annotation-help.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-insert.svg","path":"lib/pdf/web/images/annotation-insert.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-key.svg","path":"lib/pdf/web/images/annotation-key.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-newparagraph.svg","path":"lib/pdf/web/images/annotation-newparagraph.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-noicon.svg","path":"lib/pdf/web/images/annotation-noicon.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-note.svg","path":"lib/pdf/web/images/annotation-note.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/annotation-paragraph.svg","path":"lib/pdf/web/images/annotation-paragraph.svg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next-rtl.png","path":"lib/pdf/web/images/findbarButton-next-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next-rtl@2x.png","path":"lib/pdf/web/images/findbarButton-next-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next.png","path":"lib/pdf/web/images/findbarButton-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next@2x.png","path":"lib/pdf/web/images/findbarButton-next@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous-rtl.png","path":"lib/pdf/web/images/findbarButton-previous-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous-rtl@2x.png","path":"lib/pdf/web/images/findbarButton-previous-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous.png","path":"lib/pdf/web/images/findbarButton-previous.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous@2x.png","path":"lib/pdf/web/images/findbarButton-previous@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/grab.cur","path":"lib/pdf/web/images/grab.cur","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/grabbing.cur","path":"lib/pdf/web/images/grabbing.cur","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/loading-icon.gif","path":"lib/pdf/web/images/loading-icon.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/loading-small.png","path":"lib/pdf/web/images/loading-small.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/loading-small@2x.png","path":"lib/pdf/web/images/loading-small@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-documentProperties.png","path":"lib/pdf/web/images/secondaryToolbarButton-documentProperties.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-documentProperties@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-documentProperties@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-firstPage.png","path":"lib/pdf/web/images/secondaryToolbarButton-firstPage.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-firstPage@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-firstPage@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-handTool.png","path":"lib/pdf/web/images/secondaryToolbarButton-handTool.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-handTool@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-handTool@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-lastPage.png","path":"lib/pdf/web/images/secondaryToolbarButton-lastPage.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-lastPage@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-lastPage@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCcw.png","path":"lib/pdf/web/images/secondaryToolbarButton-rotateCcw.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCcw@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-rotateCcw@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCw.png","path":"lib/pdf/web/images/secondaryToolbarButton-rotateCw.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCw@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-rotateCw@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal.png","path":"lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollVertical.png","path":"lib/pdf/web/images/secondaryToolbarButton-scrollVertical.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollVertical@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-scrollVertical@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollWrapped.png","path":"lib/pdf/web/images/secondaryToolbarButton-scrollWrapped.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollWrapped@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-scrollWrapped@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-selectTool.png","path":"lib/pdf/web/images/secondaryToolbarButton-selectTool.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-selectTool@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-selectTool@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadEven.png","path":"lib/pdf/web/images/secondaryToolbarButton-spreadEven.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadEven@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-spreadEven@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadNone.png","path":"lib/pdf/web/images/secondaryToolbarButton-spreadNone.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadNone@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-spreadNone@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadOdd.png","path":"lib/pdf/web/images/secondaryToolbarButton-spreadOdd.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadOdd@2x.png","path":"lib/pdf/web/images/secondaryToolbarButton-spreadOdd@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/shadow.png","path":"lib/pdf/web/images/shadow.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/texture.png","path":"lib/pdf/web/images/texture.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-bookmark.png","path":"lib/pdf/web/images/toolbarButton-bookmark.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-bookmark@2x.png","path":"lib/pdf/web/images/toolbarButton-bookmark@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-download.png","path":"lib/pdf/web/images/toolbarButton-download.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-download@2x.png","path":"lib/pdf/web/images/toolbarButton-download@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-menuArrows.png","path":"lib/pdf/web/images/toolbarButton-menuArrows.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-menuArrows@2x.png","path":"lib/pdf/web/images/toolbarButton-menuArrows@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-openFile.png","path":"lib/pdf/web/images/toolbarButton-openFile.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-openFile@2x.png","path":"lib/pdf/web/images/toolbarButton-openFile@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown-rtl.png","path":"lib/pdf/web/images/toolbarButton-pageDown-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown-rtl@2x.png","path":"lib/pdf/web/images/toolbarButton-pageDown-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown.png","path":"lib/pdf/web/images/toolbarButton-pageDown.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown@2x.png","path":"lib/pdf/web/images/toolbarButton-pageDown@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp-rtl.png","path":"lib/pdf/web/images/toolbarButton-pageUp-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp-rtl@2x.png","path":"lib/pdf/web/images/toolbarButton-pageUp-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp.png","path":"lib/pdf/web/images/toolbarButton-pageUp.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp@2x.png","path":"lib/pdf/web/images/toolbarButton-pageUp@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-presentationMode.png","path":"lib/pdf/web/images/toolbarButton-presentationMode.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-presentationMode@2x.png","path":"lib/pdf/web/images/toolbarButton-presentationMode@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-print.png","path":"lib/pdf/web/images/toolbarButton-print.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-print@2x.png","path":"lib/pdf/web/images/toolbarButton-print@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-search.png","path":"lib/pdf/web/images/toolbarButton-search.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-search@2x.png","path":"lib/pdf/web/images/toolbarButton-search@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl.png","path":"lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl@2x.png","path":"lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle.png","path":"lib/pdf/web/images/toolbarButton-secondaryToolbarToggle.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle@2x.png","path":"lib/pdf/web/images/toolbarButton-secondaryToolbarToggle@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle-rtl.png","path":"lib/pdf/web/images/toolbarButton-sidebarToggle-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle-rtl@2x.png","path":"lib/pdf/web/images/toolbarButton-sidebarToggle-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle.png","path":"lib/pdf/web/images/toolbarButton-sidebarToggle.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle@2x.png","path":"lib/pdf/web/images/toolbarButton-sidebarToggle@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewAttachments.png","path":"lib/pdf/web/images/toolbarButton-viewAttachments.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewAttachments@2x.png","path":"lib/pdf/web/images/toolbarButton-viewAttachments@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline-rtl.png","path":"lib/pdf/web/images/toolbarButton-viewOutline-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline-rtl@2x.png","path":"lib/pdf/web/images/toolbarButton-viewOutline-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline.png","path":"lib/pdf/web/images/toolbarButton-viewOutline.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline@2x.png","path":"lib/pdf/web/images/toolbarButton-viewOutline@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewThumbnail.png","path":"lib/pdf/web/images/toolbarButton-viewThumbnail.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewThumbnail@2x.png","path":"lib/pdf/web/images/toolbarButton-viewThumbnail@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomIn.png","path":"lib/pdf/web/images/toolbarButton-zoomIn.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomIn@2x.png","path":"lib/pdf/web/images/toolbarButton-zoomIn@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomOut.png","path":"lib/pdf/web/images/toolbarButton-zoomOut.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomOut@2x.png","path":"lib/pdf/web/images/toolbarButton-zoomOut@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed-rtl.png","path":"lib/pdf/web/images/treeitem-collapsed-rtl.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed-rtl@2x.png","path":"lib/pdf/web/images/treeitem-collapsed-rtl@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed.png","path":"lib/pdf/web/images/treeitem-collapsed.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed@2x.png","path":"lib/pdf/web/images/treeitem-collapsed@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-expanded.png","path":"lib/pdf/web/images/treeitem-expanded.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-expanded@2x.png","path":"lib/pdf/web/images/treeitem-expanded@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/locale.properties","path":"lib/pdf/web/locale/locale.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ach/viewer.properties","path":"lib/pdf/web/locale/ach/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/af/viewer.properties","path":"lib/pdf/web/locale/af/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ak/viewer.properties","path":"lib/pdf/web/locale/ak/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/an/viewer.properties","path":"lib/pdf/web/locale/an/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ar/viewer.properties","path":"lib/pdf/web/locale/ar/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ast/viewer.properties","path":"lib/pdf/web/locale/ast/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/az/viewer.properties","path":"lib/pdf/web/locale/az/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/be/viewer.properties","path":"lib/pdf/web/locale/be/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/bg/viewer.properties","path":"lib/pdf/web/locale/bg/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/bn-BD/viewer.properties","path":"lib/pdf/web/locale/bn-BD/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/bn-IN/viewer.properties","path":"lib/pdf/web/locale/bn-IN/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/br/viewer.properties","path":"lib/pdf/web/locale/br/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/brx/viewer.properties","path":"lib/pdf/web/locale/brx/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/bs/viewer.properties","path":"lib/pdf/web/locale/bs/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ca/viewer.properties","path":"lib/pdf/web/locale/ca/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/cak/viewer.properties","path":"lib/pdf/web/locale/cak/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/cs/viewer.properties","path":"lib/pdf/web/locale/cs/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/csb/viewer.properties","path":"lib/pdf/web/locale/csb/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/cy/viewer.properties","path":"lib/pdf/web/locale/cy/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/da/viewer.properties","path":"lib/pdf/web/locale/da/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/de/viewer.properties","path":"lib/pdf/web/locale/de/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/el/viewer.properties","path":"lib/pdf/web/locale/el/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/en-CA/viewer.properties","path":"lib/pdf/web/locale/en-CA/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/en-GB/viewer.properties","path":"lib/pdf/web/locale/en-GB/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/en-US/viewer.properties","path":"lib/pdf/web/locale/en-US/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/eo/viewer.properties","path":"lib/pdf/web/locale/eo/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/es-AR/viewer.properties","path":"lib/pdf/web/locale/es-AR/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/es-CL/viewer.properties","path":"lib/pdf/web/locale/es-CL/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/es-ES/viewer.properties","path":"lib/pdf/web/locale/es-ES/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/es-MX/viewer.properties","path":"lib/pdf/web/locale/es-MX/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/et/viewer.properties","path":"lib/pdf/web/locale/et/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/eu/viewer.properties","path":"lib/pdf/web/locale/eu/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/fa/viewer.properties","path":"lib/pdf/web/locale/fa/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ff/viewer.properties","path":"lib/pdf/web/locale/ff/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/fi/viewer.properties","path":"lib/pdf/web/locale/fi/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/fr/viewer.properties","path":"lib/pdf/web/locale/fr/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/fy-NL/viewer.properties","path":"lib/pdf/web/locale/fy-NL/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ga-IE/viewer.properties","path":"lib/pdf/web/locale/ga-IE/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/gd/viewer.properties","path":"lib/pdf/web/locale/gd/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/gl/viewer.properties","path":"lib/pdf/web/locale/gl/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/gn/viewer.properties","path":"lib/pdf/web/locale/gn/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/gu-IN/viewer.properties","path":"lib/pdf/web/locale/gu-IN/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/he/viewer.properties","path":"lib/pdf/web/locale/he/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/hi-IN/viewer.properties","path":"lib/pdf/web/locale/hi-IN/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/hr/viewer.properties","path":"lib/pdf/web/locale/hr/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/hsb/viewer.properties","path":"lib/pdf/web/locale/hsb/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/hto/viewer.properties","path":"lib/pdf/web/locale/hto/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/hu/viewer.properties","path":"lib/pdf/web/locale/hu/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/hy-AM/viewer.properties","path":"lib/pdf/web/locale/hy-AM/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ia/viewer.properties","path":"lib/pdf/web/locale/ia/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/id/viewer.properties","path":"lib/pdf/web/locale/id/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/is/viewer.properties","path":"lib/pdf/web/locale/is/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/it/viewer.properties","path":"lib/pdf/web/locale/it/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ja/viewer.properties","path":"lib/pdf/web/locale/ja/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ka/viewer.properties","path":"lib/pdf/web/locale/ka/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/kab/viewer.properties","path":"lib/pdf/web/locale/kab/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/kk/viewer.properties","path":"lib/pdf/web/locale/kk/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/km/viewer.properties","path":"lib/pdf/web/locale/km/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/kn/viewer.properties","path":"lib/pdf/web/locale/kn/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ko/viewer.properties","path":"lib/pdf/web/locale/ko/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/kok/viewer.properties","path":"lib/pdf/web/locale/kok/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ks/viewer.properties","path":"lib/pdf/web/locale/ks/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ku/viewer.properties","path":"lib/pdf/web/locale/ku/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/lg/viewer.properties","path":"lib/pdf/web/locale/lg/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/lij/viewer.properties","path":"lib/pdf/web/locale/lij/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/lo/viewer.properties","path":"lib/pdf/web/locale/lo/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/lt/viewer.properties","path":"lib/pdf/web/locale/lt/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ltg/viewer.properties","path":"lib/pdf/web/locale/ltg/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/lv/viewer.properties","path":"lib/pdf/web/locale/lv/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/meh/viewer.properties","path":"lib/pdf/web/locale/meh/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/mk/viewer.properties","path":"lib/pdf/web/locale/mk/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/mn/viewer.properties","path":"lib/pdf/web/locale/mn/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/mr/viewer.properties","path":"lib/pdf/web/locale/mr/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ms/viewer.properties","path":"lib/pdf/web/locale/ms/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/my/viewer.properties","path":"lib/pdf/web/locale/my/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/nb-NO/viewer.properties","path":"lib/pdf/web/locale/nb-NO/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ne-NP/viewer.properties","path":"lib/pdf/web/locale/ne-NP/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/nl/viewer.properties","path":"lib/pdf/web/locale/nl/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/nn-NO/viewer.properties","path":"lib/pdf/web/locale/nn-NO/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/nso/viewer.properties","path":"lib/pdf/web/locale/nso/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/oc/viewer.properties","path":"lib/pdf/web/locale/oc/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/pa-IN/viewer.properties","path":"lib/pdf/web/locale/pa-IN/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/pl/viewer.properties","path":"lib/pdf/web/locale/pl/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/pt-BR/viewer.properties","path":"lib/pdf/web/locale/pt-BR/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/pt-PT/viewer.properties","path":"lib/pdf/web/locale/pt-PT/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/rm/viewer.properties","path":"lib/pdf/web/locale/rm/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ro/viewer.properties","path":"lib/pdf/web/locale/ro/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ru/viewer.properties","path":"lib/pdf/web/locale/ru/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/rw/viewer.properties","path":"lib/pdf/web/locale/rw/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sah/viewer.properties","path":"lib/pdf/web/locale/sah/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sat/viewer.properties","path":"lib/pdf/web/locale/sat/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/si/viewer.properties","path":"lib/pdf/web/locale/si/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sk/viewer.properties","path":"lib/pdf/web/locale/sk/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sl/viewer.properties","path":"lib/pdf/web/locale/sl/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/son/viewer.properties","path":"lib/pdf/web/locale/son/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sq/viewer.properties","path":"lib/pdf/web/locale/sq/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sr/viewer.properties","path":"lib/pdf/web/locale/sr/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sv-SE/viewer.properties","path":"lib/pdf/web/locale/sv-SE/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/sw/viewer.properties","path":"lib/pdf/web/locale/sw/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ta/viewer.properties","path":"lib/pdf/web/locale/ta/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ta-LK/viewer.properties","path":"lib/pdf/web/locale/ta-LK/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/te/viewer.properties","path":"lib/pdf/web/locale/te/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/th/viewer.properties","path":"lib/pdf/web/locale/th/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/tl/viewer.properties","path":"lib/pdf/web/locale/tl/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/tn/viewer.properties","path":"lib/pdf/web/locale/tn/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/tr/viewer.properties","path":"lib/pdf/web/locale/tr/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/tsz/viewer.properties","path":"lib/pdf/web/locale/tsz/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/uk/viewer.properties","path":"lib/pdf/web/locale/uk/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/ur/viewer.properties","path":"lib/pdf/web/locale/ur/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/uz/viewer.properties","path":"lib/pdf/web/locale/uz/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/vi/viewer.properties","path":"lib/pdf/web/locale/vi/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/wo/viewer.properties","path":"lib/pdf/web/locale/wo/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/xh/viewer.properties","path":"lib/pdf/web/locale/xh/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/zam/viewer.properties","path":"lib/pdf/web/locale/zam/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/zh-CN/viewer.properties","path":"lib/pdf/web/locale/zh-CN/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/zh-TW/viewer.properties","path":"lib/pdf/web/locale/zh-TW/viewer.properties","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pdf/web/locale/zu/viewer.properties","path":"lib/pdf/web/locale/zu/viewer.properties","modified":1,"renderable":1}],"Cache":[{"_id":"source/404/index.md","hash":"795e77df13ba5353f111f9699053336a86df304c","modified":1680835430464},{"_id":"source/_posts/Basic-operations-of-Matrix.md","hash":"918cf94719262d859f202b2c77298fcc91925ad7","modified":1680835430464},{"_id":"source/_posts/Differential-equations.md","hash":"3bc3ccfbdeab765b8f3aab5b5c0a9e1f29bdd7ab","modified":1680835430464},{"_id":"source/_posts/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting.md","hash":"3c569db1a46a33efba3d6ee2fef382bd1e34ea53","modified":1680835430476},{"_id":"source/_posts/From-linear-regression-to-binary-classification.md","hash":"f8a8d0365ac782de3f0b499d30b9bf8ef4d98974","modified":1680835430476},{"_id":"source/_posts/Functions-Plot.md","hash":"27183729be7266a0c0cf7bf86563c44c9ee18a29","modified":1680835430480},{"_id":"source/_posts/Functions.md","hash":"1a6f32ecbf9e10d744f28160ef1a5f2b642a0e32","modified":1680835430496},{"_id":"source/_posts/Gradient-descend-for-linear-regression.md","hash":"a71ab5837901fab5526e75a14c016af7cc6e1f1b","modified":1680835430504},{"_id":"source/_posts/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe.md","hash":"8c07fe13ea38d9786f75f61ea6b6b306ae3acd79","modified":1680835430508},{"_id":"source/_posts/Hyperplane.md","hash":"709b162f35c8048de17505e780d3c6006d32d739","modified":1680835430752},{"_id":"source/_posts/Image-processing-using-Numpy.md","hash":"14d09f0b23e76c884ea38da320133eafc5fdac18","modified":1680835430752},{"_id":"source/_posts/Linear-Algebra-Basics.md","hash":"ab40b7b018efeda2b18434a8695050f245af672e","modified":1680835430796},{"_id":"source/_posts/Linear-equations.md","hash":"fdb685798374e39946dcefc27a49d7681df6dd49","modified":1680835430796},{"_id":"source/_posts/Norms.md","hash":"16a9b101c49792fa62dd4c6b9a8bee06c48beabe","modified":1680835430796},{"_id":"source/_posts/Numpy-Basics.md","hash":"6a4034de5278cdcb16b1e0ac1eb929b98ddc3b6a","modified":1680835430796},{"_id":"source/_posts/OpenCV-Hand-Tracking-to-Count-Fingers.md","hash":"383b482ca72d8978526b19a11d2155b0087e9565","modified":1680835430796},{"_id":"source/_posts/Pandas-Basics.md","hash":"4a3ef8667763fcc6e095cc63cf00dda5f9081582","modified":1680835430800},{"_id":"source/_posts/RGB-color.md","hash":"adb40ee41a4c9ac9420047463ed12e51650e4b8c","modified":1680835430808},{"_id":"source/_posts/Regression.md","hash":"0f43ae0db819141b40bcddfa57603800986d34a0","modified":1680835430820},{"_id":"source/_posts/Relationships-between-two-Sets.md","hash":"af32c2315e89fdc55966ab0f8e5b9f45c696e5f6","modified":1680835430824},{"_id":"source/_posts/Scipy-optimization.md","hash":"eee90384de955aae89d35abb9c6def16784cdaac","modified":1680835430824},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews.md","hash":"7302e5cf485336cc1ece027fdf5d7a7725cb3c6b","modified":1680835430908},{"_id":"source/_posts/Variables.md","hash":"7da532be8ea63d4b4e1013f362fbca0399587b6a","modified":1680835430912},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV.md","hash":"00a3acb39d0a5dfeacb16d74f621ec66bf4e47cc","modified":1680835430920},{"_id":"source/about/index.md","hash":"ba2f5e7914152c03384341d08d216db070ee8735","modified":1680835430944},{"_id":"source/archives/index.md","hash":"5b0bb7b67dd1eac83a3a8a8183c0775c37348ffc","modified":1680829141654},{"_id":"source/categories/index.md","hash":"af2edad31ca4acd8b6f9afb1b39f8677f5d35046","modified":1680829119838},{"_id":"source/tags/index.md","hash":"15ae980057b913aa565baad264955925acd04b24","modified":1680831616197},{"_id":"source/_posts/From-linear-regression-to-binary-classification/binaryclass1.png","hash":"8394c46e476f1a7fc4000891b1a65103ccae8cef","modified":1680835430476},{"_id":"source/_posts/Hyperplane/binary_classification_problem_in_2d.png","hash":"f43aa4b38ce44b92459322f6a58e9be4b6638320","modified":1680835430752},{"_id":"source/_posts/Linear-Algebra-Basics/2d_vector.png","hash":"4ed8e02445045b5ed7a0d1a642af684c87c50af3","modified":1680835430796},{"_id":"source/_posts/Regression/Linear Regression.png","hash":"0aa79e9c10dc08f9be24c438da10f00331e609e6","modified":1680835430820},{"_id":"source/_posts/Relationships-between-two-Sets/Cartesian Product of A and B.png","hash":"cfc16efecf47c25e60f58abd63ce1b11f0c71730","modified":1680835430824},{"_id":"source/_posts/Relationships-between-two-Sets/Venn Diagrams for cardinality.png","hash":"aa1aa8872926c161655a93dbbc782eb2e3e06a78","modified":1680835430824},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/AdaBoost.png","hash":"20f3611ee6d01d1ca43ca1cf963a9b376b64f5d8","modified":1680835430908},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Decision Tree.png","hash":"e4f6111542b35e6f271fb6c8e6cc1bc2908b6ddb","modified":1680835430908},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/K-Nearest Neighbors.png","hash":"b5b1f2adf0c44f57019f311df54b3ba27660a4e0","modified":1680835430908},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Logistic Regression.png","hash":"118a78b4e5a0b783d6d4e51df53d3e66ecb6ac9c","modified":1680835430908},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/MLP classifier model.png","hash":"f5a2c5c6b8f9a459324d3fd3ee4bc23ee5b931f4","modified":1680835430908},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Naive Bayes classifier model.png","hash":"e0e548c7ccc8fc5ca62050793ee17fe58027ace8","modified":1680835430908},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Random Forest.png","hash":"b8752bea3a78b780836d4c25a4ceaabf9d808d2f","modified":1680835430912},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/SVM.png","hash":"3dca107cc045961cb85f3390093a9c245230b4b3","modified":1680835430912},{"_id":"source/_posts/Differential-equations/Constrained_vs_Unconstrained_Optimization.png","hash":"01b0a1bdc11c2477fc78878a2bc55919736054b1","modified":1680835430464},{"_id":"source/_posts/Differential-equations/Interpolation.png","hash":"c9b4f26c34b75816ae1e4a4fa1efad25d99db46d","modified":1680835430464},{"_id":"source/_posts/Differential-equations/Local Minima.png","hash":"d0cee32d5d384c51fab110aac54a406e5fc645ca","modified":1680835430468},{"_id":"source/_posts/Differential-equations/Optimization.png","hash":"04bc99c3046879848a74ad8b916e8afaef61b7bd","modified":1680835430472},{"_id":"source/_posts/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/predictions.png","hash":"7747d17c7e23df123892c4976dba54c14067c2ec","modified":1680835430476},{"_id":"source/_posts/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/train_test_loss.png","hash":"417e06de75bff528758f3a5689e2c14919989921","modified":1680835430476},{"_id":"source/_posts/From-linear-regression-to-binary-classification/binaryclass.png","hash":"d45717b392a936fcabe2081cc8cb4d43e9489bdb","modified":1680835430476},{"_id":"source/_posts/Functions/Even and old Function.png","hash":"898ebaaa85b214398eb2005e2e4f99104f606441","modified":1680835430496},{"_id":"source/_posts/Functions/Function f(x) = x^2.png","hash":"9a9b87032b1201196a7990fe424fbb189290fa8d","modified":1680835430500},{"_id":"source/_posts/Functions/One-to-one Function.png","hash":"ba3484a3d76acd6956ca9717013b29919f1870cc","modified":1680835430500},{"_id":"source/_posts/Functions/exponential_logarithmic.png","hash":"8112198e702f39a4391f4b5d35a954da6b2d65da","modified":1680835430500},{"_id":"source/_posts/Functions/floor_ceiling.png","hash":"bac82fc8c0101401a90fa8c94164cca0d76826f3","modified":1680835430504},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient.png","hash":"4e0bbbd1a73e64198a1caf536279ac39f1640477","modified":1680835430504},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient1.png","hash":"952a8f8df75c117211e71a85962abff2af0536a2","modified":1680835430504},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient2.png","hash":"4e6510b1afca412c57672c34cf856c6fbd3b5e44","modified":1680835430504},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient3-0040620.png","hash":"a1ea320183dda469ddf91f2eedb25479368955b8","modified":1680835430504},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient3.png","hash":"19b68b8ffbc0858361d7ce336645906dda6497f9","modified":1680835430508},{"_id":"source/_posts/Norms/norm.png","hash":"d8f796f3546d8a6ad6c3f018d1c550d283815632","modified":1680835430796},{"_id":"source/_posts/Regression/Polynomial Regression of Sin(x).png","hash":"0dbb023e637a68de38e372f1627a429614ef4f9b","modified":1680835430824},{"_id":"source/_posts/Relationships-between-two-Sets/Venn Diagrams for numbers.png","hash":"4cf8249d47b5db304415399895b6a58ca5a67f84","modified":1680835430824},{"_id":"source/_posts/Variables/uniform.png","hash":"b692146e8d448d6f40fd19425408cd49a60f2f67","modified":1680835430920},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155430619.png","hash":"fcd90f448a0b9fc2101c65b9a3d6791056d10ec8","modified":1680835430928},{"_id":"source/_posts/Differential-equations/Exact_vs_Noisy_Cost_Functions.png","hash":"3b0da3257c9994a9d463e5248915661abe91b80c","modified":1680835430464},{"_id":"source/_posts/Differential-equations/smooth_non_smooth.png","hash":"8514658b6f313f6b9c189f9ae197da2ac49c3fe0","modified":1680835430476},{"_id":"source/_posts/From-linear-regression-to-binary-classification/binaryclass2.png","hash":"fe0c0d4607e7cbb92c75530a96bce748d830ef74","modified":1680835430480},{"_id":"source/_posts/From-linear-regression-to-binary-classification/sigmoid.png","hash":"07c68db7f610bfb14276199f50e43d28cbfbc15a","modified":1680835430480},{"_id":"source/_posts/Functions/convexity.png","hash":"d966757de3925bbd6c5037b1e960a7480605dfb3","modified":1680835430500},{"_id":"source/_posts/Functions-Plot/2d_functions.png","hash":"310933b848bed7c46cddb2e7a96e8f621cb64105","modified":1680835430480},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient4.png","hash":"5297c3455211a9e69130c6cabf5795ef1610302f","modified":1680835430508},{"_id":"source/_posts/Scipy-optimization/minimize_scalar.png","hash":"f0a2cef6776ac399f06d609d17eb9d6c99536eb7","modified":1680835430904},{"_id":"source/_posts/Hyperplane/binary_classification_problem_in_3d.png","hash":"8b3afeed36ec42187425265c350defe54896ad72","modified":1680835430752},{"_id":"source/_posts/RGB-color/rgb_colors.png","hash":"366c4d88ffe30d233d45021b9422299adeef1096","modified":1680835430808},{"_id":"source/_posts/Scipy-optimization/minimize_scalar1.png","hash":"0acaeec9864082cbb775bb1a85dc089ec7fd3941","modified":1680835430908},{"_id":"source/_posts/Regression/Correlation coefficients.png","hash":"45066cc54f9da39232f521b5956a81d7a0fa9ab7","modified":1680835430820},{"_id":"source/_posts/Variables/normal.png","hash":"129ce01eabc2aa76910ff951e8e2dc02aaa4ba8f","modified":1680835430920},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock.png","hash":"44e5525a541945b107d4dcc9ccf4b745b0132ce9","modified":1680835430828},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock_bfgs.png","hash":"f48a7fd55005ed74acd855331b7ed46a8258c8d1","modified":1680835430832},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock_newton.png","hash":"207237ae97b2a7f6611c3da940b82b2030f130e2","modified":1680835430904},{"_id":"source/_posts/Variables/bivariate_normal.png","hash":"26302d8f3151b8d3465ef663826e8851d280582b","modified":1680835430916},{"_id":"source/_posts/Differential-equations/Optimization with constraints.png","hash":"acbf58a68a4b8f6bcfe69739501fa973976ef3d4","modified":1680835430472},{"_id":"source/_posts/Pandas-Basics/iris.png","hash":"609288c46014fe55e653b90ecb2d7957ea9470aa","modified":1680835430808},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1680826636351},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1680826636351},{"_id":"themes/next/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1680826939086},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1680825638618},{"_id":"themes/next/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1680826939086},{"_id":"themes/next/.travis.yml","hash":"ecca3b919a5b15886e3eca58aa84aafc395590da","modified":1680826939086},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1680825638618},{"_id":"themes/next/README.md","hash":"a0430372844df9caea6e9bf96492775ed42a4578","modified":1680826939086},{"_id":"themes/next/_config.yml","hash":"a57500f6d859951982a1fae20f2d033f8dd948bd","modified":1680839395974},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1680825638618},{"_id":"themes/next/gulpfile.js","hash":"72e6d5a6e32d5f95d82e4c4d0c963d39555bb760","modified":1680826939094},{"_id":"themes/next/package.json","hash":"b7fd0a53c7cb4c40c6f236065bfed34e6188e786","modified":1680828646824},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1680825638618},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"5b4c013e0598b3211ebd899265936cfdaf7c139f","modified":1680826939090},{"_id":"themes/next/docs/AUTHORS.md","hash":"10135a2f78ac40e9f46b3add3e360c025400752f","modified":1680826939090},{"_id":"themes/next/docs/DATA-FILES.md","hash":"d0d46cb265f0efceffce82214cd36d8b82ddce13","modified":1680826939090},{"_id":"themes/next/docs/INSTALLATION.md","hash":"af88bcce035780aaa061261ed9d0d6c697678618","modified":1680826939090},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"08cda41b4bcf687facfda19ab39718ec7a05ae54","modified":1680826939090},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1680825638618},{"_id":"themes/next/docs/MATH.md","hash":"58a961498c55cf4f0c69cf3668c810b602a17529","modified":1680826939090},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"199e9ef3cb5928af0fe801d03d2d1aeea704cea4","modified":1680826939090},{"_id":"themes/next/languages/de.yml","hash":"3d8920676d89494d7d1c74d4238680151ea6d9df","modified":1680826939094},{"_id":"themes/next/languages/default.yml","hash":"c13eda783f8717c62b7ad9e8a9b724314ae74e1a","modified":1680826939094},{"_id":"themes/next/languages/en.yml","hash":"c13eda783f8717c62b7ad9e8a9b724314ae74e1a","modified":1680826939094},{"_id":"themes/next/languages/es.yml","hash":"7dc1d7d5ea1078ee3b9bc8e0e8d0f15f52a7a4aa","modified":1680826939094},{"_id":"themes/next/languages/fa.yml","hash":"269b5cb70774485d7dbbcf98eec72c9e84e135b2","modified":1680826939094},{"_id":"themes/next/languages/fr.yml","hash":"dfdcfa536c40d06125dff373d042c50e08fcafd8","modified":1680826939094},{"_id":"themes/next/languages/hu.yml","hash":"e4a5f43fb45acd992def3de3b600aa4df4c95ed7","modified":1680826939094},{"_id":"themes/next/languages/id.yml","hash":"5665dece8435964a27b5061d7283f339f84721f0","modified":1680826939094},{"_id":"themes/next/languages/it.yml","hash":"311597c620059dbb99474f19b2110a4485ecf70b","modified":1680826939094},{"_id":"themes/next/languages/ja.yml","hash":"4f929842b3d6aaed709ea99da679d3910ee184e5","modified":1680826939094},{"_id":"themes/next/languages/ko.yml","hash":"5f5194dd0f5a3c8484e7668bce6fbe23340e531a","modified":1680826939094},{"_id":"themes/next/languages/nl.yml","hash":"561c77ca68e9d51a5ce8c89d3361fdb033c96bba","modified":1680826939094},{"_id":"themes/next/languages/pt-BR.yml","hash":"13b579911e44a8b213e1860f9a50c341be1bf95e","modified":1680826939094},{"_id":"themes/next/languages/pt.yml","hash":"af9d9b581dca45ab9789ca41d3492883a911e383","modified":1680826939094},{"_id":"themes/next/languages/ru.yml","hash":"b485c57dd7b447406dafd0dcfdfc9356266708c9","modified":1680826939094},{"_id":"themes/next/languages/tr.yml","hash":"39caf8a3677fd6dfbd523e73f8482a509e87b603","modified":1680826939094},{"_id":"themes/next/languages/uk.yml","hash":"4cbdbb0ed09487c9b435be21ac35f62182f53283","modified":1680826939094},{"_id":"themes/next/languages/vi.yml","hash":"3c6bb816ee7278afcddac06998c9ebe47ee19aef","modified":1680826939094},{"_id":"themes/next/languages/zh-CN.yml","hash":"e92e1e07a89c9fab27f445f9ec0fa35049fef38c","modified":1680826939094},{"_id":"themes/next/languages/zh-HK.yml","hash":"93d10d6e448c519004b09b11fba980b5036c93af","modified":1680826939094},{"_id":"themes/next/languages/zh-TW.yml","hash":"ae2aa1c6ec1a5a01a3a3bde17bcc3a82f9a35fa7","modified":1680826939094},{"_id":"themes/next/layout/_layout.swig","hash":"512bdf6787b5d9fb1d40b126b0fa8e6f1018d1cd","modified":1680826939094},{"_id":"themes/next/layout/archive.swig","hash":"59155648f6306888077d1f1d635f63177b36148d","modified":1680826939098},{"_id":"themes/next/layout/category.swig","hash":"c55debb2588e4746b02d31ec249bf0a84fdea260","modified":1680826939098},{"_id":"themes/next/layout/index.swig","hash":"3bc6fb1e9707d74b96e1346d3f03fe6584f764f4","modified":1680826939098},{"_id":"themes/next/layout/page.swig","hash":"e61d64c055b6497a04affc143f47fdd0a6dc495b","modified":1680826939098},{"_id":"themes/next/layout/post.swig","hash":"382d9f9a9b35e1f369585f7f9f9b5dd6fa58d2f0","modified":1680826939098},{"_id":"themes/next/layout/tag.swig","hash":"7ff6e34d557a3da1c6a29ecd97842bf73ff213dc","modified":1680826939098},{"_id":"themes/next/scripts/renderer.js","hash":"49a65df2028a1bc24814dc72fa50d52231ca4f05","modified":1680826939102},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"2665f6a9d72090f9452a8811544ff2596e8899be","modified":1680826939090},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"9c4fe2873123bf9ceacab5c50d17d8a0f1baef27","modified":1680826939090},{"_id":"themes/next/docs/ru/README.md","hash":"7302b2e5318c0c13e6484aa6487be29599ebc2b2","modified":1680826939090},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"fe3f5cda1975114884d84bef384a562920d70335","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"4245fe9472647226692fcbdd5a52d6e6dcd251bc","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"ebacdc94f6f9724a7c6ef7c3cdde41ff7c37931a","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"41c06240e349a885b640c6ba4a982e3b8e7762fe","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"3b4dbf0d2ca12ab442b7e0e227769ce100b8a444","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"579c7bd8341873fb8be4732476d412814f1a3df7","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"264d131b8865bae069f8e4d78a33a0f59d28e36b","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"c7df75363851f31ae7a3e7b93798070c5d8a3053","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/README.md","hash":"1766bd2e528ec148d3c5dd55e6be55449fcda94e","modified":1680826939090},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"8109a531d3a7f5a306e36d4304c11f0c7c180c87","modified":1680826939090},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"815676d904f92748ddf4f529bed2baf066997bc6","modified":1680826939094},{"_id":"themes/next/layout/_macro/post.swig","hash":"e80d07467dcd614e940451737f4c1eaab8c8d272","modified":1680826939094},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"1116597ae81c391981f3a8b80fa6febe5796583d","modified":1680826939094},{"_id":"themes/next/layout/_partials/comments.swig","hash":"479286b378b027224c600f6bdd9ed51126086993","modified":1680826939094},{"_id":"themes/next/layout/_partials/footer.swig","hash":"ee6ae67a3c7b99ee768afbd36882390b9f4db5b0","modified":1680826939094},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"b9d3f6534efb9e637ac46318fa07c2e5607bf830","modified":1680826939094},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"83a40ce83dfd5cada417444fb2d6f5470aae6bb0","modified":1680826939098},{"_id":"themes/next/layout/_scripts/index.swig","hash":"cea942b450bcb0f352da78d76dc6d6f1d23d5029","modified":1680826939098},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"d1f2bfde6f1da51a2b35a7ab9e7e8eb6eefd1c6b","modified":1680826939098},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"9675acc599ffa546f05a60375c1637b0327be4fd","modified":1680826939098},{"_id":"themes/next/layout/_scripts/three.swig","hash":"a4f42f2301866bd25a784a2281069d8b66836d0b","modified":1680826939098},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"ef38c213679e7b6d2a4116f56c9e55d678446069","modified":1680826939098},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"8627c8c8b031ecee16c522433b66fa4d6979b8ea","modified":1680826939098},{"_id":"themes/next/layout/_third-party/index.swig","hash":"70c3c01dd181de81270c57f3d99b6d8f4c723404","modified":1680826939098},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"4abfcb5dae0e6dec5e288baa3a9fe4065829b392","modified":1680826939098},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"da6a9d14ed10203e378c6e2c00a7b5e7afabca58","modified":1680826939098},{"_id":"themes/next/scripts/events/index.js","hash":"ac2945693791e62a3046248f2a511afadcaebc16","modified":1680826939102},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"aec50ed57b9d5d3faf2db3c88374f107203617e0","modified":1680826939102},{"_id":"themes/next/scripts/filters/locals.js","hash":"ffa0e122c1cdf9c86ddca104ddb2dfbaccaa1bb5","modified":1680826939102},{"_id":"themes/next/scripts/filters/minify.js","hash":"19985723b9f677ff775f3b17dcebf314819a76ac","modified":1680826939102},{"_id":"themes/next/scripts/filters/post.js","hash":"3c1e483c2c4a1c5a2f9a99b81ce0fda5fd21926b","modified":1680826939102},{"_id":"themes/next/scripts/helpers/engine.js","hash":"b357cbc5d5b39b1bb5221149e7d358135a7ba56d","modified":1680826939102},{"_id":"themes/next/scripts/helpers/font.js","hash":"32268fb4c59c5b37c1eb1c9582ab630e09e5cc7d","modified":1680826939102},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"e60e6c0aaa979d42b01685ba2a03a76fa6e059e2","modified":1680826939102},{"_id":"themes/next/scripts/tags/button.js","hash":"1d1d25f7e579d92fa563778dd0f163e8eda190da","modified":1680826939102},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"20e392b8583ba6ae5037449c2c7e191d3927641b","modified":1680826939102},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f13430d9d1c9773b390787c2f046bb1f12a79878","modified":1680826636343},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"8fc05f22b88553bc1d96e0c925799cd97920fc6a","modified":1680826939102},{"_id":"themes/next/scripts/tags/include-raw.js","hash":"fad54f0e9e225a70390209f63d9b3cc566a5ebcb","modified":1680826939102},{"_id":"themes/next/scripts/tags/label.js","hash":"fc5b267d903facb7a35001792db28b801cccb1f8","modified":1680826939102},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"983c6c4adea86160ecc0ba2204bc312aa338121d","modified":1680826939102},{"_id":"themes/next/scripts/tags/note.js","hash":"0a02bb4c15aec41f6d5f1271cdb5c65889e265d9","modified":1680826939102},{"_id":"themes/next/scripts/tags/pdf.js","hash":"f780cc72bff91d2720626e7af69eed25e9c12a29","modified":1680826939102},{"_id":"themes/next/scripts/tags/tabs.js","hash":"00ca6340d4fe0ccdae7525373e4729117775bbfa","modified":1680826939102},{"_id":"themes/next/scripts/tags/video.js","hash":"e5ff4c44faee604dd3ea9db6b222828c4750c227","modified":1680826939102},{"_id":"themes/next/source/css/main.styl","hash":"68c3377b643162aeaae2b60c196486fdb3b509c3","modified":1680826939106},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1680825638630},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1680825638630},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1680826939110},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1680825638630},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1680825638630},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1680825638630},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1680825638630},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1680825638630},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1680825638630},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1680825638630},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1680825638630},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1680825638630},{"_id":"themes/next/source/images/me.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1680825638630},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1680826636351},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1680826636351},{"_id":"themes/next/source/js/algolia-search.js","hash":"813afcc30feee11d59f297f2d5a96f98fbbd4743","modified":1680826939110},{"_id":"themes/next/source/js/bookmark.js","hash":"c9acb262acf0cf127497b570fa9479fb32f34547","modified":1680826939110},{"_id":"themes/next/source/js/local-search.js","hash":"fda0f761ae20577f22c1528dde7ae059368fe9a8","modified":1680826939110},{"_id":"themes/next/source/js/motion.js","hash":"71e5caff1d87b1b7256f61e6b318bedf495f9e75","modified":1680826939110},{"_id":"themes/next/source/js/next-boot.js","hash":"a6a82905c6abb8e0ec418ef6b0509b946b955807","modified":1680826939110},{"_id":"themes/next/source/js/utils.js","hash":"a2984bf0631756a904cd43f8e3a8f6fb15b9ceb5","modified":1680826939110},{"_id":"themes/next/source/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1680826939110},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"f5d2c5a3421ae52888be62e2c837459d1175cc93","modified":1680826939094},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"7f94334632478fde4ff03f8d6ef1e9b2f02c30b0","modified":1680826939094},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"7487ca8f0e4b16351ea0d6b35dc52b0d32176d57","modified":1680826939094},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"30528a8da30994b1ef9355a72b09b2cd85a7c0e9","modified":1680826939094},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"ff33b5797f5e4b5cbcb3c222c17bc636c6b88df6","modified":1680826939094},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"d488664bc16608b5f829f959c2058b4381be244a","modified":1680826939094},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"fbec9f77139e1f300509c38446416b4b26350cfa","modified":1680826939094},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"c851717497ca64789f2176c9ecd1dedab237b752","modified":1680826939094},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"a56e4f6ad95c106f361d354f828d1ef4810b1d76","modified":1680826939094},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"becfa683c3e5409e20cdb7b1dc8a6db331bddefe","modified":1680826939094},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"8f14f3f8a1b2998d5114cc56b680fb5c419a6b07","modified":1680826939094},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"f79c44692451db26efce704813f7a8872b7e63a0","modified":1680826939094},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"bebf630963c1c65fd152859a1ba316b03be17cce","modified":1680826939094},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"7fa01334a0ba84500e920bb9202baa08067d2ee1","modified":1680826939094},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"d6fa9e4432b87004c5678dfe2d4b2c1f4a702b93","modified":1680826939094},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"733d6874aa4f50d1071e670a554508a5a0094eb3","modified":1680826939094},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"2afd85181eaefcd68c4db71b0526ee26e2146477","modified":1680826939098},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"246ff123cbaa507f23514c0c51c6cc006685898e","modified":1680826939098},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1680826939098},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1680826939098},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1680826939098},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1680826939098},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"4790058691b7d36cf6d2d6b4e93795a7b8d608ad","modified":1680826939098},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"194201cce870c1af6f5123a62cb766cd24e46217","modified":1680826939098},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5adea065641e8c55994dd2328ddae53215604928","modified":1680826939098},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"1472cabb0181f60a6a0b7fec8899a4d03dfb2040","modified":1680826939098},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"fdcf006e1ba2e53eab65e901b6c63159538307ef","modified":1680826939098},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"cba0e6e0fad08568a9e74ba9a5bee5341cfc04c1","modified":1680826939098},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"1130b8bd60f3b84397974486e6586d7f0afaf836","modified":1680826939098},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"fe3cdd70224bd0c8171513a5dfed7b85deb7f23d","modified":1680826939098},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"9719cb5858896aef86c2e0bec0ace259936680c4","modified":1680826939098},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"8063f65cdaae80840fcf427b875ae606f678dfa5","modified":1680826939098},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"6f95bc4d7ffaddc3c0df0ef3eeeaac58ff83f560","modified":1680826939098},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"a9c8e7987b63b9ef66e47b966aea05ac77ff920a","modified":1680826939098},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"6c5976621efd5db5f7c4c6b4f11bc79d6554885f","modified":1680826939098},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"4791c977a730f29c846efcf6c9c15131b9400ead","modified":1680826939098},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"fb27a38f9a4b8fcba4f637b03904f7a83cc73416","modified":1680826939098},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"e456d7a2aaabe55447f78cd952b30d70a6c1e742","modified":1680826939098},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"767b6c714c22588bcd26ba70b0fc19b6810cbacd","modified":1680826939098},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"ba0dbc06b9d244073a1c681ff7a722dcbf920b51","modified":1680826939098},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"d7258d02bcf0dac6c0fd8377c0909ddecb09d1d4","modified":1680826939098},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"a17ace37876822327a2f9306a472974442c9005d","modified":1680826939098},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"67e63c25d509f02a6057ee9724f1b6efd647f72f","modified":1680826939098},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"ac6a3995c1330d2d73300b2427006509d0f8dba5","modified":1680826939098},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"7f2941d119abca6627561fb010dad96fa48d2092","modified":1680826939098},{"_id":"themes/next/layout/_third-party/statistics/tencent-analytics.swig","hash":"493a1ef6c8f475d4dd3156a6ab37690dc75695ea","modified":1680826939098},{"_id":"themes/next/layout/_third-party/statistics/tencent-mta.swig","hash":"198813a3f382bda4278fe3759bf0f18a5769bb33","modified":1680826939098},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"4958fa997ff6df2b2ce05341f40cc3a81b0f91bb","modified":1680826939098},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"7fa72dc60c078842979861622839b109683e05a3","modified":1680826939098},{"_id":"themes/next/scripts/events/lib/config.js","hash":"246e55d48f2f3ef510c11594c7c08ddb93ac0928","modified":1680826939102},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"6661c1c91c7cbdefc6a5e6a034b443b8811235a1","modified":1680826939102},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"311a54c0a0b6192502e68ce8c0b20e77aed3b996","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"1fc2a94b94108175848ba9541d05898c071386d0","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"0803d4f4d3d02c24417c163ad0b27b60fda79250","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"7f2d93af012c1e14b8596fecbfc7febb43d9b7f5","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"d2ce60980fc148bfb877981aabd07bf45d2cdcda","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"c081166868e6428a07c51c5674b86b7a4cc9c2a8","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"e51dc3072c1ba0ea3008f09ecae8b46242ec6021","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"3c4bdc2a682f9889a532e1cb856bc5caeb4208e1","modified":1680826939102},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"5201cd09a5e263282ccbf205f07d46f4c6d3f700","modified":1680826939102},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2315dd8a7a2c7aabd29efa6193df08e805cb15fc","modified":1680826939106},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"644c1f0b02be9bf59955ebdf496136b3fa4b660b","modified":1680826939106},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0a25f3df1b5c39794365efde387647da81da884a","modified":1680826939106},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"52550138127ae9ebbe049bcdacd94d767c003855","modified":1680826939106},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"b9d7058db61df7bbd2b58779efe45621a06ffc18","modified":1680826939106},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"c261d685c5ed0df34718d94bb2ba977c0ed443e6","modified":1680826939106},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"b3408e6bf4eae3573ea77451ed30d6b645b00a06","modified":1680837788803},{"_id":"themes/next/source/css/_variables/base.styl","hash":"e76e0e411c9892004e73e1bb7b3c1cca2191eedc","modified":1680826939106},{"_id":"themes/next/source/js/schemes/muse.js","hash":"792f4522a3b0b96584a041a4aca20fcded410079","modified":1680826939110},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"dccbb1be3938050e13277251ab5d88c736edf396","modified":1680826939110},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1680826636355},{"_id":"themes/next/source/lib/pdf/LICENSE","hash":"a8a12e6867d7ee39c21d9b11a984066099b6fb6b","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/README.md","hash":"ddf6196548e6feeff6541891e9b70b6d171c600f","modified":1680828574456},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1680825638630},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1680825638630},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"80d359661d08b80ad561b97f8508766b3e1f6d01","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"47ee915d7b0a97e74140a25fbfc01c04d6781534","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"112f5e8f1fe5cec4419e87acfbdef0e615ed23f3","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/rainbow.styl","hash":"41c7cd1b63d49476ed5fbdd26ab9411d8f44bd05","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"170c4598cbbe49cd1527f94158d97d2320a6b906","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"990bd301ce2de0a6b936781c58318f3945d81bc2","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"44fe82eadbdbb2f66adda37ac83ebd0f85876bfc","modified":1680826939102},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"2067e15799a3a3cda8bfe7782d67a4dc42f1ef79","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"d8ba44b8e1a0332c5c1079ff65fc83d2918a5865","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"3faa8a7cdb05ef3f3b02920d381773dfd54270a5","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"8f58570a1bbc34c4989a47a1b7d42a8030f38b06","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"f3c5f1dadc01042381444102d35174dacc6f079a","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"179e33b8ac7f4d8a8e76736a7e4f965fe9ab8b42","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"08c2679a31f195940fe1e6c76e64799fb21cda99","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"4341f0e057b42e8c47629bb3196fca3b49f0cc19","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"24a086a6904bbf5355a354403c9b0e6069f7eb01","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"48743ac61af37a4de2026667e15a65de5e8cf542","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"e321bd62f5e04d1fdc101a470ec13604e99816a5","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a717969829fa6ef88225095737df3f8ee86c286b","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"3646e915b0a55f3b66e41d802b082aba88a76e06","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"4d1c17345d2d39ef7698f7acf82dfc0f59308c34","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"316ee13fc26d327c8862c2455211144c180cf9c1","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"eeab294e14abbae231107e1a327e907b25323136","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"f1f81bca31e82ccbd375f0cb9fb8dbb3beac810d","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"f5abb2ea7746586738fb4e82107fceed041708ee","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"c0ed534696ed86560c95ab2a3541b2b42a41ed39","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"c59226767164285d6708d8762f937f93bab264ca","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"0424a1fcffa1ae82fe70935972a894aca885bf9a","modified":1680826939106},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1680826939106},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1680826636355},{"_id":"themes/next/source/lib/pdf/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/.git/config","hash":"41e922210b314968e31a2af1eb65fe19da6dae89","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/index","hash":"075bb97289e67d3ab093bce2e585acd672962262","modified":1680828574560},{"_id":"themes/next/source/lib/pdf/.git/packed-refs","hash":"aa48a1e3c0de1f0db803df298cd8bbbb27fb526a","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/.github/stale.yml","hash":"fd0856f6745db8bd0228079ccb92a662830cc4fb","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/web/debugger.js","hash":"667c3445b131e4519084f42573cd4594d5d1e298","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/viewer.css","hash":"3cdfeee673984a7984a9e05f8d3cef99770df37c","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/viewer.html","hash":"ec2a94e016621a1b7a9dd4c0cb28f921c0814dde","modified":1680828574548},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fafc96c86926b22afba8bb9418c05e6afbc05a57","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"2bd0eb1512415325653b26d62a4463e6de83c5ac","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"6336c2b129db802221b1fd75e5fbe8aab85c0a1f","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"7ddb7453bf9b85b01bff136e9d10a7f06baac9e8","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"98227b4de364b48b11e21efcf4f1beb2ed3ab329","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"4b84f35e7040f9adb5cc540c366d7f9eb4c48bcc","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"e3ade812b5541eca5b863ad3ff234ea95925bf31","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"602a3c3d2785965b23412b5c219dfe74b5fb0844","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"d557a0de91a428330b43cdae9f1ec7167d24e2e4","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"3566136c06d96b34e1e7a3eca72fb0f40a63af80","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"2e2a09dddd2a394a635bcefb6207b6cddcb784c7","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"f8ba308231cf81453e41457796e94f1ce886d855","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"f5c2788a78790aca1a2f37f7149d6058afb539e0","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"99e12c9ce3d14d4837e3d3f12fc867ba9c565317","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"5b5649b9749e3fd8b63aef22ceeece0a6e1df605","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"5248880398c1318624bdab95109c1c9fdb8eec02","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8a7fc03a568b95be8d3337195e38bc7ec5ba2b23","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"ef66c0a08e4243a25e41408d70ca66682b8dcea1","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"e2992846b39bf3857b5104675af02ba73e72eed5","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"2d9d68a431a334626d463bb1bdfbcd2ea8242e94","modified":1680826939102},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"4525465f40f82bd66e5f34e986440c75a9e2d2b2","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"5528a755b180312d008054653633d857aeeb6780","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e02b1097a72a7d2ddc45ea8d53aa6d77c25ac407","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"0672ea2acf28dcc2cfc5244da36d3387d71a17cb","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"4b237e2344f35e9d1f6dbc3842d5e432d478ebfd","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"0caf32492692ba8e854da43697a2ec8a41612194","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"d5d85d3646d184e0340924addcfd2523fb289d00","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"a7ed54e2f52185a7b6bb9a8201f6c3aa74b0cb00","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"b5ba1b3d5535ccf1e5df6f4cd8ee0147d7278be9","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2cb1876e9e0c9ac32160888af27b1178dbcb0616","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"9b3ff4aa24069eab0e9771437013f45e450d4217","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"95339b71ac90553fb1634c536c9749055e0c788a","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"cc4beedb56c37246d9e0f74e4b2cc34231dabc65","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"9b479c2f9a9bfed77885e5093b8245cc5d768ec7","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"1db4ce981fe9fcb9ee4279395c29553efbb43947","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"e2ad7ccf1865a45548e3f31c70fac2c65d6ef534","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"b3220db827e1adbca7880c2bb23e78fa7cbe95cb","modified":1680826939102},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"eaa62b5de4ddb18378c1a4049a172d4fa4b655d8","modified":1680826939106},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"9a18b186b08ec220d1b17cf83812bcdd06077814","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"2b536832cfc81667dadd9603c8c700e44d458261","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"d3f73688bb7423e3ab0de1efdf6db46db5e34f80","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"4b980363822c24b3ad85c271719210a8ad2b646e","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"3b3acc5caa0b95a2598bef4eeacb21bab21bea56","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"7213e3d0ad7c95717ecd4e701d6ee9248ef2bf9f","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"879f9cec9c88d65b2e31af4346b2bc0f6941f05d","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"5bf28a03ef021c27cfd713971caca5a0b9466fd1","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"068b304be305fbfd0220276d56b93cefd968f0b6","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"2dc2a5b7becb11de1d4bdab6b5195588ae878cfc","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"419fa6cfc103d08dfd6a385ab7f24468c644d581","modified":1680826939106},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"9e4c0653cfd3cc6908fa0d97581bcf80861fb1e7","modified":1680826939106},{"_id":"themes/next/source/lib/pdf/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/fsmonitor-watchman.sample","hash":"0ec0ec9ac11111433d17ea79e0ae8cec650dcfa4","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/pre-commit.sample","hash":"a79d057388ee2c2fe6561d7697f1f5efcff96f23","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/pre-merge-commit.sample","hash":"04c64e58bc25c149482ed45dbd79e40effb89eb7","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/pre-push.sample","hash":"a599b773b930ca83dbc3a5c7c13059ac4a6eaedc","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/push-to-checkout.sample","hash":"508240328c8b55f8157c93c43bf5e291e5d2fbcb","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/hooks/update.sample","hash":"730e6bd5225478bab6147b7a62a6e2ae21d40507","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1680828573252},{"_id":"themes/next/source/lib/pdf/.git/logs/HEAD","hash":"40b83a5c8c2255f2dfb01428870bed82ae5100d4","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-EUC-H.bcmap","hash":"c84a5fe05bb2a5e4e599329d0ebb3ed8fe1ebfdf","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-EUC-V.bcmap","hash":"678dcba8720226133150374f78493cc09c9b8d9e","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-H.bcmap","hash":"e77449427a5d5411c9da1c1a64e1e3ae362bbcdf","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-RKSJ-H.bcmap","hash":"5f0f202932865c38e7b0b06924e419c77f74be85","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-RKSJ-V.bcmap","hash":"3fa6830e3e5c6b0cc5d03402cfb6712a04c08d31","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/78-V.bcmap","hash":"c58a521bdfad6ffe30e292505992a396033d03c3","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/78ms-RKSJ-H.bcmap","hash":"ef37df685e4779722b34fcc026b196b224bfca13","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/78ms-RKSJ-V.bcmap","hash":"27d45708491107b2cf673c2cd584bf22ca27e4e4","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/83pv-RKSJ-H.bcmap","hash":"c4474f77d94be66d771ba68f18ff2fd606a3c820","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/90ms-RKSJ-H.bcmap","hash":"994ca6d6232d91be047c68e087e0951dcca4cba4","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/90ms-RKSJ-V.bcmap","hash":"c4ed8e0b82fc29ff6140c72ec8ab3acc3cd0578f","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/90msp-RKSJ-H.bcmap","hash":"d3f02d6724d9c91d077ed38545c9321dba65b624","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/90msp-RKSJ-V.bcmap","hash":"ddfc0fdb34314f2d7116d707fa6dbb24bc9bf390","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/90pv-RKSJ-H.bcmap","hash":"76218acded94b2d29f747735e7fb41f19cee84eb","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/90pv-RKSJ-V.bcmap","hash":"7296d339f5c1d843b823482fa2b3857c0559eb93","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-H.bcmap","hash":"cd55ec3d5627b80505d7dbea433e5702f8c05260","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-RKSJ-H.bcmap","hash":"9a17c268decf876dc35c5f20c660ee63563fa523","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-RKSJ-V.bcmap","hash":"0e4ef11ed7f4e5ed3b2e32f267f4c3fb4359d08e","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Add-V.bcmap","hash":"02ca7b80b507640df998e9b5f6d25b346082d8c1","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-0.bcmap","hash":"241cccfc85b5ef9ea4618f94a6341e02d1b03b98","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-1.bcmap","hash":"f37b5b68198690c8270322daa0ea522225a46127","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-2.bcmap","hash":"a568bee71b12ec4e79a2fa65c4eb9f865c505a5e","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-3.bcmap","hash":"ef567b58254e03837d46e1fdff4fea5cce318a74","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-4.bcmap","hash":"5f81f4782a5f996649dc318c1587ae7728afd10b","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-5.bcmap","hash":"b7de7cea41575c7933cffdb917ad1f918df76c70","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-6.bcmap","hash":"4eaa2ec548df7cdbdece2eec227fdb9d4cb2f281","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-CNS1-UCS2.bcmap","hash":"bee971d04cae79d791a52bf0d3d5e2e9deb1d1c8","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-0.bcmap","hash":"86edf145080d2fedba2f0a0b0ab1bc18d9a5af55","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-1.bcmap","hash":"83cc28efd5e778b9d37898f9b100b502bc442dc3","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-2.bcmap","hash":"a3ce0132af54173d30a4330314bc4cf273fc29c8","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-3.bcmap","hash":"c7b6cfbeac681010771d022d319913c798416d75","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-4.bcmap","hash":"cee3007bb41ed1bbe7fd22f054c0fb036a92c8cf","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-5.bcmap","hash":"a7d9440784d773507e3d83d0bf93fa8d93a3289f","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-GB1-UCS2.bcmap","hash":"23366624efa674e2493a18bf6b6e2c16929d68d3","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-0.bcmap","hash":"ce5b494e809c30621968169d01d1136f3ad1ce3c","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-1.bcmap","hash":"a766b29745a30aa3316cafc73d884c271cc12ff4","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-2.bcmap","hash":"78c4e86cff8aa1c2f2bc18aaf83095a96f0bca50","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-3.bcmap","hash":"5b520d2cf37e21b084bc9e6a21d006c53e4e552e","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-4.bcmap","hash":"4136c902f4715ed18b8b2390965d3621d2fda048","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-5.bcmap","hash":"38970fd416a1c3ef4faa25009254347627d24964","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-6.bcmap","hash":"dfba7ab251b5ac07d7648c4e81e808ea096578c9","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Japan1-UCS2.bcmap","hash":"d99c0d908b8075afa69aa3c579a9393b13b29dd9","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-0.bcmap","hash":"ca8e1774cdd2859ba0341e4474d07d6fb2f9395b","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-1.bcmap","hash":"e9b783963160380ccfe33fa1dcdd9c79b1cf2934","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-2.bcmap","hash":"0b8d7fd848de3efa86f958c6e1cf5aece9bf1bf4","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/web/cmaps/Adobe-Korea1-UCS2.bcmap","hash":"15e4e07c96891a2bb2778b5df8dd0a131edeed52","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5-H.bcmap","hash":"771d71153bf652d1134b7d65beb8afc60c835ff6","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5-V.bcmap","hash":"dfc7362c157c24651761e5216ef0c46aba795488","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5pc-H.bcmap","hash":"29d5fd41dc8fc4f19b59949b9a7f410d63f4f3bd","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/B5pc-V.bcmap","hash":"f12ae6ed2320136959420e28b1b937001cdd4f0b","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS-EUC-H.bcmap","hash":"1da78eb52781330148c95ccf64c78edd2072a991","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS-EUC-V.bcmap","hash":"895fe039258dae00d7a8cea93b3b07d794543d2d","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS1-H.bcmap","hash":"07f422b28ca4fedf2cdc6ccdf551eaecae40f60b","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS1-V.bcmap","hash":"7455bd92e1a1f32bfd2cb5b80eb938aa665f6b8a","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS2-H.bcmap","hash":"0570a8186311bba4ad216250f805461220d41d0a","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/CNS2-V.bcmap","hash":"c0870c3fad8349e3391ff7cda29d1f3a917e27f1","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETHK-B5-H.bcmap","hash":"225205ad3aad58967faf23a2504731abebc6dccc","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETHK-B5-V.bcmap","hash":"03e35e7fc1b75495df5559a3f71c5f0cbd1517ba","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETen-B5-H.bcmap","hash":"9c3b70700d7ae2b8c4cc6f658cdc98f4e65b3be4","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETen-B5-V.bcmap","hash":"5b637fa1b203754d98463053b38a2f694cde499b","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETenms-B5-H.bcmap","hash":"1207c931295ad5f57a430317d5014fb66d0eab7d","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/ETenms-B5-V.bcmap","hash":"631c58a7f7a8094d44a858d26485ab65b499b59b","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/EUC-H.bcmap","hash":"f88729b6a413ae1365bafb5dc8076b465aa1fb87","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/EUC-V.bcmap","hash":"c47c42d9099caf1447498e57fc1c8f3c7ff417b3","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-H.bcmap","hash":"4b6a27e1125bb11bf9fd8fe9c5375f7781c95204","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-RKSJ-H.bcmap","hash":"e1c2563a6d785aa5e30de423911d179fe79ec957","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-RKSJ-V.bcmap","hash":"5443591823737ba98993537c4d4e8af70a37c92e","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Ext-V.bcmap","hash":"0d88a7517783f25ce1eee082a5ed12b0f96061c2","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-EUC-H.bcmap","hash":"4231eab22968baa29ea4e6fdc4278b737067a7da","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-EUC-V.bcmap","hash":"7d268732b300431fced1351b4bfd12b51299283e","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-H.bcmap","hash":"3f1c2a68bdd13541e6a2cd6a7a393581e9444e1e","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GB-V.bcmap","hash":"b70477a9738709f639adf6bc20e81363efcc9ed0","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK-EUC-H.bcmap","hash":"08986b370ac27b60cf8cd7023c9e49f6b784b52b","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK-EUC-V.bcmap","hash":"4f0e0cfffafa21b30f7a25e5161738faf2e265fe","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK2K-H.bcmap","hash":"a36052b8b5d7dc1dde2b721437d6abc90ec7cefe","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBK2K-V.bcmap","hash":"d27b6916b7de1993464e5f33822f176fdc8e949f","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBKp-EUC-H.bcmap","hash":"a8785a44403f130097ee9a23c3923d5af252ac51","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBKp-EUC-V.bcmap","hash":"717f6d6585184bfebb894e59868886ab8f3c38f1","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-EUC-H.bcmap","hash":"e2dda44896a41f4fa817c5397f17894763b7623e","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-EUC-V.bcmap","hash":"9d6ef5fa295e3005d620904754d7cc16104be908","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-H.bcmap","hash":"62508bbc22bcd3795e4af2c7fa3cfddc71367813","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBT-V.bcmap","hash":"2f0936e0bd4362f7c6f8c2b56642d6483366cd11","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBTpc-EUC-H.bcmap","hash":"388eb76b53b008d90dfe68c1e3288314b21c3cdc","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBTpc-EUC-V.bcmap","hash":"ce125f52097c71fc83631577977ac267b8901c78","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBpc-EUC-H.bcmap","hash":"5c34efa7cca4e2f652f81f4498fdf41db1b7b1e6","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/GBpc-EUC-V.bcmap","hash":"36004a6bedae0edfaea620a7d8f61cfb875f9640","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/H.bcmap","hash":"149c08c0eadc405f6ba64adac9329fdb300d11ab","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdla-B5-H.bcmap","hash":"57ba02cf438eba88d2071bd99d1beb816b438b9e","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdla-B5-V.bcmap","hash":"035e4064559dd56ceb0f06c3ac1c2e766aeffe62","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdlb-B5-H.bcmap","hash":"2be77ea4f4cd8a338ff7007d314773582f565efa","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKdlb-B5-V.bcmap","hash":"3dc79100304f82ec559b70d120100f6ebe6ab5c0","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKgccs-B5-H.bcmap","hash":"dbaa1026222370fa6e3275c98e3bdb5ef3d37709","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKgccs-B5-V.bcmap","hash":"6f22784990eb168bcf9192e7e36de18e08927dfb","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm314-B5-H.bcmap","hash":"cbfb65ab0cae690e7679a1769de521ea20fb6602","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm314-B5-V.bcmap","hash":"3ef5f7e35ebffe68dea8ea757cdceac5b8151372","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm471-B5-H.bcmap","hash":"a75f2e32e5495d46e14b1d07ac124b3fc675ef1a","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKm471-B5-V.bcmap","hash":"2a6f2cc4d105f464432187daeff7b81040c093e4","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKscs-B5-H.bcmap","hash":"45f1793e771de030af89938eed23fff4c7daca3a","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/HKscs-B5-V.bcmap","hash":"fa5b3a1f0b3ab6bd614f8a39c9ab80b203daadf5","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Hankaku.bcmap","hash":"dfc2f635dd66602f9978ae3fe72695a02e512a6a","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Hiragana.bcmap","hash":"10e7a0f20cde8865a1dd3086a89f2e96e330d1a6","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-EUC-H.bcmap","hash":"bc349367bb60b06af5fdeeec05047f596ac71ab3","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-EUC-V.bcmap","hash":"4529ddac78c931d63411b6061b0af740b4c44ca5","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-H.bcmap","hash":"42e15fbce70bdec4f7bb5b2cbd02b0efd8bc65fc","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-Johab-H.bcmap","hash":"3585accc6e6957eda55302393fd9c3a563db6cbb","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-Johab-V.bcmap","hash":"e68b770b37b591884c459d6ce3bb43bc4556547b","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSC-V.bcmap","hash":"22b097fd376c21e40a0f9392961be74acc316343","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-H.bcmap","hash":"4e0ed017a2a41ee7bf6eacf0f7e6b40ae60d223d","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-HW-H.bcmap","hash":"d410341b19a6f05e0c20ea4a1a77078a3084044e","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-HW-V.bcmap","hash":"6cfeb36f492702aef5ce5b7671342291010b29e1","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCms-UHC-V.bcmap","hash":"3de7c5c70cf172ff560a62d5dfe84a9336b4f5ad","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCpc-EUC-H.bcmap","hash":"3705fd3621117a7e5a3772c3849c5d69620ef08f","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/KSCpc-EUC-V.bcmap","hash":"1d3a11932c44a5fa8fa22efd2bd3dba7db9a2c8e","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Katakana.bcmap","hash":"da100ad00f2a9ba196892bfb4d6644ec828a4fcf","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/LICENSE","hash":"1afb5991fce0d60110b5092b68bf9ff76b0c73f6","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/NWP-H.bcmap","hash":"7d0f51c52d7a96bf289d0c6454d7e9dccf009c15","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/NWP-V.bcmap","hash":"891a866c52b46e7526123799a829db24ac6cda4f","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/RKSJ-H.bcmap","hash":"a4f7d5cdd13d3008cc42d82f69672d9e50a9d5b3","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/RKSJ-V.bcmap","hash":"16ae42a46e7eb92ca048fe24649b668c5103b4b2","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/Roman.bcmap","hash":"5755781c7e9c50cc8192426d8733a506382b5fdd","modified":1680828574516},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UCS2-H.bcmap","hash":"7f289b94c643b7cc43d4936078143a2347ca0fc1","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UCS2-V.bcmap","hash":"6b19ece5c921516431eb94d28d74080fdd7d35bc","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF16-H.bcmap","hash":"d73d55388c76932033915cea627bb628edad4f66","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF16-V.bcmap","hash":"0f7152f2845cc2be4d3ce7e0e1530639ec4162e3","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF32-H.bcmap","hash":"a5872864e2b121c1df5068a54201ed166c69d5f1","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF32-V.bcmap","hash":"debaa98acaf13f341a5003856ef6a6a7df8f6e14","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF8-H.bcmap","hash":"734ad1a00033d70c195c81358b643c7cba1327b2","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniCNS-UTF8-V.bcmap","hash":"019bd0716b2aa80bc1bcabfd389d3d5e1065ba8e","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UCS2-H.bcmap","hash":"868238e34cb9548c4d138af1adc1a4bea62dec37","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UCS2-V.bcmap","hash":"f5853ca83c25b888c1d925e2a20ef44e064d064e","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF16-H.bcmap","hash":"28963866dfb575b58b4370e60ebd9bfb6e56ac09","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF16-V.bcmap","hash":"1771376eef979ad42c2b5c01a1af1d34f54580b7","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF32-H.bcmap","hash":"b9ea278eb4c324d12a81e2d62479548d1e7126cb","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF32-V.bcmap","hash":"8167ba503aa8a6c805f39be0ca538b99898a967d","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF8-H.bcmap","hash":"09cc7750f69da77434093e4c94211394f5665eda","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniGB-UTF8-V.bcmap","hash":"e23616fa12132c73f52071b96e76d876430ececf","modified":1680828574520},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-H.bcmap","hash":"caf525125e29fa4de78088e5eb1785c1af1f9950","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-HW-H.bcmap","hash":"97cbb8599cf62914885a8b2b47594865fff52099","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-HW-V.bcmap","hash":"f36bad9c680f4bba6cbcf8ac57f53e7ce21c806b","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UCS2-V.bcmap","hash":"45396576a6bd5468a84e2c2e4ae64c23fe7f2e85","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF16-H.bcmap","hash":"16499e93f0a447a94e1e44bfa9951401d290d89d","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF16-V.bcmap","hash":"44402b8f73e0b0160846b641e7cb2e75ab8c81bd","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF32-H.bcmap","hash":"bc482114d214e2fffe85dd0b7422f48c3e282c17","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF32-V.bcmap","hash":"2f5ec2584fd7c39f455161a857550fa7fea5f53a","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF8-H.bcmap","hash":"f47956c1c7b2eadbda93aac25fe4546b413ec0a5","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS-UTF8-V.bcmap","hash":"b3ea8d2172a2f6f9e73cf62ae467aa84848df6d7","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF16-H.bcmap","hash":"b8b0cc6779d3960426899fc2e7cf2866ffc80167","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF16-V.bcmap","hash":"2872cb273dab9d0dbb7f331826045df18764a7b0","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF32-H.bcmap","hash":"f48723212d1ad18c0b3c41168d6f630798e04160","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF32-V.bcmap","hash":"ef16ccb3102fc44c1d46f4cad40cfbdb020ee277","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF8-H.bcmap","hash":"385ab762d03499d35539048176928e031e5340d1","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJIS2004-UTF8-V.bcmap","hash":"565560a59d5174ac379a8d91f165c8ecdef54e06","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISPro-UCS2-HW-V.bcmap","hash":"3f0a364246717707db82913593304cb7bd37c378","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISPro-UCS2-V.bcmap","hash":"b1a47305fa79afa19ab696d33af5099d35570c56","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISPro-UTF8-V.bcmap","hash":"ed6b571aeed388d3b53b9e65824af3f0146a5857","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX0213-UTF32-H.bcmap","hash":"15c953c36436d32f748ec7468a95c3e5843d70bb","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX0213-UTF32-V.bcmap","hash":"dfbe3e295505977b4e1881ef30b80362d7406bbc","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX02132004-UTF32-H.bcmap","hash":"c41dd50df01e3d3331f0acdb6da6c1b857a67cf7","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniJISX02132004-UTF32-V.bcmap","hash":"9c48a0c654acf4bcf51defde2f7d8b3ce52a063d","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UCS2-H.bcmap","hash":"50fcce1b2e3224791b480289e7c4c42938beb854","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UCS2-V.bcmap","hash":"6743b3e07370fd49962b97d97be77dae8d18aabb","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF16-H.bcmap","hash":"4f4603408966d9ac29a96c3a6755b9f23e7aa953","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF16-V.bcmap","hash":"cfdbfbf0b0e8ef98fef6236ea570c73465da1581","modified":1680828574524},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF32-H.bcmap","hash":"6b0e98e16418fa5a86338b3fb361f1700971f649","modified":1680828574528},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF32-V.bcmap","hash":"73bd343b188a80471eb156655f5b192903f86cbf","modified":1680828574528},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF8-H.bcmap","hash":"8117d31e498a8f0fb7c223c4172ba881c0496c6f","modified":1680828574528},{"_id":"themes/next/source/lib/pdf/web/cmaps/UniKS-UTF8-V.bcmap","hash":"586c64948a67e4cb12de64e221b0dc3d9e47dedf","modified":1680828574528},{"_id":"themes/next/source/lib/pdf/web/cmaps/V.bcmap","hash":"99790f12ca21a196bc1d836ae5bf0ad7af95e079","modified":1680828574528},{"_id":"themes/next/source/lib/pdf/web/cmaps/WP-Symbol.bcmap","hash":"3a6417abad460a1a083be75636c014f3a73937b5","modified":1680828574528},{"_id":"themes/next/source/lib/pdf/web/images/annotation-check.svg","hash":"015d03ffa6a0ce93b41ed93a262879e4f8cf72fd","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-comment.svg","hash":"5ec875153d5046507050a3531422ca69b44680c7","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-help.svg","hash":"2f3d88f4e8cefafc2d76932104f6b2517034af2f","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-insert.svg","hash":"7a12af74ef20d5249a0c330d992bd1132308cbac","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-key.svg","hash":"d9224d3aef774d6ecc9735b440810ada4384be11","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-newparagraph.svg","hash":"453ba47aa10b6fcf8459569e0a550b4f91260ec7","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-noicon.svg","hash":"5a5447e5c39cf7ca748853a15dbd835ddaa3b5df","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-note.svg","hash":"6100deeb6121f98c7e024ec1a273171207c84c7f","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/annotation-paragraph.svg","hash":"70591a3b26c56815c6e5ab2bae959e8a951c43fb","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next-rtl.png","hash":"d02c4e9bf493dc83029098e59b6ece2363f3c760","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next-rtl@2x.png","hash":"f9f2cea77208aa0e219f3bed69e22861c2858bc3","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next.png","hash":"4bcb69c72d25d822dd09a3999c6972c0c311f04b","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-next@2x.png","hash":"dca2a1a3bdbe036735dda32e5ed909b029829a3c","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous-rtl.png","hash":"4bcb69c72d25d822dd09a3999c6972c0c311f04b","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous-rtl@2x.png","hash":"dca2a1a3bdbe036735dda32e5ed909b029829a3c","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous.png","hash":"d02c4e9bf493dc83029098e59b6ece2363f3c760","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/findbarButton-previous@2x.png","hash":"f9f2cea77208aa0e219f3bed69e22861c2858bc3","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/grab.cur","hash":"fbd667e863c8278950e7761aee54b394cd93ea0c","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/grabbing.cur","hash":"f30d68405751e730ca94ada8628df45b4839931f","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/loading-icon.gif","hash":"e043879d3ee94a3edf10260f21f44bfa4a6fc66e","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/loading-small.png","hash":"c1abf9b89af7392824f2228312785a899df224a0","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/loading-small@2x.png","hash":"171aeb1a90c2836c639438fa85c64cd9d94b3516","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-documentProperties.png","hash":"6f1e0ce52dae6af31bb3c5b09bbb33a33849fd08","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-documentProperties@2x.png","hash":"bd55401797e24ae5066afb9677dca1463e74c839","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-firstPage.png","hash":"453a575f2676ba39eacc71c074420d6c97c87a42","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-firstPage@2x.png","hash":"fd24d7a57e2a1205a67a11a760eb6dd50748da26","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-handTool.png","hash":"8db06773a09e2f407bdf7ce448777398b40fd313","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-handTool@2x.png","hash":"eb8a16519da1e074f9ed07e8a350a6b0d52e5339","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-lastPage.png","hash":"6819bdd3000af84c50df1b10b55b3af33944a261","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-lastPage@2x.png","hash":"2fb45311e8ee9658cc4276f1202ada9a55df774d","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCcw.png","hash":"548451d8a12570d66bce4c8922d8ccffb63ca61a","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCcw@2x.png","hash":"84f034b57d24f7371d1a605bd12afa1f71b50f1b","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCw.png","hash":"252e8a4adaf406c4e9c78033d8d8163333ce4c1c","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-rotateCw@2x.png","hash":"f37e80bc600112fa88251e53e953f14946967e19","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal.png","hash":"67ec12c5bfe0d933f62e1bdfb2154db263e24712","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal@2x.png","hash":"0f23b007fe6be937bc1072737e60cf10e4b8c7e1","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollVertical.png","hash":"3509cb4c7f355106103aa663fdcfbba6143f1d96","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollVertical@2x.png","hash":"a80753f432677766ba1cfbf3677bb9498998efd7","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollWrapped.png","hash":"4409af25572feb6ac02d9f0ddcbd5ea689b3dd05","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-scrollWrapped@2x.png","hash":"8b0ebf82e3f20a7e6cd93ef80b4ac932a02512c5","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-selectTool.png","hash":"f62d271d5403f35e372b2cdf4c892aac7d364665","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-selectTool@2x.png","hash":"9a10930334b9a42429c967b77f8c7e705e31cdaa","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadEven.png","hash":"d27a628de5e1a4ce508c39fcb496b50f3d2d0fa0","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadEven@2x.png","hash":"616b232b0f166467d0c37315709508953fb79358","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadNone.png","hash":"a6648371ee01d687db409f5198f30dafaba76b6b","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadNone@2x.png","hash":"5833ee8fa2394db83739ddbb5f9f0f3f0d39709d","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadOdd.png","hash":"ff70929f97f54c2722e890a38070f749cefd12ee","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/secondaryToolbarButton-spreadOdd@2x.png","hash":"07f1a8754f63dbb8d480e0923328c9fc0336fd2c","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/shadow.png","hash":"02b6adc1ca6ad8f57605ee92943b65c6250d73ba","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/texture.png","hash":"230a3d5e2dfacfa7228f58a559de5df3734118f5","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-bookmark.png","hash":"0193cebc494facb8ba8733a1a8f50457e7189f56","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-bookmark@2x.png","hash":"f822c6228ea6f9ad2ee5465ace31c725cf3289c3","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-download.png","hash":"b25abd4a3c95097a338b8b138476e22189cb235e","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-download@2x.png","hash":"6c2ddead63c9a9ac3371bd7b8b8b914e2f81d605","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-menuArrows.png","hash":"acbbc7071a0641a10e1d50991d1abbfa26b5dce9","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-menuArrows@2x.png","hash":"fdb29640d1f7ee31b09550163f85e01a70cebd13","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-openFile.png","hash":"6b17acd1c4ea6a9d9859819456952eff133f3cc1","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-openFile@2x.png","hash":"ae13be299d7c18dde70d975d0e229d3e20137afd","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown-rtl.png","hash":"641a0e2d711ec06176c046d8efcdff670da876ef","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown-rtl@2x.png","hash":"445833e5eebdcc99270b879d0079bb54310f1615","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown.png","hash":"6e10286da3a52e0bba782d0fc4a7c33d10c8f4b9","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageDown@2x.png","hash":"2b817130c3724f8a864845b03a142bd7e1cb61e9","modified":1680828574532},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp-rtl.png","hash":"0529bff456111ea1a264771afdcb2daebe68f79a","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp-rtl@2x.png","hash":"1507890ff466f28f78ab7bd9f6eebfe2e4eeee8a","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp.png","hash":"b1eae4614fb964b6d0483f114f3dd2b49ec1b64a","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-pageUp@2x.png","hash":"9960af5e2ff7dfe8aba862d77305f409f5f1405c","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-presentationMode.png","hash":"3d206e303f9663dca95482df9abe55a08851c574","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-presentationMode@2x.png","hash":"c2d54d6f77f831963132555599e7314d4f07b49a","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-print.png","hash":"77463c425966b8a298a2d87863533e68092676bc","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-print@2x.png","hash":"7577a46df5fcc89846737010a14878bffa85098e","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-search.png","hash":"14c3ef60d3979df9e8d13cf39cad10ed043f5578","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-search@2x.png","hash":"25c50114436d8d598416a5c3eed9e1db282c43b3","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl.png","hash":"990118984a946a8c63d95fd1a8d8af848383118b","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl@2x.png","hash":"51055db76ce1e9935fa3d91aaece874c6da14147","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle.png","hash":"6cedbeddac0d6191afe09cabed7b6d517f7c7b21","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle@2x.png","hash":"6f1dca07696408ce28da5621ebcac57d0b2031a5","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle-rtl.png","hash":"422b5ed725be51f60e6339da94e0c959ad67990b","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle-rtl@2x.png","hash":"29eade71266a6c4b1048eeacb1c29411435bdb41","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle.png","hash":"ff7ef30371233abe8c548c2f3d5cbb335183ca92","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-sidebarToggle@2x.png","hash":"04c42cddc1e2bdd5130c6fa477ff3fa594edda56","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewAttachments.png","hash":"53c5a0c4c40f5f47fb6d2f57a82a4a6d0a83feb0","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewAttachments@2x.png","hash":"eb96df312c7ff6fc0451795bc0de8ebadb72cf86","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline-rtl.png","hash":"e6214527b9354eb920cbec85e6fe4e1296b7ae15","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline-rtl@2x.png","hash":"6684f9d7964446ec66a8f3865445892187d16d21","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline.png","hash":"ec7aa605c063faf6a951c2d64a8d98933b60f6a4","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewOutline@2x.png","hash":"76be930d871fbd1ebd6c4d76c4fa325f32efc624","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewThumbnail.png","hash":"f62aad7c7719300f1d8e922155f451661d41d42d","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-viewThumbnail@2x.png","hash":"ececa7ff064700efde72fa1e3889c8a1a3073dbc","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomIn.png","hash":"838adbe15d84daceec25cfd4d8d6ac1580b4f693","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomIn@2x.png","hash":"5403ddbeed138cc733020c352ae3bcd8cac03bf7","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomOut.png","hash":"63a719d5e6a708a22014f20abc0722cd54ffb0f6","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/toolbarButton-zoomOut@2x.png","hash":"4006d4387f2b0a0f0856d691a8874f74f61d0f51","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed-rtl.png","hash":"7c2ff883f666ac379b04d0d41e3e6ddb14ddf220","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed-rtl@2x.png","hash":"0465b8f9e77135e2bddd5708d425d5e1fc4ab63c","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed.png","hash":"4588ca9c86db15c10de4de3f340111d4ce211ebd","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-collapsed@2x.png","hash":"3229d96b4fa4d7e5c26fc135264d134e1024baab","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-expanded.png","hash":"b0b4bca3d9bd0949da19a56214143db18f2a4f69","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/images/treeitem-expanded@2x.png","hash":"bf924ff993236e563dab83b41193bcb43120c0b6","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/locale.properties","hash":"e29c4ff2f77884ad77b3349d0efa7d83e236ddf4","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/.git/objects/pack/pack-e96ab0bd32c4d85032ac8e5950da190e35676676.idx","hash":"364eeb76bf1f21dc96343800978cec98f4fa3564","modified":1680828574440},{"_id":"themes/next/source/lib/pdf/.git/refs/heads/master","hash":"dae4a159f77fa82f226d3ec865a9b5d88601d03d","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/web/locale/ach/viewer.properties","hash":"5e8f73b253c0e10d11909b41b0c9774ccbffc7a4","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/af/viewer.properties","hash":"4f79c194d6b404ffbec112aaa55ad4b016b9d93f","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/ak/viewer.properties","hash":"7b32cf30fd16432bc4050919607659c5e7ac7fe3","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/an/viewer.properties","hash":"a9505349d70da8f3b2821f2ee66b9074156cde3f","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/ar/viewer.properties","hash":"a50d00bfc03341506149bac8c4a68369d464be16","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/ast/viewer.properties","hash":"27977540f13015e2087a3b7551e15d8a43bb3b7f","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/az/viewer.properties","hash":"24bdd9fbbb8959b54bbf90a86872e61b088a63ba","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/be/viewer.properties","hash":"af1f8303f1c0d8878baae3e4645908e5142fb704","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/bg/viewer.properties","hash":"40860051d53e2d87860c1115c11d6a3e03ce7036","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/bn-BD/viewer.properties","hash":"684f603efdd31daf880430192a327bd3ac4bb3d2","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/bn-IN/viewer.properties","hash":"4b5286d177fba02adf8aefef7238c202fc7e254a","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/br/viewer.properties","hash":"8cb4f970c6611c34e3eefe2a9ebbdfe254e5194d","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/brx/viewer.properties","hash":"91aa4facc79d453adc42518c80b5b79500c55544","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/bs/viewer.properties","hash":"5321ec163bf54b4a2be4830d796a5a5b732db76b","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/ca/viewer.properties","hash":"28817ae36a8e7376a6f4a651e58574c5cb79f13b","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/cak/viewer.properties","hash":"210fa52440bfbb06f09b0020b14f6b04eb50f639","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/cs/viewer.properties","hash":"ecbe632692940349b8b349372157ba7c915c37f7","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/csb/viewer.properties","hash":"17e840af72cb4451a586e70f5a7c7bfeb9c20683","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/cy/viewer.properties","hash":"2aa2ba4c18b7e54061ef92e7c0f90cdcc325d156","modified":1680828574536},{"_id":"themes/next/source/lib/pdf/web/locale/da/viewer.properties","hash":"baacb40f0b6bbd40000115c9f562cc56e098ca67","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/de/viewer.properties","hash":"3973c90e85e3144adf9abae6b694904620d4b93c","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/el/viewer.properties","hash":"b911668ba0074c41689e6fc37d930c7fca28ff90","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/en-CA/viewer.properties","hash":"364f9ef3fbf161ee4c0b9e8b15dc631ca40aa58a","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/en-GB/viewer.properties","hash":"364f9ef3fbf161ee4c0b9e8b15dc631ca40aa58a","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/en-US/viewer.properties","hash":"af2f36748974bba36ebaefe663a3b2dfacc4306e","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/eo/viewer.properties","hash":"92949a390017c2932c876a67ffe347c235fd51c7","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/es-AR/viewer.properties","hash":"58e1f0f130d88aa16ffef0707b52260e35fadddc","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/es-CL/viewer.properties","hash":"1969968b1aed118b85bd263b71ef518a6b8b5941","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/es-ES/viewer.properties","hash":"b018f218210363c96afff42a0a346d8218151d50","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/es-MX/viewer.properties","hash":"e74a68a1275022a7b5017eede7423485ae962837","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/et/viewer.properties","hash":"232b9fc34da10c1d15699444ce71db8ac1beba61","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/eu/viewer.properties","hash":"d96895429a2b41bc036dffc770023c4421efe539","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/fa/viewer.properties","hash":"01d1c935374f5b0ae23f0d914c8e1a0980a8dd52","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/ff/viewer.properties","hash":"74fd6d6e5a7f01e43f6723e990240bdc1a7dec7c","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/fi/viewer.properties","hash":"f4a032df50cd1e46afb79bbd88244f13967b88a9","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/fr/viewer.properties","hash":"7a3b57afe7c681033825ee010e28e0b68cd9212b","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/fy-NL/viewer.properties","hash":"b03e41eeb6498f4e3a2e3ad239b6ffe12e0b710e","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/ga-IE/viewer.properties","hash":"f319b460b796b9c703927444f9013d0316cbe3c8","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/gd/viewer.properties","hash":"7ec1051e104e798c17cf0cc424b3cc9278c5099a","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/gl/viewer.properties","hash":"9df8ec36500ccf36646100ab4ed0a45f695afacc","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/gn/viewer.properties","hash":"c16d4e9109b81e14e58d0207845cf432877b1571","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/gu-IN/viewer.properties","hash":"5ed0a1391863eb7c3ef0afff0752cc93cc4d1306","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/he/viewer.properties","hash":"f681e165a1954964a2f1c8198d4367afecb3568a","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/hi-IN/viewer.properties","hash":"4102ed54688a55875cdefc42f0ac8bd32b54df42","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/hr/viewer.properties","hash":"7b33f2d679ae34765b90c1b087690743018bdd83","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/hsb/viewer.properties","hash":"52cafacd8cfd5a2609ab342288f0453a99f3821f","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/hto/viewer.properties","hash":"4e6fc5d6b807cfe56ccca952a01c4630670f63f8","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/hu/viewer.properties","hash":"7d4c2f500b0aeeff09d3fc9c9d79459a4ce8576a","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/hy-AM/viewer.properties","hash":"d15feb0c6de4534c35cbe224448429785f9d1d9e","modified":1680828574540},{"_id":"themes/next/source/lib/pdf/web/locale/ia/viewer.properties","hash":"a98705ccd1ce97f215804d76237381b1232dc711","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/id/viewer.properties","hash":"efb85d06ca2c0e56642f99f921bbded8dd93ae36","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/is/viewer.properties","hash":"5ee3e9690eaec6b42e32b959c837f4dd7f8e490a","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/it/viewer.properties","hash":"3a9a93706916d7cc563f9ec81f28222fd5b34dd9","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ja/viewer.properties","hash":"7655b354201dcaff5713b491eada03dc4ac6dc62","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ka/viewer.properties","hash":"92913c545711ea38ff7744f4dc070d1d3baa4e29","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/kab/viewer.properties","hash":"0949e3aa980847f01317df14fc1c9915559f290d","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/kk/viewer.properties","hash":"7a756a94950fd9176605c66f1bb59ba6e87acbd6","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/km/viewer.properties","hash":"fa84c645561a6573737a401e0c14c512401f4220","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/kn/viewer.properties","hash":"7764695f91f82e74f29452d81b41bf634134f9e6","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ko/viewer.properties","hash":"28230518ad79bf4209325ed449520223bd46631d","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/kok/viewer.properties","hash":"d887d8a052a35be54159f58f7243372dbf7ec258","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ks/viewer.properties","hash":"4805e2e3aac56f9559516125daa1dcc6bc214875","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ku/viewer.properties","hash":"46739e80d58ab8559ccfb21d6b0692a37e16e6a9","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/lg/viewer.properties","hash":"18c1b9f7ca30c648bd31e31b15d16c876242ee73","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/lij/viewer.properties","hash":"f949bbb3bc2129cf6e1176c63b471035affac86f","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/lo/viewer.properties","hash":"625438b69b56a04f2e45464f8c113cac82c7e4af","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/lt/viewer.properties","hash":"3b1cfbc3c6d6b51df4a01b025c972ef7d9ee5bd1","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ltg/viewer.properties","hash":"eff20b98155297340728776fc6117091fc6c3661","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/lv/viewer.properties","hash":"11556a8d2494811f17651c1eccfcb570d3dad35c","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/meh/viewer.properties","hash":"1024719401b6ab1922c872f2d7e58cfd60e6cd49","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/mk/viewer.properties","hash":"33cbeaf98eae66a5d37ce2e21c52c6700d0b0eec","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/mn/viewer.properties","hash":"7986acd89509d0467129b71ce25922ecfbd4817e","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/mr/viewer.properties","hash":"17be823b511abbc00250ecbd41b75743ffa6c0e1","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ms/viewer.properties","hash":"d556fd6c1ae83c1e48f16efe0bbef62d75beb51d","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/my/viewer.properties","hash":"28c90a2d281d43d509f7f72539eac9adc110456d","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/nb-NO/viewer.properties","hash":"15f68983d348b407527ab38c71d683f7e3e87ca5","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/ne-NP/viewer.properties","hash":"276511a05f160ea500ac4060b4a5fd39d5735690","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/nl/viewer.properties","hash":"0e0fac0dd4fb595b47e01772865cfa5870d3ac9c","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/nn-NO/viewer.properties","hash":"adc3d40b11f97b5e6d254ddd672c64675948176c","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/nso/viewer.properties","hash":"176afe940078cca679275adf9dbc1ca1d6e8f7ce","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/oc/viewer.properties","hash":"d6fa7c4febc8c1d7bc4474670a60484ff0083083","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/pa-IN/viewer.properties","hash":"6b1b298820df47e1bd98c5cbd151efeb947d7028","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/pl/viewer.properties","hash":"493fa50175a829daa8254f1b1d7f3b25967b014f","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/pt-BR/viewer.properties","hash":"66bea896ccc2f3653157bf241dfcfc525b420b21","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/pt-PT/viewer.properties","hash":"fb8b82049ca660944199991eb114e7559928df09","modified":1680828574544},{"_id":"themes/next/source/lib/pdf/web/locale/rm/viewer.properties","hash":"a38b02acefc80f44166dc090be31ef4ab275320d","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/ro/viewer.properties","hash":"6a999f4a8c5072c029f8fab9997efae2a4a3fd85","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/ru/viewer.properties","hash":"1784657fc48a6921388fbea00287a79cde218ce6","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/rw/viewer.properties","hash":"7d96bc96802f37a1c9ead373524a425d08e1dbcf","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sah/viewer.properties","hash":"ef69f15f4aa8ffcd0292b67519495ac962f0a846","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sat/viewer.properties","hash":"02709cba9da0380bdc9e174094769f5ae60bf8ad","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/si/viewer.properties","hash":"b1f41db0c4faebadb7bb91a44b265b50c6de0996","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sk/viewer.properties","hash":"2ded3adc04e47fa5b70f5829d3e1af80d8afe7f6","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sl/viewer.properties","hash":"aa5bb76131503a2f29ce853c2b6329088dfd072f","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/son/viewer.properties","hash":"89384fd7cb2359b1360345c7169031b0509f8df1","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sq/viewer.properties","hash":"d996492e4770e38f0f99c9de4328ac90e0eb1792","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sr/viewer.properties","hash":"987c57c1ef644ad80e65cce437a7dfaf693c1512","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sv-SE/viewer.properties","hash":"6a907106906861bdcefd5da5b5a88ebef4effc46","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/sw/viewer.properties","hash":"7e5b770e8155a7465f77d1b2d7792fa22e50bcd0","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/ta/viewer.properties","hash":"1428a3ae798b137138993313b0ccbfaf13cb26d4","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/ta-LK/viewer.properties","hash":"646e2182307793f70a61584fc436886c946482c4","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/te/viewer.properties","hash":"151b8f9e20079c504cd5fb91788e1fb0fd506457","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/th/viewer.properties","hash":"59b3fa265599019597d9dafd0558c8a63c9d58ff","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/tl/viewer.properties","hash":"9ab570bebf0910bac1201c12b439d91ec4fbcef2","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/tn/viewer.properties","hash":"b1839a14243baf851f7811e5be779d8e0e147105","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/tr/viewer.properties","hash":"11294fdc4adad18e1f06d778f4b901273c11413e","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/tsz/viewer.properties","hash":"0e3086f1dea298a35dcc91dd78d5a24250f1c908","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/uk/viewer.properties","hash":"51432a861c9034db193cbb45c6a807ada8a9ec2e","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/ur/viewer.properties","hash":"f6db5457f03bcf3029cc15508accc1e05dfe7235","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/uz/viewer.properties","hash":"331a3fc72e3572d5cae07672b872f2d89b324286","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/vi/viewer.properties","hash":"bc6cc7571a6a64d6a4ad61a84687cf3955d143c1","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/wo/viewer.properties","hash":"1426459b8518b593673ac0b758407f2a228c89ba","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/xh/viewer.properties","hash":"4ce7fd8d9366220b4264e4ae712cf88348f4f83d","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/zam/viewer.properties","hash":"a186e34704f3a1ba4cbf22fce81c576ab6487ed7","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/zh-CN/viewer.properties","hash":"da462329ec0503c949b7268591af2f0847f9649f","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/zh-TW/viewer.properties","hash":"c0199a6f89e6a5ad249605152986d9e23341320e","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/web/locale/zu/viewer.properties","hash":"1c283ba7792aa61cad501198bd8e4d7b13fa5bb3","modified":1680828574548},{"_id":"themes/next/source/lib/pdf/.git/logs/refs/heads/master","hash":"40b83a5c8c2255f2dfb01428870bed82ae5100d4","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1680828574456},{"_id":"themes/next/source/lib/pdf/.git/logs/refs/remotes/origin/HEAD","hash":"40b83a5c8c2255f2dfb01428870bed82ae5100d4","modified":1680828574456},{"_id":"source/_posts/RGB-color/rgb_cubic.png","hash":"9b2fa6f3955e6112ec76c0fa8e7052c84e30ae87","modified":1680835430820},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1680826636355},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1680826636355},{"_id":"themes/next/package-lock.json","hash":"68de601ea3345e1510ce23e062d331dfec0a8e32","modified":1680828646824},{"_id":"themes/next/source/lib/pdf/web/viewer.js","hash":"9fa24e98c083ca6c32a292a3296c4782ed51d958","modified":1680828574552},{"_id":"themes/next/source/lib/pdf/web/viewer.js.map","hash":"6e317140fdedb6ec0b9e5c8de9167cd2cb7e2313","modified":1680828574560},{"_id":"themes/next/source/lib/pdf/build/pdf.js","hash":"50b88ce99fd16fba98e7b69e05b75dcf1766ddb5","modified":1680828574468},{"_id":"source/_posts/Functions-Plot/3d_functions.png","hash":"653f419c3dbc5c9910337bfd8c3598945d51dc86","modified":1680835430496},{"_id":"source/_posts/OpenCV-Hand-Tracking-to-Count-Fingers/image-20230401192321128.png","hash":"ba4fece9f0ba16a64d300d08cc7972c92322909b","modified":1680835430800},{"_id":"themes/next/source/lib/pdf/web/compressed.tracemonkey-pldi-09.pdf","hash":"0d281938d3ff2377541704cab6ba1c4408420733","modified":1680828574532},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230402154048465.png","hash":"162450129bcd94dc0764503f4acbee216e163d69","modified":1680835430944},{"_id":"themes/next/source/lib/pdf/build/pdf.js.map","hash":"430ce9f42522bca793bbc7e1f2a3b92e2b0f04a5","modified":1680828574500},{"_id":"source/_posts/Image-processing-using-Numpy/rose_chanel_order.png","hash":"0b4d3759110ff20c60a6987428ce95db4cf561c0","modified":1680835430776},{"_id":"themes/next/source/lib/pdf/build/pdf.worker.js","hash":"36a7f91a9f55abe41454e529aa449ab1741af31c","modified":1680828574504},{"_id":"source/_posts/Image-processing-using-Numpy/rose_channels.png","hash":"bc416048bf2ada694c115d49e63c4e4a315e8445","modified":1680835430796},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155315817.png","hash":"5f9341eaf4431ec8e4077fcfb0f5f478db050ed3","modified":1680835430928},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401160906919.png","hash":"f8de001d409343e09873a5567da6840308e41083","modified":1680835430936},{"_id":"themes/next/source/lib/pdf/build/pdf.worker.js.map","hash":"acf0c0d4f6196758c90b05d302f22bf7cb32923e","modified":1680828574512},{"_id":"themes/next/source/lib/pdf/.git/objects/pack/pack-e96ab0bd32c4d85032ac8e5950da190e35676676.pack","hash":"4ce844e88522944c0927de27192d0dbe4a7e43d0","modified":1680828574436},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock_methods.png","hash":"182df39c3601157bb3c7d46df193b97c4bee4859","modified":1680835430900},{"_id":"source/_posts/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness.gif","hash":"cb2c3c8ddf164289d842de5d53afcbe2b00ad643","modified":1680835430548},{"_id":"source/_posts/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness_control.gif","hash":"0b2b5efe4911129fe1d40301bb5f19d03a20b504","modified":1680835430748},{"_id":"public/search.xml","hash":"aca63b17f22dba34b88c949cfb3edd6d6dfa6f76","modified":1680918029817},{"_id":"public/404/index.html","hash":"7ec9895e6fcc11dbb07c37308adb45d812c3d854","modified":1680918029817},{"_id":"public/about/index.html","hash":"1f77205b996e9f6a4da3e1ed1bdd62b02d218700","modified":1680918029817},{"_id":"public/categories/index.html","hash":"7fc263e63e12dd746eec7e1a9e07aea61a1b9052","modified":1680918029817},{"_id":"public/tags/index.html","hash":"017073ee863edb08a30633b4b270d609635574e0","modified":1680918029817},{"_id":"public/archives/page/3/index.html","hash":"95538400cd0c4530fd58d944b1bb15e5c1560692","modified":1680918029817},{"_id":"public/archives/2023/page/3/index.html","hash":"8da484ad0f68d19d09b9747432e2f3c59c710580","modified":1680918029817},{"_id":"public/archives/2023/03/page/2/index.html","hash":"b644631db37d922ce8cea6fc049c96d44d6e7dcf","modified":1680918029817},{"_id":"public/archives/2023/04/index.html","hash":"c20c8c161a4a79295ada1459d4076eeba1d28334","modified":1680918029817},{"_id":"public/tags/Matrix/index.html","hash":"dd1818d210565ca01f358b8e3d8d51f8e4d2b8c8","modified":1680918029817},{"_id":"public/tags/Linear-combination/index.html","hash":"e8c80d92a1e403fbf6172365729ba42299052f06","modified":1680918029817},{"_id":"public/tags/Basics/index.html","hash":"67d607b9a9ef3e28c35b28523dee400b44dd2474","modified":1680918029817},{"_id":"public/tags/Math/index.html","hash":"17beb7899beabe605f027ef1d6cf0698c644e097","modified":1680918029817},{"_id":"public/tags/Python/page/2/index.html","hash":"36ca90f8d35e42ee807713a29f3bd1775db76d72","modified":1680918029817},{"_id":"public/tags/Scipy/index.html","hash":"64b88aff84de9804164e3e02f3b71fa707faf1c1","modified":1680918029817},{"_id":"public/tags/Classification/index.html","hash":"f69a66129116c38d9aa7a2333b8bbe7a5b7e2075","modified":1680918029817},{"_id":"public/tags/Torch/index.html","hash":"162d368ed3f8e940a61f3add2fd3dc29b4d36824","modified":1680918029817},{"_id":"public/tags/Linear-regression/index.html","hash":"bac0fdf2bca5b52f6b92bb6b18661267883d0a11","modified":1680918029817},{"_id":"public/tags/Logistic-regression/index.html","hash":"89a095c75f83eda685fb3efc293111d7e548055a","modified":1680918029817},{"_id":"public/tags/Linear-algebra/index.html","hash":"2a21b257398e49b8add6f107d6bdd6cb06ea654c","modified":1680918029817},{"_id":"public/tags/Binary-classification/index.html","hash":"1e0affd6d5ccfd87380e316724dfd5256e744df3","modified":1680918029817},{"_id":"public/tags/Sigmoid/index.html","hash":"470bc1087b2b8c4fc4dd9739db5b897a73dace5c","modified":1680918029817},{"_id":"public/tags/Functions/index.html","hash":"b1e271e059e03d78d23e336072158aea15fd8a2a","modified":1680918029817},{"_id":"public/tags/Numpy/index.html","hash":"2bf09f71497f6b82e46a86e938f86531fa3c6b02","modified":1680918029817},{"_id":"public/tags/Matplotlib/index.html","hash":"1160acc984b3823f801ddc01ccea4e34d2e7f873","modified":1680918029817},{"_id":"public/tags/Probability/index.html","hash":"85252c4a2b0091d29a178b297e6035f391d05ccd","modified":1680918029817},{"_id":"public/tags/Gradient-descend/index.html","hash":"c274a325af6dc19c999a2f5bdf69c007e9b9f135","modified":1680918029817},{"_id":"public/tags/Optimization/index.html","hash":"1c5380a52a81c590ad2634e5733f26ede55e7779","modified":1680918029817},{"_id":"public/tags/Mean-squared-error/index.html","hash":"07ae163f4565997c4ef48651f0c51fd94c58dfb6","modified":1680918029817},{"_id":"public/tags/Loss-function/index.html","hash":"76abb144d1c47caf6f329c0aada9f67a41d5de77","modified":1680918029817},{"_id":"public/tags/Machine-learning/index.html","hash":"e0710af6488ef48c64f5984e83e05e51c31f83fd","modified":1680918029817},{"_id":"public/tags/Hand-gesture/index.html","hash":"9d61ebceb2d2b63005bf6095e42d52c253cdf8c8","modified":1680918029817},{"_id":"public/tags/Mediapipe/index.html","hash":"2a0d52495d809e778177944dbaebeba75f47aa2f","modified":1680918029817},{"_id":"public/tags/OpenCV/index.html","hash":"b36889efe64769e16eb6fd3145bb2c420912cde5","modified":1680918029817},{"_id":"public/tags/Computer-vision/index.html","hash":"9334e4b6bc8a6a047e8f35d4116f6b6304f953db","modified":1680918029817},{"_id":"public/tags/Image-processing/index.html","hash":"5021a4e246319d1545d838cad8dd8e1f303948d6","modified":1680918029817},{"_id":"public/tags/Real-time-tracking/index.html","hash":"c4ced31f0da2a7b8d29a65e242e175c6cd3f82dd","modified":1680918029817},{"_id":"public/tags/Hyperplane/index.html","hash":"3074e051f336c886137d40cfbbd1896638f279ce","modified":1680918029817},{"_id":"public/tags/linear-regression/index.html","hash":"0054404b56659c5c948410d31f1933c993b4fbbd","modified":1680918029817},{"_id":"public/tags/Linear-equations/index.html","hash":"05795d4252020fb18b840a280210386c3483ef7c","modified":1680918029817},{"_id":"public/tags/Norm/index.html","hash":"a670c834a6bbff60ed7d40a0170bba90d14ec67b","modified":1680918029817},{"_id":"public/tags/Array/index.html","hash":"a27906d0cf4c9cdb8ce3660f7bad4fdda2ffde19","modified":1680918029817},{"_id":"public/tags/Opencv/index.html","hash":"923c540a799409aeb37dc82d10e233ace4b0d606","modified":1680918029817},{"_id":"public/tags/Video-processing/index.html","hash":"22d22c71be61e52bd85bb3f43724909d1ce849c1","modified":1680918029817},{"_id":"public/tags/Detection/index.html","hash":"41c99a91f48c59a1c8b4c54268f536031235807e","modified":1680918029817},{"_id":"public/tags/Pandas/index.html","hash":"3e64b6b6137f851a4d06894b764260341c6cfe58","modified":1680918029817},{"_id":"public/tags/Data-visualization/index.html","hash":"bc2db88a0e627a618b0f6094c0af002808d8f992","modified":1680918029817},{"_id":"public/tags/Polynomial-regression/index.html","hash":"bee4454b6988d499a038ab9491add31e7168ebf6","modified":1680918029817},{"_id":"public/tags/Span/index.html","hash":"f520df0c9fa40cdc76fb486e701ccd2f837d729e","modified":1680918029817},{"_id":"public/tags/Rank/index.html","hash":"815a6af9ffb7ba25424438b77ae51e1a4c06895f","modified":1680918029817},{"_id":"public/tags/Set/index.html","hash":"7adbd23c58801df19edc8e7ffb1f08d7f4c1cb5c","modified":1680918029817},{"_id":"public/tags/Gradient/index.html","hash":"55eeb8f4270d0f5debf68f397f38e18f1fed88ab","modified":1680918029817},{"_id":"public/tags/Sentiment-analysis/index.html","hash":"b58a5088b3d86fcfc29576f56a4c605cd1e8bb2a","modified":1680918029817},{"_id":"public/tags/MLP-classifier/index.html","hash":"ab87e549cb829458acf13e6b16a0ce0ab6e6deeb","modified":1680918029817},{"_id":"public/tags/Naive-Bayes-classifier/index.html","hash":"c122fed428247f72cb4c75b8b77734b2fb431747","modified":1680918029817},{"_id":"public/tags/SVM/index.html","hash":"ee1bd0751839c65a389cace41bcc73cfa8dc6bce","modified":1680918029817},{"_id":"public/tags/Random-Forest/index.html","hash":"3a939eb57f79ed95aecfff16fd550e4790d35534","modified":1680918029817},{"_id":"public/tags/Logistic-Regression/index.html","hash":"de64633e04e69c7b5ee23dc75de72e0be7fdfbd6","modified":1680918029817},{"_id":"public/tags/K-Nearest-Neighbors/index.html","hash":"bd79531355938df53a5c90f9897850c1281803c7","modified":1680918029817},{"_id":"public/tags/Decision-Tree/index.html","hash":"00411ea6eb0f2e07abcc6309a07f0b504ed3091d","modified":1680918029817},{"_id":"public/tags/AdaBoost/index.html","hash":"5208dde096132cffbce7657ea5131de8e074916b","modified":1680918029817},{"_id":"public/tags/Gradient-Boosting/index.html","hash":"a15e714792d3fa84671a0f4c51f9ce12575b8275","modified":1680918029817},{"_id":"public/tags/Probabilities/index.html","hash":"1ff1bf7f2d69ebefee19a2639959df689d77d1a1","modified":1680918029817},{"_id":"public/tags/Variables/index.html","hash":"1cb071d4f06bd5a717c40c851f0218174ad3aa43","modified":1680918029817},{"_id":"public/tags/Uniform-distribution/index.html","hash":"33e15202d6090632520156cbc092e01a1bd59f46","modified":1680918029817},{"_id":"public/tags/Normal-distribution/index.html","hash":"a0f2136e894325335e401df70e12ddafe507271c","modified":1680918029817},{"_id":"public/archives/index.html","hash":"921f19608079b58b8ff20787b762e60fb686a8c4","modified":1680918029817},{"_id":"public/2023/04/03/Scipy-optimization/index.html","hash":"00ed6e9612e1dd97167177b11d784096c2137b5d","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/index.html","hash":"18f1d7e82b23fccfd63148963e189cfc0fd25f41","modified":1680918029817},{"_id":"public/2023/04/03/Functions/index.html","hash":"c3fd41660da18e2f8298bf22d223f7aac1b97cbc","modified":1680918029817},{"_id":"public/2023/04/03/Relationships-between-two-Sets/index.html","hash":"a6712a189d1d692c47b9436826843ccd634282d6","modified":1680918029817},{"_id":"public/2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/index.html","hash":"5f3aa7a5202ceac359e1e7ecb5909274676226ca","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/index.html","hash":"6c63ea8c354469dda162c1bd7282161adc23bca3","modified":1680918029817},{"_id":"public/2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/index.html","hash":"bb5484c1633c084af2c8bb7b3d59fa06eaf73731","modified":1680918029817},{"_id":"public/2023/04/01/OpenCV-Hand-Tracking-to-Count-Fingers/index.html","hash":"1df919a3e1da4b8940ca0260fa4b7365b5538c91","modified":1680918029817},{"_id":"public/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/index.html","hash":"3530d3d8d9aacebda39ddc451f19d985cc8704c6","modified":1680918029817},{"_id":"public/2023/03/29/From-linear-regression-to-binary-classification/index.html","hash":"f7563076eef978978ec2f7598f0fe61e274a67b7","modified":1680918029817},{"_id":"public/2023/03/28/Gradient-descend-for-linear-regression/index.html","hash":"95863ac46269e9313e93924efc01c3409b140c8f","modified":1680918029817},{"_id":"public/2023/03/28/Regression/index.html","hash":"9b63ef70c1b2928c9a438fcf84a815d3515444f4","modified":1680918029817},{"_id":"public/2023/03/28/Hyperplane/index.html","hash":"99ad194270ad0e9a7dee5e12fa5d5a9ebf614fc5","modified":1680918029817},{"_id":"public/2023/03/28/Linear-equations/index.html","hash":"ecd3763f29c500cdf8da18c36665c83071b8f1b7","modified":1680918029817},{"_id":"public/2023/03/28/Pandas-Basics/index.html","hash":"2b3ae41ccbd44354d3eb7d6b2bdcac9852b0dbfe","modified":1680918029817},{"_id":"public/2023/03/28/Functions-Plot/index.html","hash":"53d3e61c5c687ca5ac40085643ea8748c1f8c4b9","modified":1680918029817},{"_id":"public/2023/03/28/Image-processing-using-Numpy/index.html","hash":"f1754eae32111cdb98eb8e3c3472cb4ea407bdd6","modified":1680918029817},{"_id":"public/2023/03/28/Numpy-Basics/index.html","hash":"e585c2d3c2af04a9ab9814da63bd610be6e11168","modified":1680918029817},{"_id":"public/2023/03/27/Variables/index.html","hash":"248a29d50e524eb73c3d8d8b9c981d9f5d8df415","modified":1680918029817},{"_id":"public/2023/03/27/Norms/index.html","hash":"102ac3d97992f3fe0607a47a7fb96a1185f2f4ff","modified":1680918029817},{"_id":"public/2023/03/27/Basic-operations-of-Matrix/index.html","hash":"7ed9d6d402eb9260dc52755c1be14b97a5d5cb09","modified":1680918029817},{"_id":"public/2023/03/27/Linear-Algebra-Basics/index.html","hash":"3febeceeca63699b41eb3f68a4e37dfe59fffe18","modified":1680918029817},{"_id":"public/2023/03/04/RGB-color/index.html","hash":"7ffd5a89ff03e00ce750d63197eb5d092db58525","modified":1680918029817},{"_id":"public/archives/page/2/index.html","hash":"bf51caee3bb43fade6dde28aa5f5627c552e0911","modified":1680918029817},{"_id":"public/archives/2023/index.html","hash":"53cbacf864681d62be7fa36aeedf2ab3c182b139","modified":1680918029817},{"_id":"public/archives/2023/page/2/index.html","hash":"f7ba91b620e23e85123ee4107c0cae284bc447a3","modified":1680918029817},{"_id":"public/archives/2023/03/index.html","hash":"65391a1e0698587c16585ea157e5bba6e5363d02","modified":1680918029817},{"_id":"public/index.html","hash":"582b34b3f97f48bcb8fcafa17b6400bfcd990e15","modified":1680918029817},{"_id":"public/page/2/index.html","hash":"c5b3060d7cff279e3b8b1d9c45fc306bf05264a8","modified":1680918029817},{"_id":"public/page/3/index.html","hash":"a2fa28d9f7ea6eb3028ebd25eac8d0c4049de1fe","modified":1680918029817},{"_id":"public/tags/Python/index.html","hash":"1340d7d76c03ad174aeb660ca717d29e858f7953","modified":1680918029817},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1680918029817},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1680918029817},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1680918029817},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1680918029817},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1680918029817},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1680918029817},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1680918029817},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1680918029817},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1680918029817},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1680918029817},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1680918029817},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1680918029817},{"_id":"public/images/me.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1680918029817},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1680918029817},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1680918029817},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1680918029817},{"_id":"public/lib/pdf/LICENSE","hash":"a8a12e6867d7ee39c21d9b11a984066099b6fb6b","modified":1680918029817},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78-EUC-H.bcmap","hash":"c84a5fe05bb2a5e4e599329d0ebb3ed8fe1ebfdf","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78-EUC-V.bcmap","hash":"678dcba8720226133150374f78493cc09c9b8d9e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78-H.bcmap","hash":"e77449427a5d5411c9da1c1a64e1e3ae362bbcdf","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78-RKSJ-H.bcmap","hash":"5f0f202932865c38e7b0b06924e419c77f74be85","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78-RKSJ-V.bcmap","hash":"3fa6830e3e5c6b0cc5d03402cfb6712a04c08d31","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78-V.bcmap","hash":"c58a521bdfad6ffe30e292505992a396033d03c3","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78ms-RKSJ-H.bcmap","hash":"ef37df685e4779722b34fcc026b196b224bfca13","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/78ms-RKSJ-V.bcmap","hash":"27d45708491107b2cf673c2cd584bf22ca27e4e4","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/83pv-RKSJ-H.bcmap","hash":"c4474f77d94be66d771ba68f18ff2fd606a3c820","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/90ms-RKSJ-H.bcmap","hash":"994ca6d6232d91be047c68e087e0951dcca4cba4","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/90ms-RKSJ-V.bcmap","hash":"c4ed8e0b82fc29ff6140c72ec8ab3acc3cd0578f","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/90msp-RKSJ-H.bcmap","hash":"d3f02d6724d9c91d077ed38545c9321dba65b624","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/90msp-RKSJ-V.bcmap","hash":"ddfc0fdb34314f2d7116d707fa6dbb24bc9bf390","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/90pv-RKSJ-H.bcmap","hash":"76218acded94b2d29f747735e7fb41f19cee84eb","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/90pv-RKSJ-V.bcmap","hash":"7296d339f5c1d843b823482fa2b3857c0559eb93","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Add-H.bcmap","hash":"cd55ec3d5627b80505d7dbea433e5702f8c05260","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Add-RKSJ-H.bcmap","hash":"9a17c268decf876dc35c5f20c660ee63563fa523","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Add-RKSJ-V.bcmap","hash":"0e4ef11ed7f4e5ed3b2e32f267f4c3fb4359d08e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Add-V.bcmap","hash":"02ca7b80b507640df998e9b5f6d25b346082d8c1","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-0.bcmap","hash":"241cccfc85b5ef9ea4618f94a6341e02d1b03b98","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-1.bcmap","hash":"f37b5b68198690c8270322daa0ea522225a46127","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-2.bcmap","hash":"a568bee71b12ec4e79a2fa65c4eb9f865c505a5e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-3.bcmap","hash":"ef567b58254e03837d46e1fdff4fea5cce318a74","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-4.bcmap","hash":"5f81f4782a5f996649dc318c1587ae7728afd10b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-5.bcmap","hash":"b7de7cea41575c7933cffdb917ad1f918df76c70","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-6.bcmap","hash":"4eaa2ec548df7cdbdece2eec227fdb9d4cb2f281","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-CNS1-UCS2.bcmap","hash":"bee971d04cae79d791a52bf0d3d5e2e9deb1d1c8","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-GB1-0.bcmap","hash":"86edf145080d2fedba2f0a0b0ab1bc18d9a5af55","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-GB1-1.bcmap","hash":"83cc28efd5e778b9d37898f9b100b502bc442dc3","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-GB1-2.bcmap","hash":"a3ce0132af54173d30a4330314bc4cf273fc29c8","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-GB1-3.bcmap","hash":"c7b6cfbeac681010771d022d319913c798416d75","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-GB1-4.bcmap","hash":"cee3007bb41ed1bbe7fd22f054c0fb036a92c8cf","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-GB1-5.bcmap","hash":"a7d9440784d773507e3d83d0bf93fa8d93a3289f","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-GB1-UCS2.bcmap","hash":"23366624efa674e2493a18bf6b6e2c16929d68d3","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-0.bcmap","hash":"ce5b494e809c30621968169d01d1136f3ad1ce3c","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-1.bcmap","hash":"a766b29745a30aa3316cafc73d884c271cc12ff4","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-2.bcmap","hash":"78c4e86cff8aa1c2f2bc18aaf83095a96f0bca50","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-3.bcmap","hash":"5b520d2cf37e21b084bc9e6a21d006c53e4e552e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-4.bcmap","hash":"4136c902f4715ed18b8b2390965d3621d2fda048","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-5.bcmap","hash":"38970fd416a1c3ef4faa25009254347627d24964","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-6.bcmap","hash":"dfba7ab251b5ac07d7648c4e81e808ea096578c9","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Japan1-UCS2.bcmap","hash":"d99c0d908b8075afa69aa3c579a9393b13b29dd9","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Korea1-0.bcmap","hash":"ca8e1774cdd2859ba0341e4474d07d6fb2f9395b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Korea1-1.bcmap","hash":"e9b783963160380ccfe33fa1dcdd9c79b1cf2934","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Korea1-2.bcmap","hash":"0b8d7fd848de3efa86f958c6e1cf5aece9bf1bf4","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Adobe-Korea1-UCS2.bcmap","hash":"15e4e07c96891a2bb2778b5df8dd0a131edeed52","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/B5-H.bcmap","hash":"771d71153bf652d1134b7d65beb8afc60c835ff6","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/B5-V.bcmap","hash":"dfc7362c157c24651761e5216ef0c46aba795488","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/B5pc-H.bcmap","hash":"29d5fd41dc8fc4f19b59949b9a7f410d63f4f3bd","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/B5pc-V.bcmap","hash":"f12ae6ed2320136959420e28b1b937001cdd4f0b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/CNS-EUC-H.bcmap","hash":"1da78eb52781330148c95ccf64c78edd2072a991","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/CNS-EUC-V.bcmap","hash":"895fe039258dae00d7a8cea93b3b07d794543d2d","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/CNS1-H.bcmap","hash":"07f422b28ca4fedf2cdc6ccdf551eaecae40f60b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/CNS1-V.bcmap","hash":"7455bd92e1a1f32bfd2cb5b80eb938aa665f6b8a","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/CNS2-H.bcmap","hash":"0570a8186311bba4ad216250f805461220d41d0a","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/CNS2-V.bcmap","hash":"c0870c3fad8349e3391ff7cda29d1f3a917e27f1","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/ETHK-B5-H.bcmap","hash":"225205ad3aad58967faf23a2504731abebc6dccc","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/ETHK-B5-V.bcmap","hash":"03e35e7fc1b75495df5559a3f71c5f0cbd1517ba","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/ETen-B5-H.bcmap","hash":"9c3b70700d7ae2b8c4cc6f658cdc98f4e65b3be4","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/ETen-B5-V.bcmap","hash":"5b637fa1b203754d98463053b38a2f694cde499b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/ETenms-B5-H.bcmap","hash":"1207c931295ad5f57a430317d5014fb66d0eab7d","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/ETenms-B5-V.bcmap","hash":"631c58a7f7a8094d44a858d26485ab65b499b59b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/EUC-H.bcmap","hash":"f88729b6a413ae1365bafb5dc8076b465aa1fb87","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/EUC-V.bcmap","hash":"c47c42d9099caf1447498e57fc1c8f3c7ff417b3","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Ext-H.bcmap","hash":"4b6a27e1125bb11bf9fd8fe9c5375f7781c95204","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Ext-RKSJ-H.bcmap","hash":"e1c2563a6d785aa5e30de423911d179fe79ec957","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Ext-RKSJ-V.bcmap","hash":"5443591823737ba98993537c4d4e8af70a37c92e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Ext-V.bcmap","hash":"0d88a7517783f25ce1eee082a5ed12b0f96061c2","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GB-EUC-H.bcmap","hash":"4231eab22968baa29ea4e6fdc4278b737067a7da","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GB-EUC-V.bcmap","hash":"7d268732b300431fced1351b4bfd12b51299283e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GB-H.bcmap","hash":"3f1c2a68bdd13541e6a2cd6a7a393581e9444e1e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GB-V.bcmap","hash":"b70477a9738709f639adf6bc20e81363efcc9ed0","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBK-EUC-H.bcmap","hash":"08986b370ac27b60cf8cd7023c9e49f6b784b52b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBK-EUC-V.bcmap","hash":"4f0e0cfffafa21b30f7a25e5161738faf2e265fe","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBK2K-H.bcmap","hash":"a36052b8b5d7dc1dde2b721437d6abc90ec7cefe","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBK2K-V.bcmap","hash":"d27b6916b7de1993464e5f33822f176fdc8e949f","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBKp-EUC-H.bcmap","hash":"a8785a44403f130097ee9a23c3923d5af252ac51","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBKp-EUC-V.bcmap","hash":"717f6d6585184bfebb894e59868886ab8f3c38f1","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBT-EUC-H.bcmap","hash":"e2dda44896a41f4fa817c5397f17894763b7623e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBT-EUC-V.bcmap","hash":"9d6ef5fa295e3005d620904754d7cc16104be908","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBT-H.bcmap","hash":"62508bbc22bcd3795e4af2c7fa3cfddc71367813","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBT-V.bcmap","hash":"2f0936e0bd4362f7c6f8c2b56642d6483366cd11","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBTpc-EUC-H.bcmap","hash":"388eb76b53b008d90dfe68c1e3288314b21c3cdc","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBTpc-EUC-V.bcmap","hash":"ce125f52097c71fc83631577977ac267b8901c78","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBpc-EUC-H.bcmap","hash":"5c34efa7cca4e2f652f81f4498fdf41db1b7b1e6","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/GBpc-EUC-V.bcmap","hash":"36004a6bedae0edfaea620a7d8f61cfb875f9640","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/H.bcmap","hash":"149c08c0eadc405f6ba64adac9329fdb300d11ab","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKdla-B5-H.bcmap","hash":"57ba02cf438eba88d2071bd99d1beb816b438b9e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKdla-B5-V.bcmap","hash":"035e4064559dd56ceb0f06c3ac1c2e766aeffe62","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKdlb-B5-H.bcmap","hash":"2be77ea4f4cd8a338ff7007d314773582f565efa","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKdlb-B5-V.bcmap","hash":"3dc79100304f82ec559b70d120100f6ebe6ab5c0","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKgccs-B5-H.bcmap","hash":"dbaa1026222370fa6e3275c98e3bdb5ef3d37709","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKgccs-B5-V.bcmap","hash":"6f22784990eb168bcf9192e7e36de18e08927dfb","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKm314-B5-H.bcmap","hash":"cbfb65ab0cae690e7679a1769de521ea20fb6602","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKm314-B5-V.bcmap","hash":"3ef5f7e35ebffe68dea8ea757cdceac5b8151372","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKm471-B5-H.bcmap","hash":"a75f2e32e5495d46e14b1d07ac124b3fc675ef1a","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKm471-B5-V.bcmap","hash":"2a6f2cc4d105f464432187daeff7b81040c093e4","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKscs-B5-H.bcmap","hash":"45f1793e771de030af89938eed23fff4c7daca3a","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/HKscs-B5-V.bcmap","hash":"fa5b3a1f0b3ab6bd614f8a39c9ab80b203daadf5","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Hankaku.bcmap","hash":"dfc2f635dd66602f9978ae3fe72695a02e512a6a","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Hiragana.bcmap","hash":"10e7a0f20cde8865a1dd3086a89f2e96e330d1a6","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSC-EUC-H.bcmap","hash":"bc349367bb60b06af5fdeeec05047f596ac71ab3","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSC-EUC-V.bcmap","hash":"4529ddac78c931d63411b6061b0af740b4c44ca5","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSC-H.bcmap","hash":"42e15fbce70bdec4f7bb5b2cbd02b0efd8bc65fc","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSC-Johab-H.bcmap","hash":"3585accc6e6957eda55302393fd9c3a563db6cbb","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSC-Johab-V.bcmap","hash":"e68b770b37b591884c459d6ce3bb43bc4556547b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSC-V.bcmap","hash":"22b097fd376c21e40a0f9392961be74acc316343","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSCms-UHC-H.bcmap","hash":"4e0ed017a2a41ee7bf6eacf0f7e6b40ae60d223d","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSCms-UHC-HW-H.bcmap","hash":"d410341b19a6f05e0c20ea4a1a77078a3084044e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSCms-UHC-HW-V.bcmap","hash":"6cfeb36f492702aef5ce5b7671342291010b29e1","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSCms-UHC-V.bcmap","hash":"3de7c5c70cf172ff560a62d5dfe84a9336b4f5ad","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSCpc-EUC-H.bcmap","hash":"3705fd3621117a7e5a3772c3849c5d69620ef08f","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/KSCpc-EUC-V.bcmap","hash":"1d3a11932c44a5fa8fa22efd2bd3dba7db9a2c8e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Katakana.bcmap","hash":"da100ad00f2a9ba196892bfb4d6644ec828a4fcf","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/LICENSE","hash":"1afb5991fce0d60110b5092b68bf9ff76b0c73f6","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/NWP-H.bcmap","hash":"7d0f51c52d7a96bf289d0c6454d7e9dccf009c15","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/NWP-V.bcmap","hash":"891a866c52b46e7526123799a829db24ac6cda4f","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/RKSJ-H.bcmap","hash":"a4f7d5cdd13d3008cc42d82f69672d9e50a9d5b3","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/RKSJ-V.bcmap","hash":"16ae42a46e7eb92ca048fe24649b668c5103b4b2","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/Roman.bcmap","hash":"5755781c7e9c50cc8192426d8733a506382b5fdd","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UCS2-H.bcmap","hash":"7f289b94c643b7cc43d4936078143a2347ca0fc1","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UCS2-V.bcmap","hash":"6b19ece5c921516431eb94d28d74080fdd7d35bc","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UTF16-H.bcmap","hash":"d73d55388c76932033915cea627bb628edad4f66","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UTF16-V.bcmap","hash":"0f7152f2845cc2be4d3ce7e0e1530639ec4162e3","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UTF32-H.bcmap","hash":"a5872864e2b121c1df5068a54201ed166c69d5f1","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UTF32-V.bcmap","hash":"debaa98acaf13f341a5003856ef6a6a7df8f6e14","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UTF8-H.bcmap","hash":"734ad1a00033d70c195c81358b643c7cba1327b2","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniCNS-UTF8-V.bcmap","hash":"019bd0716b2aa80bc1bcabfd389d3d5e1065ba8e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UCS2-H.bcmap","hash":"868238e34cb9548c4d138af1adc1a4bea62dec37","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UCS2-V.bcmap","hash":"f5853ca83c25b888c1d925e2a20ef44e064d064e","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UTF16-H.bcmap","hash":"28963866dfb575b58b4370e60ebd9bfb6e56ac09","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UTF16-V.bcmap","hash":"1771376eef979ad42c2b5c01a1af1d34f54580b7","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UTF32-H.bcmap","hash":"b9ea278eb4c324d12a81e2d62479548d1e7126cb","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UTF32-V.bcmap","hash":"8167ba503aa8a6c805f39be0ca538b99898a967d","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UTF8-H.bcmap","hash":"09cc7750f69da77434093e4c94211394f5665eda","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniGB-UTF8-V.bcmap","hash":"e23616fa12132c73f52071b96e76d876430ececf","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UCS2-H.bcmap","hash":"caf525125e29fa4de78088e5eb1785c1af1f9950","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UCS2-HW-H.bcmap","hash":"97cbb8599cf62914885a8b2b47594865fff52099","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UCS2-HW-V.bcmap","hash":"f36bad9c680f4bba6cbcf8ac57f53e7ce21c806b","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UCS2-V.bcmap","hash":"45396576a6bd5468a84e2c2e4ae64c23fe7f2e85","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UTF16-H.bcmap","hash":"16499e93f0a447a94e1e44bfa9951401d290d89d","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UTF16-V.bcmap","hash":"44402b8f73e0b0160846b641e7cb2e75ab8c81bd","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UTF32-H.bcmap","hash":"bc482114d214e2fffe85dd0b7422f48c3e282c17","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UTF32-V.bcmap","hash":"2f5ec2584fd7c39f455161a857550fa7fea5f53a","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UTF8-H.bcmap","hash":"f47956c1c7b2eadbda93aac25fe4546b413ec0a5","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS-UTF8-V.bcmap","hash":"b3ea8d2172a2f6f9e73cf62ae467aa84848df6d7","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS2004-UTF16-H.bcmap","hash":"b8b0cc6779d3960426899fc2e7cf2866ffc80167","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS2004-UTF16-V.bcmap","hash":"2872cb273dab9d0dbb7f331826045df18764a7b0","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS2004-UTF32-H.bcmap","hash":"f48723212d1ad18c0b3c41168d6f630798e04160","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS2004-UTF32-V.bcmap","hash":"ef16ccb3102fc44c1d46f4cad40cfbdb020ee277","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS2004-UTF8-H.bcmap","hash":"385ab762d03499d35539048176928e031e5340d1","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJIS2004-UTF8-V.bcmap","hash":"565560a59d5174ac379a8d91f165c8ecdef54e06","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJISPro-UCS2-HW-V.bcmap","hash":"3f0a364246717707db82913593304cb7bd37c378","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJISPro-UCS2-V.bcmap","hash":"b1a47305fa79afa19ab696d33af5099d35570c56","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJISPro-UTF8-V.bcmap","hash":"ed6b571aeed388d3b53b9e65824af3f0146a5857","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJISX0213-UTF32-H.bcmap","hash":"15c953c36436d32f748ec7468a95c3e5843d70bb","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJISX0213-UTF32-V.bcmap","hash":"dfbe3e295505977b4e1881ef30b80362d7406bbc","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJISX02132004-UTF32-H.bcmap","hash":"c41dd50df01e3d3331f0acdb6da6c1b857a67cf7","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniJISX02132004-UTF32-V.bcmap","hash":"9c48a0c654acf4bcf51defde2f7d8b3ce52a063d","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UCS2-H.bcmap","hash":"50fcce1b2e3224791b480289e7c4c42938beb854","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UCS2-V.bcmap","hash":"6743b3e07370fd49962b97d97be77dae8d18aabb","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UTF16-H.bcmap","hash":"4f4603408966d9ac29a96c3a6755b9f23e7aa953","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UTF16-V.bcmap","hash":"cfdbfbf0b0e8ef98fef6236ea570c73465da1581","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UTF32-H.bcmap","hash":"6b0e98e16418fa5a86338b3fb361f1700971f649","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UTF32-V.bcmap","hash":"73bd343b188a80471eb156655f5b192903f86cbf","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UTF8-H.bcmap","hash":"8117d31e498a8f0fb7c223c4172ba881c0496c6f","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/UniKS-UTF8-V.bcmap","hash":"586c64948a67e4cb12de64e221b0dc3d9e47dedf","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/V.bcmap","hash":"99790f12ca21a196bc1d836ae5bf0ad7af95e079","modified":1680918029817},{"_id":"public/lib/pdf/web/cmaps/WP-Symbol.bcmap","hash":"3a6417abad460a1a083be75636c014f3a73937b5","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-check.svg","hash":"015d03ffa6a0ce93b41ed93a262879e4f8cf72fd","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-comment.svg","hash":"5ec875153d5046507050a3531422ca69b44680c7","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-help.svg","hash":"2f3d88f4e8cefafc2d76932104f6b2517034af2f","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-insert.svg","hash":"7a12af74ef20d5249a0c330d992bd1132308cbac","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-key.svg","hash":"d9224d3aef774d6ecc9735b440810ada4384be11","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-newparagraph.svg","hash":"453ba47aa10b6fcf8459569e0a550b4f91260ec7","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-noicon.svg","hash":"5a5447e5c39cf7ca748853a15dbd835ddaa3b5df","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-note.svg","hash":"6100deeb6121f98c7e024ec1a273171207c84c7f","modified":1680918029817},{"_id":"public/lib/pdf/web/images/annotation-paragraph.svg","hash":"70591a3b26c56815c6e5ab2bae959e8a951c43fb","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-next-rtl.png","hash":"d02c4e9bf493dc83029098e59b6ece2363f3c760","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-next-rtl@2x.png","hash":"f9f2cea77208aa0e219f3bed69e22861c2858bc3","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-next.png","hash":"4bcb69c72d25d822dd09a3999c6972c0c311f04b","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-next@2x.png","hash":"dca2a1a3bdbe036735dda32e5ed909b029829a3c","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-previous-rtl.png","hash":"4bcb69c72d25d822dd09a3999c6972c0c311f04b","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-previous-rtl@2x.png","hash":"dca2a1a3bdbe036735dda32e5ed909b029829a3c","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-previous.png","hash":"d02c4e9bf493dc83029098e59b6ece2363f3c760","modified":1680918029817},{"_id":"public/lib/pdf/web/images/findbarButton-previous@2x.png","hash":"f9f2cea77208aa0e219f3bed69e22861c2858bc3","modified":1680918029817},{"_id":"public/lib/pdf/web/images/grab.cur","hash":"fbd667e863c8278950e7761aee54b394cd93ea0c","modified":1680918029817},{"_id":"public/lib/pdf/web/images/grabbing.cur","hash":"f30d68405751e730ca94ada8628df45b4839931f","modified":1680918029817},{"_id":"public/lib/pdf/web/images/loading-icon.gif","hash":"e043879d3ee94a3edf10260f21f44bfa4a6fc66e","modified":1680918029817},{"_id":"public/lib/pdf/web/images/loading-small.png","hash":"c1abf9b89af7392824f2228312785a899df224a0","modified":1680918029817},{"_id":"public/lib/pdf/web/images/loading-small@2x.png","hash":"171aeb1a90c2836c639438fa85c64cd9d94b3516","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-documentProperties.png","hash":"6f1e0ce52dae6af31bb3c5b09bbb33a33849fd08","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-documentProperties@2x.png","hash":"bd55401797e24ae5066afb9677dca1463e74c839","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-firstPage.png","hash":"453a575f2676ba39eacc71c074420d6c97c87a42","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-firstPage@2x.png","hash":"fd24d7a57e2a1205a67a11a760eb6dd50748da26","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-handTool.png","hash":"8db06773a09e2f407bdf7ce448777398b40fd313","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-handTool@2x.png","hash":"eb8a16519da1e074f9ed07e8a350a6b0d52e5339","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-lastPage.png","hash":"6819bdd3000af84c50df1b10b55b3af33944a261","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-lastPage@2x.png","hash":"2fb45311e8ee9658cc4276f1202ada9a55df774d","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-rotateCcw.png","hash":"548451d8a12570d66bce4c8922d8ccffb63ca61a","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-rotateCcw@2x.png","hash":"84f034b57d24f7371d1a605bd12afa1f71b50f1b","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-rotateCw.png","hash":"252e8a4adaf406c4e9c78033d8d8163333ce4c1c","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-rotateCw@2x.png","hash":"f37e80bc600112fa88251e53e953f14946967e19","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal.png","hash":"67ec12c5bfe0d933f62e1bdfb2154db263e24712","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-scrollHorizontal@2x.png","hash":"0f23b007fe6be937bc1072737e60cf10e4b8c7e1","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-scrollVertical.png","hash":"3509cb4c7f355106103aa663fdcfbba6143f1d96","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-scrollVertical@2x.png","hash":"a80753f432677766ba1cfbf3677bb9498998efd7","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-scrollWrapped.png","hash":"4409af25572feb6ac02d9f0ddcbd5ea689b3dd05","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-scrollWrapped@2x.png","hash":"8b0ebf82e3f20a7e6cd93ef80b4ac932a02512c5","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-selectTool.png","hash":"f62d271d5403f35e372b2cdf4c892aac7d364665","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-selectTool@2x.png","hash":"9a10930334b9a42429c967b77f8c7e705e31cdaa","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-spreadEven.png","hash":"d27a628de5e1a4ce508c39fcb496b50f3d2d0fa0","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-spreadEven@2x.png","hash":"616b232b0f166467d0c37315709508953fb79358","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-spreadNone.png","hash":"a6648371ee01d687db409f5198f30dafaba76b6b","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-spreadNone@2x.png","hash":"5833ee8fa2394db83739ddbb5f9f0f3f0d39709d","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-spreadOdd.png","hash":"ff70929f97f54c2722e890a38070f749cefd12ee","modified":1680918029817},{"_id":"public/lib/pdf/web/images/secondaryToolbarButton-spreadOdd@2x.png","hash":"07f1a8754f63dbb8d480e0923328c9fc0336fd2c","modified":1680918029817},{"_id":"public/lib/pdf/web/images/shadow.png","hash":"02b6adc1ca6ad8f57605ee92943b65c6250d73ba","modified":1680918029817},{"_id":"public/lib/pdf/web/images/texture.png","hash":"230a3d5e2dfacfa7228f58a559de5df3734118f5","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-bookmark.png","hash":"0193cebc494facb8ba8733a1a8f50457e7189f56","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-bookmark@2x.png","hash":"f822c6228ea6f9ad2ee5465ace31c725cf3289c3","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-download.png","hash":"b25abd4a3c95097a338b8b138476e22189cb235e","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-download@2x.png","hash":"6c2ddead63c9a9ac3371bd7b8b8b914e2f81d605","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-menuArrows.png","hash":"acbbc7071a0641a10e1d50991d1abbfa26b5dce9","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-menuArrows@2x.png","hash":"fdb29640d1f7ee31b09550163f85e01a70cebd13","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-openFile.png","hash":"6b17acd1c4ea6a9d9859819456952eff133f3cc1","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-openFile@2x.png","hash":"ae13be299d7c18dde70d975d0e229d3e20137afd","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageDown-rtl.png","hash":"641a0e2d711ec06176c046d8efcdff670da876ef","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageDown-rtl@2x.png","hash":"445833e5eebdcc99270b879d0079bb54310f1615","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageDown.png","hash":"6e10286da3a52e0bba782d0fc4a7c33d10c8f4b9","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageDown@2x.png","hash":"2b817130c3724f8a864845b03a142bd7e1cb61e9","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageUp-rtl.png","hash":"0529bff456111ea1a264771afdcb2daebe68f79a","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageUp-rtl@2x.png","hash":"1507890ff466f28f78ab7bd9f6eebfe2e4eeee8a","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageUp.png","hash":"b1eae4614fb964b6d0483f114f3dd2b49ec1b64a","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-pageUp@2x.png","hash":"9960af5e2ff7dfe8aba862d77305f409f5f1405c","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-presentationMode.png","hash":"3d206e303f9663dca95482df9abe55a08851c574","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-presentationMode@2x.png","hash":"c2d54d6f77f831963132555599e7314d4f07b49a","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-print.png","hash":"77463c425966b8a298a2d87863533e68092676bc","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-print@2x.png","hash":"7577a46df5fcc89846737010a14878bffa85098e","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-search.png","hash":"14c3ef60d3979df9e8d13cf39cad10ed043f5578","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-search@2x.png","hash":"25c50114436d8d598416a5c3eed9e1db282c43b3","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl.png","hash":"990118984a946a8c63d95fd1a8d8af848383118b","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle-rtl@2x.png","hash":"51055db76ce1e9935fa3d91aaece874c6da14147","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle.png","hash":"6cedbeddac0d6191afe09cabed7b6d517f7c7b21","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-secondaryToolbarToggle@2x.png","hash":"6f1dca07696408ce28da5621ebcac57d0b2031a5","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-sidebarToggle-rtl.png","hash":"422b5ed725be51f60e6339da94e0c959ad67990b","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-sidebarToggle-rtl@2x.png","hash":"29eade71266a6c4b1048eeacb1c29411435bdb41","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-sidebarToggle.png","hash":"ff7ef30371233abe8c548c2f3d5cbb335183ca92","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-sidebarToggle@2x.png","hash":"04c42cddc1e2bdd5130c6fa477ff3fa594edda56","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewAttachments.png","hash":"53c5a0c4c40f5f47fb6d2f57a82a4a6d0a83feb0","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewAttachments@2x.png","hash":"eb96df312c7ff6fc0451795bc0de8ebadb72cf86","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewOutline-rtl.png","hash":"e6214527b9354eb920cbec85e6fe4e1296b7ae15","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewOutline-rtl@2x.png","hash":"6684f9d7964446ec66a8f3865445892187d16d21","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewOutline.png","hash":"ec7aa605c063faf6a951c2d64a8d98933b60f6a4","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewOutline@2x.png","hash":"76be930d871fbd1ebd6c4d76c4fa325f32efc624","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewThumbnail.png","hash":"f62aad7c7719300f1d8e922155f451661d41d42d","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-viewThumbnail@2x.png","hash":"ececa7ff064700efde72fa1e3889c8a1a3073dbc","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-zoomIn.png","hash":"838adbe15d84daceec25cfd4d8d6ac1580b4f693","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-zoomIn@2x.png","hash":"5403ddbeed138cc733020c352ae3bcd8cac03bf7","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-zoomOut.png","hash":"63a719d5e6a708a22014f20abc0722cd54ffb0f6","modified":1680918029817},{"_id":"public/lib/pdf/web/images/toolbarButton-zoomOut@2x.png","hash":"4006d4387f2b0a0f0856d691a8874f74f61d0f51","modified":1680918029817},{"_id":"public/lib/pdf/web/images/treeitem-collapsed-rtl.png","hash":"7c2ff883f666ac379b04d0d41e3e6ddb14ddf220","modified":1680918029817},{"_id":"public/lib/pdf/web/images/treeitem-collapsed-rtl@2x.png","hash":"0465b8f9e77135e2bddd5708d425d5e1fc4ab63c","modified":1680918029817},{"_id":"public/lib/pdf/web/images/treeitem-collapsed.png","hash":"4588ca9c86db15c10de4de3f340111d4ce211ebd","modified":1680918029817},{"_id":"public/lib/pdf/web/images/treeitem-collapsed@2x.png","hash":"3229d96b4fa4d7e5c26fc135264d134e1024baab","modified":1680918029817},{"_id":"public/lib/pdf/web/images/treeitem-expanded.png","hash":"b0b4bca3d9bd0949da19a56214143db18f2a4f69","modified":1680918029817},{"_id":"public/lib/pdf/web/images/treeitem-expanded@2x.png","hash":"bf924ff993236e563dab83b41193bcb43120c0b6","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/locale.properties","hash":"e29c4ff2f77884ad77b3349d0efa7d83e236ddf4","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ach/viewer.properties","hash":"5e8f73b253c0e10d11909b41b0c9774ccbffc7a4","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/af/viewer.properties","hash":"4f79c194d6b404ffbec112aaa55ad4b016b9d93f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ak/viewer.properties","hash":"7b32cf30fd16432bc4050919607659c5e7ac7fe3","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/an/viewer.properties","hash":"a9505349d70da8f3b2821f2ee66b9074156cde3f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ar/viewer.properties","hash":"a50d00bfc03341506149bac8c4a68369d464be16","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ast/viewer.properties","hash":"27977540f13015e2087a3b7551e15d8a43bb3b7f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/az/viewer.properties","hash":"24bdd9fbbb8959b54bbf90a86872e61b088a63ba","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/be/viewer.properties","hash":"af1f8303f1c0d8878baae3e4645908e5142fb704","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/bg/viewer.properties","hash":"40860051d53e2d87860c1115c11d6a3e03ce7036","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/bn-BD/viewer.properties","hash":"684f603efdd31daf880430192a327bd3ac4bb3d2","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/bn-IN/viewer.properties","hash":"4b5286d177fba02adf8aefef7238c202fc7e254a","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/br/viewer.properties","hash":"8cb4f970c6611c34e3eefe2a9ebbdfe254e5194d","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/brx/viewer.properties","hash":"91aa4facc79d453adc42518c80b5b79500c55544","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/bs/viewer.properties","hash":"5321ec163bf54b4a2be4830d796a5a5b732db76b","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ca/viewer.properties","hash":"28817ae36a8e7376a6f4a651e58574c5cb79f13b","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/cak/viewer.properties","hash":"210fa52440bfbb06f09b0020b14f6b04eb50f639","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/cs/viewer.properties","hash":"ecbe632692940349b8b349372157ba7c915c37f7","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/csb/viewer.properties","hash":"17e840af72cb4451a586e70f5a7c7bfeb9c20683","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/cy/viewer.properties","hash":"2aa2ba4c18b7e54061ef92e7c0f90cdcc325d156","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/da/viewer.properties","hash":"baacb40f0b6bbd40000115c9f562cc56e098ca67","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/de/viewer.properties","hash":"3973c90e85e3144adf9abae6b694904620d4b93c","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/el/viewer.properties","hash":"b911668ba0074c41689e6fc37d930c7fca28ff90","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/en-CA/viewer.properties","hash":"364f9ef3fbf161ee4c0b9e8b15dc631ca40aa58a","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/en-GB/viewer.properties","hash":"364f9ef3fbf161ee4c0b9e8b15dc631ca40aa58a","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/en-US/viewer.properties","hash":"af2f36748974bba36ebaefe663a3b2dfacc4306e","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/eo/viewer.properties","hash":"92949a390017c2932c876a67ffe347c235fd51c7","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/es-AR/viewer.properties","hash":"58e1f0f130d88aa16ffef0707b52260e35fadddc","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/es-CL/viewer.properties","hash":"1969968b1aed118b85bd263b71ef518a6b8b5941","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/es-ES/viewer.properties","hash":"b018f218210363c96afff42a0a346d8218151d50","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/es-MX/viewer.properties","hash":"e74a68a1275022a7b5017eede7423485ae962837","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/et/viewer.properties","hash":"232b9fc34da10c1d15699444ce71db8ac1beba61","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/eu/viewer.properties","hash":"d96895429a2b41bc036dffc770023c4421efe539","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/fa/viewer.properties","hash":"01d1c935374f5b0ae23f0d914c8e1a0980a8dd52","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ff/viewer.properties","hash":"74fd6d6e5a7f01e43f6723e990240bdc1a7dec7c","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/fi/viewer.properties","hash":"f4a032df50cd1e46afb79bbd88244f13967b88a9","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/fr/viewer.properties","hash":"7a3b57afe7c681033825ee010e28e0b68cd9212b","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/fy-NL/viewer.properties","hash":"b03e41eeb6498f4e3a2e3ad239b6ffe12e0b710e","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ga-IE/viewer.properties","hash":"f319b460b796b9c703927444f9013d0316cbe3c8","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/gd/viewer.properties","hash":"7ec1051e104e798c17cf0cc424b3cc9278c5099a","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/gl/viewer.properties","hash":"9df8ec36500ccf36646100ab4ed0a45f695afacc","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/gn/viewer.properties","hash":"c16d4e9109b81e14e58d0207845cf432877b1571","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/gu-IN/viewer.properties","hash":"5ed0a1391863eb7c3ef0afff0752cc93cc4d1306","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/he/viewer.properties","hash":"f681e165a1954964a2f1c8198d4367afecb3568a","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/hi-IN/viewer.properties","hash":"4102ed54688a55875cdefc42f0ac8bd32b54df42","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/hr/viewer.properties","hash":"7b33f2d679ae34765b90c1b087690743018bdd83","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/hsb/viewer.properties","hash":"52cafacd8cfd5a2609ab342288f0453a99f3821f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/hto/viewer.properties","hash":"4e6fc5d6b807cfe56ccca952a01c4630670f63f8","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/hu/viewer.properties","hash":"7d4c2f500b0aeeff09d3fc9c9d79459a4ce8576a","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/hy-AM/viewer.properties","hash":"d15feb0c6de4534c35cbe224448429785f9d1d9e","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ia/viewer.properties","hash":"a98705ccd1ce97f215804d76237381b1232dc711","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/id/viewer.properties","hash":"efb85d06ca2c0e56642f99f921bbded8dd93ae36","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/is/viewer.properties","hash":"5ee3e9690eaec6b42e32b959c837f4dd7f8e490a","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/it/viewer.properties","hash":"3a9a93706916d7cc563f9ec81f28222fd5b34dd9","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ja/viewer.properties","hash":"7655b354201dcaff5713b491eada03dc4ac6dc62","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ka/viewer.properties","hash":"92913c545711ea38ff7744f4dc070d1d3baa4e29","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/kab/viewer.properties","hash":"0949e3aa980847f01317df14fc1c9915559f290d","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/kk/viewer.properties","hash":"7a756a94950fd9176605c66f1bb59ba6e87acbd6","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/km/viewer.properties","hash":"fa84c645561a6573737a401e0c14c512401f4220","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/kn/viewer.properties","hash":"7764695f91f82e74f29452d81b41bf634134f9e6","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ko/viewer.properties","hash":"28230518ad79bf4209325ed449520223bd46631d","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/kok/viewer.properties","hash":"d887d8a052a35be54159f58f7243372dbf7ec258","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ks/viewer.properties","hash":"4805e2e3aac56f9559516125daa1dcc6bc214875","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ku/viewer.properties","hash":"46739e80d58ab8559ccfb21d6b0692a37e16e6a9","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/lg/viewer.properties","hash":"18c1b9f7ca30c648bd31e31b15d16c876242ee73","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/lij/viewer.properties","hash":"f949bbb3bc2129cf6e1176c63b471035affac86f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/lo/viewer.properties","hash":"625438b69b56a04f2e45464f8c113cac82c7e4af","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/lt/viewer.properties","hash":"3b1cfbc3c6d6b51df4a01b025c972ef7d9ee5bd1","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ltg/viewer.properties","hash":"eff20b98155297340728776fc6117091fc6c3661","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/lv/viewer.properties","hash":"11556a8d2494811f17651c1eccfcb570d3dad35c","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/meh/viewer.properties","hash":"1024719401b6ab1922c872f2d7e58cfd60e6cd49","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/mk/viewer.properties","hash":"33cbeaf98eae66a5d37ce2e21c52c6700d0b0eec","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/mn/viewer.properties","hash":"7986acd89509d0467129b71ce25922ecfbd4817e","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/mr/viewer.properties","hash":"17be823b511abbc00250ecbd41b75743ffa6c0e1","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ms/viewer.properties","hash":"d556fd6c1ae83c1e48f16efe0bbef62d75beb51d","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/my/viewer.properties","hash":"28c90a2d281d43d509f7f72539eac9adc110456d","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/nb-NO/viewer.properties","hash":"15f68983d348b407527ab38c71d683f7e3e87ca5","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ne-NP/viewer.properties","hash":"276511a05f160ea500ac4060b4a5fd39d5735690","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/nl/viewer.properties","hash":"0e0fac0dd4fb595b47e01772865cfa5870d3ac9c","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/nn-NO/viewer.properties","hash":"adc3d40b11f97b5e6d254ddd672c64675948176c","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/nso/viewer.properties","hash":"176afe940078cca679275adf9dbc1ca1d6e8f7ce","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/oc/viewer.properties","hash":"d6fa7c4febc8c1d7bc4474670a60484ff0083083","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/pa-IN/viewer.properties","hash":"6b1b298820df47e1bd98c5cbd151efeb947d7028","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/pl/viewer.properties","hash":"493fa50175a829daa8254f1b1d7f3b25967b014f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/pt-BR/viewer.properties","hash":"66bea896ccc2f3653157bf241dfcfc525b420b21","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/pt-PT/viewer.properties","hash":"fb8b82049ca660944199991eb114e7559928df09","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/rm/viewer.properties","hash":"a38b02acefc80f44166dc090be31ef4ab275320d","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ro/viewer.properties","hash":"6a999f4a8c5072c029f8fab9997efae2a4a3fd85","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ru/viewer.properties","hash":"1784657fc48a6921388fbea00287a79cde218ce6","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/rw/viewer.properties","hash":"7d96bc96802f37a1c9ead373524a425d08e1dbcf","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sah/viewer.properties","hash":"ef69f15f4aa8ffcd0292b67519495ac962f0a846","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sat/viewer.properties","hash":"02709cba9da0380bdc9e174094769f5ae60bf8ad","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/si/viewer.properties","hash":"b1f41db0c4faebadb7bb91a44b265b50c6de0996","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sk/viewer.properties","hash":"2ded3adc04e47fa5b70f5829d3e1af80d8afe7f6","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sl/viewer.properties","hash":"aa5bb76131503a2f29ce853c2b6329088dfd072f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/son/viewer.properties","hash":"89384fd7cb2359b1360345c7169031b0509f8df1","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sq/viewer.properties","hash":"d996492e4770e38f0f99c9de4328ac90e0eb1792","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sr/viewer.properties","hash":"987c57c1ef644ad80e65cce437a7dfaf693c1512","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sv-SE/viewer.properties","hash":"6a907106906861bdcefd5da5b5a88ebef4effc46","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/sw/viewer.properties","hash":"7e5b770e8155a7465f77d1b2d7792fa22e50bcd0","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ta/viewer.properties","hash":"1428a3ae798b137138993313b0ccbfaf13cb26d4","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ta-LK/viewer.properties","hash":"646e2182307793f70a61584fc436886c946482c4","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/te/viewer.properties","hash":"151b8f9e20079c504cd5fb91788e1fb0fd506457","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/th/viewer.properties","hash":"59b3fa265599019597d9dafd0558c8a63c9d58ff","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/tl/viewer.properties","hash":"9ab570bebf0910bac1201c12b439d91ec4fbcef2","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/tn/viewer.properties","hash":"b1839a14243baf851f7811e5be779d8e0e147105","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/tr/viewer.properties","hash":"11294fdc4adad18e1f06d778f4b901273c11413e","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/tsz/viewer.properties","hash":"0e3086f1dea298a35dcc91dd78d5a24250f1c908","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/uk/viewer.properties","hash":"51432a861c9034db193cbb45c6a807ada8a9ec2e","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/ur/viewer.properties","hash":"f6db5457f03bcf3029cc15508accc1e05dfe7235","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/uz/viewer.properties","hash":"331a3fc72e3572d5cae07672b872f2d89b324286","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/vi/viewer.properties","hash":"bc6cc7571a6a64d6a4ad61a84687cf3955d143c1","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/wo/viewer.properties","hash":"1426459b8518b593673ac0b758407f2a228c89ba","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/xh/viewer.properties","hash":"4ce7fd8d9366220b4264e4ae712cf88348f4f83d","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/zam/viewer.properties","hash":"a186e34704f3a1ba4cbf22fce81c576ab6487ed7","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/zh-CN/viewer.properties","hash":"da462329ec0503c949b7268591af2f0847f9649f","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/zh-TW/viewer.properties","hash":"c0199a6f89e6a5ad249605152986d9e23341320e","modified":1680918029817},{"_id":"public/lib/pdf/web/locale/zu/viewer.properties","hash":"1c283ba7792aa61cad501198bd8e4d7b13fa5bb3","modified":1680918029817},{"_id":"public/2023/03/29/From-linear-regression-to-binary-classification/binaryclass1.png","hash":"8394c46e476f1a7fc4000891b1a65103ccae8cef","modified":1680918029817},{"_id":"public/2023/03/28/Hyperplane/binary_classification_problem_in_2d.png","hash":"f43aa4b38ce44b92459322f6a58e9be4b6638320","modified":1680918029817},{"_id":"public/2023/03/27/Linear-Algebra-Basics/2d_vector.png","hash":"4ed8e02445045b5ed7a0d1a642af684c87c50af3","modified":1680918029817},{"_id":"public/2023/03/28/Regression/Linear Regression.png","hash":"0aa79e9c10dc08f9be24c438da10f00331e609e6","modified":1680918029817},{"_id":"public/2023/04/03/Relationships-between-two-Sets/Cartesian Product of A and B.png","hash":"cfc16efecf47c25e60f58abd63ce1b11f0c71730","modified":1680918029817},{"_id":"public/2023/04/03/Relationships-between-two-Sets/Venn Diagrams for cardinality.png","hash":"aa1aa8872926c161655a93dbbc782eb2e3e06a78","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/AdaBoost.png","hash":"20f3611ee6d01d1ca43ca1cf963a9b376b64f5d8","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Decision Tree.png","hash":"e4f6111542b35e6f271fb6c8e6cc1bc2908b6ddb","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/K-Nearest Neighbors.png","hash":"b5b1f2adf0c44f57019f311df54b3ba27660a4e0","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Logistic Regression.png","hash":"118a78b4e5a0b783d6d4e51df53d3e66ecb6ac9c","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/MLP classifier model.png","hash":"f5a2c5c6b8f9a459324d3fd3ee4bc23ee5b931f4","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Naive Bayes classifier model.png","hash":"e0e548c7ccc8fc5ca62050793ee17fe58027ace8","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Random Forest.png","hash":"b8752bea3a78b780836d4c25a4ceaabf9d808d2f","modified":1680918029817},{"_id":"public/2023/04/01/Sentiment-Analysis-on-Product-Reviews/SVM.png","hash":"3dca107cc045961cb85f3390093a9c245230b4b3","modified":1680918029817},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1680918029817},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/Constrained_vs_Unconstrained_Optimization.png","hash":"01b0a1bdc11c2477fc78878a2bc55919736054b1","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/Interpolation.png","hash":"c9b4f26c34b75816ae1e4a4fa1efad25d99db46d","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/Local Minima.png","hash":"d0cee32d5d384c51fab110aac54a406e5fc645ca","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/Optimization.png","hash":"04bc99c3046879848a74ad8b916e8afaef61b7bd","modified":1680918029817},{"_id":"public/2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/predictions.png","hash":"7747d17c7e23df123892c4976dba54c14067c2ec","modified":1680918029817},{"_id":"public/2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/train_test_loss.png","hash":"417e06de75bff528758f3a5689e2c14919989921","modified":1680918029817},{"_id":"public/2023/03/29/From-linear-regression-to-binary-classification/binaryclass.png","hash":"d45717b392a936fcabe2081cc8cb4d43e9489bdb","modified":1680918029817},{"_id":"public/2023/04/03/Functions/Even and old Function.png","hash":"898ebaaa85b214398eb2005e2e4f99104f606441","modified":1680918029817},{"_id":"public/2023/04/03/Functions/Function f(x) = x^2.png","hash":"9a9b87032b1201196a7990fe424fbb189290fa8d","modified":1680918029817},{"_id":"public/2023/04/03/Functions/One-to-one Function.png","hash":"ba3484a3d76acd6956ca9717013b29919f1870cc","modified":1680918029817},{"_id":"public/2023/04/03/Functions/exponential_logarithmic.png","hash":"8112198e702f39a4391f4b5d35a954da6b2d65da","modified":1680918029817},{"_id":"public/2023/04/03/Functions/floor_ceiling.png","hash":"bac82fc8c0101401a90fa8c94164cca0d76826f3","modified":1680918029817},{"_id":"public/2023/03/28/Gradient-descend-for-linear-regression/gradient.png","hash":"4e0bbbd1a73e64198a1caf536279ac39f1640477","modified":1680918029817},{"_id":"public/2023/03/28/Gradient-descend-for-linear-regression/gradient1.png","hash":"952a8f8df75c117211e71a85962abff2af0536a2","modified":1680918029817},{"_id":"public/2023/03/28/Gradient-descend-for-linear-regression/gradient2.png","hash":"4e6510b1afca412c57672c34cf856c6fbd3b5e44","modified":1680918029817},{"_id":"public/2023/03/28/Gradient-descend-for-linear-regression/gradient3-0040620.png","hash":"a1ea320183dda469ddf91f2eedb25479368955b8","modified":1680918029817},{"_id":"public/2023/03/28/Gradient-descend-for-linear-regression/gradient3.png","hash":"19b68b8ffbc0858361d7ce336645906dda6497f9","modified":1680918029817},{"_id":"public/2023/03/27/Norms/norm.png","hash":"d8f796f3546d8a6ad6c3f018d1c550d283815632","modified":1680918029817},{"_id":"public/2023/03/28/Regression/Polynomial Regression of Sin(x).png","hash":"0dbb023e637a68de38e372f1627a429614ef4f9b","modified":1680918029817},{"_id":"public/2023/04/03/Relationships-between-two-Sets/Venn Diagrams for numbers.png","hash":"4cf8249d47b5db304415399895b6a58ca5a67f84","modified":1680918029817},{"_id":"public/2023/03/27/Variables/uniform.png","hash":"b692146e8d448d6f40fd19425408cd49a60f2f67","modified":1680918029817},{"_id":"public/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155430619.png","hash":"fcd90f448a0b9fc2101c65b9a3d6791056d10ec8","modified":1680918029817},{"_id":"public/js/algolia-search.js","hash":"813afcc30feee11d59f297f2d5a96f98fbbd4743","modified":1680918029817},{"_id":"public/js/bookmark.js","hash":"c9acb262acf0cf127497b570fa9479fb32f34547","modified":1680918029817},{"_id":"public/js/local-search.js","hash":"fda0f761ae20577f22c1528dde7ae059368fe9a8","modified":1680918029817},{"_id":"public/js/motion.js","hash":"71e5caff1d87b1b7256f61e6b318bedf495f9e75","modified":1680918029817},{"_id":"public/js/next-boot.js","hash":"a6a82905c6abb8e0ec418ef6b0509b946b955807","modified":1680918029817},{"_id":"public/js/utils.js","hash":"a2984bf0631756a904cd43f8e3a8f6fb15b9ceb5","modified":1680918029817},{"_id":"public/js/schemes/muse.js","hash":"792f4522a3b0b96584a041a4aca20fcded410079","modified":1680918029817},{"_id":"public/js/schemes/pisces.js","hash":"dccbb1be3938050e13277251ab5d88c736edf396","modified":1680918029817},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1680918029817},{"_id":"public/lib/pdf/README.html","hash":"c9afcec4f0e4781f746d1d77ad3d686a2cb5ee62","modified":1680918029817},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1680918029817},{"_id":"public/css/main.css","hash":"d0d947758aa1e0e35a8faca175a04acd6cfe6ff5","modified":1680918029817},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1680918029817},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1680918029817},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1680918029817},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1680918029817},{"_id":"public/lib/pdf/web/debugger.js","hash":"667c3445b131e4519084f42573cd4594d5d1e298","modified":1680918029817},{"_id":"public/lib/pdf/web/viewer.css","hash":"3cdfeee673984a7984a9e05f8d3cef99770df37c","modified":1680918029817},{"_id":"public/lib/pdf/web/viewer.html","hash":"ec2a94e016621a1b7a9dd4c0cb28f921c0814dde","modified":1680918029817},{"_id":"public/lib/pdf/web/viewer.js","hash":"9fa24e98c083ca6c32a292a3296c4782ed51d958","modified":1680918029817},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/Exact_vs_Noisy_Cost_Functions.png","hash":"3b0da3257c9994a9d463e5248915661abe91b80c","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/smooth_non_smooth.png","hash":"8514658b6f313f6b9c189f9ae197da2ac49c3fe0","modified":1680918029817},{"_id":"public/2023/03/29/From-linear-regression-to-binary-classification/binaryclass2.png","hash":"fe0c0d4607e7cbb92c75530a96bce748d830ef74","modified":1680918029817},{"_id":"public/2023/03/29/From-linear-regression-to-binary-classification/sigmoid.png","hash":"07c68db7f610bfb14276199f50e43d28cbfbc15a","modified":1680918029817},{"_id":"public/2023/03/28/Functions-Plot/2d_functions.png","hash":"310933b848bed7c46cddb2e7a96e8f621cb64105","modified":1680918029817},{"_id":"public/2023/04/03/Functions/convexity.png","hash":"d966757de3925bbd6c5037b1e960a7480605dfb3","modified":1680918029817},{"_id":"public/2023/03/28/Gradient-descend-for-linear-regression/gradient4.png","hash":"5297c3455211a9e69130c6cabf5795ef1610302f","modified":1680918029817},{"_id":"public/2023/04/03/Scipy-optimization/minimize_scalar.png","hash":"f0a2cef6776ac399f06d609d17eb9d6c99536eb7","modified":1680918029817},{"_id":"public/lib/pdf/build/pdf.js","hash":"50b88ce99fd16fba98e7b69e05b75dcf1766ddb5","modified":1680918029817},{"_id":"public/2023/03/28/Hyperplane/binary_classification_problem_in_3d.png","hash":"8b3afeed36ec42187425265c350defe54896ad72","modified":1680918029817},{"_id":"public/2023/03/04/RGB-color/rgb_colors.png","hash":"366c4d88ffe30d233d45021b9422299adeef1096","modified":1680918029817},{"_id":"public/2023/04/03/Scipy-optimization/minimize_scalar1.png","hash":"0acaeec9864082cbb775bb1a85dc089ec7fd3941","modified":1680918029817},{"_id":"public/2023/03/28/Regression/Correlation coefficients.png","hash":"45066cc54f9da39232f521b5956a81d7a0fa9ab7","modified":1680918029817},{"_id":"public/2023/03/27/Variables/normal.png","hash":"129ce01eabc2aa76910ff951e8e2dc02aaa4ba8f","modified":1680918029817},{"_id":"public/lib/pdf/build/pdf.worker.js","hash":"36a7f91a9f55abe41454e529aa449ab1741af31c","modified":1680918029817},{"_id":"public/2023/04/03/Scipy-optimization/minimize_rosenbrock.png","hash":"44e5525a541945b107d4dcc9ccf4b745b0132ce9","modified":1680918029817},{"_id":"public/2023/04/03/Scipy-optimization/minimize_rosenbrock_bfgs.png","hash":"f48a7fd55005ed74acd855331b7ed46a8258c8d1","modified":1680918029817},{"_id":"public/2023/04/03/Scipy-optimization/minimize_rosenbrock_newton.png","hash":"207237ae97b2a7f6611c3da940b82b2030f130e2","modified":1680918029817},{"_id":"public/2023/03/27/Variables/bivariate_normal.png","hash":"26302d8f3151b8d3465ef663826e8851d280582b","modified":1680918029817},{"_id":"public/2023/04/03/Differential-equations/Optimization with constraints.png","hash":"acbf58a68a4b8f6bcfe69739501fa973976ef3d4","modified":1680918029817},{"_id":"public/lib/pdf/web/viewer.js.map","hash":"6e317140fdedb6ec0b9e5c8de9167cd2cb7e2313","modified":1680918029817},{"_id":"public/2023/03/28/Pandas-Basics/iris.png","hash":"609288c46014fe55e653b90ecb2d7957ea9470aa","modified":1680918029817},{"_id":"public/lib/pdf/web/compressed.tracemonkey-pldi-09.pdf","hash":"0d281938d3ff2377541704cab6ba1c4408420733","modified":1680918029817},{"_id":"public/2023/03/04/RGB-color/rgb_cubic.png","hash":"9b2fa6f3955e6112ec76c0fa8e7052c84e30ae87","modified":1680918029817},{"_id":"public/lib/pdf/build/pdf.js.map","hash":"430ce9f42522bca793bbc7e1f2a3b92e2b0f04a5","modified":1680918029817},{"_id":"public/2023/03/28/Functions-Plot/3d_functions.png","hash":"653f419c3dbc5c9910337bfd8c3598945d51dc86","modified":1680918029817},{"_id":"public/2023/04/01/OpenCV-Hand-Tracking-to-Count-Fingers/image-20230401192321128.png","hash":"ba4fece9f0ba16a64d300d08cc7972c92322909b","modified":1680918029817},{"_id":"public/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230402154048465.png","hash":"162450129bcd94dc0764503f4acbee216e163d69","modified":1680918029817},{"_id":"public/2023/03/28/Image-processing-using-Numpy/rose_chanel_order.png","hash":"0b4d3759110ff20c60a6987428ce95db4cf561c0","modified":1680918029817},{"_id":"public/2023/03/28/Image-processing-using-Numpy/rose_channels.png","hash":"bc416048bf2ada694c115d49e63c4e4a315e8445","modified":1680918029817},{"_id":"public/lib/pdf/build/pdf.worker.js.map","hash":"acf0c0d4f6196758c90b05d302f22bf7cb32923e","modified":1680918029817},{"_id":"public/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155315817.png","hash":"5f9341eaf4431ec8e4077fcfb0f5f478db050ed3","modified":1680918029817},{"_id":"public/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401160906919.png","hash":"f8de001d409343e09873a5567da6840308e41083","modified":1680918029817},{"_id":"public/2023/04/03/Scipy-optimization/minimize_rosenbrock_methods.png","hash":"182df39c3601157bb3c7d46df193b97c4bee4859","modified":1680918029817},{"_id":"public/2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness.gif","hash":"cb2c3c8ddf164289d842de5d53afcbe2b00ad643","modified":1680918029817},{"_id":"public/2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness_control.gif","hash":"0b2b5efe4911129fe1d40301bb5f19d03a20b504","modified":1680918029817}],"Category":[],"Data":[],"Page":[{"title":"404","date":"2023-04-07T00:59:24.000Z","_content":"\n\n\n\n\n\n\n\n","source":"404/index.md","raw":"---\ntitle: 404\ndate: 2023-04-07 00:59:24\n---\n\n\n\n\n\n\n\n\n","updated":"2023-04-07T02:43:50.464Z","path":"404/index.html","comments":1,"layout":"page","_id":"clg7b73g30000ozpigibjabyr","content":"<html><head></head><body></body></html><html><head></head><body><p></p>\n<p></p>\n<p></p>\n<p></p>\n</body></html>","site":{"data":{}},"related_posts":[],"length":92,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p></p>\n<p></p>\n<p></p>\n<p></p>\n</body></html>"},{"title":"About me","date":"2023-04-07T01:41:17.000Z","_content":"\nI am Mei Jiaojiao, nice to meet you.\n\nCurrently I am 23 years old, a master's student majoring in Artificial Intelligence, with fully-founded support of Chinese government scholarships  and Stipendium Hungaricum scholarship programme  . Bachelor's studies in Electronic Engineering, with two papers in signal processing, prizes in mathematical modeling competitions, two exchange semester programs, a degree in Chinese Law, eight months experience in patents drafting and analysis. This site is created to record my studying notes. \n\nThe website is called wintersweet, the name of a flower that blooms in winter, which is also the English translation of my family name. This flower can bring some beautiful colors to the world at a time everything is withered, and it is not afraid of blowing wind and snow. I hope I can have one tenth of such toughness and courage in my lifetime, and bring some warmth to people around me.\n\nAs for why the domain of this website ends with \"love\", it's because I have a passion for love. I believe that math can simplify many of life's complex problems. However, no matter what kind of model or intelligence we create, we cannot simulate love.\n","source":"about/index.md","raw":"---\ntitle: About me\ndate: 2023-04-07 01:41:17\n---\n\nI am Mei Jiaojiao, nice to meet you.\n\nCurrently I am 23 years old, a master's student majoring in Artificial Intelligence, with fully-founded support of Chinese government scholarships  and Stipendium Hungaricum scholarship programme  . Bachelor's studies in Electronic Engineering, with two papers in signal processing, prizes in mathematical modeling competitions, two exchange semester programs, a degree in Chinese Law, eight months experience in patents drafting and analysis. This site is created to record my studying notes. \n\nThe website is called wintersweet, the name of a flower that blooms in winter, which is also the English translation of my family name. This flower can bring some beautiful colors to the world at a time everything is withered, and it is not afraid of blowing wind and snow. I hope I can have one tenth of such toughness and courage in my lifetime, and bring some warmth to people around me.\n\nAs for why the domain of this website ends with \"love\", it's because I have a passion for love. I believe that math can simplify many of life's complex problems. However, no matter what kind of model or intelligence we create, we cannot simulate love.\n","updated":"2023-04-07T02:43:50.944Z","path":"about/index.html","comments":1,"layout":"page","_id":"clg7b73ge0002ozpi1g11h05h","content":"<html><head></head><body></body></html><html><head></head><body><p>I am Mei Jiaojiao, nice to meet you.</p>\n<p>Currently I am 23 years old, a masters student majoring in Artificial Intelligence, with fully-founded support of Chinese government scholarships  and Stipendium Hungaricum scholarship programme  . Bachelors studies in Electronic Engineering, with two papers in signal processing, prizes in mathematical modeling competitions, two exchange semester programs, a degree in Chinese Law, eight months experience in patents drafting and analysis. This site is created to record my studying notes. </p>\n<p>The website is called wintersweet, the name of a flower that blooms in winter, which is also the English translation of my family name. This flower can bring some beautiful colors to the world at a time everything is withered, and it is not afraid of blowing wind and snow. I hope I can have one tenth of such toughness and courage in my lifetime, and bring some warmth to people around me.</p>\n<p>As for why the domain of this website ends with love, its because I have a passion for love. I believe that math can simplify many of lifes complex problems. However, no matter what kind of model or intelligence we create, we cannot simulate love.</p>\n</body></html>","site":{"data":{}},"related_posts":[],"length":194,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>I am Mei Jiaojiao, nice to meet you.</p>\n<p>Currently I am 23 years old, a masters student majoring in Artificial Intelligence, with fully-founded support of Chinese government scholarships  and Stipendium Hungaricum scholarship programme  . Bachelors studies in Electronic Engineering, with two papers in signal processing, prizes in mathematical modeling competitions, two exchange semester programs, a degree in Chinese Law, eight months experience in patents drafting and analysis. This site is created to record my studying notes. </p>\n<p>The website is called wintersweet, the name of a flower that blooms in winter, which is also the English translation of my family name. This flower can bring some beautiful colors to the world at a time everything is withered, and it is not afraid of blowing wind and snow. I hope I can have one tenth of such toughness and courage in my lifetime, and bring some warmth to people around me.</p>\n<p>As for why the domain of this website ends with love, its because I have a passion for love. I believe that math can simplify many of lifes complex problems. However, no matter what kind of model or intelligence we create, we cannot simulate love.</p>\n</body></html>"},{"title":"archives","date":"2023-04-07T00:59:01.000Z","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2023-04-07 00:59:01\n---\n","updated":"2023-04-07T00:59:01.654Z","path":"archives/index.html","comments":1,"layout":"page","_id":"clg7b73gj0005ozpi4pte8iqp","content":"<html><head></head><body></body></html><html><head></head><body></body></html>","site":{"data":{}},"related_posts":[],"length":0,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body></body></html>"},{"title":"categories","date":"2023-04-07T00:58:39.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2023-04-07 00:58:39\n---\n","updated":"2023-04-07T00:58:39.838Z","path":"categories/index.html","comments":1,"layout":"page","_id":"clg7b73gl0007ozpih3zv4cnp","content":"<html><head></head><body></body></html><html><head></head><body></body></html>","site":{"data":{}},"related_posts":[],"length":0,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body></body></html>"},{"title":"tags","date":"2023-04-07T01:40:16.000Z","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2023-04-07 01:40:16\n---\n","updated":"2023-04-07T01:40:16.197Z","path":"tags/index.html","comments":1,"layout":"page","_id":"clg7b73gn0009ozpib3jmd8uj","content":"<html><head></head><body></body></html><html><head></head><body></body></html>","site":{"data":{}},"related_posts":[],"length":0,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body></body></html>"}],"Post":[{"mathjax":true,"title":"Basic operations of Matrix","date":"2023-03-27T18:42:35.000Z","_content":"\n### Matrix transpose\n\nThe transpose of a matrix is an operation that flips the matrix over its diagonal, i.e., it switches the rows and columns of the matrix. \n$$\n\\begin{equation}\nA_{i, j}^{\\top}=A_{i, j}\n\\end{equation}\n$$\nConsider the following $2 \\times 3$ matrix :\n$$\nA=\\left[\\begin{array}{lll}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{array}\\right]\n$$\nThe transpose of $A$, denoted as $A^{\\wedge} T$, can be obtained by flipping the rows and columns of A:\n$$\nA^T=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right]\n$$\nNote that the original matrix $A$ has dimensions $2 \\times 3$, while the transpose $\\mathrm{A}^{\\wedge} \\mathrm{T}$ has dimensions $3 \\times 2$. This is because the number of rows in A becomes the number of columns in $\\mathrm{A}^{\\wedge} \\mathrm{T}$, and vice versa.\n\n### Vector addition\n\nVector addition is the process of combining two or more vectors into a single vector. The resulting vector is the sum of the individual vectors.\n$$\n\\begin{equation}\n\\boldsymbol{v}=\\left[\\begin{array}{r}\n1 \\\\\n1 \\\\\n-1\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n2 \\\\\n3 \\\\\n4\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{v}+\\boldsymbol{w}=\\left[\\begin{array}{l}\n3 \\\\\n4 \\\\\n3\n\\end{array}\\right]\n\\end{equation}\n$$\n### Matrix addition\n\nMatrix addition is the process of combining two or more matrices into a single matrix. The resulting matrix is the sum of the individual matrices.\n\nIf we have two matrices A and B with the same dimensions m x n, then their sum, C, is defined as:\n$$\n\\begin{equation}\n\\boldsymbol{C}=\\boldsymbol{A}+\\boldsymbol{B}, C_{i, j}=A_{i, j}+B_{i, j}\n\\end{equation}\n$$\nConsider the following matrices $\\mathrm{A}$ and $\\mathrm{B}$ :\n$$\n\\begin{gathered}\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4 \\\\\n5 & 6\n\\end{array}\\right] \\\\\nB=\\left[\\begin{array}{cc}\n-1 & 2 \\\\\n4 & -3 \\\\\n7 & 1\n\\end{array}\\right]\n\\end{gathered}\n$$\nTo add these matrices, we add the corresponding elements:\n$$\nA+B=\\left[\\begin{array}{cc}\n1+(-1) & 2+2 \\\\\n3+4 & 4+(-3) \\\\\n5+7 & 6+1\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n0 & 4 \\\\\n7 & 1 \\\\\n12 & 7\n\\end{array}\\right]\n$$\n### Scalar multiplication\n\nScalar multiplication is the process of multiplying a vector or a matrix by a scalar value. The scalar value is a single number that scales or stretches the vector or matrix.\n\n Vectors can be multiplied by 2 or by -1 or by any number $c$. \n$$\n\\begin{equation}\n2 \\boldsymbol{v}=\\left[\\begin{array}{l}\n2 v_1 \\\\\n2 v_2\n\\end{array}\\right]=\\boldsymbol{v}+\\boldsymbol{v}\n\\end{equation}\n$$\n\n$$\n\\begin{equation}\n-\\boldsymbol{v}=\\left[\\begin{array}{l}\n-v_1 \\\\\n-v_2\n\\end{array}\\right]\n\\end{equation}\n$$\n\nIn case of a Matrix, let $A$ be a $2 \\times 2$ matrix:\n$$\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]\n$$\nTo find the scalar multiplication of A by 2 , we simply multiply each element of the matrix by 2 :\n$$\n2 A=2\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n2 & 4 \\\\\n6 & 8\n\\end{array}\\right]\n$$\nSimilarly, we can find the scalar multiplication of $A$ by -1 by multiplying each element of the matrix by -1 :\n$$\n-1 A=-\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n-1 & -2 \\\\\n-3 & -4\n\\end{array}\\right]\n$$\nIn general, given a matrix $A$ and a scalar $\\mathrm{c}$, the scalar multiplication of $A$ by $\\mathrm{c}$ is defined as:\n$$\nc A=c\\left[\\begin{array}{cccc}\na_{11} & a_{12} & \\ldots & a_{1 n} \\\\\na_{21} & a_{22} & \\ldots & a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m 1} & a_{m 2} & \\ldots & a_{m n}\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nc a_{11} & c a_{12} & \\ldots & c a_{1 n} \\\\\nc a_{21} & c a_{22} & \\ldots & c a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nc a_{m 1} & c a_{m 2} & \\ldots & c a_{m n}\n\\end{array}\\right]\n$$\n\n### Linear combination\n\nLinear combination is a combination of addition and multiplication.\n\nGiven a set of vectors $\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_n$ and a set of scalars $c_1, c_2, \\dots, c_n$, a linear combination of the vectors is defined as the sum of the vectors multiplied by their corresponding scalar coefficients:\n$$\nc_1 \\boldsymbol{v}_1+c_2 \\boldsymbol{v}_2+\\cdots+c_n \\boldsymbol{v}_n=\\sum_{i=1}^n c_i \\boldsymbol{v}_i\n$$\nThis expression represents the linear combination of the vectors $\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_n$ using the scalar coefficients $c_1, c_2, \\dots, c_n$, where the addition of the vectors and the multiplication of the scalars are both included.\n\nFor example, consider the following set of vectors:\n$$\n\\boldsymbol{v}_1=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{v}_2=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right], \\quad \\boldsymbol{v}_3=\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]\n$$\nA linear combination of these vectors using the scalar coefficients $c_1 = 2$, $c_2 = -1$, and $c_3 = 3$ is:\n$$\n2 v_1-v_2+3 v_3=2\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right]-\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]+3\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]=\\left[\\begin{array}{l}\n29 \\\\\n32 \\\\\n35\n\\end{array}\\right]\n$$\n### Dot product\n\nGiven two vectors $\\boldsymbol{v}$ and $\\boldsymbol{w}$ of the same dimension, the dot product between $\\boldsymbol{v}$ and $\\boldsymbol{w}$, denoted as $\\boldsymbol{v} \\cdot \\boldsymbol{w}$, is the sum of the products of the corresponding components:\n$$\n\\begin{equation}\n\\boldsymbol{v} \\cdot \\boldsymbol{w}=\\sum_{i=1}^n v_i w_i=v_1 w_1+v_2 w_2+\\cdots+v_n w_n\n\\end{equation}\n$$\nFor example, consider the following two vectors:\n$$\n\\boldsymbol{v}=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]\n$$\nTo compute the dot product of $\\boldsymbol{v}$ and  $ \\boldsymbol {w}$, we multiply the corresponding elements of the two vectors and then sum the resulting products:\n$$\nv \\cdot w=(1 \\times 4)+(2 \\times 5)+(3 \\times 6)=32\n$$\n\n### Matrix multiplication\n\nGiven two matrices A and B, where A has dimensions $m \\cdot n$ and B has dimensions $n \\cdot p$, the product of A and B, denoted as C, is a matrix with dimensions $m \\cdot p$, where the element in row $i$ and column $j$ is obtained by multiplying the $i$-th row of A with the $j$-th column of B, and then summing the resulting products:\n$$\n\\begin{equation}\nC_{i, j}=\\sum_{k=1}^n A_{i, k} B_{k, j}, \\quad \\text { for } 1 \\leq i \\leq m, 1 \\leq j \\leq p\n\\end{equation}\n$$\nFor example, consider the following matrices $A$ and $B$ :\n$$\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right], B=\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]\n$$\nTo multiply $A$ and $B$, we take the dot product of each row of $A$ with each column of $B$ :\n$$\n\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 \\cdot 5+2 \\cdot 7 & 1 \\cdot 6+2 \\cdot 8 \\\\\n3 \\cdot 5+4 \\cdot 7 & 3 \\cdot 6+4 \\cdot 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n19 & 22 \\\\\n43 & 50\n\\end{array}\\right]\n$$\n\n### Identity matrix\n\nThe identity matrix, denoted by $\\boldsymbol{I}_n$, is a square matrix of dimension $n$ with ones on the main diagonal and zeros everywhere else. In other words, the entry in the $i$-th row and $j$-th column of $\\boldsymbol{I}_n$ is:\n$$\n\\begin{equation}\n\\left(\\boldsymbol{I}_n\\right)_{i, j}= \\begin{cases}1 & \\text { if } i=j \\\\ 0 & \\text { if } i \\neq j\\end{cases}\n\\end{equation}\n$$\nFor example, the $3 \\times 3$ identity matrix is:\n$$\n\\begin{equation}\n\\boldsymbol{I}_3=\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right]\n\\end{equation}\n$$\nThe identity matrix is a special type of matrix in that it behaves like the number 1 in multiplication. Specifically, if $\\boldsymbol{A}$ is a square matrix of dimension $n$, then:\n$$\n\\begin{equation}\n\\boldsymbol{A} \\boldsymbol{I}_n=\\boldsymbol{I}_n \\boldsymbol{A}=\\boldsymbol{A}\n\\end{equation}\n$$\n\n### Matrix inverse\n\nThe inverse of a matrix $\\boldsymbol{A}$, denoted as $\\boldsymbol{A}^{-1}$, is defined as a matrix such that:\n$$\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A}=\\boldsymbol{I}_n\n\\end{equation}\n$$\nwhere $\\boldsymbol{I}_n$ is the identity matrix of dimension $n$. If $\\boldsymbol{A}^{-1}$ exists (**not all matrices are invertible**), then the solution to the linear system $\\boldsymbol{A x}=\\boldsymbol{b}$ is given by:\n$$\n\\begin{equation}\n\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}\n$$\nThis is because we can multiply both sides of the equation $\\boldsymbol{A x}=\\boldsymbol{b}$ by $\\boldsymbol{A}^{-1}$ on the left to obtain:\n$$\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}\n$$\nwhich simplifies to:\n$$\n\\begin{equation}\n\\boldsymbol{I}_n \\boldsymbol{x}=\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}\n$$\nIf the determinant of $\\boldsymbol{A}$ is zero, then the matrix $\\boldsymbol{A}$ is singular or non-invertible, and it does not have an inverse. \n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 22:26\n\nimport numpy as np\n\n# Matrix Transpose\nA = np.array([[1, 2, 3], [4, 5, 6]])\nprint(\"Matrix A:\")\nprint(A)\nprint(\"Transpose of A:\")\nprint(A.T)\n\n# Vector Addition\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nw = u + v\nprint(\"Vector u:\", u)\nprint(\"Vector v:\", v)\nprint(\"Vector u + v:\", w)\n\n# Matrix Addition\nB = np.array([[1, 2, 3], [4, 5, 6]])\nC = np.array([[7, 8, 9], [10, 11, 12]])\nD = B + C\nprint(\"Matrix B:\")\nprint(B)\nprint(\"Matrix C:\")\nprint(C)\nprint(\"Matrix B + C:\")\nprint(D)\n\n# Scalar Multiplication\nk = 3\nE = np.array([[1, 2, 3], [4, 5, 6]])\nF = k * E\nprint(\"Scalar k:\", k)\nprint(\"Matrix E:\")\nprint(E)\nprint(\"Scalar k times E:\")\nprint(F)\n\n# Linear Combination\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\na = 2\nb = 3\nw = a * u + b * v\nprint(\"Vector u:\", u)\nprint(\"Vector v:\", v)\nprint(\"Scalar a:\", a)\nprint(\"Scalar b:\", b)\nprint(\"Linear combination a*u + b*v:\")\nprint(w)\n\n# Dot Product\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nw = np.dot(u, v)\nprint(\"Vector u:\", u)\nprint(\"Vector v:\", v)\nprint(\"Dot product of u and v:\", w)\n\n# Matrix Multiplication\nA = np.array([[1, 2], [3, 4], [5, 6]])\nB = np.array([[7, 8], [9, 10]])\nC = np.dot(A, B)\nprint(\"Matrix A:\")\nprint(A)\nprint(\"Matrix B:\")\nprint(B)\nprint(\"Matrix product of A and B:\")\nprint(C)\n\n# Identity Matrix\nI = np.eye(3)\nprint(\"Identity matrix of size 3:\")\nprint(I)\n\n# Matrix Inverse\nA = np.array([[1, 2], [3, 4]])\nB = np.linalg.inv(A)\nprint(\"Matrix A:\")\nprint(A)\nprint(\"Inverse of A:\")\nprint(B)\n```\n\n### Reference\n\n1. Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.\n2. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Basic-operations-of-Matrix.md","raw":"---\nmathjax: true\ntitle: Basic operations of Matrix\ndate: 2023-03-27 18:42:35\ntags: [Matrix, Linear combination, Basics]\n---\n\n### Matrix transpose\n\nThe transpose of a matrix is an operation that flips the matrix over its diagonal, i.e., it switches the rows and columns of the matrix. \n$$\n\\begin{equation}\nA_{i, j}^{\\top}=A_{i, j}\n\\end{equation}\n$$\nConsider the following $2 \\times 3$ matrix :\n$$\nA=\\left[\\begin{array}{lll}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{array}\\right]\n$$\nThe transpose of $A$, denoted as $A^{\\wedge} T$, can be obtained by flipping the rows and columns of A:\n$$\nA^T=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right]\n$$\nNote that the original matrix $A$ has dimensions $2 \\times 3$, while the transpose $\\mathrm{A}^{\\wedge} \\mathrm{T}$ has dimensions $3 \\times 2$. This is because the number of rows in A becomes the number of columns in $\\mathrm{A}^{\\wedge} \\mathrm{T}$, and vice versa.\n\n### Vector addition\n\nVector addition is the process of combining two or more vectors into a single vector. The resulting vector is the sum of the individual vectors.\n$$\n\\begin{equation}\n\\boldsymbol{v}=\\left[\\begin{array}{r}\n1 \\\\\n1 \\\\\n-1\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n2 \\\\\n3 \\\\\n4\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{v}+\\boldsymbol{w}=\\left[\\begin{array}{l}\n3 \\\\\n4 \\\\\n3\n\\end{array}\\right]\n\\end{equation}\n$$\n### Matrix addition\n\nMatrix addition is the process of combining two or more matrices into a single matrix. The resulting matrix is the sum of the individual matrices.\n\nIf we have two matrices A and B with the same dimensions m x n, then their sum, C, is defined as:\n$$\n\\begin{equation}\n\\boldsymbol{C}=\\boldsymbol{A}+\\boldsymbol{B}, C_{i, j}=A_{i, j}+B_{i, j}\n\\end{equation}\n$$\nConsider the following matrices $\\mathrm{A}$ and $\\mathrm{B}$ :\n$$\n\\begin{gathered}\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4 \\\\\n5 & 6\n\\end{array}\\right] \\\\\nB=\\left[\\begin{array}{cc}\n-1 & 2 \\\\\n4 & -3 \\\\\n7 & 1\n\\end{array}\\right]\n\\end{gathered}\n$$\nTo add these matrices, we add the corresponding elements:\n$$\nA+B=\\left[\\begin{array}{cc}\n1+(-1) & 2+2 \\\\\n3+4 & 4+(-3) \\\\\n5+7 & 6+1\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n0 & 4 \\\\\n7 & 1 \\\\\n12 & 7\n\\end{array}\\right]\n$$\n### Scalar multiplication\n\nScalar multiplication is the process of multiplying a vector or a matrix by a scalar value. The scalar value is a single number that scales or stretches the vector or matrix.\n\n Vectors can be multiplied by 2 or by -1 or by any number $c$. \n$$\n\\begin{equation}\n2 \\boldsymbol{v}=\\left[\\begin{array}{l}\n2 v_1 \\\\\n2 v_2\n\\end{array}\\right]=\\boldsymbol{v}+\\boldsymbol{v}\n\\end{equation}\n$$\n\n$$\n\\begin{equation}\n-\\boldsymbol{v}=\\left[\\begin{array}{l}\n-v_1 \\\\\n-v_2\n\\end{array}\\right]\n\\end{equation}\n$$\n\nIn case of a Matrix, let $A$ be a $2 \\times 2$ matrix:\n$$\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]\n$$\nTo find the scalar multiplication of A by 2 , we simply multiply each element of the matrix by 2 :\n$$\n2 A=2\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n2 & 4 \\\\\n6 & 8\n\\end{array}\\right]\n$$\nSimilarly, we can find the scalar multiplication of $A$ by -1 by multiplying each element of the matrix by -1 :\n$$\n-1 A=-\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n-1 & -2 \\\\\n-3 & -4\n\\end{array}\\right]\n$$\nIn general, given a matrix $A$ and a scalar $\\mathrm{c}$, the scalar multiplication of $A$ by $\\mathrm{c}$ is defined as:\n$$\nc A=c\\left[\\begin{array}{cccc}\na_{11} & a_{12} & \\ldots & a_{1 n} \\\\\na_{21} & a_{22} & \\ldots & a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m 1} & a_{m 2} & \\ldots & a_{m n}\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nc a_{11} & c a_{12} & \\ldots & c a_{1 n} \\\\\nc a_{21} & c a_{22} & \\ldots & c a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nc a_{m 1} & c a_{m 2} & \\ldots & c a_{m n}\n\\end{array}\\right]\n$$\n\n### Linear combination\n\nLinear combination is a combination of addition and multiplication.\n\nGiven a set of vectors $\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_n$ and a set of scalars $c_1, c_2, \\dots, c_n$, a linear combination of the vectors is defined as the sum of the vectors multiplied by their corresponding scalar coefficients:\n$$\nc_1 \\boldsymbol{v}_1+c_2 \\boldsymbol{v}_2+\\cdots+c_n \\boldsymbol{v}_n=\\sum_{i=1}^n c_i \\boldsymbol{v}_i\n$$\nThis expression represents the linear combination of the vectors $\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\dots, \\boldsymbol{v}_n$ using the scalar coefficients $c_1, c_2, \\dots, c_n$, where the addition of the vectors and the multiplication of the scalars are both included.\n\nFor example, consider the following set of vectors:\n$$\n\\boldsymbol{v}_1=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{v}_2=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right], \\quad \\boldsymbol{v}_3=\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]\n$$\nA linear combination of these vectors using the scalar coefficients $c_1 = 2$, $c_2 = -1$, and $c_3 = 3$ is:\n$$\n2 v_1-v_2+3 v_3=2\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right]-\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]+3\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]=\\left[\\begin{array}{l}\n29 \\\\\n32 \\\\\n35\n\\end{array}\\right]\n$$\n### Dot product\n\nGiven two vectors $\\boldsymbol{v}$ and $\\boldsymbol{w}$ of the same dimension, the dot product between $\\boldsymbol{v}$ and $\\boldsymbol{w}$, denoted as $\\boldsymbol{v} \\cdot \\boldsymbol{w}$, is the sum of the products of the corresponding components:\n$$\n\\begin{equation}\n\\boldsymbol{v} \\cdot \\boldsymbol{w}=\\sum_{i=1}^n v_i w_i=v_1 w_1+v_2 w_2+\\cdots+v_n w_n\n\\end{equation}\n$$\nFor example, consider the following two vectors:\n$$\n\\boldsymbol{v}=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]\n$$\nTo compute the dot product of $\\boldsymbol{v}$ and  $ \\boldsymbol {w}$, we multiply the corresponding elements of the two vectors and then sum the resulting products:\n$$\nv \\cdot w=(1 \\times 4)+(2 \\times 5)+(3 \\times 6)=32\n$$\n\n### Matrix multiplication\n\nGiven two matrices A and B, where A has dimensions $m \\cdot n$ and B has dimensions $n \\cdot p$, the product of A and B, denoted as C, is a matrix with dimensions $m \\cdot p$, where the element in row $i$ and column $j$ is obtained by multiplying the $i$-th row of A with the $j$-th column of B, and then summing the resulting products:\n$$\n\\begin{equation}\nC_{i, j}=\\sum_{k=1}^n A_{i, k} B_{k, j}, \\quad \\text { for } 1 \\leq i \\leq m, 1 \\leq j \\leq p\n\\end{equation}\n$$\nFor example, consider the following matrices $A$ and $B$ :\n$$\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right], B=\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]\n$$\nTo multiply $A$ and $B$, we take the dot product of each row of $A$ with each column of $B$ :\n$$\n\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 \\cdot 5+2 \\cdot 7 & 1 \\cdot 6+2 \\cdot 8 \\\\\n3 \\cdot 5+4 \\cdot 7 & 3 \\cdot 6+4 \\cdot 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n19 & 22 \\\\\n43 & 50\n\\end{array}\\right]\n$$\n\n### Identity matrix\n\nThe identity matrix, denoted by $\\boldsymbol{I}_n$, is a square matrix of dimension $n$ with ones on the main diagonal and zeros everywhere else. In other words, the entry in the $i$-th row and $j$-th column of $\\boldsymbol{I}_n$ is:\n$$\n\\begin{equation}\n\\left(\\boldsymbol{I}_n\\right)_{i, j}= \\begin{cases}1 & \\text { if } i=j \\\\ 0 & \\text { if } i \\neq j\\end{cases}\n\\end{equation}\n$$\nFor example, the $3 \\times 3$ identity matrix is:\n$$\n\\begin{equation}\n\\boldsymbol{I}_3=\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right]\n\\end{equation}\n$$\nThe identity matrix is a special type of matrix in that it behaves like the number 1 in multiplication. Specifically, if $\\boldsymbol{A}$ is a square matrix of dimension $n$, then:\n$$\n\\begin{equation}\n\\boldsymbol{A} \\boldsymbol{I}_n=\\boldsymbol{I}_n \\boldsymbol{A}=\\boldsymbol{A}\n\\end{equation}\n$$\n\n### Matrix inverse\n\nThe inverse of a matrix $\\boldsymbol{A}$, denoted as $\\boldsymbol{A}^{-1}$, is defined as a matrix such that:\n$$\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A}=\\boldsymbol{I}_n\n\\end{equation}\n$$\nwhere $\\boldsymbol{I}_n$ is the identity matrix of dimension $n$. If $\\boldsymbol{A}^{-1}$ exists (**not all matrices are invertible**), then the solution to the linear system $\\boldsymbol{A x}=\\boldsymbol{b}$ is given by:\n$$\n\\begin{equation}\n\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}\n$$\nThis is because we can multiply both sides of the equation $\\boldsymbol{A x}=\\boldsymbol{b}$ by $\\boldsymbol{A}^{-1}$ on the left to obtain:\n$$\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}\n$$\nwhich simplifies to:\n$$\n\\begin{equation}\n\\boldsymbol{I}_n \\boldsymbol{x}=\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}\n$$\nIf the determinant of $\\boldsymbol{A}$ is zero, then the matrix $\\boldsymbol{A}$ is singular or non-invertible, and it does not have an inverse. \n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 22:26\n\nimport numpy as np\n\n# Matrix Transpose\nA = np.array([[1, 2, 3], [4, 5, 6]])\nprint(\"Matrix A:\")\nprint(A)\nprint(\"Transpose of A:\")\nprint(A.T)\n\n# Vector Addition\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nw = u + v\nprint(\"Vector u:\", u)\nprint(\"Vector v:\", v)\nprint(\"Vector u + v:\", w)\n\n# Matrix Addition\nB = np.array([[1, 2, 3], [4, 5, 6]])\nC = np.array([[7, 8, 9], [10, 11, 12]])\nD = B + C\nprint(\"Matrix B:\")\nprint(B)\nprint(\"Matrix C:\")\nprint(C)\nprint(\"Matrix B + C:\")\nprint(D)\n\n# Scalar Multiplication\nk = 3\nE = np.array([[1, 2, 3], [4, 5, 6]])\nF = k * E\nprint(\"Scalar k:\", k)\nprint(\"Matrix E:\")\nprint(E)\nprint(\"Scalar k times E:\")\nprint(F)\n\n# Linear Combination\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\na = 2\nb = 3\nw = a * u + b * v\nprint(\"Vector u:\", u)\nprint(\"Vector v:\", v)\nprint(\"Scalar a:\", a)\nprint(\"Scalar b:\", b)\nprint(\"Linear combination a*u + b*v:\")\nprint(w)\n\n# Dot Product\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nw = np.dot(u, v)\nprint(\"Vector u:\", u)\nprint(\"Vector v:\", v)\nprint(\"Dot product of u and v:\", w)\n\n# Matrix Multiplication\nA = np.array([[1, 2], [3, 4], [5, 6]])\nB = np.array([[7, 8], [9, 10]])\nC = np.dot(A, B)\nprint(\"Matrix A:\")\nprint(A)\nprint(\"Matrix B:\")\nprint(B)\nprint(\"Matrix product of A and B:\")\nprint(C)\n\n# Identity Matrix\nI = np.eye(3)\nprint(\"Identity matrix of size 3:\")\nprint(I)\n\n# Matrix Inverse\nA = np.array([[1, 2], [3, 4]])\nB = np.linalg.inv(A)\nprint(\"Matrix A:\")\nprint(A)\nprint(\"Inverse of A:\")\nprint(B)\n```\n\n### Reference\n\n1. Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.\n2. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT Press.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Basic-operations-of-Matrix","published":1,"updated":"2023-04-07T02:43:50.464Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73g70001ozpi1nzvcst6","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Matrix-transpose\"><a href=\"#Matrix-transpose\" class=\"headerlink\" title=\"Matrix transpose\"></a>Matrix transpose</h3><p>The transpose of a matrix is an operation that flips the matrix over its diagonal, i.e., it switches the rows and columns of the matrix. </p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nA_{i, j}^{\\top}=A_{i, j}\n\\end{equation}</script><p>Consider the following <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> matrix :</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{lll}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{array}\\right]</script><p>The transpose of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container>, denoted as <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.544ex\" height=\"1.778ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -785.8 2008.6 785.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2227\" d=\"M318 591Q325 598 333 598Q344 598 348 591Q349 590 414 445T545 151T611 -4Q609 -22 591 -22Q588 -22 586 -21T581 -20T577 -17T575 -13T572 -9T570 -4L333 528L96 -4Q87 -20 80 -21Q78 -22 75 -22Q57 -22 55 -4Q55 2 120 150T251 444T318 591Z\"></path></g></g></g><g data-mml-node=\"mi\" transform=\"translate(1304.6,0)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g></g></svg></mjx-container>, can be obtained by flipping the rows and columns of A:</p>\n<script type=\"math/tex; mode=display\">\nA^T=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right]</script><p>Note that the original matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container>, while the transpose <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.585ex\" height=\"1.778ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -785.8 2026.6 785.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2227\" d=\"M318 591Q325 598 333 598Q344 598 348 591Q349 590 414 445T545 151T611 -4Q609 -22 591 -22Q588 -22 586 -21T581 -20T577 -17T575 -13T572 -9T570 -4L333 528L96 -4Q87 -20 80 -21Q78 -22 75 -22Q57 -22 55 -4Q55 2 120 150T251 444T318 591Z\"></path></g></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1304.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"54\" d=\"M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z\"></path></g></g></g></g></svg></mjx-container> has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container>. This is because the number of rows in A becomes the number of columns in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.585ex\" height=\"1.778ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -785.8 2026.6 785.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2227\" d=\"M318 591Q325 598 333 598Q344 598 348 591Q349 590 414 445T545 151T611 -4Q609 -22 591 -22Q588 -22 586 -21T581 -20T577 -17T575 -13T572 -9T570 -4L333 528L96 -4Q87 -20 80 -21Q78 -22 75 -22Q57 -22 55 -4Q55 2 120 150T251 444T318 591Z\"></path></g></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1304.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"54\" d=\"M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z\"></path></g></g></g></g></svg></mjx-container>, and vice versa.</p>\n<h3 id=\"Vector-addition\"><a href=\"#Vector-addition\" class=\"headerlink\" title=\"Vector addition\"></a>Vector addition</h3><p>Vector addition is the process of combining two or more vectors into a single vector. The resulting vector is the sum of the individual vectors.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{v}=\\left[\\begin{array}{r}\n1 \\\\\n1 \\\\\n-1\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n2 \\\\\n3 \\\\\n4\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{v}+\\boldsymbol{w}=\\left[\\begin{array}{l}\n3 \\\\\n4 \\\\\n3\n\\end{array}\\right]\n\\end{equation}</script><h3 id=\"Matrix-addition\"><a href=\"#Matrix-addition\" class=\"headerlink\" title=\"Matrix addition\"></a>Matrix addition</h3><p>Matrix addition is the process of combining two or more matrices into a single matrix. The resulting matrix is the sum of the individual matrices.</p>\n<p>If we have two matrices A and B with the same dimensions m x n, then their sum, C, is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{C}=\\boldsymbol{A}+\\boldsymbol{B}, C_{i, j}=A_{i, j}+B_{i, j}\n\\end{equation}</script><p>Consider the following matrices <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.602ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 708 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z\"></path></g></g></g></g></svg></mjx-container> :</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4 \\\\\n5 & 6\n\\end{array}\\right] \\\\\nB=\\left[\\begin{array}{cc}\n-1 & 2 \\\\\n4 & -3 \\\\\n7 & 1\n\\end{array}\\right]\n\\end{gathered}</script><p>To add these matrices, we add the corresponding elements:</p>\n<script type=\"math/tex; mode=display\">\nA+B=\\left[\\begin{array}{cc}\n1+(-1) & 2+2 \\\\\n3+4 & 4+(-3) \\\\\n5+7 & 6+1\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n0 & 4 \\\\\n7 & 1 \\\\\n12 & 7\n\\end{array}\\right]</script><h3 id=\"Scalar-multiplication\"><a href=\"#Scalar-multiplication\" class=\"headerlink\" title=\"Scalar multiplication\"></a>Scalar multiplication</h3><p>Scalar multiplication is the process of multiplying a vector or a matrix by a scalar value. The scalar value is a single number that scales or stretches the vector or matrix.</p>\n<p> Vectors can be multiplied by 2 or by -1 or by any number <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.98ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 433 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></svg></mjx-container>. </p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n2 \\boldsymbol{v}=\\left[\\begin{array}{l}\n2 v_1 \\\\\n2 v_2\n\\end{array}\\right]=\\boldsymbol{v}+\\boldsymbol{v}\n\\end{equation}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n-\\boldsymbol{v}=\\left[\\begin{array}{l}\n-v_1 \\\\\n-v_2\n\\end{array}\\right]\n\\end{equation}</script><p>In case of a Matrix, let <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> be a <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.507ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 666\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container> matrix:</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]</script><p>To find the scalar multiplication of A by 2 , we simply multiply each element of the matrix by 2 :</p>\n<script type=\"math/tex; mode=display\">\n2 A=2\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n2 & 4 \\\\\n6 & 8\n\\end{array}\\right]</script><p>Similarly, we can find the scalar multiplication of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> by -1 by multiplying each element of the matrix by -1 :</p>\n<script type=\"math/tex; mode=display\">\n-1 A=-\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n-1 & -2 \\\\\n-3 & -4\n\\end{array}\\right]</script><p>In general, given a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and a scalar <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.005ex\" height=\"1.038ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -448 444 459\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"63\" d=\"M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z\"></path></g></g></g></g></svg></mjx-container>, the scalar multiplication of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.005ex\" height=\"1.038ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -448 444 459\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"63\" d=\"M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z\"></path></g></g></g></g></svg></mjx-container> is defined as:</p>\n<script type=\"math/tex; mode=display\">\nc A=c\\left[\\begin{array}{cccc}\na_{11} & a_{12} & \\ldots & a_{1 n} \\\\\na_{21} & a_{22} & \\ldots & a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m 1} & a_{m 2} & \\ldots & a_{m n}\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nc a_{11} & c a_{12} & \\ldots & c a_{1 n} \\\\\nc a_{21} & c a_{22} & \\ldots & c a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nc a_{m 1} & c a_{m 2} & \\ldots & c a_{m n}\n\\end{array}\\right]</script><h3 id=\"Linear-combination\"><a href=\"#Linear-combination\" class=\"headerlink\" title=\"Linear combination\"></a>Linear combination</h3><p>Linear combination is a combination of addition and multiplication.</p>\n<p>Given a set of vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.018ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 5754 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1003.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1448.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2451.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2896.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4235.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4679.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> and a set of scalars <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.109ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 5352 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(869.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1314.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2183.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2628.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3967.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4411.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>, a linear combination of the vectors is defined as the sum of the vectors multiplied by their corresponding scalar coefficients:</p>\n<script type=\"math/tex; mode=display\">\nc_1 \\boldsymbol{v}_1+c_2 \\boldsymbol{v}_2+\\cdots+c_n \\boldsymbol{v}_n=\\sum_{i=1}^n c_i \\boldsymbol{v}_i</script><p>This expression represents the linear combination of the vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.018ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 5754 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1003.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1448.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2451.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2896.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4235.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4679.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> using the scalar coefficients <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.109ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 5352 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(869.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1314.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2183.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2628.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3967.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4411.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>, where the addition of the vectors and the multiplication of the scalars are both included.</p>\n<p>For example, consider the following set of vectors:</p>\n<script type=\"math/tex; mode=display\">\n\\boldsymbol{v}_1=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{v}_2=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right], \\quad \\boldsymbol{v}_3=\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]</script><p>A linear combination of these vectors using the scalar coefficients <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.116ex\" height=\"1.846ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2703.1 816\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1147.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2203.1,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container>, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.876ex\" height=\"1.846ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3481.1 816\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1147.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2203.1,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2981.1,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.116ex\" height=\"1.879ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2703.1 830.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1147.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2203.1,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> is:</p>\n<script type=\"math/tex; mode=display\">\n2 v_1-v_2+3 v_3=2\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right]-\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]+3\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]=\\left[\\begin{array}{l}\n29 \\\\\n32 \\\\\n35\n\\end{array}\\right]</script><h3 id=\"Dot-product\"><a href=\"#Dot-product\" class=\"headerlink\" title=\"Dot product\"></a>Dot product</h3><p>Given two vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.283ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 567 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.88ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 831 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container> of the same dimension, the dot product between <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.283ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 567 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.88ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 831 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container>, denoted as <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.797ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 2120.4 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(789.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1289.4,0)\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container>, is the sum of the products of the corresponding components:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{v} \\cdot \\boldsymbol{w}=\\sum_{i=1}^n v_i w_i=v_1 w_1+v_2 w_2+\\cdots+v_n w_n\n\\end{equation}</script><p>For example, consider the following two vectors:</p>\n<script type=\"math/tex; mode=display\">\n\\boldsymbol{v}=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]</script><p>To compute the dot product of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.283ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 567 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g></g></g></svg></mjx-container> and  <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.88ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 831 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container>, we multiply the corresponding elements of the two vectors and then sum the resulting products:</p>\n<script type=\"math/tex; mode=display\">\nv \\cdot w=(1 \\times 4)+(2 \\times 5)+(3 \\times 6)=32</script><h3 id=\"Matrix-multiplication\"><a href=\"#Matrix-multiplication\" class=\"headerlink\" title=\"Matrix multiplication\"></a>Matrix multiplication</h3><p>Given two matrices A and B, where A has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.978ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 2200.4 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1100.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1600.4,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> and B has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.13ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 1825.4 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1322.4,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g></svg></mjx-container>, the product of A and B, denoted as C, is a matrix with dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.759ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 2103.4 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1100.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1600.4,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g></svg></mjx-container>, where the element in row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> and column <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.462ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.932ex\" height=\"1.957ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 412 865\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></svg></mjx-container> is obtained by multiplying the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th row of A with the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.462ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.932ex\" height=\"1.957ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 412 865\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></svg></mjx-container>-th column of B, and then summing the resulting products:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nC_{i, j}=\\sum_{k=1}^n A_{i, k} B_{k, j}, \\quad \\text { for } 1 \\leq i \\leq m, 1 \\leq j \\leq p\n\\end{equation}</script><p>For example, consider the following matrices <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container> :</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right], B=\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]</script><p>To multiply <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container>, we take the dot product of each row of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> with each column of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container> :</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 \\cdot 5+2 \\cdot 7 & 1 \\cdot 6+2 \\cdot 8 \\\\\n3 \\cdot 5+4 \\cdot 7 & 3 \\cdot 6+4 \\cdot 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n19 & 22 \\\\\n43 & 50\n\\end{array}\\right]</script><h3 id=\"Identity-matrix\"><a href=\"#Identity-matrix\" class=\"headerlink\" title=\"Identity matrix\"></a>Identity matrix</h3><p>The identity matrix, denoted by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.304ex\" height=\"1.909ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 1018.3 843.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D470\" d=\"M247 624Q242 624 233 624T220 623Q186 623 186 640Q186 647 190 664T202 684Q206 686 226 686Q277 684 393 684Q435 684 471 684T528 685T553 686Q573 686 573 670Q573 650 564 632Q556 624 537 624H501H449L380 344Q309 64 309 63T356 62Q361 62 370 62T384 63Q417 63 417 46Q417 26 408 8Q403 3 396 0L352 1Q325 2 216 2T82 1L45 0Q30 7 30 16Q33 51 46 60Q51 62 102 62H154L294 623Q294 624 247 624Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(544,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>, is a square matrix of dimension <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> with ones on the main diagonal and zeros everywhere else. In other words, the entry in the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th row and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.462ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.932ex\" height=\"1.957ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 412 865\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></svg></mjx-container>-th column of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.304ex\" height=\"1.909ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 1018.3 843.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D470\" d=\"M247 624Q242 624 233 624T220 623Q186 623 186 640Q186 647 190 664T202 684Q206 686 226 686Q277 684 393 684Q435 684 471 684T528 685T553 686Q573 686 573 670Q573 650 564 632Q556 624 537 624H501H449L380 344Q309 64 309 63T356 62Q361 62 370 62T384 63Q417 63 417 46Q417 26 408 8Q403 3 396 0L352 1Q325 2 216 2T82 1L45 0Q30 7 30 16Q33 51 46 60Q51 62 102 62H154L294 623Q294 624 247 624Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(544,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\left(\\boldsymbol{I}_n\\right)_{i, j}= \\begin{cases}1 & \\text { if } i=j \\\\ 0 & \\text { if } i \\neq j\\end{cases}\n\\end{equation}</script><p>For example, the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.554ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2222.4 687\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> identity matrix is:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{I}_3=\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right]\n\\end{equation}</script><p>The identity matrix is a special type of matrix in that it behaves like the number 1 in multiplication. Specifically, if <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container> is a square matrix of dimension <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>, then:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{A} \\boldsymbol{I}_n=\\boldsymbol{I}_n \\boldsymbol{A}=\\boldsymbol{A}\n\\end{equation}</script><h3 id=\"Matrix-inverse\"><a href=\"#Matrix-inverse\" class=\"headerlink\" title=\"Matrix inverse\"></a>Matrix inverse</h3><p>The inverse of a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container>, denoted as <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.198ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1855.7 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(902,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></g></svg></mjx-container>, is defined as a matrix such that:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A}=\\boldsymbol{I}_n\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.304ex\" height=\"1.909ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 1018.3 843.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D470\" d=\"M247 624Q242 624 233 624T220 623Q186 623 186 640Q186 647 190 664T202 684Q206 686 226 686Q277 684 393 684Q435 684 471 684T528 685T553 686Q573 686 573 670Q573 650 564 632Q556 624 537 624H501H449L380 344Q309 64 309 63T356 62Q361 62 370 62T384 63Q417 63 417 46Q417 26 408 8Q403 3 396 0L352 1Q325 2 216 2T82 1L45 0Q30 7 30 16Q33 51 46 60Q51 62 102 62H154L294 623Q294 624 247 624Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(544,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the identity matrix of dimension <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>. If <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.198ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1855.7 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(902,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></g></svg></mjx-container> exists (<strong>not all matrices are invertible</strong>), then the solution to the linear system <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.653ex\" height=\"1.794ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 3382.6 793\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(869,0)\"><path data-c=\"1D499\" d=\"M74 282H63Q43 282 43 296Q43 298 45 307T56 332T76 365T110 401T159 433Q200 451 233 451H236Q273 451 282 450Q358 437 382 400L392 410Q434 452 483 452Q538 452 568 421T599 346Q599 303 573 280T517 256Q494 256 478 270T462 308Q462 343 488 367Q501 377 520 385Q520 386 516 389T502 396T480 400T462 398Q429 383 415 341Q354 116 354 80T405 44Q449 44 485 74T535 142Q539 156 542 159T562 162H568H579Q599 162 599 148Q599 135 586 111T550 60T485 12T397 -8Q313 -8 266 35L258 44Q215 -7 161 -7H156Q99 -7 71 25T43 95Q43 143 70 165T125 188Q148 188 164 174T180 136Q180 101 154 77Q141 67 122 59Q124 54 136 49T161 43Q183 43 200 61T226 103Q287 328 287 364T236 400Q200 400 164 377T107 302Q103 288 100 285T80 282H74Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1805.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2861.6,0)\"><path data-c=\"1D483\" d=\"M220 -8Q142 -8 94 35T45 155V167Q45 187 52 218T104 426L153 622H149Q148 622 144 622T134 623T122 624T111 624T101 624T96 625Q84 628 84 642Q84 647 88 661T94 679Q98 684 109 685T185 690Q258 694 272 694Q289 694 293 679Q293 676 263 553L232 429L244 434Q256 440 281 446T331 452Q417 452 465 407T513 285Q513 235 494 184T439 90T346 20T220 -8ZM385 337Q385 400 318 400Q269 400 226 360Q214 349 211 341T191 268Q162 149 162 113Q162 44 226 44Q269 44 299 76T339 135T362 215Q364 222 365 226Q385 303 385 337Z\"></path></g></g></g></svg></mjx-container> is given by:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}</script><p>This is because we can multiply both sides of the equation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.653ex\" height=\"1.794ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 3382.6 793\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(869,0)\"><path data-c=\"1D499\" d=\"M74 282H63Q43 282 43 296Q43 298 45 307T56 332T76 365T110 401T159 433Q200 451 233 451H236Q273 451 282 450Q358 437 382 400L392 410Q434 452 483 452Q538 452 568 421T599 346Q599 303 573 280T517 256Q494 256 478 270T462 308Q462 343 488 367Q501 377 520 385Q520 386 516 389T502 396T480 400T462 398Q429 383 415 341Q354 116 354 80T405 44Q449 44 485 74T535 142Q539 156 542 159T562 162H568H579Q599 162 599 148Q599 135 586 111T550 60T485 12T397 -8Q313 -8 266 35L258 44Q215 -7 161 -7H156Q99 -7 71 25T43 95Q43 143 70 165T125 188Q148 188 164 174T180 136Q180 101 154 77Q141 67 122 59Q124 54 136 49T161 43Q183 43 200 61T226 103Q287 328 287 364T236 400Q200 400 164 377T107 302Q103 288 100 285T80 282H74Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1805.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2861.6,0)\"><path data-c=\"1D483\" d=\"M220 -8Q142 -8 94 35T45 155V167Q45 187 52 218T104 426L153 622H149Q148 622 144 622T134 623T122 624T111 624T101 624T96 625Q84 628 84 642Q84 647 88 661T94 679Q98 684 109 685T185 690Q258 694 272 694Q289 694 293 679Q293 676 263 553L232 429L244 434Q256 440 281 446T331 452Q417 452 465 407T513 285Q513 235 494 184T439 90T346 20T220 -8ZM385 337Q385 400 318 400Q269 400 226 360Q214 349 211 341T191 268Q162 149 162 113Q162 44 226 44Q269 44 299 76T339 135T362 215Q364 222 365 226Q385 303 385 337Z\"></path></g></g></g></svg></mjx-container> by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.198ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1855.7 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(902,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></g></svg></mjx-container> on the left to obtain:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}</script><p>which simplifies to:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{I}_n \\boldsymbol{x}=\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}</script><p>If the determinant of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container> is zero, then the matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container> is singular or non-invertible, and it does not have an inverse. </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 22:26</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Transpose</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Transpose of A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.T)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Vector Addition</span></span><br><span class=\"line\">u = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">v = np.array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">w = u + v</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u:\"</span>, u)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector v:\"</span>, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u + v:\"</span>, w)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Addition</span></span><br><span class=\"line\">B = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">C = np.array([[<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>]])</span><br><span class=\"line\">D = B + C</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix B:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix C:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(C)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix B + C:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(D)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Scalar Multiplication</span></span><br><span class=\"line\">k = <span class=\"number\">3</span></span><br><span class=\"line\">E = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">F = k * E</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar k:\"</span>, k)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix E:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(E)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar k times E:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(F)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Linear Combination</span></span><br><span class=\"line\">u = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">v = np.array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">a = <span class=\"number\">2</span></span><br><span class=\"line\">b = <span class=\"number\">3</span></span><br><span class=\"line\">w = a * u + b * v</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u:\"</span>, u)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector v:\"</span>, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar a:\"</span>, a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar b:\"</span>, b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Linear combination a*u + b*v:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(w)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dot Product</span></span><br><span class=\"line\">u = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">v = np.array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">w = np.dot(u, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u:\"</span>, u)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector v:\"</span>, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Dot product of u and v:\"</span>, w)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Multiplication</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">B = np.array([[<span class=\"number\">7</span>, <span class=\"number\">8</span>], [<span class=\"number\">9</span>, <span class=\"number\">10</span>]])</span><br><span class=\"line\">C = np.dot(A, B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix B:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix product of A and B:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(C)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Identity Matrix</span></span><br><span class=\"line\">I = np.eye(<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Identity matrix of size 3:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(I)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Inverse</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]])</span><br><span class=\"line\">B = np.linalg.inv(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Inverse of A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(B)</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.</li>\n<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep learning. MIT Press.</li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/27/Linear-Algebra-Basics/","2023/03/28/Numpy-Basics/","2023/03/27/Norms/","2023/03/28/Functions-Plot/","2023/03/29/From-linear-regression-to-binary-classification/"],"length":1890,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Matrix-transpose\"><a href=\"#Matrix-transpose\" class=\"headerlink\" title=\"Matrix transpose\"></a>Matrix transpose</h3><p>The transpose of a matrix is an operation that flips the matrix over its diagonal, i.e., it switches the rows and columns of the matrix. </p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nA_{i, j}^{\\top}=A_{i, j}\n\\end{equation}</script><p>Consider the following <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> matrix :</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{lll}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{array}\\right]</script><p>The transpose of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container>, denoted as <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.544ex\" height=\"1.778ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -785.8 2008.6 785.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2227\" d=\"M318 591Q325 598 333 598Q344 598 348 591Q349 590 414 445T545 151T611 -4Q609 -22 591 -22Q588 -22 586 -21T581 -20T577 -17T575 -13T572 -9T570 -4L333 528L96 -4Q87 -20 80 -21Q78 -22 75 -22Q57 -22 55 -4Q55 2 120 150T251 444T318 591Z\"></path></g></g></g><g data-mml-node=\"mi\" transform=\"translate(1304.6,0)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g></g></svg></mjx-container>, can be obtained by flipping the rows and columns of A:</p>\n<script type=\"math/tex; mode=display\">\nA^T=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right]</script><p>Note that the original matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container>, while the transpose <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.585ex\" height=\"1.778ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -785.8 2026.6 785.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2227\" d=\"M318 591Q325 598 333 598Q344 598 348 591Q349 590 414 445T545 151T611 -4Q609 -22 591 -22Q588 -22 586 -21T581 -20T577 -17T575 -13T572 -9T570 -4L333 528L96 -4Q87 -20 80 -21Q78 -22 75 -22Q57 -22 55 -4Q55 2 120 150T251 444T318 591Z\"></path></g></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1304.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"54\" d=\"M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z\"></path></g></g></g></g></svg></mjx-container> has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container>. This is because the number of rows in A becomes the number of columns in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.585ex\" height=\"1.778ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -785.8 2026.6 785.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2227\" d=\"M318 591Q325 598 333 598Q344 598 348 591Q349 590 414 445T545 151T611 -4Q609 -22 591 -22Q588 -22 586 -21T581 -20T577 -17T575 -13T572 -9T570 -4L333 528L96 -4Q87 -20 80 -21Q78 -22 75 -22Q57 -22 55 -4Q55 2 120 150T251 444T318 591Z\"></path></g></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1304.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"54\" d=\"M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z\"></path></g></g></g></g></svg></mjx-container>, and vice versa.</p>\n<h3 id=\"Vector-addition\"><a href=\"#Vector-addition\" class=\"headerlink\" title=\"Vector addition\"></a>Vector addition</h3><p>Vector addition is the process of combining two or more vectors into a single vector. The resulting vector is the sum of the individual vectors.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{v}=\\left[\\begin{array}{r}\n1 \\\\\n1 \\\\\n-1\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n2 \\\\\n3 \\\\\n4\n\\end{array}\\right] \\quad \\text { and } \\quad \\boldsymbol{v}+\\boldsymbol{w}=\\left[\\begin{array}{l}\n3 \\\\\n4 \\\\\n3\n\\end{array}\\right]\n\\end{equation}</script><h3 id=\"Matrix-addition\"><a href=\"#Matrix-addition\" class=\"headerlink\" title=\"Matrix addition\"></a>Matrix addition</h3><p>Matrix addition is the process of combining two or more matrices into a single matrix. The resulting matrix is the sum of the individual matrices.</p>\n<p>If we have two matrices A and B with the same dimensions m x n, then their sum, C, is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{C}=\\boldsymbol{A}+\\boldsymbol{B}, C_{i, j}=A_{i, j}+B_{i, j}\n\\end{equation}</script><p>Consider the following matrices <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.602ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 708 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z\"></path></g></g></g></g></svg></mjx-container> :</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4 \\\\\n5 & 6\n\\end{array}\\right] \\\\\nB=\\left[\\begin{array}{cc}\n-1 & 2 \\\\\n4 & -3 \\\\\n7 & 1\n\\end{array}\\right]\n\\end{gathered}</script><p>To add these matrices, we add the corresponding elements:</p>\n<script type=\"math/tex; mode=display\">\nA+B=\\left[\\begin{array}{cc}\n1+(-1) & 2+2 \\\\\n3+4 & 4+(-3) \\\\\n5+7 & 6+1\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n0 & 4 \\\\\n7 & 1 \\\\\n12 & 7\n\\end{array}\\right]</script><h3 id=\"Scalar-multiplication\"><a href=\"#Scalar-multiplication\" class=\"headerlink\" title=\"Scalar multiplication\"></a>Scalar multiplication</h3><p>Scalar multiplication is the process of multiplying a vector or a matrix by a scalar value. The scalar value is a single number that scales or stretches the vector or matrix.</p>\n<p> Vectors can be multiplied by 2 or by -1 or by any number <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.98ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 433 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g></g></g></svg></mjx-container>. </p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n2 \\boldsymbol{v}=\\left[\\begin{array}{l}\n2 v_1 \\\\\n2 v_2\n\\end{array}\\right]=\\boldsymbol{v}+\\boldsymbol{v}\n\\end{equation}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n-\\boldsymbol{v}=\\left[\\begin{array}{l}\n-v_1 \\\\\n-v_2\n\\end{array}\\right]\n\\end{equation}</script><p>In case of a Matrix, let <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> be a <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.507ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2222.4 666\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container> matrix:</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]</script><p>To find the scalar multiplication of A by 2 , we simply multiply each element of the matrix by 2 :</p>\n<script type=\"math/tex; mode=display\">\n2 A=2\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n2 & 4 \\\\\n6 & 8\n\\end{array}\\right]</script><p>Similarly, we can find the scalar multiplication of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> by -1 by multiplying each element of the matrix by -1 :</p>\n<script type=\"math/tex; mode=display\">\n-1 A=-\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n-1 & -2 \\\\\n-3 & -4\n\\end{array}\\right]</script><p>In general, given a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and a scalar <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.005ex\" height=\"1.038ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -448 444 459\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"63\" d=\"M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z\"></path></g></g></g></g></svg></mjx-container>, the scalar multiplication of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.005ex\" height=\"1.038ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -448 444 459\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"63\" d=\"M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z\"></path></g></g></g></g></svg></mjx-container> is defined as:</p>\n<script type=\"math/tex; mode=display\">\nc A=c\\left[\\begin{array}{cccc}\na_{11} & a_{12} & \\ldots & a_{1 n} \\\\\na_{21} & a_{22} & \\ldots & a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m 1} & a_{m 2} & \\ldots & a_{m n}\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nc a_{11} & c a_{12} & \\ldots & c a_{1 n} \\\\\nc a_{21} & c a_{22} & \\ldots & c a_{2 n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nc a_{m 1} & c a_{m 2} & \\ldots & c a_{m n}\n\\end{array}\\right]</script><h3 id=\"Linear-combination\"><a href=\"#Linear-combination\" class=\"headerlink\" title=\"Linear combination\"></a>Linear combination</h3><p>Linear combination is a combination of addition and multiplication.</p>\n<p>Given a set of vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.018ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 5754 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1003.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1448.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2451.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2896.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4235.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4679.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> and a set of scalars <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.109ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 5352 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(869.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1314.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2183.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2628.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3967.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4411.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>, a linear combination of the vectors is defined as the sum of the vectors multiplied by their corresponding scalar coefficients:</p>\n<script type=\"math/tex; mode=display\">\nc_1 \\boldsymbol{v}_1+c_2 \\boldsymbol{v}_2+\\cdots+c_n \\boldsymbol{v}_n=\\sum_{i=1}^n c_i \\boldsymbol{v}_i</script><p>This expression represents the linear combination of the vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.018ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 5754 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1003.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1448.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2451.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2896.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4235.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4679.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(600,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> using the scalar coefficients <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.109ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 5352 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(869.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1314.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2183.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2628.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3967.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4411.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>, where the addition of the vectors and the multiplication of the scalars are both included.</p>\n<p>For example, consider the following set of vectors:</p>\n<script type=\"math/tex; mode=display\">\n\\boldsymbol{v}_1=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{v}_2=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right], \\quad \\boldsymbol{v}_3=\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]</script><p>A linear combination of these vectors using the scalar coefficients <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.116ex\" height=\"1.846ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2703.1 816\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1147.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2203.1,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container>, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.876ex\" height=\"1.846ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3481.1 816\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1147.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2203.1,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2981.1,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.116ex\" height=\"1.879ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2703.1 830.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(466,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1147.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2203.1,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> is:</p>\n<script type=\"math/tex; mode=display\">\n2 v_1-v_2+3 v_3=2\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right]-\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]+3\\left[\\begin{array}{l}\n7 \\\\\n8 \\\\\n9\n\\end{array}\\right]=\\left[\\begin{array}{l}\n29 \\\\\n32 \\\\\n35\n\\end{array}\\right]</script><h3 id=\"Dot-product\"><a href=\"#Dot-product\" class=\"headerlink\" title=\"Dot product\"></a>Dot product</h3><p>Given two vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.283ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 567 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.88ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 831 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container> of the same dimension, the dot product between <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.283ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 567 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.88ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 831 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container>, denoted as <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.797ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 2120.4 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(789.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1289.4,0)\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container>, is the sum of the products of the corresponding components:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{v} \\cdot \\boldsymbol{w}=\\sum_{i=1}^n v_i w_i=v_1 w_1+v_2 w_2+\\cdots+v_n w_n\n\\end{equation}</script><p>For example, consider the following two vectors:</p>\n<script type=\"math/tex; mode=display\">\n\\boldsymbol{v}=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n3\n\\end{array}\\right], \\quad \\boldsymbol{w}=\\left[\\begin{array}{l}\n4 \\\\\n5 \\\\\n6\n\\end{array}\\right]</script><p>To compute the dot product of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.283ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 567 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D497\" d=\"M380 367Q380 397 406 425T465 453Q493 453 516 430T540 357Q540 314 524 250T467 115T373 13Q338 -8 292 -8Q218 -8 167 23T116 129Q116 178 152 275T189 388Q189 396 187 398T176 401Q148 398 125 372T89 304Q84 288 81 285T61 282H55H44Q24 282 24 296Q24 306 34 330T64 382T116 431T189 452Q231 452 269 429T308 362Q308 346 273 255T238 114Q238 43 306 43Q336 43 363 65T407 118T437 182T456 239T462 268Q462 290 417 315Q380 335 380 367Z\"></path></g></g></g></svg></mjx-container> and  <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.018ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.88ex\" height=\"1.043ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -453 831 461\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D498\" d=\"M636 367Q636 400 664 426T719 453Q748 453 772 431T796 357Q796 321 782 256T727 112T633 6Q604 -8 567 -8Q466 -8 415 43Q414 42 410 38T403 31T396 25T388 18T378 11T367 5T355 0T340 -4T324 -7T306 -8Q249 -8 209 5T151 40T125 84T117 129Q117 176 153 274T190 388Q190 408 158 396Q112 376 90 306Q85 288 81 285T61 282H55H44Q24 282 24 296Q24 305 34 328T63 380T114 430T187 452Q240 452 274 427T309 362Q309 346 275 255T240 117Q240 43 317 43Q325 43 333 45T347 50T359 57T369 66T377 75T383 83T388 90L390 95Q390 99 389 110T387 129Q387 139 391 167Q393 177 419 282T448 396Q456 414 475 429T519 444Q546 444 559 428T572 397Q572 384 542 265T511 114Q511 43 579 43Q608 43 633 66T673 122T699 188T714 244L718 267Q718 291 673 315Q636 335 636 367Z\"></path></g></g></g></svg></mjx-container>, we multiply the corresponding elements of the two vectors and then sum the resulting products:</p>\n<script type=\"math/tex; mode=display\">\nv \\cdot w=(1 \\times 4)+(2 \\times 5)+(3 \\times 6)=32</script><h3 id=\"Matrix-multiplication\"><a href=\"#Matrix-multiplication\" class=\"headerlink\" title=\"Matrix multiplication\"></a>Matrix multiplication</h3><p>Given two matrices A and B, where A has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.978ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 2200.4 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1100.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1600.4,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> and B has dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.13ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 1825.4 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1322.4,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g></svg></mjx-container>, the product of A and B, denoted as C, is a matrix with dimensions <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.759ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 2103.4 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1100.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1600.4,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g></svg></mjx-container>, where the element in row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> and column <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.462ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.932ex\" height=\"1.957ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 412 865\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></svg></mjx-container> is obtained by multiplying the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th row of A with the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.462ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.932ex\" height=\"1.957ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 412 865\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></svg></mjx-container>-th column of B, and then summing the resulting products:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nC_{i, j}=\\sum_{k=1}^n A_{i, k} B_{k, j}, \\quad \\text { for } 1 \\leq i \\leq m, 1 \\leq j \\leq p\n\\end{equation}</script><p>For example, consider the following matrices <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container> :</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right], B=\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]</script><p>To multiply <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container>, we take the dot product of each row of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> with each column of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container> :</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ll}\n1 & 2 \\\\\n3 & 4\n\\end{array}\\right]\\left[\\begin{array}{ll}\n5 & 6 \\\\\n7 & 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n1 \\cdot 5+2 \\cdot 7 & 1 \\cdot 6+2 \\cdot 8 \\\\\n3 \\cdot 5+4 \\cdot 7 & 3 \\cdot 6+4 \\cdot 8\n\\end{array}\\right]=\\left[\\begin{array}{ll}\n19 & 22 \\\\\n43 & 50\n\\end{array}\\right]</script><h3 id=\"Identity-matrix\"><a href=\"#Identity-matrix\" class=\"headerlink\" title=\"Identity matrix\"></a>Identity matrix</h3><p>The identity matrix, denoted by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.304ex\" height=\"1.909ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 1018.3 843.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D470\" d=\"M247 624Q242 624 233 624T220 623Q186 623 186 640Q186 647 190 664T202 684Q206 686 226 686Q277 684 393 684Q435 684 471 684T528 685T553 686Q573 686 573 670Q573 650 564 632Q556 624 537 624H501H449L380 344Q309 64 309 63T356 62Q361 62 370 62T384 63Q417 63 417 46Q417 26 408 8Q403 3 396 0L352 1Q325 2 216 2T82 1L45 0Q30 7 30 16Q33 51 46 60Q51 62 102 62H154L294 623Q294 624 247 624Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(544,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>, is a square matrix of dimension <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> with ones on the main diagonal and zeros everywhere else. In other words, the entry in the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th row and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.462ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.932ex\" height=\"1.957ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 412 865\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></svg></mjx-container>-th column of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.304ex\" height=\"1.909ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 1018.3 843.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D470\" d=\"M247 624Q242 624 233 624T220 623Q186 623 186 640Q186 647 190 664T202 684Q206 686 226 686Q277 684 393 684Q435 684 471 684T528 685T553 686Q573 686 573 670Q573 650 564 632Q556 624 537 624H501H449L380 344Q309 64 309 63T356 62Q361 62 370 62T384 63Q417 63 417 46Q417 26 408 8Q403 3 396 0L352 1Q325 2 216 2T82 1L45 0Q30 7 30 16Q33 51 46 60Q51 62 102 62H154L294 623Q294 624 247 624Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(544,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\left(\\boldsymbol{I}_n\\right)_{i, j}= \\begin{cases}1 & \\text { if } i=j \\\\ 0 & \\text { if } i \\neq j\\end{cases}\n\\end{equation}</script><p>For example, the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.028ex\" height=\"1.554ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2222.4 687\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1722.4,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> identity matrix is:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{I}_3=\\left[\\begin{array}{lll}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right]\n\\end{equation}</script><p>The identity matrix is a special type of matrix in that it behaves like the number 1 in multiplication. Specifically, if <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container> is a square matrix of dimension <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>, then:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{A} \\boldsymbol{I}_n=\\boldsymbol{I}_n \\boldsymbol{A}=\\boldsymbol{A}\n\\end{equation}</script><h3 id=\"Matrix-inverse\"><a href=\"#Matrix-inverse\" class=\"headerlink\" title=\"Matrix inverse\"></a>Matrix inverse</h3><p>The inverse of a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container>, denoted as <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.198ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1855.7 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(902,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></g></svg></mjx-container>, is defined as a matrix such that:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A}=\\boldsymbol{I}_n\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.357ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.304ex\" height=\"1.909ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 1018.3 843.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D470\" d=\"M247 624Q242 624 233 624T220 623Q186 623 186 640Q186 647 190 664T202 684Q206 686 226 686Q277 684 393 684Q435 684 471 684T528 685T553 686Q573 686 573 670Q573 650 564 632Q556 624 537 624H501H449L380 344Q309 64 309 63T356 62Q361 62 370 62T384 63Q417 63 417 46Q417 26 408 8Q403 3 396 0L352 1Q325 2 216 2T82 1L45 0Q30 7 30 16Q33 51 46 60Q51 62 102 62H154L294 623Q294 624 247 624Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(544,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the identity matrix of dimension <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>. If <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.198ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1855.7 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(902,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></g></svg></mjx-container> exists (<strong>not all matrices are invertible</strong>), then the solution to the linear system <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.653ex\" height=\"1.794ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 3382.6 793\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(869,0)\"><path data-c=\"1D499\" d=\"M74 282H63Q43 282 43 296Q43 298 45 307T56 332T76 365T110 401T159 433Q200 451 233 451H236Q273 451 282 450Q358 437 382 400L392 410Q434 452 483 452Q538 452 568 421T599 346Q599 303 573 280T517 256Q494 256 478 270T462 308Q462 343 488 367Q501 377 520 385Q520 386 516 389T502 396T480 400T462 398Q429 383 415 341Q354 116 354 80T405 44Q449 44 485 74T535 142Q539 156 542 159T562 162H568H579Q599 162 599 148Q599 135 586 111T550 60T485 12T397 -8Q313 -8 266 35L258 44Q215 -7 161 -7H156Q99 -7 71 25T43 95Q43 143 70 165T125 188Q148 188 164 174T180 136Q180 101 154 77Q141 67 122 59Q124 54 136 49T161 43Q183 43 200 61T226 103Q287 328 287 364T236 400Q200 400 164 377T107 302Q103 288 100 285T80 282H74Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1805.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2861.6,0)\"><path data-c=\"1D483\" d=\"M220 -8Q142 -8 94 35T45 155V167Q45 187 52 218T104 426L153 622H149Q148 622 144 622T134 623T122 624T111 624T101 624T96 625Q84 628 84 642Q84 647 88 661T94 679Q98 684 109 685T185 690Q258 694 272 694Q289 694 293 679Q293 676 263 553L232 429L244 434Q256 440 281 446T331 452Q417 452 465 407T513 285Q513 235 494 184T439 90T346 20T220 -8ZM385 337Q385 400 318 400Q269 400 226 360Q214 349 211 341T191 268Q162 149 162 113Q162 44 226 44Q269 44 299 76T339 135T362 215Q364 222 365 226Q385 303 385 337Z\"></path></g></g></g></svg></mjx-container> is given by:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}</script><p>This is because we can multiply both sides of the equation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.653ex\" height=\"1.794ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 3382.6 793\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(869,0)\"><path data-c=\"1D499\" d=\"M74 282H63Q43 282 43 296Q43 298 45 307T56 332T76 365T110 401T159 433Q200 451 233 451H236Q273 451 282 450Q358 437 382 400L392 410Q434 452 483 452Q538 452 568 421T599 346Q599 303 573 280T517 256Q494 256 478 270T462 308Q462 343 488 367Q501 377 520 385Q520 386 516 389T502 396T480 400T462 398Q429 383 415 341Q354 116 354 80T405 44Q449 44 485 74T535 142Q539 156 542 159T562 162H568H579Q599 162 599 148Q599 135 586 111T550 60T485 12T397 -8Q313 -8 266 35L258 44Q215 -7 161 -7H156Q99 -7 71 25T43 95Q43 143 70 165T125 188Q148 188 164 174T180 136Q180 101 154 77Q141 67 122 59Q124 54 136 49T161 43Q183 43 200 61T226 103Q287 328 287 364T236 400Q200 400 164 377T107 302Q103 288 100 285T80 282H74Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1805.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2861.6,0)\"><path data-c=\"1D483\" d=\"M220 -8Q142 -8 94 35T45 155V167Q45 187 52 218T104 426L153 622H149Q148 622 144 622T134 623T122 624T111 624T101 624T96 625Q84 628 84 642Q84 647 88 661T94 679Q98 684 109 685T185 690Q258 694 272 694Q289 694 293 679Q293 676 263 553L232 429L244 434Q256 440 281 446T331 452Q417 452 465 407T513 285Q513 235 494 184T439 90T346 20T220 -8ZM385 337Q385 400 318 400Q269 400 226 360Q214 349 211 341T191 268Q162 149 162 113Q162 44 226 44Q269 44 299 76T339 135T362 215Q364 222 365 226Q385 303 385 337Z\"></path></g></g></g></svg></mjx-container> by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.198ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1855.7 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(902,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></g></svg></mjx-container> on the left to obtain:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{A}^{-1} \\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}</script><p>which simplifies to:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\boldsymbol{I}_n \\boldsymbol{x}=\\boldsymbol{x}=\\boldsymbol{A}^{-1} \\boldsymbol{b}\n\\end{equation}</script><p>If the determinant of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container> is zero, then the matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.609ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -711 869 711\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D468\" d=\"M65 0Q45 0 45 18Q48 52 61 60Q65 62 81 62Q155 62 165 74Q166 74 265 228T465 539T569 699Q576 707 583 709T611 711T637 710T649 700Q650 697 695 380L741 63L784 62H827Q839 50 839 45L835 29Q831 9 827 5T806 0Q803 0 790 0T743 1T657 2Q585 2 547 1T504 0Q481 0 481 17Q484 54 497 60Q501 62 541 62Q580 62 580 63Q580 68 573 121T564 179V181H308L271 124Q236 69 236 67T283 62H287Q316 62 316 46Q316 26 307 8Q302 3 295 0L262 1Q242 2 168 2Q119 2 93 1T65 0ZM537 372Q533 402 528 435T521 486T518 504V505Q517 505 433 375L348 244L451 243Q555 243 555 244L537 372Z\"></path></g></g></g></svg></mjx-container> is singular or non-invertible, and it does not have an inverse. </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 22:26</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Transpose</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Transpose of A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A.T)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Vector Addition</span></span><br><span class=\"line\">u = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">v = np.array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">w = u + v</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u:\"</span>, u)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector v:\"</span>, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u + v:\"</span>, w)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Addition</span></span><br><span class=\"line\">B = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">C = np.array([[<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>]])</span><br><span class=\"line\">D = B + C</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix B:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix C:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(C)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix B + C:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(D)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Scalar Multiplication</span></span><br><span class=\"line\">k = <span class=\"number\">3</span></span><br><span class=\"line\">E = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">F = k * E</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar k:\"</span>, k)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix E:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(E)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar k times E:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(F)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Linear Combination</span></span><br><span class=\"line\">u = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">v = np.array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">a = <span class=\"number\">2</span></span><br><span class=\"line\">b = <span class=\"number\">3</span></span><br><span class=\"line\">w = a * u + b * v</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u:\"</span>, u)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector v:\"</span>, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar a:\"</span>, a)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar b:\"</span>, b)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Linear combination a*u + b*v:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(w)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dot Product</span></span><br><span class=\"line\">u = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">v = np.array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">w = np.dot(u, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector u:\"</span>, u)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector v:\"</span>, v)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Dot product of u and v:\"</span>, w)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Multiplication</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">B = np.array([[<span class=\"number\">7</span>, <span class=\"number\">8</span>], [<span class=\"number\">9</span>, <span class=\"number\">10</span>]])</span><br><span class=\"line\">C = np.dot(A, B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix B:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix product of A and B:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(C)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Identity Matrix</span></span><br><span class=\"line\">I = np.eye(<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Identity matrix of size 3:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(I)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrix Inverse</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]])</span><br><span class=\"line\">B = np.linalg.inv(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Inverse of A:\"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(B)</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.</li>\n<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep learning. MIT Press.</li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Scipy implementation examples","date":"2023-04-03T16:57:37.000Z","_content":"\n### Interpolation\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 19:06\n\nimport numpy as np\nfrom scipy.interpolate import interp1d\nimport matplotlib.pyplot as plt\n\n# Generate some random data\nx = np.linspace(0, 10, num=11, endpoint=True)\ny = np.cos(-x**2/9.0)\n\n# Create an interpolation function\nf = interp1d(x, y, kind='cubic')\n\n# Generate new x values to interpolate at\nx_new = np.linspace(0, 10, num=41, endpoint=True)\n\n# Use the interpolation function to generate y values\ny_new = f(x_new)\n\n# Plot the original data and interpolated data\nplt.plot(x, y, 'o', label='Original Data')\nplt.plot(x_new, y_new, label='Interpolated Data')\nplt.title('Cubic Interpolation')\n\nplt.legend()\nplt.savefig('Interpolation.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Interpolation](Differential-equations/Interpolation.png)\n\n### Optimization\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 20:01\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n\n# Define the function to be optimized\ndef f(x):\n    return x ** 2 + 3 * np.sin(x)\n\n\n# Use the minimize function from scipy.optimize to find the minimum of the function\nresult = minimize(f, x0=0)\n\n# Generate some data for plotting\nx_vals = np.linspace(-5, 5, 100)\ny_vals = f(x_vals)\n\n# Plot the function and the optimized point\nplt.plot(x_vals, y_vals, label='Function')\nplt.scatter(result.x, result.fun, color='red', label='Optimized Point')\nplt.title('Optimization')\nplt.legend()\nplt.savefig('Optimization.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Optimization](Differential-equations/Optimization.png)\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 20:03\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy.optimize import minimize\n\n# Define the function\ndef f(x):\n    return (4 - 2.1 * x[0] ** 2 + x[0] ** 4 / 3) * x[0] ** 2 + x[0] * x[1] + (4 * x[1] ** 2 - 4) * x[1] ** 2\n\n# Define the bounds\nbounds = [(-2, 2), (-1, 1)]\n\n# Find the global minimum\nres1 = minimize(f, x0=[1, -1], bounds=bounds)\nres2 = minimize(f, x0=[-1, 1], bounds=bounds)\nres3 = minimize(f, x0=[0, 0], bounds=bounds)\n\n# Plot the function's 3D surface and contour\nx = np.linspace(-2, 2, 100)\ny = np.linspace(-1, 1, 100)\nX, Y = np.meshgrid(x, y)\nZ = f([X, Y])\nfig = plt.figure(figsize=(12, 6))\nax1 = fig.add_subplot(1, 2, 1, projection='3d')\nax1.plot_surface(X, Y, Z, cmap='coolwarm', alpha=0.8)\nax1.set_xlabel('x')\nax1.set_ylabel('y')\nax1.set_zlabel('f(x, y)')\nax1.set_title('3D Surface')\n# colorbar\nm = plt.cm.ScalarMappable(cmap='coolwarm')\nfig.colorbar(m, ax=ax1)\n\nax2 = fig.add_subplot(1, 2, 2)\nax2.contourf(X, Y, Z, 50, cmap='coolwarm')\nax2.set_xlabel('x')\nax2.set_ylabel('y')\nax2.set_title('Contourf for f(x, y)')\n# plot global minimum\nax2.scatter(res1.x[0], res1.x[1], color='red', label='Global minimum with initial guess[1, -1]', marker='*', s=200)\nax2.scatter(res2.x[0], res2.x[1], color='orange', label='Global minimum with initial guess[-1, 1]', marker='*', s=200)\nax2.scatter(res3.x[0], res3.x[1], color='cyan', label='Global minimum with initial guess[0, 0]', marker='*', s=200)\nax2.legend()\n# move the legend\nax2.legend(bbox_to_anchor=(0, 1), loc='upper left', borderaxespad=0)\n# colorbar\nfig.colorbar(m, ax=ax2)\nplt.savefig('Optimization with constraints.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Optimization with constraints](Differential-equations/Optimization%20with%20constraints.png)\n\n### Local minima and global minima\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 20:27\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\n\n\n# Define the function to find the minima of\ndef my_function(x):\n    return np.sin(x) + np.sin(2 * x) + np.sin(4 * x) + np.sqrt(abs(x))\n\n\n# Generate x values for the function\nx = np.linspace(-3, 6 * np.pi, 1000)\n\n# Plot the function\nplt.plot(x, my_function(x))\n\n# Find the global minimum of the function\nglobal_min = np.min(my_function(x))\n\n# Plot the global minimum as a red dot\nplt.plot(x[np.argmin(my_function(x))], global_min, 'ro', label='Global Minimum',markersize=10)\n\n# Find the local minima of the function\nlocal_mins, _ = find_peaks(-my_function(x))\n\n# Plot the local minima as blue dots\nplt.plot(x[local_mins], my_function(x)[local_mins], 'bo', label='Local Minima',markersize=7)\n\n# Add a legend to the plot\nplt.legend(['Function', 'Global Minimum', 'Local Minima'])\n\n# Show the plot\nplt.savefig('Local Minima.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Local Minima](Differential-equations/Local%20Minima.png)\n\n### Smooth and non-smooth\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:03\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some sample data\nx = np.linspace(-5, 5, 100)\ny_smooth = np.sin(x)\ny_non_smooth = np.abs(x)\n\n# Create a plot with two subplots\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot the smooth function in the first subplot\naxs[0].plot(x, y_smooth)\naxs[0].set_title(\"Smooth Function\")\n\n# Plot the non-smooth function in the second subplot\naxs[1].plot(x, y_non_smooth)\naxs[1].set_title(\"Non-Smooth Function\")\n\n# Add labels and a title to the overall figure\nfig.suptitle(\"Smooth vs Non-Smooth Functions\")\nfig.text(0.5, 0.04, \"x\", ha=\"center\")\nfig.text(0.04, 0.5, \"y\", va=\"center\", rotation=\"vertical\")\n\n# Show the plot\nplt.savefig('smooth_non_smooth.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![smooth_non_smooth](Differential-equations/smooth_non_smooth.png)\n\n### Noisy versus exact cost functions\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:04\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the exact and noisy cost functions\ndef exact_cost(x):\n    return np.sin(x)\n\ndef noisy_cost(x):\n    return np.sin(x) + np.random.normal(scale=0.1)\n\n# Generate data\nx = np.linspace(0, 2*np.pi, 100)\nexact_y = exact_cost(x)\nnoisy_y = np.array([noisy_cost(xi) for xi in x])\n\n# Plot the exact and noisy cost functions\nplt.plot(x, exact_y, label='Exact Cost')\nplt.plot(x, noisy_y, label='Noisy Cost')\nplt.title('Exact vs Noisy Cost Functions')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.savefig('Exact_vs_Noisy_Cost_Functions.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Exact_vs_Noisy_Cost_Functions](Differential-equations/Exact_vs_Noisy_Cost_Functions.png)\n\n### Constraints\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:07\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n# Define the objective function\ndef objective_function(x):\n    return (x[0] - 2) ** 2 + (x[1] - 2) ** 2\n\n# Define the bounds of the search space\nbounds = ((-1, 1), (-1, 1))\n\n# Define the constrained optimization problem\ndef constrained_optimization():\n    res = minimize(objective_function, x0=(0, 0), bounds=bounds)\n    return res\n\n# Define the unconstrained optimization problem\ndef unconstrained_optimization():\n    res = minimize(objective_function, x0=(0, 0))\n    return res\n\n# Plot the objective function and the search space\nx = np.linspace(-2, 4, 100)\ny = np.linspace(-2, 4, 100)\nX, Y = np.meshgrid(x, y)\nZ = objective_function((X, Y))\n\nfig, ax = plt.subplots()\ncmap = plt.get_cmap('viridis')\ncf = ax.contourf(X, Y, Z, cmap=cmap, levels=20)\nfig.colorbar(cf, ax=ax)\nax.set_title('Objective Function')\n\n# Plot the search space\nax.plot([-1, 1], [-1, -1], 'k', linewidth=2)\nax.plot([-1, 1], [1, 1], 'k', linewidth=2)\nax.plot([-1, -1], [-1, 1], 'k', linewidth=2)\nax.plot([1, 1], [-1, 1], 'k', linewidth=2)\n\n# Plot the constrained minimum\nres_constrained = constrained_optimization()\nax.plot(res_constrained.x[0], res_constrained.x[1], 'ro', label='Constrained Minimum')\n\n# Plot the unconstrained minimum\nres_unconstrained = unconstrained_optimization()\nax.plot(res_unconstrained.x[0], res_unconstrained.x[1], 'bo', label='Unconstrained Minimum')\n\nax.legend()\nplt.savefig('Constrained_vs_Unconstrained_Optimization.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Constrained_vs_Unconstrained_Optimization](Differential-equations/Constrained_vs_Unconstrained_Optimization.png)\n\n### Reference\n\n1. *Scipy Lecture Notes  Scipy lecture notes*. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Differential-equations.md","raw":"---\nmathjax: true\ntitle: Scipy implementation examples\ndate: 2023-04-03 16:57:37\ntags:\n  - Math\n  - Python\n  - Scipy\n---\n\n### Interpolation\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 19:06\n\nimport numpy as np\nfrom scipy.interpolate import interp1d\nimport matplotlib.pyplot as plt\n\n# Generate some random data\nx = np.linspace(0, 10, num=11, endpoint=True)\ny = np.cos(-x**2/9.0)\n\n# Create an interpolation function\nf = interp1d(x, y, kind='cubic')\n\n# Generate new x values to interpolate at\nx_new = np.linspace(0, 10, num=41, endpoint=True)\n\n# Use the interpolation function to generate y values\ny_new = f(x_new)\n\n# Plot the original data and interpolated data\nplt.plot(x, y, 'o', label='Original Data')\nplt.plot(x_new, y_new, label='Interpolated Data')\nplt.title('Cubic Interpolation')\n\nplt.legend()\nplt.savefig('Interpolation.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Interpolation](Differential-equations/Interpolation.png)\n\n### Optimization\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 20:01\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n\n# Define the function to be optimized\ndef f(x):\n    return x ** 2 + 3 * np.sin(x)\n\n\n# Use the minimize function from scipy.optimize to find the minimum of the function\nresult = minimize(f, x0=0)\n\n# Generate some data for plotting\nx_vals = np.linspace(-5, 5, 100)\ny_vals = f(x_vals)\n\n# Plot the function and the optimized point\nplt.plot(x_vals, y_vals, label='Function')\nplt.scatter(result.x, result.fun, color='red', label='Optimized Point')\nplt.title('Optimization')\nplt.legend()\nplt.savefig('Optimization.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Optimization](Differential-equations/Optimization.png)\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 20:03\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy.optimize import minimize\n\n# Define the function\ndef f(x):\n    return (4 - 2.1 * x[0] ** 2 + x[0] ** 4 / 3) * x[0] ** 2 + x[0] * x[1] + (4 * x[1] ** 2 - 4) * x[1] ** 2\n\n# Define the bounds\nbounds = [(-2, 2), (-1, 1)]\n\n# Find the global minimum\nres1 = minimize(f, x0=[1, -1], bounds=bounds)\nres2 = minimize(f, x0=[-1, 1], bounds=bounds)\nres3 = minimize(f, x0=[0, 0], bounds=bounds)\n\n# Plot the function's 3D surface and contour\nx = np.linspace(-2, 2, 100)\ny = np.linspace(-1, 1, 100)\nX, Y = np.meshgrid(x, y)\nZ = f([X, Y])\nfig = plt.figure(figsize=(12, 6))\nax1 = fig.add_subplot(1, 2, 1, projection='3d')\nax1.plot_surface(X, Y, Z, cmap='coolwarm', alpha=0.8)\nax1.set_xlabel('x')\nax1.set_ylabel('y')\nax1.set_zlabel('f(x, y)')\nax1.set_title('3D Surface')\n# colorbar\nm = plt.cm.ScalarMappable(cmap='coolwarm')\nfig.colorbar(m, ax=ax1)\n\nax2 = fig.add_subplot(1, 2, 2)\nax2.contourf(X, Y, Z, 50, cmap='coolwarm')\nax2.set_xlabel('x')\nax2.set_ylabel('y')\nax2.set_title('Contourf for f(x, y)')\n# plot global minimum\nax2.scatter(res1.x[0], res1.x[1], color='red', label='Global minimum with initial guess[1, -1]', marker='*', s=200)\nax2.scatter(res2.x[0], res2.x[1], color='orange', label='Global minimum with initial guess[-1, 1]', marker='*', s=200)\nax2.scatter(res3.x[0], res3.x[1], color='cyan', label='Global minimum with initial guess[0, 0]', marker='*', s=200)\nax2.legend()\n# move the legend\nax2.legend(bbox_to_anchor=(0, 1), loc='upper left', borderaxespad=0)\n# colorbar\nfig.colorbar(m, ax=ax2)\nplt.savefig('Optimization with constraints.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Optimization with constraints](Differential-equations/Optimization%20with%20constraints.png)\n\n### Local minima and global minima\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 20:27\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\n\n\n# Define the function to find the minima of\ndef my_function(x):\n    return np.sin(x) + np.sin(2 * x) + np.sin(4 * x) + np.sqrt(abs(x))\n\n\n# Generate x values for the function\nx = np.linspace(-3, 6 * np.pi, 1000)\n\n# Plot the function\nplt.plot(x, my_function(x))\n\n# Find the global minimum of the function\nglobal_min = np.min(my_function(x))\n\n# Plot the global minimum as a red dot\nplt.plot(x[np.argmin(my_function(x))], global_min, 'ro', label='Global Minimum',markersize=10)\n\n# Find the local minima of the function\nlocal_mins, _ = find_peaks(-my_function(x))\n\n# Plot the local minima as blue dots\nplt.plot(x[local_mins], my_function(x)[local_mins], 'bo', label='Local Minima',markersize=7)\n\n# Add a legend to the plot\nplt.legend(['Function', 'Global Minimum', 'Local Minima'])\n\n# Show the plot\nplt.savefig('Local Minima.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Local Minima](Differential-equations/Local%20Minima.png)\n\n### Smooth and non-smooth\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:03\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some sample data\nx = np.linspace(-5, 5, 100)\ny_smooth = np.sin(x)\ny_non_smooth = np.abs(x)\n\n# Create a plot with two subplots\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot the smooth function in the first subplot\naxs[0].plot(x, y_smooth)\naxs[0].set_title(\"Smooth Function\")\n\n# Plot the non-smooth function in the second subplot\naxs[1].plot(x, y_non_smooth)\naxs[1].set_title(\"Non-Smooth Function\")\n\n# Add labels and a title to the overall figure\nfig.suptitle(\"Smooth vs Non-Smooth Functions\")\nfig.text(0.5, 0.04, \"x\", ha=\"center\")\nfig.text(0.04, 0.5, \"y\", va=\"center\", rotation=\"vertical\")\n\n# Show the plot\nplt.savefig('smooth_non_smooth.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![smooth_non_smooth](Differential-equations/smooth_non_smooth.png)\n\n### Noisy versus exact cost functions\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:04\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the exact and noisy cost functions\ndef exact_cost(x):\n    return np.sin(x)\n\ndef noisy_cost(x):\n    return np.sin(x) + np.random.normal(scale=0.1)\n\n# Generate data\nx = np.linspace(0, 2*np.pi, 100)\nexact_y = exact_cost(x)\nnoisy_y = np.array([noisy_cost(xi) for xi in x])\n\n# Plot the exact and noisy cost functions\nplt.plot(x, exact_y, label='Exact Cost')\nplt.plot(x, noisy_y, label='Noisy Cost')\nplt.title('Exact vs Noisy Cost Functions')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.savefig('Exact_vs_Noisy_Cost_Functions.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Exact_vs_Noisy_Cost_Functions](Differential-equations/Exact_vs_Noisy_Cost_Functions.png)\n\n### Constraints\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:07\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n# Define the objective function\ndef objective_function(x):\n    return (x[0] - 2) ** 2 + (x[1] - 2) ** 2\n\n# Define the bounds of the search space\nbounds = ((-1, 1), (-1, 1))\n\n# Define the constrained optimization problem\ndef constrained_optimization():\n    res = minimize(objective_function, x0=(0, 0), bounds=bounds)\n    return res\n\n# Define the unconstrained optimization problem\ndef unconstrained_optimization():\n    res = minimize(objective_function, x0=(0, 0))\n    return res\n\n# Plot the objective function and the search space\nx = np.linspace(-2, 4, 100)\ny = np.linspace(-2, 4, 100)\nX, Y = np.meshgrid(x, y)\nZ = objective_function((X, Y))\n\nfig, ax = plt.subplots()\ncmap = plt.get_cmap('viridis')\ncf = ax.contourf(X, Y, Z, cmap=cmap, levels=20)\nfig.colorbar(cf, ax=ax)\nax.set_title('Objective Function')\n\n# Plot the search space\nax.plot([-1, 1], [-1, -1], 'k', linewidth=2)\nax.plot([-1, 1], [1, 1], 'k', linewidth=2)\nax.plot([-1, -1], [-1, 1], 'k', linewidth=2)\nax.plot([1, 1], [-1, 1], 'k', linewidth=2)\n\n# Plot the constrained minimum\nres_constrained = constrained_optimization()\nax.plot(res_constrained.x[0], res_constrained.x[1], 'ro', label='Constrained Minimum')\n\n# Plot the unconstrained minimum\nres_unconstrained = unconstrained_optimization()\nax.plot(res_unconstrained.x[0], res_unconstrained.x[1], 'bo', label='Unconstrained Minimum')\n\nax.legend()\nplt.savefig('Constrained_vs_Unconstrained_Optimization.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Constrained_vs_Unconstrained_Optimization](Differential-equations/Constrained_vs_Unconstrained_Optimization.png)\n\n### Reference\n\n1. *Scipy Lecture Notes  Scipy lecture notes*. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Differential-equations","published":1,"updated":"2023-04-07T02:43:50.464Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73ge0003ozpi3j0sczxr","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Interpolation\"><a href=\"#Interpolation\" class=\"headerlink\" title=\"Interpolation\"></a>Interpolation</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 19:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.interpolate <span class=\"keyword\">import</span> interp1d</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, num=<span class=\"number\">11</span>, endpoint=<span class=\"literal\">True</span>)</span><br><span class=\"line\">y = np.cos(-x**<span class=\"number\">2</span>/<span class=\"number\">9.0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create an interpolation function</span></span><br><span class=\"line\">f = interp1d(x, y, kind=<span class=\"string\">'cubic'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate new x values to interpolate at</span></span><br><span class=\"line\">x_new = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, num=<span class=\"number\">41</span>, endpoint=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use the interpolation function to generate y values</span></span><br><span class=\"line\">y_new = f(x_new)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the original data and interpolated data</span></span><br><span class=\"line\">plt.plot(x, y, <span class=\"string\">'o'</span>, label=<span class=\"string\">'Original Data'</span>)</span><br><span class=\"line\">plt.plot(x_new, y_new, label=<span class=\"string\">'Interpolated Data'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Cubic Interpolation'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Interpolation.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Interpolation\" data-src=\"/2023/04/03/Differential-equations/Interpolation.png\"></p>\n<h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 20:01</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function to be optimized</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span> + <span class=\"number\">3</span> * np.sin(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use the minimize function from scipy.optimize to find the minimum of the function</span></span><br><span class=\"line\">result = minimize(f, x0=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some data for plotting</span></span><br><span class=\"line\">x_vals = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y_vals = f(x_vals)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function and the optimized point</span></span><br><span class=\"line\">plt.plot(x_vals, y_vals, label=<span class=\"string\">'Function'</span>)</span><br><span class=\"line\">plt.scatter(result.x, result.fun, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Optimized Point'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Optimization'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Optimization.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Optimization\" data-src=\"/2023/04/03/Differential-equations/Optimization.png\"></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 20:03</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"number\">4</span> - <span class=\"number\">2.1</span> * x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span> + x[<span class=\"number\">0</span>] ** <span class=\"number\">4</span> / <span class=\"number\">3</span>) * x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span> + x[<span class=\"number\">0</span>] * x[<span class=\"number\">1</span>] + (<span class=\"number\">4</span> * x[<span class=\"number\">1</span>] ** <span class=\"number\">2</span> - <span class=\"number\">4</span>) * x[<span class=\"number\">1</span>] ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the bounds</span></span><br><span class=\"line\">bounds = [(-<span class=\"number\">2</span>, <span class=\"number\">2</span>), (-<span class=\"number\">1</span>, <span class=\"number\">1</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find the global minimum</span></span><br><span class=\"line\">res1 = minimize(f, x0=[<span class=\"number\">1</span>, -<span class=\"number\">1</span>], bounds=bounds)</span><br><span class=\"line\">res2 = minimize(f, x0=[-<span class=\"number\">1</span>, <span class=\"number\">1</span>], bounds=bounds)</span><br><span class=\"line\">res3 = minimize(f, x0=[<span class=\"number\">0</span>, <span class=\"number\">0</span>], bounds=bounds)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function's 3D surface and contour</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = f([X, Y])</span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">ax1 = fig.add_subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax1.plot_surface(X, Y, Z, cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.8</span>)</span><br><span class=\"line\">ax1.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax1.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax1.set_zlabel(<span class=\"string\">'f(x, y)'</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'3D Surface'</span>)</span><br><span class=\"line\"><span class=\"comment\"># colorbar</span></span><br><span class=\"line\">m = plt.cm.ScalarMappable(cmap=<span class=\"string\">'coolwarm'</span>)</span><br><span class=\"line\">fig.colorbar(m, ax=ax1)</span><br><span class=\"line\"></span><br><span class=\"line\">ax2 = fig.add_subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">ax2.contourf(X, Y, Z, <span class=\"number\">50</span>, cmap=<span class=\"string\">'coolwarm'</span>)</span><br><span class=\"line\">ax2.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax2.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'Contourf for f(x, y)'</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot global minimum</span></span><br><span class=\"line\">ax2.scatter(res1.x[<span class=\"number\">0</span>], res1.x[<span class=\"number\">1</span>], color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Global minimum with initial guess[1, -1]'</span>, marker=<span class=\"string\">'*'</span>, s=<span class=\"number\">200</span>)</span><br><span class=\"line\">ax2.scatter(res2.x[<span class=\"number\">0</span>], res2.x[<span class=\"number\">1</span>], color=<span class=\"string\">'orange'</span>, label=<span class=\"string\">'Global minimum with initial guess[-1, 1]'</span>, marker=<span class=\"string\">'*'</span>, s=<span class=\"number\">200</span>)</span><br><span class=\"line\">ax2.scatter(res3.x[<span class=\"number\">0</span>], res3.x[<span class=\"number\">1</span>], color=<span class=\"string\">'cyan'</span>, label=<span class=\"string\">'Global minimum with initial guess[0, 0]'</span>, marker=<span class=\"string\">'*'</span>, s=<span class=\"number\">200</span>)</span><br><span class=\"line\">ax2.legend()</span><br><span class=\"line\"><span class=\"comment\"># move the legend</span></span><br><span class=\"line\">ax2.legend(bbox_to_anchor=(<span class=\"number\">0</span>, <span class=\"number\">1</span>), loc=<span class=\"string\">'upper left'</span>, borderaxespad=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"comment\"># colorbar</span></span><br><span class=\"line\">fig.colorbar(m, ax=ax2)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Optimization with constraints.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Optimization with constraints\" data-src=\"/2023/04/03/Differential-equations/Optimization%20with%20constraints.png\"></p>\n<h3 id=\"Local-minima-and-global-minima\"><a href=\"#Local-minima-and-global-minima\" class=\"headerlink\" title=\"Local minima and global minima\"></a>Local minima and global minima</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 20:27</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.signal <span class=\"keyword\">import</span> find_peaks</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function to find the minima of</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">my_function</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(x) + np.sin(<span class=\"number\">2</span> * x) + np.sin(<span class=\"number\">4</span> * x) + np.sqrt(<span class=\"built_in\">abs</span>(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate x values for the function</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">3</span>, <span class=\"number\">6</span> * np.pi, <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function</span></span><br><span class=\"line\">plt.plot(x, my_function(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find the global minimum of the function</span></span><br><span class=\"line\">global_min = np.<span class=\"built_in\">min</span>(my_function(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the global minimum as a red dot</span></span><br><span class=\"line\">plt.plot(x[np.argmin(my_function(x))], global_min, <span class=\"string\">'ro'</span>, label=<span class=\"string\">'Global Minimum'</span>,markersize=<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find the local minima of the function</span></span><br><span class=\"line\">local_mins, _ = find_peaks(-my_function(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the local minima as blue dots</span></span><br><span class=\"line\">plt.plot(x[local_mins], my_function(x)[local_mins], <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Local Minima'</span>,markersize=<span class=\"number\">7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add a legend to the plot</span></span><br><span class=\"line\">plt.legend([<span class=\"string\">'Function'</span>, <span class=\"string\">'Global Minimum'</span>, <span class=\"string\">'Local Minima'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Local Minima.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Local Minima\" data-src=\"/2023/04/03/Differential-equations/Local%20Minima.png\"></p>\n<h3 id=\"Smooth-and-non-smooth\"><a href=\"#Smooth-and-non-smooth\" class=\"headerlink\" title=\"Smooth and non-smooth\"></a>Smooth and non-smooth</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:03</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some sample data</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y_smooth = np.sin(x)</span><br><span class=\"line\">y_non_smooth = np.<span class=\"built_in\">abs</span>(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a plot with two subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the smooth function in the first subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x, y_smooth)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">\"Smooth Function\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the non-smooth function in the second subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x, y_non_smooth)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">\"Non-Smooth Function\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and a title to the overall figure</span></span><br><span class=\"line\">fig.suptitle(<span class=\"string\">\"Smooth vs Non-Smooth Functions\"</span>)</span><br><span class=\"line\">fig.text(<span class=\"number\">0.5</span>, <span class=\"number\">0.04</span>, <span class=\"string\">\"x\"</span>, ha=<span class=\"string\">\"center\"</span>)</span><br><span class=\"line\">fig.text(<span class=\"number\">0.04</span>, <span class=\"number\">0.5</span>, <span class=\"string\">\"y\"</span>, va=<span class=\"string\">\"center\"</span>, rotation=<span class=\"string\">\"vertical\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'smooth_non_smooth.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"smooth_non_smooth\" data-src=\"/2023/04/03/Differential-equations/smooth_non_smooth.png\"></p>\n<h3 id=\"Noisy-versus-exact-cost-functions\"><a href=\"#Noisy-versus-exact-cost-functions\" class=\"headerlink\" title=\"Noisy versus exact cost functions\"></a>Noisy versus exact cost functions</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:04</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the exact and noisy cost functions</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">exact_cost</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">noisy_cost</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(x) + np.random.normal(scale=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate data</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">2</span>*np.pi, <span class=\"number\">100</span>)</span><br><span class=\"line\">exact_y = exact_cost(x)</span><br><span class=\"line\">noisy_y = np.array([noisy_cost(xi) <span class=\"keyword\">for</span> xi <span class=\"keyword\">in</span> x])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the exact and noisy cost functions</span></span><br><span class=\"line\">plt.plot(x, exact_y, label=<span class=\"string\">'Exact Cost'</span>)</span><br><span class=\"line\">plt.plot(x, noisy_y, label=<span class=\"string\">'Noisy Cost'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Exact vs Noisy Cost Functions'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Exact_vs_Noisy_Cost_Functions.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Exact_vs_Noisy_Cost_Functions\" data-src=\"/2023/04/03/Differential-equations/Exact_vs_Noisy_Cost_Functions.png\"></p>\n<h3 id=\"Constraints\"><a href=\"#Constraints\" class=\"headerlink\" title=\"Constraints\"></a>Constraints</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:07</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the objective function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">objective_function</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (x[<span class=\"number\">0</span>] - <span class=\"number\">2</span>) ** <span class=\"number\">2</span> + (x[<span class=\"number\">1</span>] - <span class=\"number\">2</span>) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the bounds of the search space</span></span><br><span class=\"line\">bounds = ((-<span class=\"number\">1</span>, <span class=\"number\">1</span>), (-<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the constrained optimization problem</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">constrained_optimization</span>():</span><br><span class=\"line\">    res = minimize(objective_function, x0=(<span class=\"number\">0</span>, <span class=\"number\">0</span>), bounds=bounds)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the unconstrained optimization problem</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">unconstrained_optimization</span>():</span><br><span class=\"line\">    res = minimize(objective_function, x0=(<span class=\"number\">0</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the objective function and the search space</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = objective_function((X, Y))</span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots()</span><br><span class=\"line\">cmap = plt.get_cmap(<span class=\"string\">'viridis'</span>)</span><br><span class=\"line\">cf = ax.contourf(X, Y, Z, cmap=cmap, levels=<span class=\"number\">20</span>)</span><br><span class=\"line\">fig.colorbar(cf, ax=ax)</span><br><span class=\"line\">ax.set_title(<span class=\"string\">'Objective Function'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the search space</span></span><br><span class=\"line\">ax.plot([-<span class=\"number\">1</span>, <span class=\"number\">1</span>], [-<span class=\"number\">1</span>, -<span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">ax.plot([-<span class=\"number\">1</span>, <span class=\"number\">1</span>], [<span class=\"number\">1</span>, <span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">ax.plot([-<span class=\"number\">1</span>, -<span class=\"number\">1</span>], [-<span class=\"number\">1</span>, <span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">ax.plot([<span class=\"number\">1</span>, <span class=\"number\">1</span>], [-<span class=\"number\">1</span>, <span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the constrained minimum</span></span><br><span class=\"line\">res_constrained = constrained_optimization()</span><br><span class=\"line\">ax.plot(res_constrained.x[<span class=\"number\">0</span>], res_constrained.x[<span class=\"number\">1</span>], <span class=\"string\">'ro'</span>, label=<span class=\"string\">'Constrained Minimum'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the unconstrained minimum</span></span><br><span class=\"line\">res_unconstrained = unconstrained_optimization()</span><br><span class=\"line\">ax.plot(res_unconstrained.x[<span class=\"number\">0</span>], res_unconstrained.x[<span class=\"number\">1</span>], <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Unconstrained Minimum'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Constrained_vs_Unconstrained_Optimization.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Constrained_vs_Unconstrained_Optimization\" data-src=\"/2023/04/03/Differential-equations/Constrained_vs_Unconstrained_Optimization.png\"></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>Scipy Lecture Notes  Scipy lecture notes</em>. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. <a href=\"https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\">https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/03/Scipy-optimization/","2023/03/28/Functions-Plot/"],"length":1167,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Interpolation\"><a href=\"#Interpolation\" class=\"headerlink\" title=\"Interpolation\"></a>Interpolation</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 19:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.interpolate <span class=\"keyword\">import</span> interp1d</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, num=<span class=\"number\">11</span>, endpoint=<span class=\"literal\">True</span>)</span><br><span class=\"line\">y = np.cos(-x**<span class=\"number\">2</span>/<span class=\"number\">9.0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create an interpolation function</span></span><br><span class=\"line\">f = interp1d(x, y, kind=<span class=\"string\">'cubic'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate new x values to interpolate at</span></span><br><span class=\"line\">x_new = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, num=<span class=\"number\">41</span>, endpoint=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use the interpolation function to generate y values</span></span><br><span class=\"line\">y_new = f(x_new)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the original data and interpolated data</span></span><br><span class=\"line\">plt.plot(x, y, <span class=\"string\">'o'</span>, label=<span class=\"string\">'Original Data'</span>)</span><br><span class=\"line\">plt.plot(x_new, y_new, label=<span class=\"string\">'Interpolated Data'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Cubic Interpolation'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Interpolation.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Interpolation\" data-src=\"/2023/04/03/Differential-equations/Interpolation.png\"></p>\n<h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 20:01</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function to be optimized</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span> + <span class=\"number\">3</span> * np.sin(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use the minimize function from scipy.optimize to find the minimum of the function</span></span><br><span class=\"line\">result = minimize(f, x0=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some data for plotting</span></span><br><span class=\"line\">x_vals = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y_vals = f(x_vals)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function and the optimized point</span></span><br><span class=\"line\">plt.plot(x_vals, y_vals, label=<span class=\"string\">'Function'</span>)</span><br><span class=\"line\">plt.scatter(result.x, result.fun, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Optimized Point'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Optimization'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Optimization.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Optimization\" data-src=\"/2023/04/03/Differential-equations/Optimization.png\"></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 20:03</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"number\">4</span> - <span class=\"number\">2.1</span> * x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span> + x[<span class=\"number\">0</span>] ** <span class=\"number\">4</span> / <span class=\"number\">3</span>) * x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span> + x[<span class=\"number\">0</span>] * x[<span class=\"number\">1</span>] + (<span class=\"number\">4</span> * x[<span class=\"number\">1</span>] ** <span class=\"number\">2</span> - <span class=\"number\">4</span>) * x[<span class=\"number\">1</span>] ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the bounds</span></span><br><span class=\"line\">bounds = [(-<span class=\"number\">2</span>, <span class=\"number\">2</span>), (-<span class=\"number\">1</span>, <span class=\"number\">1</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find the global minimum</span></span><br><span class=\"line\">res1 = minimize(f, x0=[<span class=\"number\">1</span>, -<span class=\"number\">1</span>], bounds=bounds)</span><br><span class=\"line\">res2 = minimize(f, x0=[-<span class=\"number\">1</span>, <span class=\"number\">1</span>], bounds=bounds)</span><br><span class=\"line\">res3 = minimize(f, x0=[<span class=\"number\">0</span>, <span class=\"number\">0</span>], bounds=bounds)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function's 3D surface and contour</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = f([X, Y])</span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">ax1 = fig.add_subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax1.plot_surface(X, Y, Z, cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.8</span>)</span><br><span class=\"line\">ax1.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax1.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax1.set_zlabel(<span class=\"string\">'f(x, y)'</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'3D Surface'</span>)</span><br><span class=\"line\"><span class=\"comment\"># colorbar</span></span><br><span class=\"line\">m = plt.cm.ScalarMappable(cmap=<span class=\"string\">'coolwarm'</span>)</span><br><span class=\"line\">fig.colorbar(m, ax=ax1)</span><br><span class=\"line\"></span><br><span class=\"line\">ax2 = fig.add_subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">ax2.contourf(X, Y, Z, <span class=\"number\">50</span>, cmap=<span class=\"string\">'coolwarm'</span>)</span><br><span class=\"line\">ax2.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax2.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'Contourf for f(x, y)'</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot global minimum</span></span><br><span class=\"line\">ax2.scatter(res1.x[<span class=\"number\">0</span>], res1.x[<span class=\"number\">1</span>], color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Global minimum with initial guess[1, -1]'</span>, marker=<span class=\"string\">'*'</span>, s=<span class=\"number\">200</span>)</span><br><span class=\"line\">ax2.scatter(res2.x[<span class=\"number\">0</span>], res2.x[<span class=\"number\">1</span>], color=<span class=\"string\">'orange'</span>, label=<span class=\"string\">'Global minimum with initial guess[-1, 1]'</span>, marker=<span class=\"string\">'*'</span>, s=<span class=\"number\">200</span>)</span><br><span class=\"line\">ax2.scatter(res3.x[<span class=\"number\">0</span>], res3.x[<span class=\"number\">1</span>], color=<span class=\"string\">'cyan'</span>, label=<span class=\"string\">'Global minimum with initial guess[0, 0]'</span>, marker=<span class=\"string\">'*'</span>, s=<span class=\"number\">200</span>)</span><br><span class=\"line\">ax2.legend()</span><br><span class=\"line\"><span class=\"comment\"># move the legend</span></span><br><span class=\"line\">ax2.legend(bbox_to_anchor=(<span class=\"number\">0</span>, <span class=\"number\">1</span>), loc=<span class=\"string\">'upper left'</span>, borderaxespad=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"comment\"># colorbar</span></span><br><span class=\"line\">fig.colorbar(m, ax=ax2)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Optimization with constraints.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Optimization with constraints\" data-src=\"/2023/04/03/Differential-equations/Optimization%20with%20constraints.png\"></p>\n<h3 id=\"Local-minima-and-global-minima\"><a href=\"#Local-minima-and-global-minima\" class=\"headerlink\" title=\"Local minima and global minima\"></a>Local minima and global minima</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 20:27</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.signal <span class=\"keyword\">import</span> find_peaks</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function to find the minima of</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">my_function</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(x) + np.sin(<span class=\"number\">2</span> * x) + np.sin(<span class=\"number\">4</span> * x) + np.sqrt(<span class=\"built_in\">abs</span>(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate x values for the function</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">3</span>, <span class=\"number\">6</span> * np.pi, <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function</span></span><br><span class=\"line\">plt.plot(x, my_function(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find the global minimum of the function</span></span><br><span class=\"line\">global_min = np.<span class=\"built_in\">min</span>(my_function(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the global minimum as a red dot</span></span><br><span class=\"line\">plt.plot(x[np.argmin(my_function(x))], global_min, <span class=\"string\">'ro'</span>, label=<span class=\"string\">'Global Minimum'</span>,markersize=<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find the local minima of the function</span></span><br><span class=\"line\">local_mins, _ = find_peaks(-my_function(x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the local minima as blue dots</span></span><br><span class=\"line\">plt.plot(x[local_mins], my_function(x)[local_mins], <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Local Minima'</span>,markersize=<span class=\"number\">7</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add a legend to the plot</span></span><br><span class=\"line\">plt.legend([<span class=\"string\">'Function'</span>, <span class=\"string\">'Global Minimum'</span>, <span class=\"string\">'Local Minima'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Local Minima.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Local Minima\" data-src=\"/2023/04/03/Differential-equations/Local%20Minima.png\"></p>\n<h3 id=\"Smooth-and-non-smooth\"><a href=\"#Smooth-and-non-smooth\" class=\"headerlink\" title=\"Smooth and non-smooth\"></a>Smooth and non-smooth</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:03</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some sample data</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y_smooth = np.sin(x)</span><br><span class=\"line\">y_non_smooth = np.<span class=\"built_in\">abs</span>(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a plot with two subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the smooth function in the first subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x, y_smooth)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">\"Smooth Function\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the non-smooth function in the second subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x, y_non_smooth)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">\"Non-Smooth Function\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and a title to the overall figure</span></span><br><span class=\"line\">fig.suptitle(<span class=\"string\">\"Smooth vs Non-Smooth Functions\"</span>)</span><br><span class=\"line\">fig.text(<span class=\"number\">0.5</span>, <span class=\"number\">0.04</span>, <span class=\"string\">\"x\"</span>, ha=<span class=\"string\">\"center\"</span>)</span><br><span class=\"line\">fig.text(<span class=\"number\">0.04</span>, <span class=\"number\">0.5</span>, <span class=\"string\">\"y\"</span>, va=<span class=\"string\">\"center\"</span>, rotation=<span class=\"string\">\"vertical\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'smooth_non_smooth.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"smooth_non_smooth\" data-src=\"/2023/04/03/Differential-equations/smooth_non_smooth.png\"></p>\n<h3 id=\"Noisy-versus-exact-cost-functions\"><a href=\"#Noisy-versus-exact-cost-functions\" class=\"headerlink\" title=\"Noisy versus exact cost functions\"></a>Noisy versus exact cost functions</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:04</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the exact and noisy cost functions</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">exact_cost</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">noisy_cost</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(x) + np.random.normal(scale=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate data</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">2</span>*np.pi, <span class=\"number\">100</span>)</span><br><span class=\"line\">exact_y = exact_cost(x)</span><br><span class=\"line\">noisy_y = np.array([noisy_cost(xi) <span class=\"keyword\">for</span> xi <span class=\"keyword\">in</span> x])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the exact and noisy cost functions</span></span><br><span class=\"line\">plt.plot(x, exact_y, label=<span class=\"string\">'Exact Cost'</span>)</span><br><span class=\"line\">plt.plot(x, noisy_y, label=<span class=\"string\">'Noisy Cost'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Exact vs Noisy Cost Functions'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Exact_vs_Noisy_Cost_Functions.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Exact_vs_Noisy_Cost_Functions\" data-src=\"/2023/04/03/Differential-equations/Exact_vs_Noisy_Cost_Functions.png\"></p>\n<h3 id=\"Constraints\"><a href=\"#Constraints\" class=\"headerlink\" title=\"Constraints\"></a>Constraints</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:07</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the objective function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">objective_function</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (x[<span class=\"number\">0</span>] - <span class=\"number\">2</span>) ** <span class=\"number\">2</span> + (x[<span class=\"number\">1</span>] - <span class=\"number\">2</span>) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the bounds of the search space</span></span><br><span class=\"line\">bounds = ((-<span class=\"number\">1</span>, <span class=\"number\">1</span>), (-<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the constrained optimization problem</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">constrained_optimization</span>():</span><br><span class=\"line\">    res = minimize(objective_function, x0=(<span class=\"number\">0</span>, <span class=\"number\">0</span>), bounds=bounds)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the unconstrained optimization problem</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">unconstrained_optimization</span>():</span><br><span class=\"line\">    res = minimize(objective_function, x0=(<span class=\"number\">0</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the objective function and the search space</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = objective_function((X, Y))</span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots()</span><br><span class=\"line\">cmap = plt.get_cmap(<span class=\"string\">'viridis'</span>)</span><br><span class=\"line\">cf = ax.contourf(X, Y, Z, cmap=cmap, levels=<span class=\"number\">20</span>)</span><br><span class=\"line\">fig.colorbar(cf, ax=ax)</span><br><span class=\"line\">ax.set_title(<span class=\"string\">'Objective Function'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the search space</span></span><br><span class=\"line\">ax.plot([-<span class=\"number\">1</span>, <span class=\"number\">1</span>], [-<span class=\"number\">1</span>, -<span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">ax.plot([-<span class=\"number\">1</span>, <span class=\"number\">1</span>], [<span class=\"number\">1</span>, <span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">ax.plot([-<span class=\"number\">1</span>, -<span class=\"number\">1</span>], [-<span class=\"number\">1</span>, <span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\">ax.plot([<span class=\"number\">1</span>, <span class=\"number\">1</span>], [-<span class=\"number\">1</span>, <span class=\"number\">1</span>], <span class=\"string\">'k'</span>, linewidth=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the constrained minimum</span></span><br><span class=\"line\">res_constrained = constrained_optimization()</span><br><span class=\"line\">ax.plot(res_constrained.x[<span class=\"number\">0</span>], res_constrained.x[<span class=\"number\">1</span>], <span class=\"string\">'ro'</span>, label=<span class=\"string\">'Constrained Minimum'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the unconstrained minimum</span></span><br><span class=\"line\">res_unconstrained = unconstrained_optimization()</span><br><span class=\"line\">ax.plot(res_unconstrained.x[<span class=\"number\">0</span>], res_unconstrained.x[<span class=\"number\">1</span>], <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Unconstrained Minimum'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Constrained_vs_Unconstrained_Optimization.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Constrained_vs_Unconstrained_Optimization\" data-src=\"/2023/04/03/Differential-equations/Constrained_vs_Unconstrained_Optimization.png\"></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>Scipy Lecture Notes  Scipy lecture notes</em>. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. <a href=\"https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\">https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"FashionMNIST Classification with PyTorch","date":"2023-04-01T18:47:57.000Z","_content":"\nThis code trains a neural network model to classify images from the FashionMNIST dataset using PyTorch. The model is trained using stochastic gradient descent (SGD) with cross-entropy loss as the loss function. The code loads the training and test datasets, creates data loaders for batching the data, and defines a neural network model using PyTorch's nn.Module class. The code then trains the model for a specified number of epochs, and records the training and test losses at each epoch. The final model is saved to a file, and example predictions are made on a 3x3 grid of test images, with the actual and predicted labels displayed for each image. The code also generates plots of the training and test loss over time, as well as the example predictions.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/23 19:57\n\n# Import necessary libraries\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load the FashionMNIST training and test datasets\ntraining_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor())\ntest_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor())\n\n# Specify the batch size and create data loaders\nbatch_size = 16\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\n# Get a batch of training data and display its shape\nimages, labels = next(iter(train_dataloader))\nprint(images.shape)\nprint(labels.shape)\nprint(labels[0])\n\n\n# Create a neural network model\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n\n# Check if CUDA is available and set the device accordingly\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)\n\n# Create an instance of the model and move it to the device\nmodel = Model().to(device)\n\n# Specify the loss function and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n\n\n# Define a function to train the model\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    train_loss = []  # initialize a list to record the training loss\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = loss_fn(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f'loss: {loss:>7f}  [{current: >5d}/ {size:>5d}]')\n            train_loss.append(loss)  # record the training loss at this iteration\n    return train_loss[-1:]  # return only the last value of the train_loss list\n\n\n# Define a function to test the model\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n    print(f'Test Error: \\n Accuracy: {(100 * correct):>0.1f}, Avg Loss: {test_loss:>8f}\\n')\n    return test_loss\n\n\n# Train the model for a specified number of epochs\nepochs = 30\ntrain_losses = []  # initialize a list to record the training loss at each epoch\ntest_losses = []  # initialize a list to record the test loss at each epoch\nfor t in range(epochs):\n    print(f'Epoch {t + 1}\\n-------------------------------------------')\n    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n    train_losses += train_loss  # concatenate the list of training losses from this epoch\n    test_loss = test(test_dataloader, model, loss_fn)\n    test_losses.append(test_loss)  # record the test loss for this epoch\nprint('Done!')\n\n# Create a plot of the training and test loss over time\nplt.plot(train_losses, label='Training Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig(\"train_test_loss.png\", dpi=300, bbox_inches='tight', pad_inches=0.1, transparent=True)\nplt.show()\n\n# Save the model\ntorch.save(model.state_dict(), 'model.pth')\n\n# Load the model\nmodel = Model()\nmodel.load_state_dict(torch.load('model.pth'))\n\n# Define the labels for the classes\nclasses = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n# Load the saved model from the file\nmodel = Model()\nmodel.load_state_dict(torch.load('model.pth'))\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Create a 3x3 grid of subplots\nfig, axes = plt.subplots(3, 3, figsize=(10, 10))\n\n# Loop through the first 9 images in the test dataset\nfor ax, idx in zip(axes.flatten(), range(9)):\n    # Get an example image and label from the test dataset\n    x, y = test_data[idx][0], test_data[idx][1]\n\n    # Use the model to predict the label of the image\n    with torch.no_grad():\n        pred = model(x.unsqueeze(0))\n        predicted, actual = classes[pred.argmax(1)], classes[y]\n\n    # Display the image and label\n    ax.imshow(x.view(28, 28), cmap='gray')\n    ax.set_title(f'Actual: {actual}\\nPredicted: {predicted}')\n    ax.axis('off')\n\n# Show the plot\nplt.savefig(\"predictions.png\", dpi=300, bbox_inches='tight', pad_inches=0.1, transparent=True)\nplt.show()\n```\n\n<div style=\"text-align:center\"><img src=\"FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/train_test_loss.png\" alt=\"train_test_loss\" style=\"zoom:33%;\" /></div> \n\n<div style=\"text-align:center\">     <img src=\"FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/predictions.png\" alt=\"predictions\" style=\"zoom:67%;\" /> </div>\n\nThe final test accuracy of the model is 73.4% and the average loss is 0.739739.\n\n### Reference\n\n1. Z. (2022, March 21). *GitHub - zalandoresearch/fashion-mnist: A MNIST-like fashion product database. Benchmark*. GitHub. https://github.com/zalandoresearch/fashion-mnist\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting.md","raw":"---\nmathjax: true\ntitle: >-\n  FashionMNIST Classification with PyTorch\ndate: 2023-04-01 18:47:57\ntags:\n  - Python\n  - Classification\n  - Torch\n---\n\nThis code trains a neural network model to classify images from the FashionMNIST dataset using PyTorch. The model is trained using stochastic gradient descent (SGD) with cross-entropy loss as the loss function. The code loads the training and test datasets, creates data loaders for batching the data, and defines a neural network model using PyTorch's nn.Module class. The code then trains the model for a specified number of epochs, and records the training and test losses at each epoch. The final model is saved to a file, and example predictions are made on a 3x3 grid of test images, with the actual and predicted labels displayed for each image. The code also generates plots of the training and test loss over time, as well as the example predictions.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/23 19:57\n\n# Import necessary libraries\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load the FashionMNIST training and test datasets\ntraining_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor())\ntest_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor())\n\n# Specify the batch size and create data loaders\nbatch_size = 16\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\n# Get a batch of training data and display its shape\nimages, labels = next(iter(train_dataloader))\nprint(images.shape)\nprint(labels.shape)\nprint(labels[0])\n\n\n# Create a neural network model\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n\n# Check if CUDA is available and set the device accordingly\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)\n\n# Create an instance of the model and move it to the device\nmodel = Model().to(device)\n\n# Specify the loss function and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n\n\n# Define a function to train the model\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    train_loss = []  # initialize a list to record the training loss\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = loss_fn(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f'loss: {loss:>7f}  [{current: >5d}/ {size:>5d}]')\n            train_loss.append(loss)  # record the training loss at this iteration\n    return train_loss[-1:]  # return only the last value of the train_loss list\n\n\n# Define a function to test the model\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n    print(f'Test Error: \\n Accuracy: {(100 * correct):>0.1f}, Avg Loss: {test_loss:>8f}\\n')\n    return test_loss\n\n\n# Train the model for a specified number of epochs\nepochs = 30\ntrain_losses = []  # initialize a list to record the training loss at each epoch\ntest_losses = []  # initialize a list to record the test loss at each epoch\nfor t in range(epochs):\n    print(f'Epoch {t + 1}\\n-------------------------------------------')\n    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n    train_losses += train_loss  # concatenate the list of training losses from this epoch\n    test_loss = test(test_dataloader, model, loss_fn)\n    test_losses.append(test_loss)  # record the test loss for this epoch\nprint('Done!')\n\n# Create a plot of the training and test loss over time\nplt.plot(train_losses, label='Training Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig(\"train_test_loss.png\", dpi=300, bbox_inches='tight', pad_inches=0.1, transparent=True)\nplt.show()\n\n# Save the model\ntorch.save(model.state_dict(), 'model.pth')\n\n# Load the model\nmodel = Model()\nmodel.load_state_dict(torch.load('model.pth'))\n\n# Define the labels for the classes\nclasses = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n# Load the saved model from the file\nmodel = Model()\nmodel.load_state_dict(torch.load('model.pth'))\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Create a 3x3 grid of subplots\nfig, axes = plt.subplots(3, 3, figsize=(10, 10))\n\n# Loop through the first 9 images in the test dataset\nfor ax, idx in zip(axes.flatten(), range(9)):\n    # Get an example image and label from the test dataset\n    x, y = test_data[idx][0], test_data[idx][1]\n\n    # Use the model to predict the label of the image\n    with torch.no_grad():\n        pred = model(x.unsqueeze(0))\n        predicted, actual = classes[pred.argmax(1)], classes[y]\n\n    # Display the image and label\n    ax.imshow(x.view(28, 28), cmap='gray')\n    ax.set_title(f'Actual: {actual}\\nPredicted: {predicted}')\n    ax.axis('off')\n\n# Show the plot\nplt.savefig(\"predictions.png\", dpi=300, bbox_inches='tight', pad_inches=0.1, transparent=True)\nplt.show()\n```\n\n<div style=\"text-align:center\"><img src=\"FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/train_test_loss.png\" alt=\"train_test_loss\" style=\"zoom:33%;\" /></div> \n\n<div style=\"text-align:center\">     <img src=\"FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/predictions.png\" alt=\"predictions\" style=\"zoom:67%;\" /> </div>\n\nThe final test accuracy of the model is 73.4% and the average loss is 0.739739.\n\n### Reference\n\n1. Z. (2022, March 21). *GitHub - zalandoresearch/fashion-mnist: A MNIST-like fashion product database. Benchmark*. GitHub. https://github.com/zalandoresearch/fashion-mnist\n\n\n\n\n\n\n\n\n\n\n\n","slug":"FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting","published":1,"updated":"2023-04-07T02:43:50.476Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gk0006ozpidupa93ld","content":"<html><head></head><body></body></html><html><head></head><body><p>This code trains a neural network model to classify images from the FashionMNIST dataset using PyTorch. The model is trained using stochastic gradient descent (SGD) with cross-entropy loss as the loss function. The code loads the training and test datasets, creates data loaders for batching the data, and defines a neural network model using PyTorchs nn.Module class. The code then trains the model for a specified number of epochs, and records the training and test losses at each epoch. The final model is saved to a file, and example predictions are made on a 3x3 grid of test images, with the actual and predicted labels displayed for each image. The code also generates plots of the training and test loss over time, as well as the example predictions.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/23 19:57</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Import necessary libraries</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToTensor</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load the FashionMNIST training and test datasets</span></span><br><span class=\"line\">training_data = datasets.FashionMNIST(root=<span class=\"string\">'data'</span>, train=<span class=\"literal\">True</span>, download=<span class=\"literal\">True</span>, transform=ToTensor())</span><br><span class=\"line\">test_data = datasets.FashionMNIST(root=<span class=\"string\">'data'</span>, train=<span class=\"literal\">False</span>, download=<span class=\"literal\">True</span>, transform=ToTensor())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Specify the batch size and create data loaders</span></span><br><span class=\"line\">batch_size = <span class=\"number\">16</span></span><br><span class=\"line\">train_dataloader = DataLoader(training_data, batch_size=batch_size)</span><br><span class=\"line\">test_dataloader = DataLoader(test_data, batch_size=batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get a batch of training data and display its shape</span></span><br><span class=\"line\">images, labels = <span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(train_dataloader))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(images.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a neural network model</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Model</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.flatten = nn.Flatten()</span><br><span class=\"line\">        self.linear_relu_stack = nn.Sequential(</span><br><span class=\"line\">            nn.Linear(<span class=\"number\">28</span> * <span class=\"number\">28</span>, <span class=\"number\">512</span>),</span><br><span class=\"line\">            nn.ReLU(),</span><br><span class=\"line\">            nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">512</span>),</span><br><span class=\"line\">            nn.ReLU(),</span><br><span class=\"line\">            nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        x = self.flatten(x)</span><br><span class=\"line\">        logits = self.linear_relu_stack(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> logits</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check if CUDA is available and set the device accordingly</span></span><br><span class=\"line\">device = <span class=\"string\">'cuda'</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">'cpu'</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create an instance of the model and move it to the device</span></span><br><span class=\"line\">model = Model().to(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Specify the loss function and optimizer</span></span><br><span class=\"line\">loss_fn = nn.CrossEntropyLoss()</span><br><span class=\"line\">optimizer = torch.optim.SGD(model.parameters(), lr=<span class=\"number\">1e-4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a function to train the model</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">dataloader, model, loss_fn, optimizer</span>):</span><br><span class=\"line\">    size = <span class=\"built_in\">len</span>(dataloader.dataset)</span><br><span class=\"line\">    model.train()</span><br><span class=\"line\">    train_loss = []  <span class=\"comment\"># initialize a list to record the training loss</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> batch, (X, y) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(dataloader):</span><br><span class=\"line\">        X, y = X.to(device), y.to(device)</span><br><span class=\"line\">        pred = model(X)</span><br><span class=\"line\">        loss = loss_fn(pred, y)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> batch % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            loss, current = loss.item(), batch * <span class=\"built_in\">len</span>(X)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f'loss: <span class=\"subst\">{loss:&gt;7f}</span>  [<span class=\"subst\">{current: &gt;5d}</span>/ <span class=\"subst\">{size:&gt;5d}</span>]'</span>)</span><br><span class=\"line\">            train_loss.append(loss)  <span class=\"comment\"># record the training loss at this iteration</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_loss[-<span class=\"number\">1</span>:]  <span class=\"comment\"># return only the last value of the train_loss list</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a function to test the model</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">test</span>(<span class=\"params\">dataloader, model, loss_fn</span>):</span><br><span class=\"line\">    size = <span class=\"built_in\">len</span>(dataloader.dataset)</span><br><span class=\"line\">    num_batches = <span class=\"built_in\">len</span>(dataloader)</span><br><span class=\"line\">    model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">    test_loss, correct = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> dataloader:</span><br><span class=\"line\">            X, y = X.to(device), y.to(device)</span><br><span class=\"line\">            pred = model(X)</span><br><span class=\"line\">            test_loss += loss_fn(pred, y).item()</span><br><span class=\"line\">            correct += (pred.argmax(<span class=\"number\">1</span>) == y).<span class=\"built_in\">type</span>(torch.<span class=\"built_in\">float</span>).<span class=\"built_in\">sum</span>().item()</span><br><span class=\"line\"></span><br><span class=\"line\">    test_loss /= num_batches</span><br><span class=\"line\">    correct /= size</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'Test Error: \\n Accuracy: <span class=\"subst\">{(<span class=\"number\">100</span> * correct):&gt;<span class=\"number\">0.1</span>f}</span>, Avg Loss: <span class=\"subst\">{test_loss:&gt;8f}</span>\\n'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> test_loss</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Train the model for a specified number of epochs</span></span><br><span class=\"line\">epochs = <span class=\"number\">30</span></span><br><span class=\"line\">train_losses = []  <span class=\"comment\"># initialize a list to record the training loss at each epoch</span></span><br><span class=\"line\">test_losses = []  <span class=\"comment\"># initialize a list to record the test loss at each epoch</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(epochs):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'Epoch <span class=\"subst\">{t + <span class=\"number\">1</span>}</span>\\n-------------------------------------------'</span>)</span><br><span class=\"line\">    train_loss = train(train_dataloader, model, loss_fn, optimizer)</span><br><span class=\"line\">    train_losses += train_loss  <span class=\"comment\"># concatenate the list of training losses from this epoch</span></span><br><span class=\"line\">    test_loss = test(test_dataloader, model, loss_fn)</span><br><span class=\"line\">    test_losses.append(test_loss)  <span class=\"comment\"># record the test loss for this epoch</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Done!'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a plot of the training and test loss over time</span></span><br><span class=\"line\">plt.plot(train_losses, label=<span class=\"string\">'Training Loss'</span>)</span><br><span class=\"line\">plt.plot(test_losses, label=<span class=\"string\">'Test Loss'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Iterations'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Loss'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"train_test_loss.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>, transparent=<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the model</span></span><br><span class=\"line\">torch.save(model.state_dict(), <span class=\"string\">'model.pth'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load the model</span></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">model.load_state_dict(torch.load(<span class=\"string\">'model.pth'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the labels for the classes</span></span><br><span class=\"line\">classes = [<span class=\"string\">'T-shirt/top'</span>, <span class=\"string\">'Trouser'</span>, <span class=\"string\">'Pullover'</span>, <span class=\"string\">'Dress'</span>, <span class=\"string\">'Coat'</span>, <span class=\"string\">'Sandal'</span>, <span class=\"string\">'Shirt'</span>, <span class=\"string\">'Sneaker'</span>, <span class=\"string\">'Bag'</span>, <span class=\"string\">'Ankle boot'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load the saved model from the file</span></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">model.load_state_dict(torch.load(<span class=\"string\">'model.pth'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the model to evaluation mode</span></span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 3x3 grid of subplots</span></span><br><span class=\"line\">fig, axes = plt.subplots(<span class=\"number\">3</span>, <span class=\"number\">3</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Loop through the first 9 images in the test dataset</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ax, idx <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(axes.flatten(), <span class=\"built_in\">range</span>(<span class=\"number\">9</span>)):</span><br><span class=\"line\">    <span class=\"comment\"># Get an example image and label from the test dataset</span></span><br><span class=\"line\">    x, y = test_data[idx][<span class=\"number\">0</span>], test_data[idx][<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Use the model to predict the label of the image</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        pred = model(x.unsqueeze(<span class=\"number\">0</span>))</span><br><span class=\"line\">        predicted, actual = classes[pred.argmax(<span class=\"number\">1</span>)], classes[y]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Display the image and label</span></span><br><span class=\"line\">    ax.imshow(x.view(<span class=\"number\">28</span>, <span class=\"number\">28</span>), cmap=<span class=\"string\">'gray'</span>)</span><br><span class=\"line\">    ax.set_title(<span class=\"string\">f'Actual: <span class=\"subst\">{actual}</span>\\nPredicted: <span class=\"subst\">{predicted}</span>'</span>)</span><br><span class=\"line\">    ax.axis(<span class=\"string\">'off'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"predictions.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>, transparent=<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"><img alt=\"train_test_loss\" style=\"zoom:33%;\" data-src=\"/2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/train_test_loss.png\"></div> \n\n<div style=\"text-align:center\">     <img alt=\"predictions\" style=\"zoom:67%;\" data-src=\"/2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/predictions.png\"> </div>\n\n<p>The final test accuracy of the model is 73.4% and the average loss is 0.739739.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Z. (2022, March 21). <em>GitHub - zalandoresearch/fashion-mnist: A MNIST-like fashion product database. Benchmark</em>. GitHub. <a href=\"https://github.com/zalandoresearch/fashion-mnist\">https://github.com/zalandoresearch/fashion-mnist</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/01/Sentiment-Analysis-on-Product-Reviews/","2023/03/28/Image-processing-using-Numpy/"],"length":847,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>This code trains a neural network model to classify images from the FashionMNIST dataset using PyTorch. The model is trained using stochastic gradient descent (SGD) with cross-entropy loss as the loss function. The code loads the training and test datasets, creates data loaders for batching the data, and defines a neural network model using PyTorchs nn.Module class. The code then trains the model for a specified number of epochs, and records the training and test losses at each epoch. The final model is saved to a file, and example predictions are made on a 3x3 grid of test images, with the actual and predicted labels displayed for each image. The code also generates plots of the training and test loss over time, as well as the example predictions.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/23 19:57</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Import necessary libraries</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> DataLoader</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToTensor</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load the FashionMNIST training and test datasets</span></span><br><span class=\"line\">training_data = datasets.FashionMNIST(root=<span class=\"string\">'data'</span>, train=<span class=\"literal\">True</span>, download=<span class=\"literal\">True</span>, transform=ToTensor())</span><br><span class=\"line\">test_data = datasets.FashionMNIST(root=<span class=\"string\">'data'</span>, train=<span class=\"literal\">False</span>, download=<span class=\"literal\">True</span>, transform=ToTensor())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Specify the batch size and create data loaders</span></span><br><span class=\"line\">batch_size = <span class=\"number\">16</span></span><br><span class=\"line\">train_dataloader = DataLoader(training_data, batch_size=batch_size)</span><br><span class=\"line\">test_dataloader = DataLoader(test_data, batch_size=batch_size)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get a batch of training data and display its shape</span></span><br><span class=\"line\">images, labels = <span class=\"built_in\">next</span>(<span class=\"built_in\">iter</span>(train_dataloader))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(images.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(labels[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a neural network model</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Model</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.flatten = nn.Flatten()</span><br><span class=\"line\">        self.linear_relu_stack = nn.Sequential(</span><br><span class=\"line\">            nn.Linear(<span class=\"number\">28</span> * <span class=\"number\">28</span>, <span class=\"number\">512</span>),</span><br><span class=\"line\">            nn.ReLU(),</span><br><span class=\"line\">            nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">512</span>),</span><br><span class=\"line\">            nn.ReLU(),</span><br><span class=\"line\">            nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        x = self.flatten(x)</span><br><span class=\"line\">        logits = self.linear_relu_stack(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> logits</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check if CUDA is available and set the device accordingly</span></span><br><span class=\"line\">device = <span class=\"string\">'cuda'</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">'cpu'</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create an instance of the model and move it to the device</span></span><br><span class=\"line\">model = Model().to(device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Specify the loss function and optimizer</span></span><br><span class=\"line\">loss_fn = nn.CrossEntropyLoss()</span><br><span class=\"line\">optimizer = torch.optim.SGD(model.parameters(), lr=<span class=\"number\">1e-4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a function to train the model</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">dataloader, model, loss_fn, optimizer</span>):</span><br><span class=\"line\">    size = <span class=\"built_in\">len</span>(dataloader.dataset)</span><br><span class=\"line\">    model.train()</span><br><span class=\"line\">    train_loss = []  <span class=\"comment\"># initialize a list to record the training loss</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> batch, (X, y) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(dataloader):</span><br><span class=\"line\">        X, y = X.to(device), y.to(device)</span><br><span class=\"line\">        pred = model(X)</span><br><span class=\"line\">        loss = loss_fn(pred, y)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> batch % <span class=\"number\">100</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            loss, current = loss.item(), batch * <span class=\"built_in\">len</span>(X)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f'loss: <span class=\"subst\">{loss:&gt;7f}</span>  [<span class=\"subst\">{current: &gt;5d}</span>/ <span class=\"subst\">{size:&gt;5d}</span>]'</span>)</span><br><span class=\"line\">            train_loss.append(loss)  <span class=\"comment\"># record the training loss at this iteration</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_loss[-<span class=\"number\">1</span>:]  <span class=\"comment\"># return only the last value of the train_loss list</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a function to test the model</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">test</span>(<span class=\"params\">dataloader, model, loss_fn</span>):</span><br><span class=\"line\">    size = <span class=\"built_in\">len</span>(dataloader.dataset)</span><br><span class=\"line\">    num_batches = <span class=\"built_in\">len</span>(dataloader)</span><br><span class=\"line\">    model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">    test_loss, correct = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> dataloader:</span><br><span class=\"line\">            X, y = X.to(device), y.to(device)</span><br><span class=\"line\">            pred = model(X)</span><br><span class=\"line\">            test_loss += loss_fn(pred, y).item()</span><br><span class=\"line\">            correct += (pred.argmax(<span class=\"number\">1</span>) == y).<span class=\"built_in\">type</span>(torch.<span class=\"built_in\">float</span>).<span class=\"built_in\">sum</span>().item()</span><br><span class=\"line\"></span><br><span class=\"line\">    test_loss /= num_batches</span><br><span class=\"line\">    correct /= size</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'Test Error: \\n Accuracy: <span class=\"subst\">{(<span class=\"number\">100</span> * correct):&gt;<span class=\"number\">0.1</span>f}</span>, Avg Loss: <span class=\"subst\">{test_loss:&gt;8f}</span>\\n'</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> test_loss</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Train the model for a specified number of epochs</span></span><br><span class=\"line\">epochs = <span class=\"number\">30</span></span><br><span class=\"line\">train_losses = []  <span class=\"comment\"># initialize a list to record the training loss at each epoch</span></span><br><span class=\"line\">test_losses = []  <span class=\"comment\"># initialize a list to record the test loss at each epoch</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(epochs):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'Epoch <span class=\"subst\">{t + <span class=\"number\">1</span>}</span>\\n-------------------------------------------'</span>)</span><br><span class=\"line\">    train_loss = train(train_dataloader, model, loss_fn, optimizer)</span><br><span class=\"line\">    train_losses += train_loss  <span class=\"comment\"># concatenate the list of training losses from this epoch</span></span><br><span class=\"line\">    test_loss = test(test_dataloader, model, loss_fn)</span><br><span class=\"line\">    test_losses.append(test_loss)  <span class=\"comment\"># record the test loss for this epoch</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Done!'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a plot of the training and test loss over time</span></span><br><span class=\"line\">plt.plot(train_losses, label=<span class=\"string\">'Training Loss'</span>)</span><br><span class=\"line\">plt.plot(test_losses, label=<span class=\"string\">'Test Loss'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Iterations'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Loss'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"train_test_loss.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>, transparent=<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the model</span></span><br><span class=\"line\">torch.save(model.state_dict(), <span class=\"string\">'model.pth'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load the model</span></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">model.load_state_dict(torch.load(<span class=\"string\">'model.pth'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the labels for the classes</span></span><br><span class=\"line\">classes = [<span class=\"string\">'T-shirt/top'</span>, <span class=\"string\">'Trouser'</span>, <span class=\"string\">'Pullover'</span>, <span class=\"string\">'Dress'</span>, <span class=\"string\">'Coat'</span>, <span class=\"string\">'Sandal'</span>, <span class=\"string\">'Shirt'</span>, <span class=\"string\">'Sneaker'</span>, <span class=\"string\">'Bag'</span>, <span class=\"string\">'Ankle boot'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load the saved model from the file</span></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">model.load_state_dict(torch.load(<span class=\"string\">'model.pth'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the model to evaluation mode</span></span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 3x3 grid of subplots</span></span><br><span class=\"line\">fig, axes = plt.subplots(<span class=\"number\">3</span>, <span class=\"number\">3</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Loop through the first 9 images in the test dataset</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ax, idx <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(axes.flatten(), <span class=\"built_in\">range</span>(<span class=\"number\">9</span>)):</span><br><span class=\"line\">    <span class=\"comment\"># Get an example image and label from the test dataset</span></span><br><span class=\"line\">    x, y = test_data[idx][<span class=\"number\">0</span>], test_data[idx][<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Use the model to predict the label of the image</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        pred = model(x.unsqueeze(<span class=\"number\">0</span>))</span><br><span class=\"line\">        predicted, actual = classes[pred.argmax(<span class=\"number\">1</span>)], classes[y]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Display the image and label</span></span><br><span class=\"line\">    ax.imshow(x.view(<span class=\"number\">28</span>, <span class=\"number\">28</span>), cmap=<span class=\"string\">'gray'</span>)</span><br><span class=\"line\">    ax.set_title(<span class=\"string\">f'Actual: <span class=\"subst\">{actual}</span>\\nPredicted: <span class=\"subst\">{predicted}</span>'</span>)</span><br><span class=\"line\">    ax.axis(<span class=\"string\">'off'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"predictions.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>, transparent=<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"><img alt=\"train_test_loss\" style=\"zoom:33%;\" data-src=\"/2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/train_test_loss.png\"></div> \n\n<div style=\"text-align:center\">     <img alt=\"predictions\" style=\"zoom:67%;\" data-src=\"/2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/predictions.png\"> </div>\n\n<p>The final test accuracy of the model is 73.4% and the average loss is 0.739739.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Z. (2022, March 21). <em>GitHub - zalandoresearch/fashion-mnist: A MNIST-like fashion product database. Benchmark</em>. GitHub. <a href=\"https://github.com/zalandoresearch/fashion-mnist\">https://github.com/zalandoresearch/fashion-mnist</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"From linear regression to binary classification","date":"2023-03-29T12:22:17.000Z","_content":"\n### Regression and classification \n\nLinear regression involves finding a line that fits a set of data points, while binary classification involves finding a line that separates a set of points into two groups. Specifically, some points will be on one side of the line and others on the other side.\n\nRegression problems and binary classification problems have many similarities. They both take a set of input data points and aim to find a single line. The difference is in the purpose of the line. In regression problems, the line is used to make predictions based on the input data, while in binary classification problems, the line is used to separate the data into two classes.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/29/23 14:49\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 2 * np.random.randn(5)\n\n# Fit a linear regression model to the data\nmodel = np.polyfit(x, y, 1)\npredicted = np.polyval(model, x)\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x, predicted, color='red', label='Predicted')\n\n# Highlight the difference between actual and predicted values\nfor i in range(len(x)):\n    plt.plot([x[i], x[i]], [y[i], predicted[i]], color='gray', linestyle='--')\n\n# Color-code the actual data points based on whether they are above or below the regression line\nabove = y > predicted\nbelow = y < predicted\nplt.scatter(x[above], y[above], color='green', label='Above')\nplt.scatter(x[below], y[below], color='purple', label='Below')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression')\nplt.legend()\n\n# Display the plot\nplt.savefig('binaryclass.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\"> <img src=\"From-linear-regression-to-binary-classification/binaryclass.png\" alt=\"binaryclass\" style=\"zoom:30%;\" /> </p>\n\nNow, building on the concept of linear regression, we can view the data points above the regression line as one class, and the points below the line as another class. This transforms the regression problem into a binary classification problem, where the goal is to find a line that best separates the two classes.\n\n### The relationship between a point and a line\n\nGiven a line with equation $Ax + By + C = 0$ and a point with coordinates $(x_0, y_0)$, we can determine the relationship between the point and the line using the vector inner product.\n\nWe first define a vector $\\vec{n} = \\begin{pmatrix} A \\ B \\end{pmatrix}$ as the normal vector to the line. Then, we define a vector $\\vec{p} = \\begin{pmatrix} x_0 \\ y_0 \\end{pmatrix}$ as the vector representing the point. The relationship between the point and the line can then be determined by taking the dot product of these two vectors:\n$$\n\\begin{equation}\n\\vec{n} \\cdot \\vec{p}=\\left(\\begin{array}{l}\nA \\\\\nB\n\\end{array}\\right) \\cdot\\left(\\begin{array}{l}\nx_0 \\\\\ny_0\n\\end{array}\\right)=A x_0+B y_0\n\\end{equation}\n$$\nIf $\\vec{n} \\cdot \\vec{p} + C = 0$, then the point lies on the line. If $\\vec{n} \\cdot \\vec{p} + C > 0$, then the point lies on one side of the line, and if $\\vec{n} \\cdot \\vec{p} + C < 0$, then the point lies on the other side of the line.\n\nit feels like this:\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the line equation\nA = 2\nB = -3\nC = 1\n\n# Generate some random points to plot\nx = np.linspace(-100, 100, 100)\ny = np.linspace(-100, 100, 100)\nX, Y = np.meshgrid(x, y)\nZ = A*X + B*Y + C\n\n# plot the line\nplt.figure(figsize=(4, 4))\nplt.subplot(1, 1, 1)\nlabels = Z > 0\n# Plot the points with different colors based on their labels\nplt.scatter(X, Y, c=labels, cmap='plasma')\nplt.savefig('binaryclass1.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\"> <img src=\"From-linear-regression-to-binary-classification/binaryclass1.png\" alt=\"binaryclass\" style=\"zoom:30%;\" /> </p>\n\n**Now we have a problem, the classification approach we just described is that it does not take into account the distance between each point and the line. Some points may be far away from the line, while others may be closer. This is similar to the problem of classifying people as male or female based on certain characteristics. While there may be some defining characteristics for each gender, most people have a combination of both male and female traits, and it's a gradient rather than a clear-cut binary classification.**\n\nwe need sigmoid function to solve this problem.\n\n### Sigmoid\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/29/23 15:54\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n\ndef sigmoid_derivative(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\n\nx = np.linspace(-10, 10, 100)\ny = sigmoid(x)\ndy = sigmoid_derivative(x)\n\nfig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n\nax[0].plot(x, y)\nax[0].set_title('Sigmoid function')\nax[0].set_xlabel('x')\nax[0].set_ylabel('sigmoid(x)')\n\nax[1].plot(x, dy)\nax[1].set_title('Sigmoid derivative')\nax[1].set_xlabel('x')\nax[1].set_ylabel('sigmoid\\'(x)')\n\nplt.tight_layout()\nplt.savefig('sigmoid.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![sigmoid](From-linear-regression-to-binary-classification/sigmoid.png)\n\nThe sigmoid function is defined as:\n$$\n\\begin{equation}\n\\sigma(\\mathrm{x})=\\frac{1}{1+e^{-\\mathrm{x}}}\n\\end{equation}\n$$\nwhere $z$ is the input to the function. It maps any input value to a value between 0 and 1, which makes it suitable for modeling probabilities.\n\nSigmoid derivative:\n$$\n\\begin{equation}\n\\begin{aligned}\n\\frac{\\mathrm{d}}{\\mathrm{dx}} \\sigma(\\mathrm{x}) & =\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left[\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right]=\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-1} \\\\\n& =-1 *\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-2}\\left(-\\mathrm{e}^{-\\mathrm{x}}\\right) \\\\\n& =\\frac{-\\mathrm{e}^{-\\mathrm{x}}}{-\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{\\mathrm{e}^{-\\mathrm{x}}}{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}+(1-1)}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)-1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[\\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)}{1+\\mathrm{e}^{-\\mathrm{x}}}-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[1-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\sigma(\\mathrm{x})(1-\\sigma(\\mathrm{x}))\n\\end{aligned}\n\\end{equation}\n$$\n\n### Mapping though sigmoid\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the line equation\nA = 2\nB = -3\nC = 1\n\n# Generate some random points to plot\nx = np.linspace(-2, 2, 2000)\ny = np.linspace(-2, 2, 2000)\nX, Y = np.meshgrid(x, y)\nZ1 = A * X + B * Y + C\n\n# plot the line\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\n# if z > 0, then assign 1 to the point\n# if z < 0, then assign 0 to the point\nZ1[Z1 > 0] = 1\nZ1[Z1 < 0] = 0\n# Plot the points with different colors based on their labels\nplt.imshow(Z1, extent=[-100, 100, -100, 100], cmap='plasma', origin='lower')\nplt.colorbar()\n\n\nplt.subplot(1, 2, 2)\n# map the Z values through the sigmoid function\nZ2 = A * X + B * Y + C\nZ2 = 1 / (1 + np.exp(-Z2))\n# now Z is between 0 and 1\n# if we plot Z, then Z should show a gradually changing color\nplt.imshow(Z2, extent=[-100, 100, -100, 100], cmap='plasma', origin='lower')\nplt.colorbar()\nplt.savefig('binaryclass2.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\"> <img src=\"From-linear-regression-to-binary-classification/binaryclass2.png\" alt=\"binaryclass\" style=\"zoom:30%;\" /> </p>\n\n**Previously, the points were separated into two classes on either side of a straight line. Now, the results are passed through a sigmoid function to map the values to the range of 0-1. This way, the distance from the points to the line can be more easily observed.**\n\n### Decision boundary\n\nGenerally, the decision boundary is set at 0.5, since the points on the decision boundary will be mapped to 0.5 after passing through the sigmoid function. Therefore, any point with a sigmoid value above 0.5 is classified as one class, while any point with a sigmoid value below 0.5 is classified as the other class.\n\nHowever, in certain cases, it may be more appropriate to set the decision boundary at a different value. For example, in the case of spam email classification, a decision boundary of 0.8 or 0.9 may be more appropriate to reduce the number of false positives and ensure that fewer emails are mistakenly identified as spam. Ultimately, the choice of decision boundary depends on the specific application and the trade-offs between different types of classification errors.\n\n### Reference \n\n1. Wright, R. E. (1995). Logistic regression.\n2. King, J. E. (2008). Binary logistic regression. *Best practices in quantitative methods*, 358-384.\n3. Wikipedia contributors. (2023, March 28). Logistic regression. In Wikipedia, The Free Encyclopedia. Retrieved 21:05, March 28, 2023, from https://en.wikipedia.org/wiki/Logistic_regression\n4. Weisstein, Eric W. \"Sigmoid Function.\" From MathWorld--A Wolfram Web Resource. https://mathworld.wolfram.com/SigmoidFunction.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/From-linear-regression-to-binary-classification.md","raw":"---\nmathjax: true\ntitle: From linear regression to binary classification\ndate: 2023-03-29 12:22:17\ntags: \n  - Linear regression\n  - Logistic regression\n  - Linear algebra\n  - Binary classification\n  - Sigmoid\n---\n\n### Regression and classification \n\nLinear regression involves finding a line that fits a set of data points, while binary classification involves finding a line that separates a set of points into two groups. Specifically, some points will be on one side of the line and others on the other side.\n\nRegression problems and binary classification problems have many similarities. They both take a set of input data points and aim to find a single line. The difference is in the purpose of the line. In regression problems, the line is used to make predictions based on the input data, while in binary classification problems, the line is used to separate the data into two classes.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/29/23 14:49\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 2 * np.random.randn(5)\n\n# Fit a linear regression model to the data\nmodel = np.polyfit(x, y, 1)\npredicted = np.polyval(model, x)\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x, predicted, color='red', label='Predicted')\n\n# Highlight the difference between actual and predicted values\nfor i in range(len(x)):\n    plt.plot([x[i], x[i]], [y[i], predicted[i]], color='gray', linestyle='--')\n\n# Color-code the actual data points based on whether they are above or below the regression line\nabove = y > predicted\nbelow = y < predicted\nplt.scatter(x[above], y[above], color='green', label='Above')\nplt.scatter(x[below], y[below], color='purple', label='Below')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression')\nplt.legend()\n\n# Display the plot\nplt.savefig('binaryclass.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\"> <img src=\"From-linear-regression-to-binary-classification/binaryclass.png\" alt=\"binaryclass\" style=\"zoom:30%;\" /> </p>\n\nNow, building on the concept of linear regression, we can view the data points above the regression line as one class, and the points below the line as another class. This transforms the regression problem into a binary classification problem, where the goal is to find a line that best separates the two classes.\n\n### The relationship between a point and a line\n\nGiven a line with equation $Ax + By + C = 0$ and a point with coordinates $(x_0, y_0)$, we can determine the relationship between the point and the line using the vector inner product.\n\nWe first define a vector $\\vec{n} = \\begin{pmatrix} A \\ B \\end{pmatrix}$ as the normal vector to the line. Then, we define a vector $\\vec{p} = \\begin{pmatrix} x_0 \\ y_0 \\end{pmatrix}$ as the vector representing the point. The relationship between the point and the line can then be determined by taking the dot product of these two vectors:\n$$\n\\begin{equation}\n\\vec{n} \\cdot \\vec{p}=\\left(\\begin{array}{l}\nA \\\\\nB\n\\end{array}\\right) \\cdot\\left(\\begin{array}{l}\nx_0 \\\\\ny_0\n\\end{array}\\right)=A x_0+B y_0\n\\end{equation}\n$$\nIf $\\vec{n} \\cdot \\vec{p} + C = 0$, then the point lies on the line. If $\\vec{n} \\cdot \\vec{p} + C > 0$, then the point lies on one side of the line, and if $\\vec{n} \\cdot \\vec{p} + C < 0$, then the point lies on the other side of the line.\n\nit feels like this:\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the line equation\nA = 2\nB = -3\nC = 1\n\n# Generate some random points to plot\nx = np.linspace(-100, 100, 100)\ny = np.linspace(-100, 100, 100)\nX, Y = np.meshgrid(x, y)\nZ = A*X + B*Y + C\n\n# plot the line\nplt.figure(figsize=(4, 4))\nplt.subplot(1, 1, 1)\nlabels = Z > 0\n# Plot the points with different colors based on their labels\nplt.scatter(X, Y, c=labels, cmap='plasma')\nplt.savefig('binaryclass1.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\"> <img src=\"From-linear-regression-to-binary-classification/binaryclass1.png\" alt=\"binaryclass\" style=\"zoom:30%;\" /> </p>\n\n**Now we have a problem, the classification approach we just described is that it does not take into account the distance between each point and the line. Some points may be far away from the line, while others may be closer. This is similar to the problem of classifying people as male or female based on certain characteristics. While there may be some defining characteristics for each gender, most people have a combination of both male and female traits, and it's a gradient rather than a clear-cut binary classification.**\n\nwe need sigmoid function to solve this problem.\n\n### Sigmoid\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/29/23 15:54\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n\ndef sigmoid_derivative(x):\n    return sigmoid(x) * (1 - sigmoid(x))\n\n\nx = np.linspace(-10, 10, 100)\ny = sigmoid(x)\ndy = sigmoid_derivative(x)\n\nfig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n\nax[0].plot(x, y)\nax[0].set_title('Sigmoid function')\nax[0].set_xlabel('x')\nax[0].set_ylabel('sigmoid(x)')\n\nax[1].plot(x, dy)\nax[1].set_title('Sigmoid derivative')\nax[1].set_xlabel('x')\nax[1].set_ylabel('sigmoid\\'(x)')\n\nplt.tight_layout()\nplt.savefig('sigmoid.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![sigmoid](From-linear-regression-to-binary-classification/sigmoid.png)\n\nThe sigmoid function is defined as:\n$$\n\\begin{equation}\n\\sigma(\\mathrm{x})=\\frac{1}{1+e^{-\\mathrm{x}}}\n\\end{equation}\n$$\nwhere $z$ is the input to the function. It maps any input value to a value between 0 and 1, which makes it suitable for modeling probabilities.\n\nSigmoid derivative:\n$$\n\\begin{equation}\n\\begin{aligned}\n\\frac{\\mathrm{d}}{\\mathrm{dx}} \\sigma(\\mathrm{x}) & =\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left[\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right]=\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-1} \\\\\n& =-1 *\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-2}\\left(-\\mathrm{e}^{-\\mathrm{x}}\\right) \\\\\n& =\\frac{-\\mathrm{e}^{-\\mathrm{x}}}{-\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{\\mathrm{e}^{-\\mathrm{x}}}{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}+(1-1)}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)-1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[\\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)}{1+\\mathrm{e}^{-\\mathrm{x}}}-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[1-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\sigma(\\mathrm{x})(1-\\sigma(\\mathrm{x}))\n\\end{aligned}\n\\end{equation}\n$$\n\n### Mapping though sigmoid\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the line equation\nA = 2\nB = -3\nC = 1\n\n# Generate some random points to plot\nx = np.linspace(-2, 2, 2000)\ny = np.linspace(-2, 2, 2000)\nX, Y = np.meshgrid(x, y)\nZ1 = A * X + B * Y + C\n\n# plot the line\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\n# if z > 0, then assign 1 to the point\n# if z < 0, then assign 0 to the point\nZ1[Z1 > 0] = 1\nZ1[Z1 < 0] = 0\n# Plot the points with different colors based on their labels\nplt.imshow(Z1, extent=[-100, 100, -100, 100], cmap='plasma', origin='lower')\nplt.colorbar()\n\n\nplt.subplot(1, 2, 2)\n# map the Z values through the sigmoid function\nZ2 = A * X + B * Y + C\nZ2 = 1 / (1 + np.exp(-Z2))\n# now Z is between 0 and 1\n# if we plot Z, then Z should show a gradually changing color\nplt.imshow(Z2, extent=[-100, 100, -100, 100], cmap='plasma', origin='lower')\nplt.colorbar()\nplt.savefig('binaryclass2.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\"> <img src=\"From-linear-regression-to-binary-classification/binaryclass2.png\" alt=\"binaryclass\" style=\"zoom:30%;\" /> </p>\n\n**Previously, the points were separated into two classes on either side of a straight line. Now, the results are passed through a sigmoid function to map the values to the range of 0-1. This way, the distance from the points to the line can be more easily observed.**\n\n### Decision boundary\n\nGenerally, the decision boundary is set at 0.5, since the points on the decision boundary will be mapped to 0.5 after passing through the sigmoid function. Therefore, any point with a sigmoid value above 0.5 is classified as one class, while any point with a sigmoid value below 0.5 is classified as the other class.\n\nHowever, in certain cases, it may be more appropriate to set the decision boundary at a different value. For example, in the case of spam email classification, a decision boundary of 0.8 or 0.9 may be more appropriate to reduce the number of false positives and ensure that fewer emails are mistakenly identified as spam. Ultimately, the choice of decision boundary depends on the specific application and the trade-offs between different types of classification errors.\n\n### Reference \n\n1. Wright, R. E. (1995). Logistic regression.\n2. King, J. E. (2008). Binary logistic regression. *Best practices in quantitative methods*, 358-384.\n3. Wikipedia contributors. (2023, March 28). Logistic regression. In Wikipedia, The Free Encyclopedia. Retrieved 21:05, March 28, 2023, from https://en.wikipedia.org/wiki/Logistic_regression\n4. Weisstein, Eric W. \"Sigmoid Function.\" From MathWorld--A Wolfram Web Resource. https://mathworld.wolfram.com/SigmoidFunction.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"From-linear-regression-to-binary-classification","published":1,"updated":"2023-04-07T02:43:50.476Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gm0008ozpi2g202xwp","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Regression-and-classification\"><a href=\"#Regression-and-classification\" class=\"headerlink\" title=\"Regression and classification\"></a>Regression and classification</h3><p>Linear regression involves finding a line that fits a set of data points, while binary classification involves finding a line that separates a set of points into two groups. Specifically, some points will be on one side of the line and others on the other side.</p>\n<p>Regression problems and binary classification problems have many similarities. They both take a set of input data points and aim to find a single line. The difference is in the purpose of the line. In regression problems, the line is used to make predictions based on the input data, while in binary classification problems, the line is used to separate the data into two classes.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/29/23 14:49</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">2</span> * np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\">model = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted = np.polyval(model, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x, predicted, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Highlight the difference between actual and predicted values</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)):</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted[i]], color=<span class=\"string\">'gray'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Color-code the actual data points based on whether they are above or below the regression line</span></span><br><span class=\"line\">above = y &gt; predicted</span><br><span class=\"line\">below = y &lt; predicted</span><br><span class=\"line\">plt.scatter(x[above], y[above], color=<span class=\"string\">'green'</span>, label=<span class=\"string\">'Above'</span>)</span><br><span class=\"line\">plt.scatter(x[below], y[below], color=<span class=\"string\">'purple'</span>, label=<span class=\"string\">'Below'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binaryclass.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"binaryclass\" style=\"zoom:30%;\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/binaryclass.png\"> </p>\n\n<p>Now, building on the concept of linear regression, we can view the data points above the regression line as one class, and the points below the line as another class. This transforms the regression problem into a binary classification problem, where the goal is to find a line that best separates the two classes.</p>\n<h3 id=\"The-relationship-between-a-point-and-a-line\"><a href=\"#The-relationship-between-a-point-and-a-line\" class=\"headerlink\" title=\"The relationship between a point and a line\"></a>The relationship between a point and a line</h3><p>Given a line with equation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"17.216ex\" height=\"2.084ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 7609.4 921\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(750,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1544.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2544.4,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3303.4,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4015.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5015.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6053.7,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(7109.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container> and a point with coordinates <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.144ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 3157.8 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1397.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1842.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2768.8,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>, we can determine the relationship between the point and the line using the vector inner product.</p>\n<p>We first define a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"10.114ex\" height=\"2.477ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 4470.6 1095\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(877.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mrow\" transform=\"translate(1933.6,0)\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mtable\" transform=\"translate(389,0)\"><g data-mml-node=\"mtr\"><g data-mml-node=\"mtd\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mtext\" transform=\"translate(750,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1000,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2148,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></svg></mjx-container> as the normal vector to the line. Then, we define a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"10.859ex\" height=\"2.477ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 4799.7 1095\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mrow\" transform=\"translate(1836.6,0)\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mtable\" transform=\"translate(389,0)\"><g data-mml-node=\"mtr\"><g data-mml-node=\"mtd\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtext\" transform=\"translate(1008.6,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1258.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2574.1,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></svg></mjx-container> as the vector representing the point. The relationship between the point and the line can then be determined by taking the dot product of these two vectors:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\vec{n} \\cdot \\vec{p}=\\left(\\begin{array}{l}\nA \\\\\nB\n\\end{array}\\right) \\cdot\\left(\\begin{array}{l}\nx_0 \\\\\ny_0\n\\end{array}\\right)=A x_0+B y_0\n\\end{equation}</script><p>If <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.763ex\" height=\"2.351ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 5641.4 1039\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1322.4,0)\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2047.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3047.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4085.7,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(5141.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container>, then the point lies on the line. If <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.763ex\" height=\"2.351ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 5641.4 1039\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1322.4,0)\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2047.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3047.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4085.7,0)\"><path data-c=\"3E\" d=\"M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(5141.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container>, then the point lies on one side of the line, and if <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.763ex\" height=\"2.351ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 5641.4 1039\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1322.4,0)\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2047.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3047.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4085.7,0)\"><path data-c=\"3C\" d=\"M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(5141.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container>, then the point lies on the other side of the line.</p>\n<p>it feels like this:</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the line equation</span></span><br><span class=\"line\">A = <span class=\"number\">2</span></span><br><span class=\"line\">B = -<span class=\"number\">3</span></span><br><span class=\"line\">C = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random points to plot</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = A*X + B*Y + C</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the line</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">4</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">labels = Z &gt; <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"comment\"># Plot the points with different colors based on their labels</span></span><br><span class=\"line\">plt.scatter(X, Y, c=labels, cmap=<span class=\"string\">'plasma'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binaryclass1.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"binaryclass\" style=\"zoom:30%;\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/binaryclass1.png\"> </p>\n\n<p><strong>Now we have a problem, the classification approach we just described is that it does not take into account the distance between each point and the line. Some points may be far away from the line, while others may be closer. This is similar to the problem of classifying people as male or female based on certain characteristics. While there may be some defining characteristics for each gender, most people have a combination of both male and female traits, and its a gradient rather than a clear-cut binary classification.</strong></p>\n<p>we need sigmoid function to solve this problem.</p>\n<h3 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/29/23 15:54</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sigmoid</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sigmoid_derivative</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sigmoid(x) * (<span class=\"number\">1</span> - sigmoid(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">10</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = sigmoid(x)</span><br><span class=\"line\">dy = sigmoid_derivative(x)</span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(nrows=<span class=\"number\">2</span>, ncols=<span class=\"number\">1</span>, figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">ax[<span class=\"number\">0</span>].plot(x, y)</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Sigmoid function'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'sigmoid(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax[<span class=\"number\">1</span>].plot(x, dy)</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Sigmoid derivative'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'sigmoid\\'(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'sigmoid.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"sigmoid\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/sigmoid.png\"></p>\n<p>The sigmoid function is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\sigma(\\mathrm{x})=\\frac{1}{1+e^{-\\mathrm{x}}}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.052ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 465 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D467\" d=\"M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z\"></path></g></g></g></svg></mjx-container> is the input to the function. It maps any input value to a value between 0 and 1, which makes it suitable for modeling probabilities.</p>\n<p>Sigmoid derivative:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\begin{aligned}\n\\frac{\\mathrm{d}}{\\mathrm{dx}} \\sigma(\\mathrm{x}) & =\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left[\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right]=\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-1} \\\\\n& =-1 *\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-2}\\left(-\\mathrm{e}^{-\\mathrm{x}}\\right) \\\\\n& =\\frac{-\\mathrm{e}^{-\\mathrm{x}}}{-\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{\\mathrm{e}^{-\\mathrm{x}}}{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}+(1-1)}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)-1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[\\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)}{1+\\mathrm{e}^{-\\mathrm{x}}}-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[1-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\sigma(\\mathrm{x})(1-\\sigma(\\mathrm{x}))\n\\end{aligned}\n\\end{equation}</script><h3 id=\"Mapping-though-sigmoid\"><a href=\"#Mapping-though-sigmoid\" class=\"headerlink\" title=\"Mapping though sigmoid\"></a>Mapping though sigmoid</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the line equation</span></span><br><span class=\"line\">A = <span class=\"number\">2</span></span><br><span class=\"line\">B = -<span class=\"number\">3</span></span><br><span class=\"line\">C = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random points to plot</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2000</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2000</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z1 = A * X + B * Y + C</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the line</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># if z &gt; 0, then assign 1 to the point</span></span><br><span class=\"line\"><span class=\"comment\"># if z &lt; 0, then assign 0 to the point</span></span><br><span class=\"line\">Z1[Z1 &gt; <span class=\"number\">0</span>] = <span class=\"number\">1</span></span><br><span class=\"line\">Z1[Z1 &lt; <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"comment\"># Plot the points with different colors based on their labels</span></span><br><span class=\"line\">plt.imshow(Z1, extent=[-<span class=\"number\">100</span>, <span class=\"number\">100</span>, -<span class=\"number\">100</span>, <span class=\"number\">100</span>], cmap=<span class=\"string\">'plasma'</span>, origin=<span class=\"string\">'lower'</span>)</span><br><span class=\"line\">plt.colorbar()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># map the Z values through the sigmoid function</span></span><br><span class=\"line\">Z2 = A * X + B * Y + C</span><br><span class=\"line\">Z2 = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-Z2))</span><br><span class=\"line\"><span class=\"comment\"># now Z is between 0 and 1</span></span><br><span class=\"line\"><span class=\"comment\"># if we plot Z, then Z should show a gradually changing color</span></span><br><span class=\"line\">plt.imshow(Z2, extent=[-<span class=\"number\">100</span>, <span class=\"number\">100</span>, -<span class=\"number\">100</span>, <span class=\"number\">100</span>], cmap=<span class=\"string\">'plasma'</span>, origin=<span class=\"string\">'lower'</span>)</span><br><span class=\"line\">plt.colorbar()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binaryclass2.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"binaryclass\" style=\"zoom:30%;\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/binaryclass2.png\"> </p>\n\n<p><strong>Previously, the points were separated into two classes on either side of a straight line. Now, the results are passed through a sigmoid function to map the values to the range of 0-1. This way, the distance from the points to the line can be more easily observed.</strong></p>\n<h3 id=\"Decision-boundary\"><a href=\"#Decision-boundary\" class=\"headerlink\" title=\"Decision boundary\"></a>Decision boundary</h3><p>Generally, the decision boundary is set at 0.5, since the points on the decision boundary will be mapped to 0.5 after passing through the sigmoid function. Therefore, any point with a sigmoid value above 0.5 is classified as one class, while any point with a sigmoid value below 0.5 is classified as the other class.</p>\n<p>However, in certain cases, it may be more appropriate to set the decision boundary at a different value. For example, in the case of spam email classification, a decision boundary of 0.8 or 0.9 may be more appropriate to reduce the number of false positives and ensure that fewer emails are mistakenly identified as spam. Ultimately, the choice of decision boundary depends on the specific application and the trade-offs between different types of classification errors.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Wright, R. E. (1995). Logistic regression.</li>\n<li>King, J. E. (2008). Binary logistic regression. <em>Best practices in quantitative methods</em>, 358-384.</li>\n<li>Wikipedia contributors. (2023, March 28). Logistic regression. In Wikipedia, The Free Encyclopedia. Retrieved 21:05, March 28, 2023, from <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">https://en.wikipedia.org/wiki/Logistic_regression</a></li>\n<li>Weisstein, Eric W. Sigmoid Function. From MathWorldA Wolfram Web Resource. <a href=\"https://mathworld.wolfram.com/SigmoidFunction.html\">https://mathworld.wolfram.com/SigmoidFunction.html</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/27/Norms/","2023/03/28/Hyperplane/","2023/03/27/Basic-operations-of-Matrix/","2023/03/28/Functions-Plot/","2023/03/28/Gradient-descend-for-linear-regression/"],"length":1545,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Regression-and-classification\"><a href=\"#Regression-and-classification\" class=\"headerlink\" title=\"Regression and classification\"></a>Regression and classification</h3><p>Linear regression involves finding a line that fits a set of data points, while binary classification involves finding a line that separates a set of points into two groups. Specifically, some points will be on one side of the line and others on the other side.</p>\n<p>Regression problems and binary classification problems have many similarities. They both take a set of input data points and aim to find a single line. The difference is in the purpose of the line. In regression problems, the line is used to make predictions based on the input data, while in binary classification problems, the line is used to separate the data into two classes.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/29/23 14:49</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">2</span> * np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\">model = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted = np.polyval(model, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x, predicted, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Highlight the difference between actual and predicted values</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)):</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted[i]], color=<span class=\"string\">'gray'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Color-code the actual data points based on whether they are above or below the regression line</span></span><br><span class=\"line\">above = y &gt; predicted</span><br><span class=\"line\">below = y &lt; predicted</span><br><span class=\"line\">plt.scatter(x[above], y[above], color=<span class=\"string\">'green'</span>, label=<span class=\"string\">'Above'</span>)</span><br><span class=\"line\">plt.scatter(x[below], y[below], color=<span class=\"string\">'purple'</span>, label=<span class=\"string\">'Below'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binaryclass.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"binaryclass\" style=\"zoom:30%;\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/binaryclass.png\"> </p>\n\n<p>Now, building on the concept of linear regression, we can view the data points above the regression line as one class, and the points below the line as another class. This transforms the regression problem into a binary classification problem, where the goal is to find a line that best separates the two classes.</p>\n<h3 id=\"The-relationship-between-a-point-and-a-line\"><a href=\"#The-relationship-between-a-point-and-a-line\" class=\"headerlink\" title=\"The relationship between a point and a line\"></a>The relationship between a point and a line</h3><p>Given a line with equation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"17.216ex\" height=\"2.084ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 7609.4 921\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(750,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1544.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2544.4,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3303.4,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4015.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5015.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6053.7,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(7109.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container> and a point with coordinates <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.144ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 3157.8 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1397.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1842.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2768.8,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>, we can determine the relationship between the point and the line using the vector inner product.</p>\n<p>We first define a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"10.114ex\" height=\"2.477ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 4470.6 1095\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(877.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mrow\" transform=\"translate(1933.6,0)\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mtable\" transform=\"translate(389,0)\"><g data-mml-node=\"mtr\"><g data-mml-node=\"mtd\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mtext\" transform=\"translate(750,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1000,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2148,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></svg></mjx-container> as the normal vector to the line. Then, we define a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"10.859ex\" height=\"2.477ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 4799.7 1095\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mrow\" transform=\"translate(1836.6,0)\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mtable\" transform=\"translate(389,0)\"><g data-mml-node=\"mtr\"><g data-mml-node=\"mtd\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtext\" transform=\"translate(1008.6,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1258.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2574.1,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></svg></mjx-container> as the vector representing the point. The relationship between the point and the line can then be determined by taking the dot product of these two vectors:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\vec{n} \\cdot \\vec{p}=\\left(\\begin{array}{l}\nA \\\\\nB\n\\end{array}\\right) \\cdot\\left(\\begin{array}{l}\nx_0 \\\\\ny_0\n\\end{array}\\right)=A x_0+B y_0\n\\end{equation}</script><p>If <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.763ex\" height=\"2.351ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 5641.4 1039\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1322.4,0)\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2047.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3047.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4085.7,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(5141.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container>, then the point lies on the line. If <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.763ex\" height=\"2.351ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 5641.4 1039\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1322.4,0)\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2047.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3047.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4085.7,0)\"><path data-c=\"3E\" d=\"M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(5141.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container>, then the point lies on one side of the line, and if <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.763ex\" height=\"2.351ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -845 5641.4 1039\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"22C5\" d=\"M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1322.4,0)\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(334.8,31) translate(-250 0)\"><path data-c=\"20D7\" d=\"M377 694Q377 702 382 708T397 714Q404 714 409 709Q414 705 419 690Q429 653 460 633Q471 626 471 615Q471 606 468 603T454 594Q411 572 379 531Q377 529 374 525T369 519T364 517T357 516Q350 516 344 521T337 536Q337 555 384 595H213L42 596Q29 605 29 615Q29 622 42 635H401Q377 673 377 694Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2047.7,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3047.9,0)\"><path data-c=\"1D436\" d=\"M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4085.7,0)\"><path data-c=\"3C\" d=\"M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(5141.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container>, then the point lies on the other side of the line.</p>\n<p>it feels like this:</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the line equation</span></span><br><span class=\"line\">A = <span class=\"number\">2</span></span><br><span class=\"line\">B = -<span class=\"number\">3</span></span><br><span class=\"line\">C = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random points to plot</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = A*X + B*Y + C</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the line</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">4</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">labels = Z &gt; <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"comment\"># Plot the points with different colors based on their labels</span></span><br><span class=\"line\">plt.scatter(X, Y, c=labels, cmap=<span class=\"string\">'plasma'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binaryclass1.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"binaryclass\" style=\"zoom:30%;\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/binaryclass1.png\"> </p>\n\n<p><strong>Now we have a problem, the classification approach we just described is that it does not take into account the distance between each point and the line. Some points may be far away from the line, while others may be closer. This is similar to the problem of classifying people as male or female based on certain characteristics. While there may be some defining characteristics for each gender, most people have a combination of both male and female traits, and its a gradient rather than a clear-cut binary classification.</strong></p>\n<p>we need sigmoid function to solve this problem.</p>\n<h3 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/29/23 15:54</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sigmoid</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sigmoid_derivative</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> sigmoid(x) * (<span class=\"number\">1</span> - sigmoid(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">10</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = sigmoid(x)</span><br><span class=\"line\">dy = sigmoid_derivative(x)</span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(nrows=<span class=\"number\">2</span>, ncols=<span class=\"number\">1</span>, figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">ax[<span class=\"number\">0</span>].plot(x, y)</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Sigmoid function'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'sigmoid(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax[<span class=\"number\">1</span>].plot(x, dy)</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Sigmoid derivative'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'sigmoid\\'(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'sigmoid.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"sigmoid\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/sigmoid.png\"></p>\n<p>The sigmoid function is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\sigma(\\mathrm{x})=\\frac{1}{1+e^{-\\mathrm{x}}}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.052ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 465 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D467\" d=\"M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z\"></path></g></g></g></svg></mjx-container> is the input to the function. It maps any input value to a value between 0 and 1, which makes it suitable for modeling probabilities.</p>\n<p>Sigmoid derivative:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\begin{aligned}\n\\frac{\\mathrm{d}}{\\mathrm{dx}} \\sigma(\\mathrm{x}) & =\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left[\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right]=\\frac{\\mathrm{d}}{\\mathrm{dx}}\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-1} \\\\\n& =-1 *\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^{-2}\\left(-\\mathrm{e}^{-\\mathrm{x}}\\right) \\\\\n& =\\frac{-\\mathrm{e}^{-\\mathrm{x}}}{-\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{\\mathrm{e}^{-\\mathrm{x}}}{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)^2} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\mathrm{e}^{-\\mathrm{x}}+(1-1)}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)-1}{1+\\mathrm{e}^{-\\mathrm{x}}} \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[\\frac{\\left(1+\\mathrm{e}^{-\\mathrm{x}}\\right)}{1+\\mathrm{e}^{-\\mathrm{x}}}-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\left[1-\\frac{1}{1+\\mathrm{e}^{-\\mathrm{x}}}\\right] \\\\\n& =\\sigma(\\mathrm{x})(1-\\sigma(\\mathrm{x}))\n\\end{aligned}\n\\end{equation}</script><h3 id=\"Mapping-though-sigmoid\"><a href=\"#Mapping-though-sigmoid\" class=\"headerlink\" title=\"Mapping though sigmoid\"></a>Mapping though sigmoid</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the line equation</span></span><br><span class=\"line\">A = <span class=\"number\">2</span></span><br><span class=\"line\">B = -<span class=\"number\">3</span></span><br><span class=\"line\">C = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random points to plot</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2000</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2000</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z1 = A * X + B * Y + C</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the line</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># if z &gt; 0, then assign 1 to the point</span></span><br><span class=\"line\"><span class=\"comment\"># if z &lt; 0, then assign 0 to the point</span></span><br><span class=\"line\">Z1[Z1 &gt; <span class=\"number\">0</span>] = <span class=\"number\">1</span></span><br><span class=\"line\">Z1[Z1 &lt; <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"comment\"># Plot the points with different colors based on their labels</span></span><br><span class=\"line\">plt.imshow(Z1, extent=[-<span class=\"number\">100</span>, <span class=\"number\">100</span>, -<span class=\"number\">100</span>, <span class=\"number\">100</span>], cmap=<span class=\"string\">'plasma'</span>, origin=<span class=\"string\">'lower'</span>)</span><br><span class=\"line\">plt.colorbar()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># map the Z values through the sigmoid function</span></span><br><span class=\"line\">Z2 = A * X + B * Y + C</span><br><span class=\"line\">Z2 = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + np.exp(-Z2))</span><br><span class=\"line\"><span class=\"comment\"># now Z is between 0 and 1</span></span><br><span class=\"line\"><span class=\"comment\"># if we plot Z, then Z should show a gradually changing color</span></span><br><span class=\"line\">plt.imshow(Z2, extent=[-<span class=\"number\">100</span>, <span class=\"number\">100</span>, -<span class=\"number\">100</span>, <span class=\"number\">100</span>], cmap=<span class=\"string\">'plasma'</span>, origin=<span class=\"string\">'lower'</span>)</span><br><span class=\"line\">plt.colorbar()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binaryclass2.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"binaryclass\" style=\"zoom:30%;\" data-src=\"/2023/03/29/From-linear-regression-to-binary-classification/binaryclass2.png\"> </p>\n\n<p><strong>Previously, the points were separated into two classes on either side of a straight line. Now, the results are passed through a sigmoid function to map the values to the range of 0-1. This way, the distance from the points to the line can be more easily observed.</strong></p>\n<h3 id=\"Decision-boundary\"><a href=\"#Decision-boundary\" class=\"headerlink\" title=\"Decision boundary\"></a>Decision boundary</h3><p>Generally, the decision boundary is set at 0.5, since the points on the decision boundary will be mapped to 0.5 after passing through the sigmoid function. Therefore, any point with a sigmoid value above 0.5 is classified as one class, while any point with a sigmoid value below 0.5 is classified as the other class.</p>\n<p>However, in certain cases, it may be more appropriate to set the decision boundary at a different value. For example, in the case of spam email classification, a decision boundary of 0.8 or 0.9 may be more appropriate to reduce the number of false positives and ensure that fewer emails are mistakenly identified as spam. Ultimately, the choice of decision boundary depends on the specific application and the trade-offs between different types of classification errors.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Wright, R. E. (1995). Logistic regression.</li>\n<li>King, J. E. (2008). Binary logistic regression. <em>Best practices in quantitative methods</em>, 358-384.</li>\n<li>Wikipedia contributors. (2023, March 28). Logistic regression. In Wikipedia, The Free Encyclopedia. Retrieved 21:05, March 28, 2023, from <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">https://en.wikipedia.org/wiki/Logistic_regression</a></li>\n<li>Weisstein, Eric W. Sigmoid Function. From MathWorldA Wolfram Web Resource. <a href=\"https://mathworld.wolfram.com/SigmoidFunction.html\">https://mathworld.wolfram.com/SigmoidFunction.html</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Functions Plot","date":"2023-03-28T08:21:10.000Z","_content":"\n### Line and curves\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 10:19\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the x-values for the functions\nx = np.linspace(-5, 5, 100)\n\n# Define the functions\ny1 = x                   # Straight line\ny2 = x**2                # Quadratic curve\ny3 = np.sin(x)           # Sine wave\ny4 = np.exp(-x**2)       # Gaussian curve\n\n# Create a new figure and set its size\nplt.figure(figsize=(8, 6))\n\n# Plot the functions in separate subplots\nplt.subplot(2, 2, 1)     # Create a subplot for the straight line\nplt.plot(x, y1)\nplt.title('Straight line')\n\nplt.subplot(2, 2, 2)     # Create a subplot for the quadratic curve\nplt.plot(x, y2)\nplt.title('Quadratic curve')\n\nplt.subplot(2, 2, 3)     # Create a subplot for the sine wave\nplt.plot(x, y3)\nplt.title('Sine wave')\n\nplt.subplot(2, 2, 4)     # Create a subplot for the Gaussian curve\nplt.plot(x, y4)\nplt.title('Gaussian curve')\n\n# Add x- and y-labels for all subplots\nfor ax in plt.gcf().axes:\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n# Adjust the spacing between subplots to avoid overlap\nplt.tight_layout()\nplt.savefig(\"2d_functions.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n# Show the figure\nplt.show()\n```\n\n![2d_functions](Functions-Plot/2d_functions.png)\n\n### 3D view of 2D functions\n\n$F_1(x) = -\\sum\\limits_{i=1}^n x_i \\sin(\\sqrt{|x_i|})$\n\n$F_2(x) = \\sum\\limits_{i=1}^n \\left(x_i^2 - 10 \\cos(2\\pi x_i) + 10\\right)$\n\n$F_3(x) = \\left(-20 \\exp\\left(-0.2 \\sqrt{\\frac{1}{n} \\sum\\limits_{i=1}^n x_i^2}\\right) - \\exp\\left(\\frac{1}{n} \\sum\\limits_{i=1}^n \\cos(2\\pi x_i)\\right) + 20 + e\\right)$\n\nNote that in these formulas, $x$ represents a vector of length $n$.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\ndef F1(x):\n    result = []\n    for i in x:\n        k = (-1) * i * np.sin(np.sqrt(np.abs(i)))\n        result.append(k)\n    return sum(result)\n\n\ndef F2(x):\n    result = [np.power(i, 2) - (10 * np.cos(2 * np.pi * i)) + 10 for i in x]\n    return sum(result)\n\n\ndef F3(x):\n    dim = len(x)\n    part1 = sum([np.power(i, 2) for i in x])\n    part2 = sum([np.cos(2 * np.pi * i) for i in x])\n    result = (-20) * np.exp(-0.2 * np.sqrt((1 / dim) * part1)) + (-np.exp((1 / dim) * part2) + 20 + np.e)\n    return result\n\n\n# Create a meshgrid of x and y values\nx = np.linspace(-500, 500, 100)\ny = np.linspace(-500, 500, 100)\nX, Y = np.meshgrid(x, y)\nZ1 = F1([X, Y])\n\n\nx = np.linspace(-5, 5, 100)\ny = np.linspace(-5, 5, 100)\nX, Y = np.meshgrid(x, y)\nZ2 = F2([X, Y])\n\nx = np.linspace(-100, 100, 100)\ny = np.linspace(-100, 100, 100)\nX, Y = np.meshgrid(x, y)\nZ3 = F3([X, Y])\n\n# Create a new figure and set its size\nfig = plt.figure(figsize=(15, 6))\n# white background\nfig.patch.set_facecolor('white')\n\n# Plot the functions in 3D subplots\nax1 = fig.add_subplot(131, projection='3d')\nax1.plot_surface(X, Y, Z1, cmap=\"coolwarm\")\n# plot projection on xy plane\nax1.contour(X, Y, Z1, zdir='z', offset=-900, cmap=\"coolwarm\")\nax1.set_title('F1')\n\nax2 = fig.add_subplot(132, projection='3d')\nax2.plot_surface(X, Y, Z2, cmap=\"coolwarm\")\n# plot projection on xy plane\nax2.contour(X, Y, Z2, zdir='z', offset=0, cmap=\"coolwarm\")\nax2.set_title('F2')\n\nax3 = fig.add_subplot(133, projection='3d')\nax3.plot_surface(X, Y, Z3, cmap=\"coolwarm\")\n# plot projection on xy plane\nax3.contour(X, Y, Z3, zdir='z', offset=0, cmap=\"coolwarm\")\nax3.set_title('F3')\n\n# Add x-, y-, and z-labels to all subplots, grid off, axis off\nfor ax in fig.axes:\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('z')\n\n# Adjust the spacing between subplots to avoid overlap\nplt.tight_layout()\n\nplt.savefig(\"3d_functions.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n# Show the figure\nplt.show()\n```\n\n![3d_functions](Functions-Plot/3d_functions.png)\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Functions-Plot.md","raw":"---\nmathjax: true\ntitle: Functions Plot\ndate: 2023-03-28 08:21:10\ntags: [Functions, Python, Numpy, Matplotlib ]\n---\n\n### Line and curves\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 10:19\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the x-values for the functions\nx = np.linspace(-5, 5, 100)\n\n# Define the functions\ny1 = x                   # Straight line\ny2 = x**2                # Quadratic curve\ny3 = np.sin(x)           # Sine wave\ny4 = np.exp(-x**2)       # Gaussian curve\n\n# Create a new figure and set its size\nplt.figure(figsize=(8, 6))\n\n# Plot the functions in separate subplots\nplt.subplot(2, 2, 1)     # Create a subplot for the straight line\nplt.plot(x, y1)\nplt.title('Straight line')\n\nplt.subplot(2, 2, 2)     # Create a subplot for the quadratic curve\nplt.plot(x, y2)\nplt.title('Quadratic curve')\n\nplt.subplot(2, 2, 3)     # Create a subplot for the sine wave\nplt.plot(x, y3)\nplt.title('Sine wave')\n\nplt.subplot(2, 2, 4)     # Create a subplot for the Gaussian curve\nplt.plot(x, y4)\nplt.title('Gaussian curve')\n\n# Add x- and y-labels for all subplots\nfor ax in plt.gcf().axes:\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n\n# Adjust the spacing between subplots to avoid overlap\nplt.tight_layout()\nplt.savefig(\"2d_functions.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n# Show the figure\nplt.show()\n```\n\n![2d_functions](Functions-Plot/2d_functions.png)\n\n### 3D view of 2D functions\n\n$F_1(x) = -\\sum\\limits_{i=1}^n x_i \\sin(\\sqrt{|x_i|})$\n\n$F_2(x) = \\sum\\limits_{i=1}^n \\left(x_i^2 - 10 \\cos(2\\pi x_i) + 10\\right)$\n\n$F_3(x) = \\left(-20 \\exp\\left(-0.2 \\sqrt{\\frac{1}{n} \\sum\\limits_{i=1}^n x_i^2}\\right) - \\exp\\left(\\frac{1}{n} \\sum\\limits_{i=1}^n \\cos(2\\pi x_i)\\right) + 20 + e\\right)$\n\nNote that in these formulas, $x$ represents a vector of length $n$.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\ndef F1(x):\n    result = []\n    for i in x:\n        k = (-1) * i * np.sin(np.sqrt(np.abs(i)))\n        result.append(k)\n    return sum(result)\n\n\ndef F2(x):\n    result = [np.power(i, 2) - (10 * np.cos(2 * np.pi * i)) + 10 for i in x]\n    return sum(result)\n\n\ndef F3(x):\n    dim = len(x)\n    part1 = sum([np.power(i, 2) for i in x])\n    part2 = sum([np.cos(2 * np.pi * i) for i in x])\n    result = (-20) * np.exp(-0.2 * np.sqrt((1 / dim) * part1)) + (-np.exp((1 / dim) * part2) + 20 + np.e)\n    return result\n\n\n# Create a meshgrid of x and y values\nx = np.linspace(-500, 500, 100)\ny = np.linspace(-500, 500, 100)\nX, Y = np.meshgrid(x, y)\nZ1 = F1([X, Y])\n\n\nx = np.linspace(-5, 5, 100)\ny = np.linspace(-5, 5, 100)\nX, Y = np.meshgrid(x, y)\nZ2 = F2([X, Y])\n\nx = np.linspace(-100, 100, 100)\ny = np.linspace(-100, 100, 100)\nX, Y = np.meshgrid(x, y)\nZ3 = F3([X, Y])\n\n# Create a new figure and set its size\nfig = plt.figure(figsize=(15, 6))\n# white background\nfig.patch.set_facecolor('white')\n\n# Plot the functions in 3D subplots\nax1 = fig.add_subplot(131, projection='3d')\nax1.plot_surface(X, Y, Z1, cmap=\"coolwarm\")\n# plot projection on xy plane\nax1.contour(X, Y, Z1, zdir='z', offset=-900, cmap=\"coolwarm\")\nax1.set_title('F1')\n\nax2 = fig.add_subplot(132, projection='3d')\nax2.plot_surface(X, Y, Z2, cmap=\"coolwarm\")\n# plot projection on xy plane\nax2.contour(X, Y, Z2, zdir='z', offset=0, cmap=\"coolwarm\")\nax2.set_title('F2')\n\nax3 = fig.add_subplot(133, projection='3d')\nax3.plot_surface(X, Y, Z3, cmap=\"coolwarm\")\n# plot projection on xy plane\nax3.contour(X, Y, Z3, zdir='z', offset=0, cmap=\"coolwarm\")\nax3.set_title('F3')\n\n# Add x-, y-, and z-labels to all subplots, grid off, axis off\nfor ax in fig.axes:\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('z')\n\n# Adjust the spacing between subplots to avoid overlap\nplt.tight_layout()\n\nplt.savefig(\"3d_functions.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n# Show the figure\nplt.show()\n```\n\n![3d_functions](Functions-Plot/3d_functions.png)\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Functions-Plot","published":1,"updated":"2023-04-07T02:43:50.480Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gn000aozpi070fdpd3","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Line-and-curves\"><a href=\"#Line-and-curves\" class=\"headerlink\" title=\"Line and curves\"></a>Line and curves</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 10:19</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the x-values for the functions</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the functions</span></span><br><span class=\"line\">y1 = x                   <span class=\"comment\"># Straight line</span></span><br><span class=\"line\">y2 = x**<span class=\"number\">2</span>                <span class=\"comment\"># Quadratic curve</span></span><br><span class=\"line\">y3 = np.sin(x)           <span class=\"comment\"># Sine wave</span></span><br><span class=\"line\">y4 = np.exp(-x**<span class=\"number\">2</span>)       <span class=\"comment\"># Gaussian curve</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a new figure and set its size</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the functions in separate subplots</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)     <span class=\"comment\"># Create a subplot for the straight line</span></span><br><span class=\"line\">plt.plot(x, y1)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Straight line'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)     <span class=\"comment\"># Create a subplot for the quadratic curve</span></span><br><span class=\"line\">plt.plot(x, y2)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Quadratic curve'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)     <span class=\"comment\"># Create a subplot for the sine wave</span></span><br><span class=\"line\">plt.plot(x, y3)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Sine wave'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)     <span class=\"comment\"># Create a subplot for the Gaussian curve</span></span><br><span class=\"line\">plt.plot(x, y4)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Gaussian curve'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add x- and y-labels for all subplots</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ax <span class=\"keyword\">in</span> plt.gcf().axes:</span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Adjust the spacing between subplots to avoid overlap</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"2d_functions.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># Show the figure</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"2d_functions\" data-src=\"/2023/03/28/Functions-Plot/2d_functions.png\"></p>\n<h3 id=\"3D-view-of-2D-functions\"><a href=\"#3D-view-of-2D-functions\" class=\"headerlink\" title=\"3D view of 2D functions\"></a>3D view of 2D functions</h3><p>$F<em>1(x) = -\\sum\\limits</em>{i=1}^n x_i \\sin(\\sqrt{|x_i|})$</p>\n<p>$F<em>2(x) = \\sum\\limits</em>{i=1}^n \\left(x_i^2 - 10 \\cos(2\\pi x_i) + 10\\right)$</p>\n<p>$F<em>3(x) = \\left(-20 \\exp\\left(-0.2 \\sqrt{\\frac{1}{n} \\sum\\limits</em>{i=1}^n x<em>i^2}\\right) - \\exp\\left(\\frac{1}{n} \\sum\\limits</em>{i=1}^n \\cos(2\\pi x_i)\\right) + 20 + e\\right)$</p>\n<p>Note that in these formulas, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.294ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 572 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g></g></g></svg></mjx-container> represents a vector of length <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">F1</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    result = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x:</span><br><span class=\"line\">        k = (-<span class=\"number\">1</span>) * i * np.sin(np.sqrt(np.<span class=\"built_in\">abs</span>(i)))</span><br><span class=\"line\">        result.append(k)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">F2</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    result = [np.power(i, <span class=\"number\">2</span>) - (<span class=\"number\">10</span> * np.cos(<span class=\"number\">2</span> * np.pi * i)) + <span class=\"number\">10</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">F3</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    dim = <span class=\"built_in\">len</span>(x)</span><br><span class=\"line\">    part1 = <span class=\"built_in\">sum</span>([np.power(i, <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x])</span><br><span class=\"line\">    part2 = <span class=\"built_in\">sum</span>([np.cos(<span class=\"number\">2</span> * np.pi * i) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x])</span><br><span class=\"line\">    result = (-<span class=\"number\">20</span>) * np.exp(-<span class=\"number\">0.2</span> * np.sqrt((<span class=\"number\">1</span> / dim) * part1)) + (-np.exp((<span class=\"number\">1</span> / dim) * part2) + <span class=\"number\">20</span> + np.e)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a meshgrid of x and y values</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">500</span>, <span class=\"number\">500</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">500</span>, <span class=\"number\">500</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z1 = F1([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z2 = F2([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z3 = F3([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a new figure and set its size</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">15</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"><span class=\"comment\"># white background</span></span><br><span class=\"line\">fig.patch.set_facecolor(<span class=\"string\">'white'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the functions in 3D subplots</span></span><br><span class=\"line\">ax1 = fig.add_subplot(<span class=\"number\">131</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax1.plot_surface(X, Y, Z1, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot projection on xy plane</span></span><br><span class=\"line\">ax1.contour(X, Y, Z1, zdir=<span class=\"string\">'z'</span>, offset=-<span class=\"number\">900</span>, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'F1'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax2 = fig.add_subplot(<span class=\"number\">132</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax2.plot_surface(X, Y, Z2, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot projection on xy plane</span></span><br><span class=\"line\">ax2.contour(X, Y, Z2, zdir=<span class=\"string\">'z'</span>, offset=<span class=\"number\">0</span>, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'F2'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax3 = fig.add_subplot(<span class=\"number\">133</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax3.plot_surface(X, Y, Z3, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot projection on xy plane</span></span><br><span class=\"line\">ax3.contour(X, Y, Z3, zdir=<span class=\"string\">'z'</span>, offset=<span class=\"number\">0</span>, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\">ax3.set_title(<span class=\"string\">'F3'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add x-, y-, and z-labels to all subplots, grid off, axis off</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ax <span class=\"keyword\">in</span> fig.axes:</span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">    ax.set_zlabel(<span class=\"string\">'z'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Adjust the spacing between subplots to avoid overlap</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"3d_functions.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># Show the figure</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"3d_functions\" data-src=\"/2023/03/28/Functions-Plot/3d_functions.png\"></p>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/03/Functions/","2023/03/27/Basic-operations-of-Matrix/","2023/03/27/Linear-Algebra-Basics/","2023/03/29/From-linear-regression-to-binary-classification/","2023/04/03/Scipy-optimization/"],"length":588,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Line-and-curves\"><a href=\"#Line-and-curves\" class=\"headerlink\" title=\"Line and curves\"></a>Line and curves</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 10:19</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the x-values for the functions</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the functions</span></span><br><span class=\"line\">y1 = x                   <span class=\"comment\"># Straight line</span></span><br><span class=\"line\">y2 = x**<span class=\"number\">2</span>                <span class=\"comment\"># Quadratic curve</span></span><br><span class=\"line\">y3 = np.sin(x)           <span class=\"comment\"># Sine wave</span></span><br><span class=\"line\">y4 = np.exp(-x**<span class=\"number\">2</span>)       <span class=\"comment\"># Gaussian curve</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a new figure and set its size</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the functions in separate subplots</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)     <span class=\"comment\"># Create a subplot for the straight line</span></span><br><span class=\"line\">plt.plot(x, y1)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Straight line'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)     <span class=\"comment\"># Create a subplot for the quadratic curve</span></span><br><span class=\"line\">plt.plot(x, y2)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Quadratic curve'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)     <span class=\"comment\"># Create a subplot for the sine wave</span></span><br><span class=\"line\">plt.plot(x, y3)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Sine wave'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)     <span class=\"comment\"># Create a subplot for the Gaussian curve</span></span><br><span class=\"line\">plt.plot(x, y4)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Gaussian curve'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add x- and y-labels for all subplots</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ax <span class=\"keyword\">in</span> plt.gcf().axes:</span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Adjust the spacing between subplots to avoid overlap</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"2d_functions.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># Show the figure</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"2d_functions\" data-src=\"/2023/03/28/Functions-Plot/2d_functions.png\"></p>\n<h3 id=\"3D-view-of-2D-functions\"><a href=\"#3D-view-of-2D-functions\" class=\"headerlink\" title=\"3D view of 2D functions\"></a>3D view of 2D functions</h3><p>$F<em>1(x) = -\\sum\\limits</em>{i=1}^n x_i \\sin(\\sqrt{|x_i|})$</p>\n<p>$F<em>2(x) = \\sum\\limits</em>{i=1}^n \\left(x_i^2 - 10 \\cos(2\\pi x_i) + 10\\right)$</p>\n<p>$F<em>3(x) = \\left(-20 \\exp\\left(-0.2 \\sqrt{\\frac{1}{n} \\sum\\limits</em>{i=1}^n x<em>i^2}\\right) - \\exp\\left(\\frac{1}{n} \\sum\\limits</em>{i=1}^n \\cos(2\\pi x_i)\\right) + 20 + e\\right)$</p>\n<p>Note that in these formulas, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.294ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 572 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g></g></g></svg></mjx-container> represents a vector of length <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">F1</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    result = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x:</span><br><span class=\"line\">        k = (-<span class=\"number\">1</span>) * i * np.sin(np.sqrt(np.<span class=\"built_in\">abs</span>(i)))</span><br><span class=\"line\">        result.append(k)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">F2</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    result = [np.power(i, <span class=\"number\">2</span>) - (<span class=\"number\">10</span> * np.cos(<span class=\"number\">2</span> * np.pi * i)) + <span class=\"number\">10</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">F3</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    dim = <span class=\"built_in\">len</span>(x)</span><br><span class=\"line\">    part1 = <span class=\"built_in\">sum</span>([np.power(i, <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x])</span><br><span class=\"line\">    part2 = <span class=\"built_in\">sum</span>([np.cos(<span class=\"number\">2</span> * np.pi * i) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x])</span><br><span class=\"line\">    result = (-<span class=\"number\">20</span>) * np.exp(-<span class=\"number\">0.2</span> * np.sqrt((<span class=\"number\">1</span> / dim) * part1)) + (-np.exp((<span class=\"number\">1</span> / dim) * part2) + <span class=\"number\">20</span> + np.e)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a meshgrid of x and y values</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">500</span>, <span class=\"number\">500</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">500</span>, <span class=\"number\">500</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z1 = F1([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z2 = F2([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">100</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z3 = F3([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a new figure and set its size</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">15</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"><span class=\"comment\"># white background</span></span><br><span class=\"line\">fig.patch.set_facecolor(<span class=\"string\">'white'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the functions in 3D subplots</span></span><br><span class=\"line\">ax1 = fig.add_subplot(<span class=\"number\">131</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax1.plot_surface(X, Y, Z1, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot projection on xy plane</span></span><br><span class=\"line\">ax1.contour(X, Y, Z1, zdir=<span class=\"string\">'z'</span>, offset=-<span class=\"number\">900</span>, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'F1'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax2 = fig.add_subplot(<span class=\"number\">132</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax2.plot_surface(X, Y, Z2, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot projection on xy plane</span></span><br><span class=\"line\">ax2.contour(X, Y, Z2, zdir=<span class=\"string\">'z'</span>, offset=<span class=\"number\">0</span>, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'F2'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax3 = fig.add_subplot(<span class=\"number\">133</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax3.plot_surface(X, Y, Z3, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># plot projection on xy plane</span></span><br><span class=\"line\">ax3.contour(X, Y, Z3, zdir=<span class=\"string\">'z'</span>, offset=<span class=\"number\">0</span>, cmap=<span class=\"string\">\"coolwarm\"</span>)</span><br><span class=\"line\">ax3.set_title(<span class=\"string\">'F3'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add x-, y-, and z-labels to all subplots, grid off, axis off</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ax <span class=\"keyword\">in</span> fig.axes:</span><br><span class=\"line\">    ax.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">    ax.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">    ax.set_zlabel(<span class=\"string\">'z'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Adjust the spacing between subplots to avoid overlap</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"3d_functions.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># Show the figure</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"3d_functions\" data-src=\"/2023/03/28/Functions-Plot/3d_functions.png\"></p>\n</body></html>"},{"mathjax":true,"title":"Functions","date":"2023-04-03T15:44:27.000Z","_content":"\n### One to one functions\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:46\n\nimport matplotlib.pyplot as plt\n\n# define a one-to-one function\ndef one_to_one(x):\n    return x\n\n# define a not one-to-one function\ndef not_one_to_one(x):\n    return x ** 2\n\n\n# create input values\nx_values = list(range(-5, 6))\n\n# apply functions to input values\ny_values_one_to_one = [one_to_one(x) for x in x_values]\ny_values_not_one_to_one = [not_one_to_one(x) for x in x_values]\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\n# plot one-to-one function\naxs[0].plot(x_values, y_values_one_to_one)\naxs[0].set_title('One-to-one Function')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\n\n# plot not one-to-one function\naxs[1].plot(x_values, y_values_not_one_to_one)\naxs[1].set_title('Not One-to-one Function')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('y')\n\n# adjust layout\nplt.tight_layout()\n\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\">\n    <img src=\"Functions/One-to-one%20Function.png\" alt=\"One-to-one Function\" style=\"zoom:33%;\" />\n</div>\n\n### Increasing and decreasing\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:51\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# define the function f(x) = x^2\ndef f(x):\n    return x ** 2\n\n# define the derivative of f(x) = x^2\ndef df(x):\n    return 2 * x\n\n# create input values\nx_values = np.linspace(-5, 5, 1000)\n\n# apply function to input values\ny_values = f(x_values)\n\n# create subplots\nfig, axs = plt.subplots(nrows=2, ncols=1)\n\n# plot function\naxs[0].plot(x_values, y_values)\naxs[0].set_title('Function f(x) = x^2')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\naxs[0].fill_between(x_values, y_values, where=x_values>=0, color='green', alpha=0.2)\naxs[0].fill_between(x_values, y_values, where=x_values<=0, color='red', alpha=0.2)\n\n# plot derivative\ny_values_derivative = df(x_values)\naxs[1].plot(x_values, y_values_derivative)\naxs[1].set_title('Derivative of f(x) = x^2')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('dy/dx')\n\n# plot horizontal line at y=0\naxs[1].axhline(y=0, color='gray', linestyle='--')\n\n# shade the increasing and decreasing regions\naxs[1].fill_between(x_values, y_values_derivative, where=y_values_derivative>=0, color='green', alpha=0.2)\naxs[1].fill_between(x_values, y_values_derivative, where=y_values_derivative<=0, color='red', alpha=0.2)\n# derivative is positive : increasing, color = 'green'\n# derivative is negative : decreasing ,color = 'red'\naxs[1].text(0, 0, 'Increasing', color='green', fontsize=12,horizontalalignment='left', verticalalignment='top')\naxs[1].text(0, 0, 'Decreasing', color='red', fontsize=12,horizontalalignment='right', verticalalignment='bottom')\n\n# adjust layout\nplt.tight_layout()\n\nplt.savefig('Function f(x) = x^2.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\">   <img src=\"Functions/Function%20f(x)%20=%20x%5E2.png\" alt=\"Function f(x) = x^2\" style=\"zoom:33%;\" /></div>\n\n### Old and Even functions\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:04\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# define an even function\ndef even(x):\n    return x ** 2\n\n# define an odd function\ndef odd(x):\n    return x ** 3\n\n# create input values\nx_values = np.linspace(-5, 5, 100)\n\n# apply functions to input values\ny_values_even = [even(x) for x in x_values]\ny_values_odd = [odd(x) for x in x_values]\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\n# plot even function\naxs[0].plot(x_values, y_values_even)\naxs[0].set_title('Even Function')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\n\n# plot odd function\naxs[1].plot(x_values, y_values_odd)\naxs[1].set_title('Odd Function')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('y')\n\n# adjust layout\nplt.tight_layout()\n\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\">  <img src=\"Functions/Even%20and%20old%20Function.png\" alt=\"Even and old Function\" style=\"zoom:30%;\" /> </div>\n\n### Convex and concave\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:13\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# define function\ndef f(x):\n    return 3 * x ** 3 - 9 * x\n\n\n# define derivative function\ndef df(x):\n    return 9 * x ** 2 - 9\n\n\n# define second derivative function\ndef ddf(x):\n    return 18 * x\n\n\n# create x values\nx_values = np.linspace(-2, 2, 1000)\n\n# plot function\nplt.plot(x_values, f(x_values), label='f(x)')\nplt.plot(x_values, df(x_values), label='f\\'(x)')\nplt.plot(x_values, ddf(x_values), label='f\\'\\'(x)')\n\n# plot tangent lines\nfor x0 in [-1, 0, 1]:\n    m = df(x0)\n    y0 = f(x0)\n    y1 = y0 + m * (x_values - x0)\n    plt.plot(x_values, y1, 'r--', linewidth=1)\n\n# plot max and min points\nplt.plot([-1, 1], [f(-1), f(1)], 'ro', label='max/min')\n\n# plot inflection point\nplt.plot([0], [0], 'go', label='inflection point')\n\n# annotate points\nplt.annotate('Max', xy=(-1, f(-1)), xytext=(-1, f(-1) + 3), ha='center',\n             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\nplt.annotate('Min', xy=(1, f(1)), xytext=(1, f(1) + 3), ha='center',\n             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\nplt.annotate('Inflection Point', xy=(0, 0), xytext=(0.5, 20), ha='center',\n             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n# concave, point to max\nplt.annotate('Concave', xy=(-1, f(-1)), xytext=(-1, f(-1) - 3), ha='center',\n                arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n# convex, point to min\nplt.annotate('Convex', xy=(1, f(1)), xytext=(1, f(1) - 3), ha='center',\n                arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n\n# add legend\nplt.legend()\n\n# set axis labels\nplt.xlabel('x')\nplt.ylabel('f(x)')\n\n# show plot\nplt.savefig('convexity.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\">  <img src=\"Functions/convexity.png\" alt=\"convexity\" style=\"zoom:67%;\" /> </div>\n\n### Exponential and logarithmic\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:42\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# define an exponential function\ndef exponential_function(x, a=1, b=1):\n    return a * np.exp(b * x)\n\n\n# define a logarithmic function\ndef logarithmic_function(x, a=1, b=1):\n    return a * np.log(b * x)\n\n\n# create input values\nx_values = np.linspace(0.1, 100, 100)\n\n# apply functions to input values\ny_values_exponential = exponential_function(x_values, a=1, b=1)\ny_values_logarithmic = logarithmic_function(x_values, a=1, b=2)\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\n# plot exponential function\naxs[0].plot(x_values, y_values_exponential)\naxs[0].set_title('Exponential Function')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\n\n# plot logarithmic function\naxs[1].plot(x_values, y_values_logarithmic)\naxs[1].set_title('Logarithmic Function')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('y')\n\n# adjust layout\nplt.tight_layout()\nplt.savefig('exponential_logarithmic.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\"> <img src=\"Functions/exponential_logarithmic.png\" alt=\"exponential_logarithmic\" style=\"zoom:50%;\" /> </div>\n\n### Floor function and ceiling function\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:47\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# define floor function\ndef floor(x):\n    return np.floor(x)\n\n\n# define ceiling function\ndef ceiling(x):\n    return np.ceil(x)\n\n\n# create input values\nx_values = np.linspace(-10, 10, 100)\n\n# apply functions to input values\ny_values_floor = floor(x_values)\ny_values_ceiling = ceiling(x_values)\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=1)\n\n# plot original values\naxs.plot(x_values, x_values, label='Original')\n\n# plot floor function\naxs.plot(x_values, y_values_floor, label='Floor')\n\n# plot ceiling function\naxs.plot(x_values, y_values_ceiling, label='Ceiling')\n\n# set title, labels, and legend\naxs.set_title('Floor and Ceiling Functions')\naxs.set_xlabel('x')\naxs.set_ylabel('y')\naxs.legend()\n\n# show plot\nplt.savefig('floor_ceiling.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\"><img src=\"Functions/floor_ceiling.png\" alt=\"floor_ceiling\" style=\"zoom:67%;\" /></div>\n\n### Reference\n\n1. Blitzstein, J. K., & Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Functions.md","raw":"---\nmathjax: true\ntitle: Functions\ndate: 2023-04-03 15:44:27\ntags:\n  - Functions\n  - Math\n  - Probability\n  - Python\n  - Basics\n---\n\n### One to one functions\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:46\n\nimport matplotlib.pyplot as plt\n\n# define a one-to-one function\ndef one_to_one(x):\n    return x\n\n# define a not one-to-one function\ndef not_one_to_one(x):\n    return x ** 2\n\n\n# create input values\nx_values = list(range(-5, 6))\n\n# apply functions to input values\ny_values_one_to_one = [one_to_one(x) for x in x_values]\ny_values_not_one_to_one = [not_one_to_one(x) for x in x_values]\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\n# plot one-to-one function\naxs[0].plot(x_values, y_values_one_to_one)\naxs[0].set_title('One-to-one Function')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\n\n# plot not one-to-one function\naxs[1].plot(x_values, y_values_not_one_to_one)\naxs[1].set_title('Not One-to-one Function')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('y')\n\n# adjust layout\nplt.tight_layout()\n\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\">\n    <img src=\"Functions/One-to-one%20Function.png\" alt=\"One-to-one Function\" style=\"zoom:33%;\" />\n</div>\n\n### Increasing and decreasing\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:51\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# define the function f(x) = x^2\ndef f(x):\n    return x ** 2\n\n# define the derivative of f(x) = x^2\ndef df(x):\n    return 2 * x\n\n# create input values\nx_values = np.linspace(-5, 5, 1000)\n\n# apply function to input values\ny_values = f(x_values)\n\n# create subplots\nfig, axs = plt.subplots(nrows=2, ncols=1)\n\n# plot function\naxs[0].plot(x_values, y_values)\naxs[0].set_title('Function f(x) = x^2')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\naxs[0].fill_between(x_values, y_values, where=x_values>=0, color='green', alpha=0.2)\naxs[0].fill_between(x_values, y_values, where=x_values<=0, color='red', alpha=0.2)\n\n# plot derivative\ny_values_derivative = df(x_values)\naxs[1].plot(x_values, y_values_derivative)\naxs[1].set_title('Derivative of f(x) = x^2')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('dy/dx')\n\n# plot horizontal line at y=0\naxs[1].axhline(y=0, color='gray', linestyle='--')\n\n# shade the increasing and decreasing regions\naxs[1].fill_between(x_values, y_values_derivative, where=y_values_derivative>=0, color='green', alpha=0.2)\naxs[1].fill_between(x_values, y_values_derivative, where=y_values_derivative<=0, color='red', alpha=0.2)\n# derivative is positive : increasing, color = 'green'\n# derivative is negative : decreasing ,color = 'red'\naxs[1].text(0, 0, 'Increasing', color='green', fontsize=12,horizontalalignment='left', verticalalignment='top')\naxs[1].text(0, 0, 'Decreasing', color='red', fontsize=12,horizontalalignment='right', verticalalignment='bottom')\n\n# adjust layout\nplt.tight_layout()\n\nplt.savefig('Function f(x) = x^2.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\">   <img src=\"Functions/Function%20f(x)%20=%20x%5E2.png\" alt=\"Function f(x) = x^2\" style=\"zoom:33%;\" /></div>\n\n### Old and Even functions\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:04\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# define an even function\ndef even(x):\n    return x ** 2\n\n# define an odd function\ndef odd(x):\n    return x ** 3\n\n# create input values\nx_values = np.linspace(-5, 5, 100)\n\n# apply functions to input values\ny_values_even = [even(x) for x in x_values]\ny_values_odd = [odd(x) for x in x_values]\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\n# plot even function\naxs[0].plot(x_values, y_values_even)\naxs[0].set_title('Even Function')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\n\n# plot odd function\naxs[1].plot(x_values, y_values_odd)\naxs[1].set_title('Odd Function')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('y')\n\n# adjust layout\nplt.tight_layout()\n\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\">  <img src=\"Functions/Even%20and%20old%20Function.png\" alt=\"Even and old Function\" style=\"zoom:30%;\" /> </div>\n\n### Convex and concave\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:13\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# define function\ndef f(x):\n    return 3 * x ** 3 - 9 * x\n\n\n# define derivative function\ndef df(x):\n    return 9 * x ** 2 - 9\n\n\n# define second derivative function\ndef ddf(x):\n    return 18 * x\n\n\n# create x values\nx_values = np.linspace(-2, 2, 1000)\n\n# plot function\nplt.plot(x_values, f(x_values), label='f(x)')\nplt.plot(x_values, df(x_values), label='f\\'(x)')\nplt.plot(x_values, ddf(x_values), label='f\\'\\'(x)')\n\n# plot tangent lines\nfor x0 in [-1, 0, 1]:\n    m = df(x0)\n    y0 = f(x0)\n    y1 = y0 + m * (x_values - x0)\n    plt.plot(x_values, y1, 'r--', linewidth=1)\n\n# plot max and min points\nplt.plot([-1, 1], [f(-1), f(1)], 'ro', label='max/min')\n\n# plot inflection point\nplt.plot([0], [0], 'go', label='inflection point')\n\n# annotate points\nplt.annotate('Max', xy=(-1, f(-1)), xytext=(-1, f(-1) + 3), ha='center',\n             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\nplt.annotate('Min', xy=(1, f(1)), xytext=(1, f(1) + 3), ha='center',\n             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\nplt.annotate('Inflection Point', xy=(0, 0), xytext=(0.5, 20), ha='center',\n             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n# concave, point to max\nplt.annotate('Concave', xy=(-1, f(-1)), xytext=(-1, f(-1) - 3), ha='center',\n                arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n# convex, point to min\nplt.annotate('Convex', xy=(1, f(1)), xytext=(1, f(1) - 3), ha='center',\n                arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n\n# add legend\nplt.legend()\n\n# set axis labels\nplt.xlabel('x')\nplt.ylabel('f(x)')\n\n# show plot\nplt.savefig('convexity.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\">  <img src=\"Functions/convexity.png\" alt=\"convexity\" style=\"zoom:67%;\" /> </div>\n\n### Exponential and logarithmic\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:42\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# define an exponential function\ndef exponential_function(x, a=1, b=1):\n    return a * np.exp(b * x)\n\n\n# define a logarithmic function\ndef logarithmic_function(x, a=1, b=1):\n    return a * np.log(b * x)\n\n\n# create input values\nx_values = np.linspace(0.1, 100, 100)\n\n# apply functions to input values\ny_values_exponential = exponential_function(x_values, a=1, b=1)\ny_values_logarithmic = logarithmic_function(x_values, a=1, b=2)\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=2)\n\n# plot exponential function\naxs[0].plot(x_values, y_values_exponential)\naxs[0].set_title('Exponential Function')\naxs[0].set_xlabel('x')\naxs[0].set_ylabel('y')\n\n# plot logarithmic function\naxs[1].plot(x_values, y_values_logarithmic)\naxs[1].set_title('Logarithmic Function')\naxs[1].set_xlabel('x')\naxs[1].set_ylabel('y')\n\n# adjust layout\nplt.tight_layout()\nplt.savefig('exponential_logarithmic.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n# show plots\nplt.show()\n```\n\n<div style=\"text-align:center\"> <img src=\"Functions/exponential_logarithmic.png\" alt=\"exponential_logarithmic\" style=\"zoom:50%;\" /> </div>\n\n### Floor function and ceiling function\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 18:47\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# define floor function\ndef floor(x):\n    return np.floor(x)\n\n\n# define ceiling function\ndef ceiling(x):\n    return np.ceil(x)\n\n\n# create input values\nx_values = np.linspace(-10, 10, 100)\n\n# apply functions to input values\ny_values_floor = floor(x_values)\ny_values_ceiling = ceiling(x_values)\n\n# create subplots\nfig, axs = plt.subplots(nrows=1, ncols=1)\n\n# plot original values\naxs.plot(x_values, x_values, label='Original')\n\n# plot floor function\naxs.plot(x_values, y_values_floor, label='Floor')\n\n# plot ceiling function\naxs.plot(x_values, y_values_ceiling, label='Ceiling')\n\n# set title, labels, and legend\naxs.set_title('Floor and Ceiling Functions')\naxs.set_xlabel('x')\naxs.set_ylabel('y')\naxs.legend()\n\n# show plot\nplt.savefig('floor_ceiling.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\"><img src=\"Functions/floor_ceiling.png\" alt=\"floor_ceiling\" style=\"zoom:67%;\" /></div>\n\n### Reference\n\n1. Blitzstein, J. K., & Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Functions","published":1,"updated":"2023-04-07T02:43:50.496Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gp000cozpi985p6hki","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"One-to-one-functions\"><a href=\"#One-to-one-functions\" class=\"headerlink\" title=\"One to one functions\"></a>One to one functions</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:46</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define a one-to-one function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">one_to_one</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define a not one-to-one function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">not_one_to_one</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(-<span class=\"number\">5</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_one_to_one = [one_to_one(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\">y_values_not_one_to_one = [not_one_to_one(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot one-to-one function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values_one_to_one)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'One-to-one Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot not one-to-one function</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_not_one_to_one)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Not One-to-one Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">\n    <img alt=\"One-to-one Function\" style=\"zoom:33%;\" data-src=\"/2023/04/03/Functions/One-to-one%20Function.png\">\n</div>\n\n<h3 id=\"Increasing-and-decreasing\"><a href=\"#Increasing-and-decreasing\" class=\"headerlink\" title=\"Increasing and decreasing\"></a>Increasing and decreasing</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:51</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define the function f(x) = x^2</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define the derivative of f(x) = x^2</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">df</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">2</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply function to input values</span></span><br><span class=\"line\">y_values = f(x_values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">2</span>, ncols=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Function f(x) = x^2'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].fill_between(x_values, y_values, where=x_values&gt;=<span class=\"number\">0</span>, color=<span class=\"string\">'green'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].fill_between(x_values, y_values, where=x_values&lt;=<span class=\"number\">0</span>, color=<span class=\"string\">'red'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot derivative</span></span><br><span class=\"line\">y_values_derivative = df(x_values)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_derivative)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Derivative of f(x) = x^2'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'dy/dx'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot horizontal line at y=0</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].axhline(y=<span class=\"number\">0</span>, color=<span class=\"string\">'gray'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># shade the increasing and decreasing regions</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].fill_between(x_values, y_values_derivative, where=y_values_derivative&gt;=<span class=\"number\">0</span>, color=<span class=\"string\">'green'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].fill_between(x_values, y_values_derivative, where=y_values_derivative&lt;=<span class=\"number\">0</span>, color=<span class=\"string\">'red'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\"><span class=\"comment\"># derivative is positive : increasing, color = 'green'</span></span><br><span class=\"line\"><span class=\"comment\"># derivative is negative : decreasing ,color = 'red'</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].text(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"string\">'Increasing'</span>, color=<span class=\"string\">'green'</span>, fontsize=<span class=\"number\">12</span>,horizontalalignment=<span class=\"string\">'left'</span>, verticalalignment=<span class=\"string\">'top'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].text(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"string\">'Decreasing'</span>, color=<span class=\"string\">'red'</span>, fontsize=<span class=\"number\">12</span>,horizontalalignment=<span class=\"string\">'right'</span>, verticalalignment=<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Function f(x) = x^2.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">   <img alt=\"Function f(x) = x^2\" style=\"zoom:33%;\" data-src=\"/2023/04/03/Functions/Function%20f(x)%20=%20x%5E2.png\"></div>\n\n<h3 id=\"Old-and-Even-functions\"><a href=\"#Old-and-Even-functions\" class=\"headerlink\" title=\"Old and Even functions\"></a>Old and Even functions</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:04</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define an even function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">even</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define an odd function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">odd</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_even = [even(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\">y_values_odd = [odd(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot even function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values_even)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Even Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot odd function</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_odd)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Odd Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">  <img alt=\"Even and old Function\" style=\"zoom:30%;\" data-src=\"/2023/04/03/Functions/Even%20and%20old%20Function.png\"> </div>\n\n<h3 id=\"Convex-and-concave\"><a href=\"#Convex-and-concave\" class=\"headerlink\" title=\"Convex and concave\"></a>Convex and concave</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:13</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">3</span> * x ** <span class=\"number\">3</span> - <span class=\"number\">9</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define derivative function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">df</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">9</span> * x ** <span class=\"number\">2</span> - <span class=\"number\">9</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define second derivative function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">ddf</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">18</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create x values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot function</span></span><br><span class=\"line\">plt.plot(x_values, f(x_values), label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">plt.plot(x_values, df(x_values), label=<span class=\"string\">'f\\'(x)'</span>)</span><br><span class=\"line\">plt.plot(x_values, ddf(x_values), label=<span class=\"string\">'f\\'\\'(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot tangent lines</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> x0 <span class=\"keyword\">in</span> [-<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>]:</span><br><span class=\"line\">    m = df(x0)</span><br><span class=\"line\">    y0 = f(x0)</span><br><span class=\"line\">    y1 = y0 + m * (x_values - x0)</span><br><span class=\"line\">    plt.plot(x_values, y1, <span class=\"string\">'r--'</span>, linewidth=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot max and min points</span></span><br><span class=\"line\">plt.plot([-<span class=\"number\">1</span>, <span class=\"number\">1</span>], [f(-<span class=\"number\">1</span>), f(<span class=\"number\">1</span>)], <span class=\"string\">'ro'</span>, label=<span class=\"string\">'max/min'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot inflection point</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>], [<span class=\"number\">0</span>], <span class=\"string\">'go'</span>, label=<span class=\"string\">'inflection point'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># annotate points</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Max'</span>, xy=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>)), xytext=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>) + <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">             arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Min'</span>, xy=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>)), xytext=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>) + <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">             arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Inflection Point'</span>, xy=(<span class=\"number\">0</span>, <span class=\"number\">0</span>), xytext=(<span class=\"number\">0.5</span>, <span class=\"number\">20</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">             arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\"><span class=\"comment\"># concave, point to max</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Concave'</span>, xy=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>)), xytext=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>) - <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">                arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\"><span class=\"comment\"># convex, point to min</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Convex'</span>, xy=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>)), xytext=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>) - <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">                arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># add legend</span></span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set axis labels</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'convexity.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">  <img alt=\"convexity\" style=\"zoom:67%;\" data-src=\"/2023/04/03/Functions/convexity.png\"> </div>\n\n<h3 id=\"Exponential-and-logarithmic\"><a href=\"#Exponential-and-logarithmic\" class=\"headerlink\" title=\"Exponential and logarithmic\"></a>Exponential and logarithmic</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:42</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define an exponential function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">exponential_function</span>(<span class=\"params\">x, a=<span class=\"number\">1</span>, b=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> a * np.exp(b * x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define a logarithmic function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">logarithmic_function</span>(<span class=\"params\">x, a=<span class=\"number\">1</span>, b=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> a * np.log(b * x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(<span class=\"number\">0.1</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_exponential = exponential_function(x_values, a=<span class=\"number\">1</span>, b=<span class=\"number\">1</span>)</span><br><span class=\"line\">y_values_logarithmic = logarithmic_function(x_values, a=<span class=\"number\">1</span>, b=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot exponential function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values_exponential)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Exponential Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot logarithmic function</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_logarithmic)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Logarithmic Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'exponential_logarithmic.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"> <img alt=\"exponential_logarithmic\" style=\"zoom:50%;\" data-src=\"/2023/04/03/Functions/exponential_logarithmic.png\"> </div>\n\n<h3 id=\"Floor-function-and-ceiling-function\"><a href=\"#Floor-function-and-ceiling-function\" class=\"headerlink\" title=\"Floor function and ceiling function\"></a>Floor function and ceiling function</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:47</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define floor function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">floor</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.floor(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define ceiling function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">ceiling</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.ceil(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">10</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_floor = floor(x_values)</span><br><span class=\"line\">y_values_ceiling = ceiling(x_values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot original values</span></span><br><span class=\"line\">axs.plot(x_values, x_values, label=<span class=\"string\">'Original'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot floor function</span></span><br><span class=\"line\">axs.plot(x_values, y_values_floor, label=<span class=\"string\">'Floor'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot ceiling function</span></span><br><span class=\"line\">axs.plot(x_values, y_values_ceiling, label=<span class=\"string\">'Ceiling'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set title, labels, and legend</span></span><br><span class=\"line\">axs.set_title(<span class=\"string\">'Floor and Ceiling Functions'</span>)</span><br><span class=\"line\">axs.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">axs.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'floor_ceiling.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"><img alt=\"floor_ceiling\" style=\"zoom:67%;\" data-src=\"/2023/04/03/Functions/floor_ceiling.png\"></div>\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Blitzstein, J. K., &amp; Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.</li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/28/Functions-Plot/","2023/04/03/Relationships-between-two-Sets/","2023/04/03/Scipy-optimization/","2023/03/27/Variables/"],"length":1184,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"One-to-one-functions\"><a href=\"#One-to-one-functions\" class=\"headerlink\" title=\"One to one functions\"></a>One to one functions</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:46</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define a one-to-one function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">one_to_one</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define a not one-to-one function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">not_one_to_one</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = <span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(-<span class=\"number\">5</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_one_to_one = [one_to_one(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\">y_values_not_one_to_one = [not_one_to_one(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot one-to-one function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values_one_to_one)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'One-to-one Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot not one-to-one function</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_not_one_to_one)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Not One-to-one Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">\n    <img alt=\"One-to-one Function\" style=\"zoom:33%;\" data-src=\"/2023/04/03/Functions/One-to-one%20Function.png\">\n</div>\n\n<h3 id=\"Increasing-and-decreasing\"><a href=\"#Increasing-and-decreasing\" class=\"headerlink\" title=\"Increasing and decreasing\"></a>Increasing and decreasing</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:51</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define the function f(x) = x^2</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define the derivative of f(x) = x^2</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">df</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">2</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply function to input values</span></span><br><span class=\"line\">y_values = f(x_values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">2</span>, ncols=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Function f(x) = x^2'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].fill_between(x_values, y_values, where=x_values&gt;=<span class=\"number\">0</span>, color=<span class=\"string\">'green'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].fill_between(x_values, y_values, where=x_values&lt;=<span class=\"number\">0</span>, color=<span class=\"string\">'red'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot derivative</span></span><br><span class=\"line\">y_values_derivative = df(x_values)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_derivative)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Derivative of f(x) = x^2'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'dy/dx'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot horizontal line at y=0</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].axhline(y=<span class=\"number\">0</span>, color=<span class=\"string\">'gray'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># shade the increasing and decreasing regions</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].fill_between(x_values, y_values_derivative, where=y_values_derivative&gt;=<span class=\"number\">0</span>, color=<span class=\"string\">'green'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].fill_between(x_values, y_values_derivative, where=y_values_derivative&lt;=<span class=\"number\">0</span>, color=<span class=\"string\">'red'</span>, alpha=<span class=\"number\">0.2</span>)</span><br><span class=\"line\"><span class=\"comment\"># derivative is positive : increasing, color = 'green'</span></span><br><span class=\"line\"><span class=\"comment\"># derivative is negative : decreasing ,color = 'red'</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].text(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"string\">'Increasing'</span>, color=<span class=\"string\">'green'</span>, fontsize=<span class=\"number\">12</span>,horizontalalignment=<span class=\"string\">'left'</span>, verticalalignment=<span class=\"string\">'top'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].text(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"string\">'Decreasing'</span>, color=<span class=\"string\">'red'</span>, fontsize=<span class=\"number\">12</span>,horizontalalignment=<span class=\"string\">'right'</span>, verticalalignment=<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Function f(x) = x^2.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">   <img alt=\"Function f(x) = x^2\" style=\"zoom:33%;\" data-src=\"/2023/04/03/Functions/Function%20f(x)%20=%20x%5E2.png\"></div>\n\n<h3 id=\"Old-and-Even-functions\"><a href=\"#Old-and-Even-functions\" class=\"headerlink\" title=\"Old and Even functions\"></a>Old and Even functions</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:04</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define an even function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">even</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define an odd function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">odd</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x ** <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_even = [even(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\">y_values_odd = [odd(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> x_values]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot even function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values_even)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Even Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot odd function</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_odd)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Odd Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">  <img alt=\"Even and old Function\" style=\"zoom:30%;\" data-src=\"/2023/04/03/Functions/Even%20and%20old%20Function.png\"> </div>\n\n<h3 id=\"Convex-and-concave\"><a href=\"#Convex-and-concave\" class=\"headerlink\" title=\"Convex and concave\"></a>Convex and concave</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:13</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">3</span> * x ** <span class=\"number\">3</span> - <span class=\"number\">9</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define derivative function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">df</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">9</span> * x ** <span class=\"number\">2</span> - <span class=\"number\">9</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define second derivative function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">ddf</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">18</span> * x</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create x values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot function</span></span><br><span class=\"line\">plt.plot(x_values, f(x_values), label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">plt.plot(x_values, df(x_values), label=<span class=\"string\">'f\\'(x)'</span>)</span><br><span class=\"line\">plt.plot(x_values, ddf(x_values), label=<span class=\"string\">'f\\'\\'(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot tangent lines</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> x0 <span class=\"keyword\">in</span> [-<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>]:</span><br><span class=\"line\">    m = df(x0)</span><br><span class=\"line\">    y0 = f(x0)</span><br><span class=\"line\">    y1 = y0 + m * (x_values - x0)</span><br><span class=\"line\">    plt.plot(x_values, y1, <span class=\"string\">'r--'</span>, linewidth=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot max and min points</span></span><br><span class=\"line\">plt.plot([-<span class=\"number\">1</span>, <span class=\"number\">1</span>], [f(-<span class=\"number\">1</span>), f(<span class=\"number\">1</span>)], <span class=\"string\">'ro'</span>, label=<span class=\"string\">'max/min'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot inflection point</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>], [<span class=\"number\">0</span>], <span class=\"string\">'go'</span>, label=<span class=\"string\">'inflection point'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># annotate points</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Max'</span>, xy=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>)), xytext=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>) + <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">             arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Min'</span>, xy=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>)), xytext=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>) + <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">             arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Inflection Point'</span>, xy=(<span class=\"number\">0</span>, <span class=\"number\">0</span>), xytext=(<span class=\"number\">0.5</span>, <span class=\"number\">20</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">             arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\"><span class=\"comment\"># concave, point to max</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Concave'</span>, xy=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>)), xytext=(-<span class=\"number\">1</span>, f(-<span class=\"number\">1</span>) - <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">                arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\"><span class=\"comment\"># convex, point to min</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">'Convex'</span>, xy=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>)), xytext=(<span class=\"number\">1</span>, f(<span class=\"number\">1</span>) - <span class=\"number\">3</span>), ha=<span class=\"string\">'center'</span>,</span><br><span class=\"line\">                arrowprops=<span class=\"built_in\">dict</span>(facecolor=<span class=\"string\">'black'</span>, arrowstyle=<span class=\"string\">\"-&gt;\"</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># add legend</span></span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set axis labels</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'convexity.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">  <img alt=\"convexity\" style=\"zoom:67%;\" data-src=\"/2023/04/03/Functions/convexity.png\"> </div>\n\n<h3 id=\"Exponential-and-logarithmic\"><a href=\"#Exponential-and-logarithmic\" class=\"headerlink\" title=\"Exponential and logarithmic\"></a>Exponential and logarithmic</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:42</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define an exponential function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">exponential_function</span>(<span class=\"params\">x, a=<span class=\"number\">1</span>, b=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> a * np.exp(b * x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define a logarithmic function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">logarithmic_function</span>(<span class=\"params\">x, a=<span class=\"number\">1</span>, b=<span class=\"number\">1</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> a * np.log(b * x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(<span class=\"number\">0.1</span>, <span class=\"number\">100</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_exponential = exponential_function(x_values, a=<span class=\"number\">1</span>, b=<span class=\"number\">1</span>)</span><br><span class=\"line\">y_values_logarithmic = logarithmic_function(x_values, a=<span class=\"number\">1</span>, b=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot exponential function</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x_values, y_values_exponential)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Exponential Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot logarithmic function</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(x_values, y_values_logarithmic)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'Logarithmic Function'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'exponential_logarithmic.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"> <img alt=\"exponential_logarithmic\" style=\"zoom:50%;\" data-src=\"/2023/04/03/Functions/exponential_logarithmic.png\"> </div>\n\n<h3 id=\"Floor-function-and-ceiling-function\"><a href=\"#Floor-function-and-ceiling-function\" class=\"headerlink\" title=\"Floor function and ceiling function\"></a>Floor function and ceiling function</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 18:47</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define floor function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">floor</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.floor(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># define ceiling function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">ceiling</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.ceil(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create input values</span></span><br><span class=\"line\">x_values = np.linspace(-<span class=\"number\">10</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># apply functions to input values</span></span><br><span class=\"line\">y_values_floor = floor(x_values)</span><br><span class=\"line\">y_values_ceiling = ceiling(x_values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">1</span>, ncols=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot original values</span></span><br><span class=\"line\">axs.plot(x_values, x_values, label=<span class=\"string\">'Original'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot floor function</span></span><br><span class=\"line\">axs.plot(x_values, y_values_floor, label=<span class=\"string\">'Floor'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot ceiling function</span></span><br><span class=\"line\">axs.plot(x_values, y_values_ceiling, label=<span class=\"string\">'Ceiling'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set title, labels, and legend</span></span><br><span class=\"line\">axs.set_title(<span class=\"string\">'Floor and Ceiling Functions'</span>)</span><br><span class=\"line\">axs.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">axs.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">axs.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'floor_ceiling.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"><img alt=\"floor_ceiling\" style=\"zoom:67%;\" data-src=\"/2023/04/03/Functions/floor_ceiling.png\"></div>\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Blitzstein, J. K., &amp; Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.</li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Gradient descend for linear regression","date":"2023-03-28T20:09:58.000Z","_content":"\n### The importance of a loss function\n\nThe importance of a loss function in machine learning cannot be overstated. Whenever we try to solve a problem, there is always some expected outcome, and the actual outcome will inevitably have some degree of error. The goal of optimization is to minimize this error as much as possible.\n\nIn linear regression, we try to find a line that best fits a set of data points. However, no matter how many data points we have, there will always be some degree of error in the fit. \n\n**When we only have a single point in the space, there are countless lines that can pass through that point, making it impossible to determine the best fit line. When we have two points, there is only one line that can pass through both points, meaning that the best fit line is well-defined. However, when we have three or more points, and those points lie on a straight line, there will always be some degree of error in the fit, no matter how we attempt to fit the line to the points.**\n\nThis is because, in this case, any line we draw will either overestimate or underestimate the data points, leading to some degree of inaccuracy in the fit. Thus, the role of the loss function is to measure this uncertainty and provide feedback to the optimization algorithm to improve the fit of the model.\n\n### Loss function\n\nA loss function is a function used to measure the difference between an expected value and a predicted value, which is also known as the loss. In simple terms, the loss function quantifies the difference between the expected value and the actual (or predicted) value.\n\nThe role of the loss function is to measure the quality of the model's output by calculating the difference between the predicted output and the actual output. The goal of training a machine learning model is to minimize the loss function, which means finding the model parameters that result in the smallest possible loss.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 22:19\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 2* np.random.randn(5)\n\n# Fit a linear regression model to the data\nmodel = np.polyfit(x, y, 1)\npredicted = np.polyval(model, x)\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x, predicted, color='red', label='Predicted')\n\n# Highlight the difference between actual and predicted values\nfor i in range(len(x)):\n    plt.plot([x[i], x[i]], [y[i], predicted[i]], color='gray', linestyle='--')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression')\nplt.legend()\n\n# Display the plot\nplt.savefig('gradient.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient.png\" alt=\"gradient\" width=\"600\" height=\"400\" />\n</p>\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 22:25\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 1.5 * np.random.randn(5)\n\n# Fit a linear regression model to the data\nmodel = np.polyfit(x, y, 1)\npredicted = np.polyval(model, x)\n\n# Calculate the residuals\nresiduals = y - predicted\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x, predicted, color='red', label='Predicted')\n\n# Plot the orthogonal lines\nfor i in range(len(x)):\n    slope = -1 / model[0]\n    intercept = y[i] - slope * x[i]\n    intersection_x = (intercept - model[1]) / (model[0] - slope)\n    intersection_y = slope * intersection_x + intercept\n    plt.plot([x[i], intersection_x], [y[i], intersection_y], color='black', linestyle='--')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression')\nplt.legend()\n\n# Display the plot\nplt.savefig('gradient1.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient1.png\" alt=\"gradient\" width=\"600\" height=\"400\" />\n</p>\n\n### Tug-of-war\n\nI had a question before about why the loss function in linear regression is represented as a vertical line instead of the distance between the point and the line. **I think of linear regression as a tug-of-war game, where the points on either side of the line are pulling the line in opposite directions.**\n\nI think about it. The vertical line is better because (1) Using a vertical line to represent the loss in linear regression is more intuitive and accurate because the goal of linear regression is to minimize the vertical distance between the predicted values and the actual values. (2) The distance between two points in a triangle is always greater than or equal to the difference between the lengths of the two sides that form the angle between them. This is known as the triangle inequality. Therefore, the use of a vertical line to represent the loss function in linear regression can be seen as a way to magnify the difference between the predicted values and the actual values, which can make it easier to see and understand the performance of the model.\n\nThe use of a vertical line to represent the residual or error in linear regression is a way to magnify the difference between the predicted values and the actual values, which makes it easier to measure the error or loss of the model. In the case of mean squared error (MSE), the use of the Euclidean distance (i.e., the distance between the points in a straight line) instead of the Manhattan distance (i.e., the sum of the absolute differences between the coordinates) is also a way to magnify the errors and make them more apparent. This is because the Euclidean distance gives more weight to larger errors, which can help to identify and prioritize the points with the greatest impact on the overall error.\n\nOverall, the use of these techniques to magnify the errors and make them more apparent is an important step in understanding and improving the performance of the model.\n\n### Euclidean Distance vs Manhattan distance\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 2 * np.random.randn(5)\n# generate two outliers\nx = np.append(x, [6, 7])\ny = np.append(y, [20, 25])\n\n# Fit a linear regression model to the data\n# model1 without outliers\nmodel1 = np.polyfit(x[:-2], y[:-2], 1)\npredicted1 = np.polyval(model1, x[:-2])\n# model2 with outliers\nmodel2 = np.polyfit(x, y, 1)\npredicted2 = np.polyval(model2, x)\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x[:-2], predicted1, color='red', label='Predicted without outliers')\nplt.plot(x, predicted2, color='green', label='Predicted with outliers')\n\n# Highlight the difference between actual and two predicted values\nfor i in range(len(x)-2):\n    plt.plot([x[i], x[i]], [y[i], predicted1[i]], color='red', linestyle='--')\n    plt.plot([x[i], x[i]], [y[i], predicted2[i]], color='green', linestyle='--')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression using Euclidean Distance')\nplt.legend()\n\n# Display the plot\nplt.savefig('gradient2.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient2.png\" alt=\"gradient\" width=\"600\" height=\"400\" />\n</p>\n\nI added two outliers to the original data, and it is clear that these outliers have a significant impact on the regression model, causing the line to shift noticeably. This is similar to a tug-of-war game where the two outliers are pulling the line strongly towards their side. With the use of the Euclidean distance, the impact of the outliers is amplified, as the larger errors have more weight in the calculation of the loss. As the line moves to adjust to the outliers, the distance between the line and the original five points increases, leading to a larger loss. The goal is to find a balance that minimizes the overall loss.\n\nIf we were to use the Manhattan distance instead, the impact of the outliers may be even greater than the impact of the original five points. This is because the Manhattan distance measures the vertical distance between the line and each point, without amplifying the error through squaring.\n\nIn practice, the choice of distance metric depends on the number and nature of the outliers. There is no one-size-fits-all solution, and it is important to carefully consider the specific characteristics of the data and the problem at hand when choosing a distance metric for regression.\n\nIn general, it is a good practice to remove or handle outliers before fitting a linear regression model. \n\n### Mean squared error\n\nMean squared error (MSE) is a common measure of the average squared difference between the predicted values and the actual values in regression analysis. It is calculated as the average of the squared differences between the predicted and actual values for each data point. The formula for MSE is:\n$$\n\\begin{equation}\n\\text { MSE }=1 / n * \\sum(y_i-\\hat{y} _i)^2\n\\end{equation}\n$$\nwhere:\n\n- n is the number of data points\n- $y_i$ is the actual value for the $i$-th data point\n- $\\hat{y} _i$ is the predicted value for the $i$-th data point\n\nThe $1/n$ term in the MSE formula is used to normalize the sum of squared errors and ensure that the MSE is relative to the number of data points in the sample. \n\nFor example, if we compare the MSE values for two datasets with 100 and 1000 data points, respectively, the MSE value for the larger dataset would be 10 times larger than the MSE value for the smaller dataset, even if the models have the same level of accuracy. By dividing the sum of squared errors by the number of data points, we can obtain an average error value that is more representative of the model's performance across different sample sizes.\n\nIn some cases, the MSE is defined with an additional factor of 1/2 to simplify the derivative calculation, as the derivative of the squared term will cancel out the 2 in the denominator. \n$$\n\\begin{equation}\nM S E=1 / 2 n * \\Sigma(y_i-\\hat{y}_i)^2\n\\end{equation}\n$$\nWhile the additional factor of 1/2 does not change the minimum value of the MSE, it can make the derivative calculation simpler and more efficient. \n\n### Gradient descend\n\nThe derivative is a scalar value that represents the rate of change of a function in one dimension, while the gradient is a vector that represents the rate of change of a function in multiple dimensions.\n\nGradient descent is an optimization algorithm used to minimize a differentiable function by iteratively adjusting its parameters in the direction of steepest descent of the function. The basic idea of gradient descent is to update the parameters in a way that minimizes the loss function.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function to minimize\nf = lambda x: (x - 3.5) ** 2 - 4.5 * x + 10\n\n# Define the gradient function\ng = lambda x: 2 * (x - 3.5) - 4.5\n\n# Generate x values for plotting\nx = np.linspace(0, 11.5, 100)\n\n# Compute y values for plotting\ny = f(x)\n\n# Plot the function\nplt.plot(x, y, label='f(x)')\n\n# Set the initial guess for the minimum\nx_min = 5.75\n\n# Set the learning rate\neta = 0.3\n\n# Perform gradient descent\nx_current = np.random.randint(0, 12, size=1)[0]\n\nx_history = [x_current]\ntolerance = 0.0001\niteration = 0\nwhile True:\n    x_previous = x_current\n    x_current = x_previous - eta * g(x_previous)\n    x_history.append(x_current)\n    iteration += 1\n    if np.abs(x_current - x_previous) < tolerance:\n        break\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\n# Plot the function\nplt.plot(x, y, label='f(x)')\n# Plot the trajectory of gradient descent\nplt.scatter(x_history, f(np.array(x_history)), color='blue', label='Trajectory')\nplt.plot(x_history, f(np.array(x_history)), color='blue', linestyle='--')\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Gradient Descent')\n# iterations, learning rate, and tolerance on the right upper corner\nplt.text(6, 20, 'Iterations: {}'.format(iteration), fontsize=12)\nplt.text(6, 18, 'Learning rate: {}'.format(eta), fontsize=12)\nplt.text(6, 16, 'Tolerance: {}'.format(tolerance), fontsize=12)\nplt.legend()\nplt.savefig('gradient3.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient3.png\" alt=\"gradient\" width=\"500\" height=\"400\" />\n</p>\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient3-0040620.png\" alt=\"gradient\" width=\"500\" height=\"400\" />\n</p>\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient4.png\" alt=\"gradient\" width=\"500\" height=\"400\" />\n</p>\n\nLearning rate is a hyperparameter that controls the step size taken during each iteration of the gradient descent optimization algorithm. Specifically, it determines how much the model parameters are updated in the direction of the negative gradient of the loss function. A high learning rate results in larger parameter updates and faster convergence, but can also cause the algorithm to overshoot the minimum and oscillate around it, or even diverge. Conversely, a low learning rate results in smaller parameter updates and slower convergence, but can also help the algorithm converge more stably and avoid overshooting.\n\n### Reference\n\n1. Ng, A. (2017). Gradient Descent. In Machine Learning (Week 2). Stanford University. Coursera. https://www.coursera.org/learn/machine-learning\n2. Wikipedia contributors. (2023, March 17). Mean squared error. In Wikipedia, The Free Encyclopedia. Retrieved 14:37, March 28, 2023, from https://en.wikipedia.org/wiki/Mean_squared_error\n\n\n\n\n\n\n\n","source":"_posts/Gradient-descend-for-linear-regression.md","raw":"---\nmathjax: true\ntitle: Gradient descend for linear regression\ndate: 2023-03-28 20:09:58\ntags:\n  - Gradient descend\n  - Linear regression\n  - Optimization\n  - Mean squared error\n  - Loss function\n  - Machine learning\n---\n\n### The importance of a loss function\n\nThe importance of a loss function in machine learning cannot be overstated. Whenever we try to solve a problem, there is always some expected outcome, and the actual outcome will inevitably have some degree of error. The goal of optimization is to minimize this error as much as possible.\n\nIn linear regression, we try to find a line that best fits a set of data points. However, no matter how many data points we have, there will always be some degree of error in the fit. \n\n**When we only have a single point in the space, there are countless lines that can pass through that point, making it impossible to determine the best fit line. When we have two points, there is only one line that can pass through both points, meaning that the best fit line is well-defined. However, when we have three or more points, and those points lie on a straight line, there will always be some degree of error in the fit, no matter how we attempt to fit the line to the points.**\n\nThis is because, in this case, any line we draw will either overestimate or underestimate the data points, leading to some degree of inaccuracy in the fit. Thus, the role of the loss function is to measure this uncertainty and provide feedback to the optimization algorithm to improve the fit of the model.\n\n### Loss function\n\nA loss function is a function used to measure the difference between an expected value and a predicted value, which is also known as the loss. In simple terms, the loss function quantifies the difference between the expected value and the actual (or predicted) value.\n\nThe role of the loss function is to measure the quality of the model's output by calculating the difference between the predicted output and the actual output. The goal of training a machine learning model is to minimize the loss function, which means finding the model parameters that result in the smallest possible loss.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 22:19\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 2* np.random.randn(5)\n\n# Fit a linear regression model to the data\nmodel = np.polyfit(x, y, 1)\npredicted = np.polyval(model, x)\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x, predicted, color='red', label='Predicted')\n\n# Highlight the difference between actual and predicted values\nfor i in range(len(x)):\n    plt.plot([x[i], x[i]], [y[i], predicted[i]], color='gray', linestyle='--')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression')\nplt.legend()\n\n# Display the plot\nplt.savefig('gradient.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient.png\" alt=\"gradient\" width=\"600\" height=\"400\" />\n</p>\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 22:25\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 1.5 * np.random.randn(5)\n\n# Fit a linear regression model to the data\nmodel = np.polyfit(x, y, 1)\npredicted = np.polyval(model, x)\n\n# Calculate the residuals\nresiduals = y - predicted\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x, predicted, color='red', label='Predicted')\n\n# Plot the orthogonal lines\nfor i in range(len(x)):\n    slope = -1 / model[0]\n    intercept = y[i] - slope * x[i]\n    intersection_x = (intercept - model[1]) / (model[0] - slope)\n    intersection_y = slope * intersection_x + intercept\n    plt.plot([x[i], intersection_x], [y[i], intersection_y], color='black', linestyle='--')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression')\nplt.legend()\n\n# Display the plot\nplt.savefig('gradient1.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient1.png\" alt=\"gradient\" width=\"600\" height=\"400\" />\n</p>\n\n### Tug-of-war\n\nI had a question before about why the loss function in linear regression is represented as a vertical line instead of the distance between the point and the line. **I think of linear regression as a tug-of-war game, where the points on either side of the line are pulling the line in opposite directions.**\n\nI think about it. The vertical line is better because (1) Using a vertical line to represent the loss in linear regression is more intuitive and accurate because the goal of linear regression is to minimize the vertical distance between the predicted values and the actual values. (2) The distance between two points in a triangle is always greater than or equal to the difference between the lengths of the two sides that form the angle between them. This is known as the triangle inequality. Therefore, the use of a vertical line to represent the loss function in linear regression can be seen as a way to magnify the difference between the predicted values and the actual values, which can make it easier to see and understand the performance of the model.\n\nThe use of a vertical line to represent the residual or error in linear regression is a way to magnify the difference between the predicted values and the actual values, which makes it easier to measure the error or loss of the model. In the case of mean squared error (MSE), the use of the Euclidean distance (i.e., the distance between the points in a straight line) instead of the Manhattan distance (i.e., the sum of the absolute differences between the coordinates) is also a way to magnify the errors and make them more apparent. This is because the Euclidean distance gives more weight to larger errors, which can help to identify and prioritize the points with the greatest impact on the overall error.\n\nOverall, the use of these techniques to magnify the errors and make them more apparent is an important step in understanding and improving the performance of the model.\n\n### Euclidean Distance vs Manhattan distance\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data for demonstration\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 6, 8, 10]) + 2 * np.random.randn(5)\n# generate two outliers\nx = np.append(x, [6, 7])\ny = np.append(y, [20, 25])\n\n# Fit a linear regression model to the data\n# model1 without outliers\nmodel1 = np.polyfit(x[:-2], y[:-2], 1)\npredicted1 = np.polyval(model1, x[:-2])\n# model2 with outliers\nmodel2 = np.polyfit(x, y, 1)\npredicted2 = np.polyval(model2, x)\n\n# Plot the data and the regression line\nplt.scatter(x, y, color='blue', label='Actual')\nplt.plot(x[:-2], predicted1, color='red', label='Predicted without outliers')\nplt.plot(x, predicted2, color='green', label='Predicted with outliers')\n\n# Highlight the difference between actual and two predicted values\nfor i in range(len(x)-2):\n    plt.plot([x[i], x[i]], [y[i], predicted1[i]], color='red', linestyle='--')\n    plt.plot([x[i], x[i]], [y[i], predicted2[i]], color='green', linestyle='--')\n\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear Regression using Euclidean Distance')\nplt.legend()\n\n# Display the plot\nplt.savefig('gradient2.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient2.png\" alt=\"gradient\" width=\"600\" height=\"400\" />\n</p>\n\nI added two outliers to the original data, and it is clear that these outliers have a significant impact on the regression model, causing the line to shift noticeably. This is similar to a tug-of-war game where the two outliers are pulling the line strongly towards their side. With the use of the Euclidean distance, the impact of the outliers is amplified, as the larger errors have more weight in the calculation of the loss. As the line moves to adjust to the outliers, the distance between the line and the original five points increases, leading to a larger loss. The goal is to find a balance that minimizes the overall loss.\n\nIf we were to use the Manhattan distance instead, the impact of the outliers may be even greater than the impact of the original five points. This is because the Manhattan distance measures the vertical distance between the line and each point, without amplifying the error through squaring.\n\nIn practice, the choice of distance metric depends on the number and nature of the outliers. There is no one-size-fits-all solution, and it is important to carefully consider the specific characteristics of the data and the problem at hand when choosing a distance metric for regression.\n\nIn general, it is a good practice to remove or handle outliers before fitting a linear regression model. \n\n### Mean squared error\n\nMean squared error (MSE) is a common measure of the average squared difference between the predicted values and the actual values in regression analysis. It is calculated as the average of the squared differences between the predicted and actual values for each data point. The formula for MSE is:\n$$\n\\begin{equation}\n\\text { MSE }=1 / n * \\sum(y_i-\\hat{y} _i)^2\n\\end{equation}\n$$\nwhere:\n\n- n is the number of data points\n- $y_i$ is the actual value for the $i$-th data point\n- $\\hat{y} _i$ is the predicted value for the $i$-th data point\n\nThe $1/n$ term in the MSE formula is used to normalize the sum of squared errors and ensure that the MSE is relative to the number of data points in the sample. \n\nFor example, if we compare the MSE values for two datasets with 100 and 1000 data points, respectively, the MSE value for the larger dataset would be 10 times larger than the MSE value for the smaller dataset, even if the models have the same level of accuracy. By dividing the sum of squared errors by the number of data points, we can obtain an average error value that is more representative of the model's performance across different sample sizes.\n\nIn some cases, the MSE is defined with an additional factor of 1/2 to simplify the derivative calculation, as the derivative of the squared term will cancel out the 2 in the denominator. \n$$\n\\begin{equation}\nM S E=1 / 2 n * \\Sigma(y_i-\\hat{y}_i)^2\n\\end{equation}\n$$\nWhile the additional factor of 1/2 does not change the minimum value of the MSE, it can make the derivative calculation simpler and more efficient. \n\n### Gradient descend\n\nThe derivative is a scalar value that represents the rate of change of a function in one dimension, while the gradient is a vector that represents the rate of change of a function in multiple dimensions.\n\nGradient descent is an optimization algorithm used to minimize a differentiable function by iteratively adjusting its parameters in the direction of steepest descent of the function. The basic idea of gradient descent is to update the parameters in a way that minimizes the loss function.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function to minimize\nf = lambda x: (x - 3.5) ** 2 - 4.5 * x + 10\n\n# Define the gradient function\ng = lambda x: 2 * (x - 3.5) - 4.5\n\n# Generate x values for plotting\nx = np.linspace(0, 11.5, 100)\n\n# Compute y values for plotting\ny = f(x)\n\n# Plot the function\nplt.plot(x, y, label='f(x)')\n\n# Set the initial guess for the minimum\nx_min = 5.75\n\n# Set the learning rate\neta = 0.3\n\n# Perform gradient descent\nx_current = np.random.randint(0, 12, size=1)[0]\n\nx_history = [x_current]\ntolerance = 0.0001\niteration = 0\nwhile True:\n    x_previous = x_current\n    x_current = x_previous - eta * g(x_previous)\n    x_history.append(x_current)\n    iteration += 1\n    if np.abs(x_current - x_previous) < tolerance:\n        break\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\n# Plot the function\nplt.plot(x, y, label='f(x)')\n# Plot the trajectory of gradient descent\nplt.scatter(x_history, f(np.array(x_history)), color='blue', label='Trajectory')\nplt.plot(x_history, f(np.array(x_history)), color='blue', linestyle='--')\n# Add labels and legend to the plot\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Gradient Descent')\n# iterations, learning rate, and tolerance on the right upper corner\nplt.text(6, 20, 'Iterations: {}'.format(iteration), fontsize=12)\nplt.text(6, 18, 'Learning rate: {}'.format(eta), fontsize=12)\nplt.text(6, 16, 'Tolerance: {}'.format(tolerance), fontsize=12)\nplt.legend()\nplt.savefig('gradient3.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n\n```\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient3.png\" alt=\"gradient\" width=\"500\" height=\"400\" />\n</p>\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient3-0040620.png\" alt=\"gradient\" width=\"500\" height=\"400\" />\n</p>\n\n<p align=\"center\">\n  <img src=\"Gradient-descend-for-linear-regression/gradient4.png\" alt=\"gradient\" width=\"500\" height=\"400\" />\n</p>\n\nLearning rate is a hyperparameter that controls the step size taken during each iteration of the gradient descent optimization algorithm. Specifically, it determines how much the model parameters are updated in the direction of the negative gradient of the loss function. A high learning rate results in larger parameter updates and faster convergence, but can also cause the algorithm to overshoot the minimum and oscillate around it, or even diverge. Conversely, a low learning rate results in smaller parameter updates and slower convergence, but can also help the algorithm converge more stably and avoid overshooting.\n\n### Reference\n\n1. Ng, A. (2017). Gradient Descent. In Machine Learning (Week 2). Stanford University. Coursera. https://www.coursera.org/learn/machine-learning\n2. Wikipedia contributors. (2023, March 17). Mean squared error. In Wikipedia, The Free Encyclopedia. Retrieved 14:37, March 28, 2023, from https://en.wikipedia.org/wiki/Mean_squared_error\n\n\n\n\n\n\n\n","slug":"Gradient-descend-for-linear-regression","published":1,"updated":"2023-04-07T02:43:50.504Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gq000dozpi6wn0fucb","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"The-importance-of-a-loss-function\"><a href=\"#The-importance-of-a-loss-function\" class=\"headerlink\" title=\"The importance of a loss function\"></a>The importance of a loss function</h3><p>The importance of a loss function in machine learning cannot be overstated. Whenever we try to solve a problem, there is always some expected outcome, and the actual outcome will inevitably have some degree of error. The goal of optimization is to minimize this error as much as possible.</p>\n<p>In linear regression, we try to find a line that best fits a set of data points. However, no matter how many data points we have, there will always be some degree of error in the fit. </p>\n<p><strong>When we only have a single point in the space, there are countless lines that can pass through that point, making it impossible to determine the best fit line. When we have two points, there is only one line that can pass through both points, meaning that the best fit line is well-defined. However, when we have three or more points, and those points lie on a straight line, there will always be some degree of error in the fit, no matter how we attempt to fit the line to the points.</strong></p>\n<p>This is because, in this case, any line we draw will either overestimate or underestimate the data points, leading to some degree of inaccuracy in the fit. Thus, the role of the loss function is to measure this uncertainty and provide feedback to the optimization algorithm to improve the fit of the model.</p>\n<h3 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h3><p>A loss function is a function used to measure the difference between an expected value and a predicted value, which is also known as the loss. In simple terms, the loss function quantifies the difference between the expected value and the actual (or predicted) value.</p>\n<p>The role of the loss function is to measure the quality of the models output by calculating the difference between the predicted output and the actual output. The goal of training a machine learning model is to minimize the loss function, which means finding the model parameters that result in the smallest possible loss.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 22:19</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">2</span>* np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\">model = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted = np.polyval(model, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x, predicted, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Highlight the difference between actual and predicted values</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)):</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted[i]], color=<span class=\"string\">'gray'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"600\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient.png\">\n</p>\n\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 22:25</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">1.5</span> * np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\">model = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted = np.polyval(model, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the residuals</span></span><br><span class=\"line\">residuals = y - predicted</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x, predicted, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the orthogonal lines</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)):</span><br><span class=\"line\">    slope = -<span class=\"number\">1</span> / model[<span class=\"number\">0</span>]</span><br><span class=\"line\">    intercept = y[i] - slope * x[i]</span><br><span class=\"line\">    intersection_x = (intercept - model[<span class=\"number\">1</span>]) / (model[<span class=\"number\">0</span>] - slope)</span><br><span class=\"line\">    intersection_y = slope * intersection_x + intercept</span><br><span class=\"line\">    plt.plot([x[i], intersection_x], [y[i], intersection_y], color=<span class=\"string\">'black'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient1.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"600\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient1.png\">\n</p>\n\n<h3 id=\"Tug-of-war\"><a href=\"#Tug-of-war\" class=\"headerlink\" title=\"Tug-of-war\"></a>Tug-of-war</h3><p>I had a question before about why the loss function in linear regression is represented as a vertical line instead of the distance between the point and the line. <strong>I think of linear regression as a tug-of-war game, where the points on either side of the line are pulling the line in opposite directions.</strong></p>\n<p>I think about it. The vertical line is better because (1) Using a vertical line to represent the loss in linear regression is more intuitive and accurate because the goal of linear regression is to minimize the vertical distance between the predicted values and the actual values. (2) The distance between two points in a triangle is always greater than or equal to the difference between the lengths of the two sides that form the angle between them. This is known as the triangle inequality. Therefore, the use of a vertical line to represent the loss function in linear regression can be seen as a way to magnify the difference between the predicted values and the actual values, which can make it easier to see and understand the performance of the model.</p>\n<p>The use of a vertical line to represent the residual or error in linear regression is a way to magnify the difference between the predicted values and the actual values, which makes it easier to measure the error or loss of the model. In the case of mean squared error (MSE), the use of the Euclidean distance (i.e., the distance between the points in a straight line) instead of the Manhattan distance (i.e., the sum of the absolute differences between the coordinates) is also a way to magnify the errors and make them more apparent. This is because the Euclidean distance gives more weight to larger errors, which can help to identify and prioritize the points with the greatest impact on the overall error.</p>\n<p>Overall, the use of these techniques to magnify the errors and make them more apparent is an important step in understanding and improving the performance of the model.</p>\n<h3 id=\"Euclidean-Distance-vs-Manhattan-distance\"><a href=\"#Euclidean-Distance-vs-Manhattan-distance\" class=\"headerlink\" title=\"Euclidean Distance vs Manhattan distance\"></a>Euclidean Distance vs Manhattan distance</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">2</span> * np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"comment\"># generate two outliers</span></span><br><span class=\"line\">x = np.append(x, [<span class=\"number\">6</span>, <span class=\"number\">7</span>])</span><br><span class=\"line\">y = np.append(y, [<span class=\"number\">20</span>, <span class=\"number\">25</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\"><span class=\"comment\"># model1 without outliers</span></span><br><span class=\"line\">model1 = np.polyfit(x[:-<span class=\"number\">2</span>], y[:-<span class=\"number\">2</span>], <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted1 = np.polyval(model1, x[:-<span class=\"number\">2</span>])</span><br><span class=\"line\"><span class=\"comment\"># model2 with outliers</span></span><br><span class=\"line\">model2 = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted2 = np.polyval(model2, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x[:-<span class=\"number\">2</span>], predicted1, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted without outliers'</span>)</span><br><span class=\"line\">plt.plot(x, predicted2, color=<span class=\"string\">'green'</span>, label=<span class=\"string\">'Predicted with outliers'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Highlight the difference between actual and two predicted values</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)-<span class=\"number\">2</span>):</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted1[i]], color=<span class=\"string\">'red'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted2[i]], color=<span class=\"string\">'green'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression using Euclidean Distance'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient2.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"600\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient2.png\">\n</p>\n\n<p>I added two outliers to the original data, and it is clear that these outliers have a significant impact on the regression model, causing the line to shift noticeably. This is similar to a tug-of-war game where the two outliers are pulling the line strongly towards their side. With the use of the Euclidean distance, the impact of the outliers is amplified, as the larger errors have more weight in the calculation of the loss. As the line moves to adjust to the outliers, the distance between the line and the original five points increases, leading to a larger loss. The goal is to find a balance that minimizes the overall loss.</p>\n<p>If we were to use the Manhattan distance instead, the impact of the outliers may be even greater than the impact of the original five points. This is because the Manhattan distance measures the vertical distance between the line and each point, without amplifying the error through squaring.</p>\n<p>In practice, the choice of distance metric depends on the number and nature of the outliers. There is no one-size-fits-all solution, and it is important to carefully consider the specific characteristics of the data and the problem at hand when choosing a distance metric for regression.</p>\n<p>In general, it is a good practice to remove or handle outliers before fitting a linear regression model. </p>\n<h3 id=\"Mean-squared-error\"><a href=\"#Mean-squared-error\" class=\"headerlink\" title=\"Mean squared error\"></a>Mean squared error</h3><p>Mean squared error (MSE) is a common measure of the average squared difference between the predicted values and the actual values in regression analysis. It is calculated as the average of the squared differences between the predicted and actual values for each data point. The formula for MSE is:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { MSE }=1 / n * \\sum(y_i-\\hat{y} _i)^2\n\\end{equation}</script><p>where:</p>\n<ul>\n<li>n is the number of data points</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.848ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 817 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the actual value for the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th data point</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.848ex\" height=\"2.296ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -810 817 1015\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300.6,16) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g><g data-mml-node=\"mi\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the predicted value for the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th data point</li>\n</ul>\n<p>The <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.62ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 1600 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(500,0)\"><g data-mml-node=\"mo\"><path data-c=\"2F\" d=\"M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(1000,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> term in the MSE formula is used to normalize the sum of squared errors and ensure that the MSE is relative to the number of data points in the sample. </p>\n<p>For example, if we compare the MSE values for two datasets with 100 and 1000 data points, respectively, the MSE value for the larger dataset would be 10 times larger than the MSE value for the smaller dataset, even if the models have the same level of accuracy. By dividing the sum of squared errors by the number of data points, we can obtain an average error value that is more representative of the models performance across different sample sizes.</p>\n<p>In some cases, the MSE is defined with an additional factor of 1/2 to simplify the derivative calculation, as the derivative of the squared term will cancel out the 2 in the denominator. </p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nM S E=1 / 2 n * \\Sigma(y_i-\\hat{y}_i)^2\n\\end{equation}</script><p>While the additional factor of 1/2 does not change the minimum value of the MSE, it can make the derivative calculation simpler and more efficient. </p>\n<h3 id=\"Gradient-descend\"><a href=\"#Gradient-descend\" class=\"headerlink\" title=\"Gradient descend\"></a>Gradient descend</h3><p>The derivative is a scalar value that represents the rate of change of a function in one dimension, while the gradient is a vector that represents the rate of change of a function in multiple dimensions.</p>\n<p>Gradient descent is an optimization algorithm used to minimize a differentiable function by iteratively adjusting its parameters in the direction of steepest descent of the function. The basic idea of gradient descent is to update the parameters in a way that minimizes the loss function.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function to minimize</span></span><br><span class=\"line\">f = <span class=\"keyword\">lambda</span> x: (x - <span class=\"number\">3.5</span>) ** <span class=\"number\">2</span> - <span class=\"number\">4.5</span> * x + <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the gradient function</span></span><br><span class=\"line\">g = <span class=\"keyword\">lambda</span> x: <span class=\"number\">2</span> * (x - <span class=\"number\">3.5</span>) - <span class=\"number\">4.5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate x values for plotting</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">11.5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Compute y values for plotting</span></span><br><span class=\"line\">y = f(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function</span></span><br><span class=\"line\">plt.plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the initial guess for the minimum</span></span><br><span class=\"line\">x_min = <span class=\"number\">5.75</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the learning rate</span></span><br><span class=\"line\">eta = <span class=\"number\">0.3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Perform gradient descent</span></span><br><span class=\"line\">x_current = np.random.randint(<span class=\"number\">0</span>, <span class=\"number\">12</span>, size=<span class=\"number\">1</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">x_history = [x_current]</span><br><span class=\"line\">tolerance = <span class=\"number\">0.0001</span></span><br><span class=\"line\">iteration = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    x_previous = x_current</span><br><span class=\"line\">    x_current = x_previous - eta * g(x_previous)</span><br><span class=\"line\">    x_history.append(x_current)</span><br><span class=\"line\">    iteration += <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> np.<span class=\"built_in\">abs</span>(x_current - x_previous) &lt; tolerance:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># Plot the function</span></span><br><span class=\"line\">plt.plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\"><span class=\"comment\"># Plot the trajectory of gradient descent</span></span><br><span class=\"line\">plt.scatter(x_history, f(np.array(x_history)), color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Trajectory'</span>)</span><br><span class=\"line\">plt.plot(x_history, f(np.array(x_history)), color=<span class=\"string\">'blue'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Gradient Descent'</span>)</span><br><span class=\"line\"><span class=\"comment\"># iterations, learning rate, and tolerance on the right upper corner</span></span><br><span class=\"line\">plt.text(<span class=\"number\">6</span>, <span class=\"number\">20</span>, <span class=\"string\">'Iterations: {}'</span>.<span class=\"built_in\">format</span>(iteration), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.text(<span class=\"number\">6</span>, <span class=\"number\">18</span>, <span class=\"string\">'Learning rate: {}'</span>.<span class=\"built_in\">format</span>(eta), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.text(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"string\">'Tolerance: {}'</span>.<span class=\"built_in\">format</span>(tolerance), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient3.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"500\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient3.png\">\n</p>\n\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"500\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient3-0040620.png\">\n</p>\n\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"500\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient4.png\">\n</p>\n\n<p>Learning rate is a hyperparameter that controls the step size taken during each iteration of the gradient descent optimization algorithm. Specifically, it determines how much the model parameters are updated in the direction of the negative gradient of the loss function. A high learning rate results in larger parameter updates and faster convergence, but can also cause the algorithm to overshoot the minimum and oscillate around it, or even diverge. Conversely, a low learning rate results in smaller parameter updates and slower convergence, but can also help the algorithm converge more stably and avoid overshooting.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Ng, A. (2017). Gradient Descent. In Machine Learning (Week 2). Stanford University. Coursera. <a href=\"https://www.coursera.org/learn/machine-learning\">https://www.coursera.org/learn/machine-learning</a></li>\n<li>Wikipedia contributors. (2023, March 17). Mean squared error. In Wikipedia, The Free Encyclopedia. Retrieved 14:37, March 28, 2023, from <a href=\"https://en.wikipedia.org/wiki/Mean_squared_error\">https://en.wikipedia.org/wiki/Mean_squared_error</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/29/From-linear-regression-to-binary-classification/","2023/04/03/Scipy-optimization/","2023/03/28/Functions-Plot/"],"length":2231,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"The-importance-of-a-loss-function\"><a href=\"#The-importance-of-a-loss-function\" class=\"headerlink\" title=\"The importance of a loss function\"></a>The importance of a loss function</h3><p>The importance of a loss function in machine learning cannot be overstated. Whenever we try to solve a problem, there is always some expected outcome, and the actual outcome will inevitably have some degree of error. The goal of optimization is to minimize this error as much as possible.</p>\n<p>In linear regression, we try to find a line that best fits a set of data points. However, no matter how many data points we have, there will always be some degree of error in the fit. </p>\n<p><strong>When we only have a single point in the space, there are countless lines that can pass through that point, making it impossible to determine the best fit line. When we have two points, there is only one line that can pass through both points, meaning that the best fit line is well-defined. However, when we have three or more points, and those points lie on a straight line, there will always be some degree of error in the fit, no matter how we attempt to fit the line to the points.</strong></p>\n<p>This is because, in this case, any line we draw will either overestimate or underestimate the data points, leading to some degree of inaccuracy in the fit. Thus, the role of the loss function is to measure this uncertainty and provide feedback to the optimization algorithm to improve the fit of the model.</p>\n<h3 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h3><p>A loss function is a function used to measure the difference between an expected value and a predicted value, which is also known as the loss. In simple terms, the loss function quantifies the difference between the expected value and the actual (or predicted) value.</p>\n<p>The role of the loss function is to measure the quality of the models output by calculating the difference between the predicted output and the actual output. The goal of training a machine learning model is to minimize the loss function, which means finding the model parameters that result in the smallest possible loss.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 22:19</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">2</span>* np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\">model = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted = np.polyval(model, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x, predicted, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Highlight the difference between actual and predicted values</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)):</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted[i]], color=<span class=\"string\">'gray'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"600\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient.png\">\n</p>\n\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 22:25</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">1.5</span> * np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\">model = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted = np.polyval(model, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the residuals</span></span><br><span class=\"line\">residuals = y - predicted</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x, predicted, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the orthogonal lines</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)):</span><br><span class=\"line\">    slope = -<span class=\"number\">1</span> / model[<span class=\"number\">0</span>]</span><br><span class=\"line\">    intercept = y[i] - slope * x[i]</span><br><span class=\"line\">    intersection_x = (intercept - model[<span class=\"number\">1</span>]) / (model[<span class=\"number\">0</span>] - slope)</span><br><span class=\"line\">    intersection_y = slope * intersection_x + intercept</span><br><span class=\"line\">    plt.plot([x[i], intersection_x], [y[i], intersection_y], color=<span class=\"string\">'black'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient1.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"600\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient1.png\">\n</p>\n\n<h3 id=\"Tug-of-war\"><a href=\"#Tug-of-war\" class=\"headerlink\" title=\"Tug-of-war\"></a>Tug-of-war</h3><p>I had a question before about why the loss function in linear regression is represented as a vertical line instead of the distance between the point and the line. <strong>I think of linear regression as a tug-of-war game, where the points on either side of the line are pulling the line in opposite directions.</strong></p>\n<p>I think about it. The vertical line is better because (1) Using a vertical line to represent the loss in linear regression is more intuitive and accurate because the goal of linear regression is to minimize the vertical distance between the predicted values and the actual values. (2) The distance between two points in a triangle is always greater than or equal to the difference between the lengths of the two sides that form the angle between them. This is known as the triangle inequality. Therefore, the use of a vertical line to represent the loss function in linear regression can be seen as a way to magnify the difference between the predicted values and the actual values, which can make it easier to see and understand the performance of the model.</p>\n<p>The use of a vertical line to represent the residual or error in linear regression is a way to magnify the difference between the predicted values and the actual values, which makes it easier to measure the error or loss of the model. In the case of mean squared error (MSE), the use of the Euclidean distance (i.e., the distance between the points in a straight line) instead of the Manhattan distance (i.e., the sum of the absolute differences between the coordinates) is also a way to magnify the errors and make them more apparent. This is because the Euclidean distance gives more weight to larger errors, which can help to identify and prioritize the points with the greatest impact on the overall error.</p>\n<p>Overall, the use of these techniques to magnify the errors and make them more apparent is an important step in understanding and improving the performance of the model.</p>\n<h3 id=\"Euclidean-Distance-vs-Manhattan-distance\"><a href=\"#Euclidean-Distance-vs-Manhattan-distance\" class=\"headerlink\" title=\"Euclidean Distance vs Manhattan distance\"></a>Euclidean Distance vs Manhattan distance</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data for demonstration</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]) + <span class=\"number\">2</span> * np.random.randn(<span class=\"number\">5</span>)</span><br><span class=\"line\"><span class=\"comment\"># generate two outliers</span></span><br><span class=\"line\">x = np.append(x, [<span class=\"number\">6</span>, <span class=\"number\">7</span>])</span><br><span class=\"line\">y = np.append(y, [<span class=\"number\">20</span>, <span class=\"number\">25</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a linear regression model to the data</span></span><br><span class=\"line\"><span class=\"comment\"># model1 without outliers</span></span><br><span class=\"line\">model1 = np.polyfit(x[:-<span class=\"number\">2</span>], y[:-<span class=\"number\">2</span>], <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted1 = np.polyval(model1, x[:-<span class=\"number\">2</span>])</span><br><span class=\"line\"><span class=\"comment\"># model2 with outliers</span></span><br><span class=\"line\">model2 = np.polyfit(x, y, <span class=\"number\">1</span>)</span><br><span class=\"line\">predicted2 = np.polyval(model2, x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Actual'</span>)</span><br><span class=\"line\">plt.plot(x[:-<span class=\"number\">2</span>], predicted1, color=<span class=\"string\">'red'</span>, label=<span class=\"string\">'Predicted without outliers'</span>)</span><br><span class=\"line\">plt.plot(x, predicted2, color=<span class=\"string\">'green'</span>, label=<span class=\"string\">'Predicted with outliers'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Highlight the difference between actual and two predicted values</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x)-<span class=\"number\">2</span>):</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted1[i]], color=<span class=\"string\">'red'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\">    plt.plot([x[i], x[i]], [y[i], predicted2[i]], color=<span class=\"string\">'green'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression using Euclidean Distance'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the plot</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient2.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"600\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient2.png\">\n</p>\n\n<p>I added two outliers to the original data, and it is clear that these outliers have a significant impact on the regression model, causing the line to shift noticeably. This is similar to a tug-of-war game where the two outliers are pulling the line strongly towards their side. With the use of the Euclidean distance, the impact of the outliers is amplified, as the larger errors have more weight in the calculation of the loss. As the line moves to adjust to the outliers, the distance between the line and the original five points increases, leading to a larger loss. The goal is to find a balance that minimizes the overall loss.</p>\n<p>If we were to use the Manhattan distance instead, the impact of the outliers may be even greater than the impact of the original five points. This is because the Manhattan distance measures the vertical distance between the line and each point, without amplifying the error through squaring.</p>\n<p>In practice, the choice of distance metric depends on the number and nature of the outliers. There is no one-size-fits-all solution, and it is important to carefully consider the specific characteristics of the data and the problem at hand when choosing a distance metric for regression.</p>\n<p>In general, it is a good practice to remove or handle outliers before fitting a linear regression model. </p>\n<h3 id=\"Mean-squared-error\"><a href=\"#Mean-squared-error\" class=\"headerlink\" title=\"Mean squared error\"></a>Mean squared error</h3><p>Mean squared error (MSE) is a common measure of the average squared difference between the predicted values and the actual values in regression analysis. It is calculated as the average of the squared differences between the predicted and actual values for each data point. The formula for MSE is:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { MSE }=1 / n * \\sum(y_i-\\hat{y} _i)^2\n\\end{equation}</script><p>where:</p>\n<ul>\n<li>n is the number of data points</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.848ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 817 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the actual value for the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th data point</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.848ex\" height=\"2.296ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -810 817 1015\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300.6,16) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g><g data-mml-node=\"mi\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the predicted value for the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.781ex\" height=\"1.52ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -661 345 672\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>-th data point</li>\n</ul>\n<p>The <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.62ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 1600 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(500,0)\"><g data-mml-node=\"mo\"><path data-c=\"2F\" d=\"M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(1000,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> term in the MSE formula is used to normalize the sum of squared errors and ensure that the MSE is relative to the number of data points in the sample. </p>\n<p>For example, if we compare the MSE values for two datasets with 100 and 1000 data points, respectively, the MSE value for the larger dataset would be 10 times larger than the MSE value for the smaller dataset, even if the models have the same level of accuracy. By dividing the sum of squared errors by the number of data points, we can obtain an average error value that is more representative of the models performance across different sample sizes.</p>\n<p>In some cases, the MSE is defined with an additional factor of 1/2 to simplify the derivative calculation, as the derivative of the squared term will cancel out the 2 in the denominator. </p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nM S E=1 / 2 n * \\Sigma(y_i-\\hat{y}_i)^2\n\\end{equation}</script><p>While the additional factor of 1/2 does not change the minimum value of the MSE, it can make the derivative calculation simpler and more efficient. </p>\n<h3 id=\"Gradient-descend\"><a href=\"#Gradient-descend\" class=\"headerlink\" title=\"Gradient descend\"></a>Gradient descend</h3><p>The derivative is a scalar value that represents the rate of change of a function in one dimension, while the gradient is a vector that represents the rate of change of a function in multiple dimensions.</p>\n<p>Gradient descent is an optimization algorithm used to minimize a differentiable function by iteratively adjusting its parameters in the direction of steepest descent of the function. The basic idea of gradient descent is to update the parameters in a way that minimizes the loss function.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the function to minimize</span></span><br><span class=\"line\">f = <span class=\"keyword\">lambda</span> x: (x - <span class=\"number\">3.5</span>) ** <span class=\"number\">2</span> - <span class=\"number\">4.5</span> * x + <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the gradient function</span></span><br><span class=\"line\">g = <span class=\"keyword\">lambda</span> x: <span class=\"number\">2</span> * (x - <span class=\"number\">3.5</span>) - <span class=\"number\">4.5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate x values for plotting</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">11.5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Compute y values for plotting</span></span><br><span class=\"line\">y = f(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the function</span></span><br><span class=\"line\">plt.plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the initial guess for the minimum</span></span><br><span class=\"line\">x_min = <span class=\"number\">5.75</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the learning rate</span></span><br><span class=\"line\">eta = <span class=\"number\">0.3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Perform gradient descent</span></span><br><span class=\"line\">x_current = np.random.randint(<span class=\"number\">0</span>, <span class=\"number\">12</span>, size=<span class=\"number\">1</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">x_history = [x_current]</span><br><span class=\"line\">tolerance = <span class=\"number\">0.0001</span></span><br><span class=\"line\">iteration = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    x_previous = x_current</span><br><span class=\"line\">    x_current = x_previous - eta * g(x_previous)</span><br><span class=\"line\">    x_history.append(x_current)</span><br><span class=\"line\">    iteration += <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> np.<span class=\"built_in\">abs</span>(x_current - x_previous) &lt; tolerance:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># Plot the function</span></span><br><span class=\"line\">plt.plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\"><span class=\"comment\"># Plot the trajectory of gradient descent</span></span><br><span class=\"line\">plt.scatter(x_history, f(np.array(x_history)), color=<span class=\"string\">'blue'</span>, label=<span class=\"string\">'Trajectory'</span>)</span><br><span class=\"line\">plt.plot(x_history, f(np.array(x_history)), color=<span class=\"string\">'blue'</span>, linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\"><span class=\"comment\"># Add labels and legend to the plot</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Gradient Descent'</span>)</span><br><span class=\"line\"><span class=\"comment\"># iterations, learning rate, and tolerance on the right upper corner</span></span><br><span class=\"line\">plt.text(<span class=\"number\">6</span>, <span class=\"number\">20</span>, <span class=\"string\">'Iterations: {}'</span>.<span class=\"built_in\">format</span>(iteration), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.text(<span class=\"number\">6</span>, <span class=\"number\">18</span>, <span class=\"string\">'Learning rate: {}'</span>.<span class=\"built_in\">format</span>(eta), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.text(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"string\">'Tolerance: {}'</span>.<span class=\"built_in\">format</span>(tolerance), fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'gradient3.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"500\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient3.png\">\n</p>\n\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"500\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient3-0040620.png\">\n</p>\n\n<p align=\"center\">\n  <img alt=\"gradient\" width=\"500\" height=\"400\" data-src=\"/2023/03/28/Gradient-descend-for-linear-regression/gradient4.png\">\n</p>\n\n<p>Learning rate is a hyperparameter that controls the step size taken during each iteration of the gradient descent optimization algorithm. Specifically, it determines how much the model parameters are updated in the direction of the negative gradient of the loss function. A high learning rate results in larger parameter updates and faster convergence, but can also cause the algorithm to overshoot the minimum and oscillate around it, or even diverge. Conversely, a low learning rate results in smaller parameter updates and slower convergence, but can also help the algorithm converge more stably and avoid overshooting.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Ng, A. (2017). Gradient Descent. In Machine Learning (Week 2). Stanford University. Coursera. <a href=\"https://www.coursera.org/learn/machine-learning\">https://www.coursera.org/learn/machine-learning</a></li>\n<li>Wikipedia contributors. (2023, March 17). Mean squared error. In Wikipedia, The Free Encyclopedia. Retrieved 14:37, March 28, 2023, from <a href=\"https://en.wikipedia.org/wiki/Mean_squared_error\">https://en.wikipedia.org/wiki/Mean_squared_error</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Hand Gesture Controlled Brightness Adjustment","date":"2023-04-02T21:09:27.000Z","_content":"\nThis code implements a hand gesture-controlled brightness adjustment using OpenCV and Mediapipe libraries. The program uses the camera feed to detect the landmarks of the user's hands and track the movement of the index finger tips.\n\nThe program first initializes the hand detector using the Mediapipe library and opens the camera. It then sets the resolution of the camera and enters a while loop to continuously read the camera feed.\n\nThe program detects the landmarks of the user's hands and tracks the movement of the index finger tips. It draws circles on the index finger tips and a line between the index finger tips of the two hands. It calculates the distance between the two index finger tips and adjusts the brightness of the camera feed based on the distance. \n\nThe program displays the brightness level and distance on the screen using text annotations. The loop continues until the user presses the 'q' key to exit the program.\n\nThe steps involved in the program are:\n\n1. Import the necessary libraries such as OpenCV, Mediapipe, and math.\n2. Initialize the hand detector using the Mediapipe library.\n3. Open the camera feed and set the camera resolution.\n4. Read the camera feed frame by frame and detect the hand landmarks using the hand detector.\n5. Draw landmarks and circles on the index finger tip of each hand.\n6. Calculate the distance between the index finger tips of both hands and adjust the brightness of the camera feed based on the distance.\n7. Display the camera feed with the brightness value and the distance between the index finger tips of both hands.\n8. Stop the program if the 'q' key is pressed, release the camera, and close all windows.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/2/23 22:31\n\nimport cv2\nimport numpy as np\nimport mediapipe as mp\nimport math\n\n# initialize hand detector\nmp_drawing = mp.solutions.drawing_utils\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.8)\n\n# open camera\ncap = cv2.VideoCapture(0)\n\n# set camera resolution\ncap.set(3, 1280)  # width\ncap.set(4, 720)  # height\n\nwhile True:\n    # read camera feed\n    success, img = cap.read()\n    if not success:\n        print(\"Unable to read camera feed\")\n        break\n    if img is None:\n        continue\n    img = cv2.flip(img, 1)\n\n    # detect the hands\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    results = hands.process(img_rgb)\n    if results.multi_hand_landmarks:\n        # check if both hands are detected\n        if len(results.multi_hand_landmarks) == 2:\n            # get the landmarks of the hands\n            lmList1 = results.multi_hand_landmarks[0].landmark\n            lmList2 = results.multi_hand_landmarks[1].landmark\n\n            # get the landmarks for the index fingers\n            h, w, c = img.shape\n            indexTip1 = (int(lmList1[8].x * w), int(lmList1[8].y * h))\n            indexTip2 = (int(lmList2[8].x * w), int(lmList2[8].y * h))\n\n            # draw circles on the index finger tips\n            cv2.circle(img, indexTip1, 15, (255, 0, 0), cv2.FILLED)\n            cv2.circle(img, indexTip2, 15, (255, 0, 0), cv2.FILLED)\n\n            # calculate the distance between the index finger tips of the two hands\n            distance = math.sqrt(\n                (indexTip2[0] - indexTip1[0]) ** 2 + (indexTip2[1] - indexTip1[1]) ** 2)\n\n            # draw a line between the index finger tips\n            cv2.line(img, indexTip1, indexTip2, (255, 0, 0), 3)\n\n            # adjust the brightness of the camera feed based on the distance\n            # brightness is from 0 to 100\n            # distance is from 0 to 1000\n            brightness = distance / 5\n            img = cv2.convertScaleAbs(img, alpha=1, beta=brightness)\n\n            # show the brightness on the screen\n            cv2.putText(img, f\"Brightness: {brightness:.2f}\", (10, 40), cv2.FONT_HERSHEY_PLAIN,\n                        2, (255, 0, 255), 2)\n\n            # draw the distance on the screen\n            cv2.putText(img, f\"Distance: {distance:.2f} pixels\", (10, 70), cv2.FONT_HERSHEY_PLAIN,\n                        2, (255, 0, 255), 2)\n        elif len(results.multi_hand_landmarks) == 1:\n            # if only one hand is detected, show the message on the screen\n            cv2.putText(img, \"Please detect two hands\", (10, 40), cv2.FONT_HERSHEY_PLAIN,\n                        2, (255, 0, 255), 2)\n            # show the blue circle on the index finger tip\n            lmList1 = results.multi_hand_landmarks[0].landmark\n            h, w, c = img.shape\n            indexTip1 = (int(lmList1[8].x * w), int(lmList1[8].y * h))\n            cv2.circle(img, indexTip1, 15, (255, 0, 0), cv2.FILLED)\n        else:\n            brightness = 0\n            img = cv2.convertScaleAbs(img, alpha=1, beta=brightness)\n\n    # show the camera feed\n    cv2.imshow(\"Image\", img)\n\n    # if the 'q' key is pressed, stop the loop\n    if cv2.waitKey(1) == ord('q'):\n        break\n\n# release the camera and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n![brightness](Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness.gif)\n\nThe full video can be accessed at https://drive.google.com/file/d/1jz8ETwaZC0zIfCRmNHkV5fICosQPOWay/view?usp=sharing. Please have fun!\n\n### Reference\n\n1. YouTube. (2021, March 30). *Gesture volume control | OPENCV python | computer vision*. YouTube. Retrieved April 2, 2023, from https://www.youtube.com/watch?v=9iEPzbG-xLE&list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q \n","source":"_posts/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe.md","raw":"---\nmathjax: true\ntitle: Hand Gesture Controlled Brightness Adjustment\ndate: 2023-04-02 21:09:27\ntags:\n  - Hand gesture\n  - Mediapipe\n  - OpenCV\n  - Computer vision\n  - Image processing\n  - Real-time tracking\n---\n\nThis code implements a hand gesture-controlled brightness adjustment using OpenCV and Mediapipe libraries. The program uses the camera feed to detect the landmarks of the user's hands and track the movement of the index finger tips.\n\nThe program first initializes the hand detector using the Mediapipe library and opens the camera. It then sets the resolution of the camera and enters a while loop to continuously read the camera feed.\n\nThe program detects the landmarks of the user's hands and tracks the movement of the index finger tips. It draws circles on the index finger tips and a line between the index finger tips of the two hands. It calculates the distance between the two index finger tips and adjusts the brightness of the camera feed based on the distance. \n\nThe program displays the brightness level and distance on the screen using text annotations. The loop continues until the user presses the 'q' key to exit the program.\n\nThe steps involved in the program are:\n\n1. Import the necessary libraries such as OpenCV, Mediapipe, and math.\n2. Initialize the hand detector using the Mediapipe library.\n3. Open the camera feed and set the camera resolution.\n4. Read the camera feed frame by frame and detect the hand landmarks using the hand detector.\n5. Draw landmarks and circles on the index finger tip of each hand.\n6. Calculate the distance between the index finger tips of both hands and adjust the brightness of the camera feed based on the distance.\n7. Display the camera feed with the brightness value and the distance between the index finger tips of both hands.\n8. Stop the program if the 'q' key is pressed, release the camera, and close all windows.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/2/23 22:31\n\nimport cv2\nimport numpy as np\nimport mediapipe as mp\nimport math\n\n# initialize hand detector\nmp_drawing = mp.solutions.drawing_utils\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.8)\n\n# open camera\ncap = cv2.VideoCapture(0)\n\n# set camera resolution\ncap.set(3, 1280)  # width\ncap.set(4, 720)  # height\n\nwhile True:\n    # read camera feed\n    success, img = cap.read()\n    if not success:\n        print(\"Unable to read camera feed\")\n        break\n    if img is None:\n        continue\n    img = cv2.flip(img, 1)\n\n    # detect the hands\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    results = hands.process(img_rgb)\n    if results.multi_hand_landmarks:\n        # check if both hands are detected\n        if len(results.multi_hand_landmarks) == 2:\n            # get the landmarks of the hands\n            lmList1 = results.multi_hand_landmarks[0].landmark\n            lmList2 = results.multi_hand_landmarks[1].landmark\n\n            # get the landmarks for the index fingers\n            h, w, c = img.shape\n            indexTip1 = (int(lmList1[8].x * w), int(lmList1[8].y * h))\n            indexTip2 = (int(lmList2[8].x * w), int(lmList2[8].y * h))\n\n            # draw circles on the index finger tips\n            cv2.circle(img, indexTip1, 15, (255, 0, 0), cv2.FILLED)\n            cv2.circle(img, indexTip2, 15, (255, 0, 0), cv2.FILLED)\n\n            # calculate the distance between the index finger tips of the two hands\n            distance = math.sqrt(\n                (indexTip2[0] - indexTip1[0]) ** 2 + (indexTip2[1] - indexTip1[1]) ** 2)\n\n            # draw a line between the index finger tips\n            cv2.line(img, indexTip1, indexTip2, (255, 0, 0), 3)\n\n            # adjust the brightness of the camera feed based on the distance\n            # brightness is from 0 to 100\n            # distance is from 0 to 1000\n            brightness = distance / 5\n            img = cv2.convertScaleAbs(img, alpha=1, beta=brightness)\n\n            # show the brightness on the screen\n            cv2.putText(img, f\"Brightness: {brightness:.2f}\", (10, 40), cv2.FONT_HERSHEY_PLAIN,\n                        2, (255, 0, 255), 2)\n\n            # draw the distance on the screen\n            cv2.putText(img, f\"Distance: {distance:.2f} pixels\", (10, 70), cv2.FONT_HERSHEY_PLAIN,\n                        2, (255, 0, 255), 2)\n        elif len(results.multi_hand_landmarks) == 1:\n            # if only one hand is detected, show the message on the screen\n            cv2.putText(img, \"Please detect two hands\", (10, 40), cv2.FONT_HERSHEY_PLAIN,\n                        2, (255, 0, 255), 2)\n            # show the blue circle on the index finger tip\n            lmList1 = results.multi_hand_landmarks[0].landmark\n            h, w, c = img.shape\n            indexTip1 = (int(lmList1[8].x * w), int(lmList1[8].y * h))\n            cv2.circle(img, indexTip1, 15, (255, 0, 0), cv2.FILLED)\n        else:\n            brightness = 0\n            img = cv2.convertScaleAbs(img, alpha=1, beta=brightness)\n\n    # show the camera feed\n    cv2.imshow(\"Image\", img)\n\n    # if the 'q' key is pressed, stop the loop\n    if cv2.waitKey(1) == ord('q'):\n        break\n\n# release the camera and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n![brightness](Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness.gif)\n\nThe full video can be accessed at https://drive.google.com/file/d/1jz8ETwaZC0zIfCRmNHkV5fICosQPOWay/view?usp=sharing. Please have fun!\n\n### Reference\n\n1. YouTube. (2021, March 30). *Gesture volume control | OPENCV python | computer vision*. YouTube. Retrieved April 2, 2023, from https://www.youtube.com/watch?v=9iEPzbG-xLE&list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q \n","slug":"Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe","published":1,"updated":"2023-04-07T02:43:50.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gw000fozpigtdj8qlg","content":"<html><head></head><body></body></html><html><head></head><body><p>This code implements a hand gesture-controlled brightness adjustment using OpenCV and Mediapipe libraries. The program uses the camera feed to detect the landmarks of the users hands and track the movement of the index finger tips.</p>\n<p>The program first initializes the hand detector using the Mediapipe library and opens the camera. It then sets the resolution of the camera and enters a while loop to continuously read the camera feed.</p>\n<p>The program detects the landmarks of the users hands and tracks the movement of the index finger tips. It draws circles on the index finger tips and a line between the index finger tips of the two hands. It calculates the distance between the two index finger tips and adjusts the brightness of the camera feed based on the distance. </p>\n<p>The program displays the brightness level and distance on the screen using text annotations. The loop continues until the user presses the q key to exit the program.</p>\n<p>The steps involved in the program are:</p>\n<ol>\n<li>Import the necessary libraries such as OpenCV, Mediapipe, and math.</li>\n<li>Initialize the hand detector using the Mediapipe library.</li>\n<li>Open the camera feed and set the camera resolution.</li>\n<li>Read the camera feed frame by frame and detect the hand landmarks using the hand detector.</li>\n<li>Draw landmarks and circles on the index finger tip of each hand.</li>\n<li>Calculate the distance between the index finger tips of both hands and adjust the brightness of the camera feed based on the distance.</li>\n<li>Display the camera feed with the brightness value and the distance between the index finger tips of both hands.</li>\n<li>Stop the program if the q key is pressed, release the camera, and close all windows.</li>\n</ol>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/2/23 22:31</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> mediapipe <span class=\"keyword\">as</span> mp</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize hand detector</span></span><br><span class=\"line\">mp_drawing = mp.solutions.drawing_utils</span><br><span class=\"line\">mp_hands = mp.solutions.hands</span><br><span class=\"line\">hands = mp_hands.Hands(max_num_hands=<span class=\"number\">2</span>, min_detection_confidence=<span class=\"number\">0.8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># open camera</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set camera resolution</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">3</span>, <span class=\"number\">1280</span>)  <span class=\"comment\"># width</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">4</span>, <span class=\"number\">720</span>)  <span class=\"comment\"># height</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># read camera feed</span></span><br><span class=\"line\">    success, img = cap.read()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"Unable to read camera feed\"</span>)</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> img <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    img = cv2.flip(img, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># detect the hands</span></span><br><span class=\"line\">    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">    results = hands.process(img_rgb)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> results.multi_hand_landmarks:</span><br><span class=\"line\">        <span class=\"comment\"># check if both hands are detected</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(results.multi_hand_landmarks) == <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"comment\"># get the landmarks of the hands</span></span><br><span class=\"line\">            lmList1 = results.multi_hand_landmarks[<span class=\"number\">0</span>].landmark</span><br><span class=\"line\">            lmList2 = results.multi_hand_landmarks[<span class=\"number\">1</span>].landmark</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># get the landmarks for the index fingers</span></span><br><span class=\"line\">            h, w, c = img.shape</span><br><span class=\"line\">            indexTip1 = (<span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].x * w), <span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].y * h))</span><br><span class=\"line\">            indexTip2 = (<span class=\"built_in\">int</span>(lmList2[<span class=\"number\">8</span>].x * w), <span class=\"built_in\">int</span>(lmList2[<span class=\"number\">8</span>].y * h))</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># draw circles on the index finger tips</span></span><br><span class=\"line\">            cv2.circle(img, indexTip1, <span class=\"number\">15</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED)</span><br><span class=\"line\">            cv2.circle(img, indexTip2, <span class=\"number\">15</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># calculate the distance between the index finger tips of the two hands</span></span><br><span class=\"line\">            distance = math.sqrt(</span><br><span class=\"line\">                (indexTip2[<span class=\"number\">0</span>] - indexTip1[<span class=\"number\">0</span>]) ** <span class=\"number\">2</span> + (indexTip2[<span class=\"number\">1</span>] - indexTip1[<span class=\"number\">1</span>]) ** <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># draw a line between the index finger tips</span></span><br><span class=\"line\">            cv2.line(img, indexTip1, indexTip2, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># adjust the brightness of the camera feed based on the distance</span></span><br><span class=\"line\">            <span class=\"comment\"># brightness is from 0 to 100</span></span><br><span class=\"line\">            <span class=\"comment\"># distance is from 0 to 1000</span></span><br><span class=\"line\">            brightness = distance / <span class=\"number\">5</span></span><br><span class=\"line\">            img = cv2.convertScaleAbs(img, alpha=<span class=\"number\">1</span>, beta=brightness)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># show the brightness on the screen</span></span><br><span class=\"line\">            cv2.putText(img, <span class=\"string\">f\"Brightness: <span class=\"subst\">{brightness:<span class=\"number\">.2</span>f}</span>\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">40</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                        <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># draw the distance on the screen</span></span><br><span class=\"line\">            cv2.putText(img, <span class=\"string\">f\"Distance: <span class=\"subst\">{distance:<span class=\"number\">.2</span>f}</span> pixels\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">70</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                        <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"built_in\">len</span>(results.multi_hand_landmarks) == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"comment\"># if only one hand is detected, show the message on the screen</span></span><br><span class=\"line\">            cv2.putText(img, <span class=\"string\">\"Please detect two hands\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">40</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                        <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">            <span class=\"comment\"># show the blue circle on the index finger tip</span></span><br><span class=\"line\">            lmList1 = results.multi_hand_landmarks[<span class=\"number\">0</span>].landmark</span><br><span class=\"line\">            h, w, c = img.shape</span><br><span class=\"line\">            indexTip1 = (<span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].x * w), <span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].y * h))</span><br><span class=\"line\">            cv2.circle(img, indexTip1, <span class=\"number\">15</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            brightness = <span class=\"number\">0</span></span><br><span class=\"line\">            img = cv2.convertScaleAbs(img, alpha=<span class=\"number\">1</span>, beta=brightness)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># show the camera feed</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">\"Image\"</span>, img)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># if the 'q' key is pressed, stop the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) == <span class=\"built_in\">ord</span>(<span class=\"string\">'q'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># release the camera and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"brightness\" data-src=\"/2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness.gif\"></p>\n<p>The full video can be accessed at <a href=\"https://drive.google.com/file/d/1jz8ETwaZC0zIfCRmNHkV5fICosQPOWay/view?usp=sharing\">https://drive.google.com/file/d/1jz8ETwaZC0zIfCRmNHkV5fICosQPOWay/view?usp=sharing</a>. Please have fun!</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>YouTube. (2021, March 30). <em>Gesture volume control | OPENCV python | computer vision</em>. YouTube. Retrieved April 2, 2023, from <a href=\"https://www.youtube.com/watch?v=9iEPzbG-xLE&amp;list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q\">https://www.youtube.com/watch?v=9iEPzbG-xLE&amp;list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q</a> </li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/01/OpenCV-Hand-Tracking-to-Count-Fingers/","2023/03/28/Numpy-Basics/","2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/"],"length":752,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>This code implements a hand gesture-controlled brightness adjustment using OpenCV and Mediapipe libraries. The program uses the camera feed to detect the landmarks of the users hands and track the movement of the index finger tips.</p>\n<p>The program first initializes the hand detector using the Mediapipe library and opens the camera. It then sets the resolution of the camera and enters a while loop to continuously read the camera feed.</p>\n<p>The program detects the landmarks of the users hands and tracks the movement of the index finger tips. It draws circles on the index finger tips and a line between the index finger tips of the two hands. It calculates the distance between the two index finger tips and adjusts the brightness of the camera feed based on the distance. </p>\n<p>The program displays the brightness level and distance on the screen using text annotations. The loop continues until the user presses the q key to exit the program.</p>\n<p>The steps involved in the program are:</p>\n<ol>\n<li>Import the necessary libraries such as OpenCV, Mediapipe, and math.</li>\n<li>Initialize the hand detector using the Mediapipe library.</li>\n<li>Open the camera feed and set the camera resolution.</li>\n<li>Read the camera feed frame by frame and detect the hand landmarks using the hand detector.</li>\n<li>Draw landmarks and circles on the index finger tip of each hand.</li>\n<li>Calculate the distance between the index finger tips of both hands and adjust the brightness of the camera feed based on the distance.</li>\n<li>Display the camera feed with the brightness value and the distance between the index finger tips of both hands.</li>\n<li>Stop the program if the q key is pressed, release the camera, and close all windows.</li>\n</ol>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/2/23 22:31</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> mediapipe <span class=\"keyword\">as</span> mp</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize hand detector</span></span><br><span class=\"line\">mp_drawing = mp.solutions.drawing_utils</span><br><span class=\"line\">mp_hands = mp.solutions.hands</span><br><span class=\"line\">hands = mp_hands.Hands(max_num_hands=<span class=\"number\">2</span>, min_detection_confidence=<span class=\"number\">0.8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># open camera</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set camera resolution</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">3</span>, <span class=\"number\">1280</span>)  <span class=\"comment\"># width</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">4</span>, <span class=\"number\">720</span>)  <span class=\"comment\"># height</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># read camera feed</span></span><br><span class=\"line\">    success, img = cap.read()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"Unable to read camera feed\"</span>)</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> img <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    img = cv2.flip(img, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># detect the hands</span></span><br><span class=\"line\">    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">    results = hands.process(img_rgb)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> results.multi_hand_landmarks:</span><br><span class=\"line\">        <span class=\"comment\"># check if both hands are detected</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(results.multi_hand_landmarks) == <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"comment\"># get the landmarks of the hands</span></span><br><span class=\"line\">            lmList1 = results.multi_hand_landmarks[<span class=\"number\">0</span>].landmark</span><br><span class=\"line\">            lmList2 = results.multi_hand_landmarks[<span class=\"number\">1</span>].landmark</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># get the landmarks for the index fingers</span></span><br><span class=\"line\">            h, w, c = img.shape</span><br><span class=\"line\">            indexTip1 = (<span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].x * w), <span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].y * h))</span><br><span class=\"line\">            indexTip2 = (<span class=\"built_in\">int</span>(lmList2[<span class=\"number\">8</span>].x * w), <span class=\"built_in\">int</span>(lmList2[<span class=\"number\">8</span>].y * h))</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># draw circles on the index finger tips</span></span><br><span class=\"line\">            cv2.circle(img, indexTip1, <span class=\"number\">15</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED)</span><br><span class=\"line\">            cv2.circle(img, indexTip2, <span class=\"number\">15</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># calculate the distance between the index finger tips of the two hands</span></span><br><span class=\"line\">            distance = math.sqrt(</span><br><span class=\"line\">                (indexTip2[<span class=\"number\">0</span>] - indexTip1[<span class=\"number\">0</span>]) ** <span class=\"number\">2</span> + (indexTip2[<span class=\"number\">1</span>] - indexTip1[<span class=\"number\">1</span>]) ** <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># draw a line between the index finger tips</span></span><br><span class=\"line\">            cv2.line(img, indexTip1, indexTip2, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># adjust the brightness of the camera feed based on the distance</span></span><br><span class=\"line\">            <span class=\"comment\"># brightness is from 0 to 100</span></span><br><span class=\"line\">            <span class=\"comment\"># distance is from 0 to 1000</span></span><br><span class=\"line\">            brightness = distance / <span class=\"number\">5</span></span><br><span class=\"line\">            img = cv2.convertScaleAbs(img, alpha=<span class=\"number\">1</span>, beta=brightness)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># show the brightness on the screen</span></span><br><span class=\"line\">            cv2.putText(img, <span class=\"string\">f\"Brightness: <span class=\"subst\">{brightness:<span class=\"number\">.2</span>f}</span>\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">40</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                        <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># draw the distance on the screen</span></span><br><span class=\"line\">            cv2.putText(img, <span class=\"string\">f\"Distance: <span class=\"subst\">{distance:<span class=\"number\">.2</span>f}</span> pixels\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">70</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                        <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"built_in\">len</span>(results.multi_hand_landmarks) == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"comment\"># if only one hand is detected, show the message on the screen</span></span><br><span class=\"line\">            cv2.putText(img, <span class=\"string\">\"Please detect two hands\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">40</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                        <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">            <span class=\"comment\"># show the blue circle on the index finger tip</span></span><br><span class=\"line\">            lmList1 = results.multi_hand_landmarks[<span class=\"number\">0</span>].landmark</span><br><span class=\"line\">            h, w, c = img.shape</span><br><span class=\"line\">            indexTip1 = (<span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].x * w), <span class=\"built_in\">int</span>(lmList1[<span class=\"number\">8</span>].y * h))</span><br><span class=\"line\">            cv2.circle(img, indexTip1, <span class=\"number\">15</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            brightness = <span class=\"number\">0</span></span><br><span class=\"line\">            img = cv2.convertScaleAbs(img, alpha=<span class=\"number\">1</span>, beta=brightness)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># show the camera feed</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">\"Image\"</span>, img)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># if the 'q' key is pressed, stop the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) == <span class=\"built_in\">ord</span>(<span class=\"string\">'q'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># release the camera and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"brightness\" data-src=\"/2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness.gif\"></p>\n<p>The full video can be accessed at <a href=\"https://drive.google.com/file/d/1jz8ETwaZC0zIfCRmNHkV5fICosQPOWay/view?usp=sharing\">https://drive.google.com/file/d/1jz8ETwaZC0zIfCRmNHkV5fICosQPOWay/view?usp=sharing</a>. Please have fun!</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>YouTube. (2021, March 30). <em>Gesture volume control | OPENCV python | computer vision</em>. YouTube. Retrieved April 2, 2023, from <a href=\"https://www.youtube.com/watch?v=9iEPzbG-xLE&amp;list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q\">https://www.youtube.com/watch?v=9iEPzbG-xLE&amp;list=PLMoSUbG1Q_r8jFS04rot-3NzidnV54Z2q</a> </li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Hyperplane","date":"2023-03-28T13:52:39.000Z","_content":"\nIn mathematics, a hyperplane is a subspace of one dimension less than its ambient space. This means that in an n-dimensional space, a hyperplane is an (n-1)-dimensional subspace.\n\nFor example, in two-dimensional space (a plane), a hyperplane is a one-dimensional subspace (a line). In three-dimensional space, a hyperplane is a two-dimensional subspace (a plane).\n\nThe equation of a hyperplane in $n+1$-dimensional space can be written as:\n$$\n\\begin{equation}\na_1 x_1+a_2 x_2+\\cdots+a_n x_n=b\n\\end{equation}\n$$\nwhere $a_1, a_2, \\ldots, a_n$ are constants, $x_1, x_2, \\ldots, x_n$ are variables representing the coordinates of a point in n-dimensional space, and $b$ is a constant.\n\n### Binary classification problem\n\nThe task of binary classification is to classify input data points into one of two classes or categories. This is a supervised learning task where the machine learning algorithm is trained on a labeled dataset where each data point is labeled as belonging to one of the two classes.\n\nIn a 2D environment, the task of binary classification is to find a line (also called a decision boundary) that can separate the two classes in the feature space. The line should be chosen in such a way that the data points belonging to one class lie on one side of the line, and the data points belonging to the other class lie on the other side of the line. \n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\n\n# Generate a random 2D binary classification problem\nX, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=42)\n\n# Train a logistic regression model on the data\nclf = LogisticRegression(random_state=42)\nclf.fit(X, y)\n\n# Plot the data points and the decision boundary\nfig = plt.figure(figsize=(4, 3))\nax = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\nx_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\ny_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\nplt.contour(xx, yy, Z, colors='black', levels=[0.5])\nplt.title('Binary Classification Problem in 2D')\nplt.axis('off')\nplt.grid(False)\nplt.savefig('binary_classification_problem_in_2d.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">   <img src=\"Hyperplane/binary_classification_problem_in_2d.png\" alt=\"binary_classification_problem_in_2d\" style=\"zoom: 33%;\" /> </p>\n\n\n\nIn a 3D environment, the task of binary classification is similar, but the decision boundary is now a plane that separates the two classes. Similarly, in higher-dimensional spaces, the decision boundary is a hyperplane that separates the two classes.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Generate random 3D points\nnp.random.seed(42)\nn_samples = 300\nX = np.random.randn(n_samples, 3)\ny = (X[:, 0] + 2 * X[:, 1] - 0.5 * X[:, 2] > 0).astype(int)\n\n# Find a hyperplane to separate the points\nfrom sklearn.svm import SVC\n\nclf = SVC(kernel='linear', C=10)\nclf.fit(X, y)\n\n# Plot the 3D points and the hyperplane\nfig = plt.figure(figsize=(8, 6))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, cmap='bwr')\nx_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\ny_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\nz_min, z_max = X[:, 2].min() - 0.5, X[:, 2].max() + 0.5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\nzz = (-clf.intercept_[0] - clf.coef_[0][0] * xx - clf.coef_[0][1] * yy) / clf.coef_[0][2]\nax.plot_surface(xx, yy, zz, alpha=0.2, color=\"green\")\nax.set_title('Binary Classification Problem in 3D')\nax.axis('off')\nax.grid(False)\nax.view_init(30, 30)\nplt.savefig('binary_classification_problem_in_3d.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">   <img src=\"Hyperplane/binary_classification_problem_in_3d.png\" alt=\"binary_classification_problem_in_3d\" style=\"zoom:30%;\" />  </p>\n\n","source":"_posts/Hyperplane.md","raw":"---\nmathjax: true\ntitle: Hyperplane\ndate: 2023-03-28 13:52:39\ntags: [Linear algebra, Logistic regression, Hyperplane]\n---\n\nIn mathematics, a hyperplane is a subspace of one dimension less than its ambient space. This means that in an n-dimensional space, a hyperplane is an (n-1)-dimensional subspace.\n\nFor example, in two-dimensional space (a plane), a hyperplane is a one-dimensional subspace (a line). In three-dimensional space, a hyperplane is a two-dimensional subspace (a plane).\n\nThe equation of a hyperplane in $n+1$-dimensional space can be written as:\n$$\n\\begin{equation}\na_1 x_1+a_2 x_2+\\cdots+a_n x_n=b\n\\end{equation}\n$$\nwhere $a_1, a_2, \\ldots, a_n$ are constants, $x_1, x_2, \\ldots, x_n$ are variables representing the coordinates of a point in n-dimensional space, and $b$ is a constant.\n\n### Binary classification problem\n\nThe task of binary classification is to classify input data points into one of two classes or categories. This is a supervised learning task where the machine learning algorithm is trained on a labeled dataset where each data point is labeled as belonging to one of the two classes.\n\nIn a 2D environment, the task of binary classification is to find a line (also called a decision boundary) that can separate the two classes in the feature space. The line should be chosen in such a way that the data points belonging to one class lie on one side of the line, and the data points belonging to the other class lie on the other side of the line. \n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\n\n# Generate a random 2D binary classification problem\nX, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=42)\n\n# Train a logistic regression model on the data\nclf = LogisticRegression(random_state=42)\nclf.fit(X, y)\n\n# Plot the data points and the decision boundary\nfig = plt.figure(figsize=(4, 3))\nax = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\nx_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\ny_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\nplt.contour(xx, yy, Z, colors='black', levels=[0.5])\nplt.title('Binary Classification Problem in 2D')\nplt.axis('off')\nplt.grid(False)\nplt.savefig('binary_classification_problem_in_2d.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">   <img src=\"Hyperplane/binary_classification_problem_in_2d.png\" alt=\"binary_classification_problem_in_2d\" style=\"zoom: 33%;\" /> </p>\n\n\n\nIn a 3D environment, the task of binary classification is similar, but the decision boundary is now a plane that separates the two classes. Similarly, in higher-dimensional spaces, the decision boundary is a hyperplane that separates the two classes.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Generate random 3D points\nnp.random.seed(42)\nn_samples = 300\nX = np.random.randn(n_samples, 3)\ny = (X[:, 0] + 2 * X[:, 1] - 0.5 * X[:, 2] > 0).astype(int)\n\n# Find a hyperplane to separate the points\nfrom sklearn.svm import SVC\n\nclf = SVC(kernel='linear', C=10)\nclf.fit(X, y)\n\n# Plot the 3D points and the hyperplane\nfig = plt.figure(figsize=(8, 6))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, cmap='bwr')\nx_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\ny_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\nz_min, z_max = X[:, 2].min() - 0.5, X[:, 2].max() + 0.5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\nzz = (-clf.intercept_[0] - clf.coef_[0][0] * xx - clf.coef_[0][1] * yy) / clf.coef_[0][2]\nax.plot_surface(xx, yy, zz, alpha=0.2, color=\"green\")\nax.set_title('Binary Classification Problem in 3D')\nax.axis('off')\nax.grid(False)\nax.view_init(30, 30)\nplt.savefig('binary_classification_problem_in_3d.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">   <img src=\"Hyperplane/binary_classification_problem_in_3d.png\" alt=\"binary_classification_problem_in_3d\" style=\"zoom:30%;\" />  </p>\n\n","slug":"Hyperplane","published":1,"updated":"2023-04-07T02:43:50.752Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gx000gozpi9xcb7s3s","content":"<html><head></head><body></body></html><html><head></head><body><p>In mathematics, a hyperplane is a subspace of one dimension less than its ambient space. This means that in an n-dimensional space, a hyperplane is an (n-1)-dimensional subspace.</p>\n<p>For example, in two-dimensional space (a plane), a hyperplane is a one-dimensional subspace (a line). In three-dimensional space, a hyperplane is a two-dimensional subspace (a plane).</p>\n<p>The equation of a hyperplane in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.254ex\" height=\"1.692ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2322.4 748\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1822.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>-dimensional space can be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\na_1 x_1+a_2 x_2+\\cdots+a_n x_n=b\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.76ex\" height=\"1.437ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -441 5640 635\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(562,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(965.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1410.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(562,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2375.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2820.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4159.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4603.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(562,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> are constants, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.052ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 5769 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1008.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1453.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2461.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2906.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4245.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4689.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> are variables representing the coordinates of a point in n-dimensional space, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.971ex\" height=\"1.595ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 429 705\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g></g></g></svg></mjx-container> is a constant.</p>\n<h3 id=\"Binary-classification-problem\"><a href=\"#Binary-classification-problem\" class=\"headerlink\" title=\"Binary classification problem\"></a>Binary classification problem</h3><p>The task of binary classification is to classify input data points into one of two classes or categories. This is a supervised learning task where the machine learning algorithm is trained on a labeled dataset where each data point is labeled as belonging to one of the two classes.</p>\n<p>In a 2D environment, the task of binary classification is to find a line (also called a decision boundary) that can separate the two classes in the feature space. The line should be chosen in such a way that the data points belonging to one class lie on one side of the line, and the data points belonging to the other class lie on the other side of the line. </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_classification</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate a random 2D binary classification problem</span></span><br><span class=\"line\">X, y = make_classification(n_samples=<span class=\"number\">100</span>, n_features=<span class=\"number\">2</span>, n_informative=<span class=\"number\">2</span>, n_redundant=<span class=\"number\">0</span>, n_clusters_per_class=<span class=\"number\">1</span>, random_state=<span class=\"number\">42</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Train a logistic regression model on the data</span></span><br><span class=\"line\">clf = LogisticRegression(random_state=<span class=\"number\">42</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data points and the decision boundary</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">4</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">ax = plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, cmap=<span class=\"string\">'bwr'</span>)</span><br><span class=\"line\">x_min, x_max = X[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">y_min, y_max = X[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>), np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\">Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class=\"line\">Z = Z.reshape(xx.shape)</span><br><span class=\"line\">plt.contour(xx, yy, Z, colors=<span class=\"string\">'black'</span>, levels=[<span class=\"number\">0.5</span>])</span><br><span class=\"line\">plt.title(<span class=\"string\">'Binary Classification Problem in 2D'</span>)</span><br><span class=\"line\">plt.axis(<span class=\"string\">'off'</span>)</span><br><span class=\"line\">plt.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binary_classification_problem_in_2d.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">   <img alt=\"binary_classification_problem_in_2d\" style=\"zoom: 33%;\" data-src=\"/2023/03/28/Hyperplane/binary_classification_problem_in_2d.png\"> </p>\n\n\n\n<p>In a 3D environment, the task of binary classification is similar, but the decision boundary is now a plane that separates the two classes. Similarly, in higher-dimensional spaces, the decision boundary is a hyperplane that separates the two classes.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate random 3D points</span></span><br><span class=\"line\">np.random.seed(<span class=\"number\">42</span>)</span><br><span class=\"line\">n_samples = <span class=\"number\">300</span></span><br><span class=\"line\">X = np.random.randn(n_samples, <span class=\"number\">3</span>)</span><br><span class=\"line\">y = (X[:, <span class=\"number\">0</span>] + <span class=\"number\">2</span> * X[:, <span class=\"number\">1</span>] - <span class=\"number\">0.5</span> * X[:, <span class=\"number\">2</span>] &gt; <span class=\"number\">0</span>).astype(<span class=\"built_in\">int</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find a hyperplane to separate the points</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"></span><br><span class=\"line\">clf = SVC(kernel=<span class=\"string\">'linear'</span>, C=<span class=\"number\">10</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the 3D points and the hyperplane</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], X[:, <span class=\"number\">2</span>], c=y, cmap=<span class=\"string\">'bwr'</span>)</span><br><span class=\"line\">x_min, x_max = X[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">y_min, y_max = X[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">z_min, z_max = X[:, <span class=\"number\">2</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">2</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>), np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\">zz = (-clf.intercept_[<span class=\"number\">0</span>] - clf.coef_[<span class=\"number\">0</span>][<span class=\"number\">0</span>] * xx - clf.coef_[<span class=\"number\">0</span>][<span class=\"number\">1</span>] * yy) / clf.coef_[<span class=\"number\">0</span>][<span class=\"number\">2</span>]</span><br><span class=\"line\">ax.plot_surface(xx, yy, zz, alpha=<span class=\"number\">0.2</span>, color=<span class=\"string\">\"green\"</span>)</span><br><span class=\"line\">ax.set_title(<span class=\"string\">'Binary Classification Problem in 3D'</span>)</span><br><span class=\"line\">ax.axis(<span class=\"string\">'off'</span>)</span><br><span class=\"line\">ax.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\">ax.view_init(<span class=\"number\">30</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binary_classification_problem_in_3d.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">   <img alt=\"binary_classification_problem_in_3d\" style=\"zoom:30%;\" data-src=\"/2023/03/28/Hyperplane/binary_classification_problem_in_3d.png\">  </p>\n\n</body></html>","site":{"data":{}},"related_posts":["2023/03/29/From-linear-regression-to-binary-classification/","2023/04/01/Sentiment-Analysis-on-Product-Reviews/","2023/04/03/Relationships-between-two-Sets/"],"length":616,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>In mathematics, a hyperplane is a subspace of one dimension less than its ambient space. This means that in an n-dimensional space, a hyperplane is an (n-1)-dimensional subspace.</p>\n<p>For example, in two-dimensional space (a plane), a hyperplane is a one-dimensional subspace (a line). In three-dimensional space, a hyperplane is a two-dimensional subspace (a plane).</p>\n<p>The equation of a hyperplane in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.254ex\" height=\"1.692ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2322.4 748\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(822.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1822.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>-dimensional space can be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\na_1 x_1+a_2 x_2+\\cdots+a_n x_n=b\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"12.76ex\" height=\"1.437ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -441 5640 635\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(562,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(965.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1410.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(562,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2375.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2820.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4159.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4603.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(562,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> are constants, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.052ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 5769 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1008.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1453.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2461.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2906.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4245.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4689.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> are variables representing the coordinates of a point in n-dimensional space, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.971ex\" height=\"1.595ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 429 705\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g></g></g></svg></mjx-container> is a constant.</p>\n<h3 id=\"Binary-classification-problem\"><a href=\"#Binary-classification-problem\" class=\"headerlink\" title=\"Binary classification problem\"></a>Binary classification problem</h3><p>The task of binary classification is to classify input data points into one of two classes or categories. This is a supervised learning task where the machine learning algorithm is trained on a labeled dataset where each data point is labeled as belonging to one of the two classes.</p>\n<p>In a 2D environment, the task of binary classification is to find a line (also called a decision boundary) that can separate the two classes in the feature space. The line should be chosen in such a way that the data points belonging to one class lie on one side of the line, and the data points belonging to the other class lie on the other side of the line. </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_classification</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate a random 2D binary classification problem</span></span><br><span class=\"line\">X, y = make_classification(n_samples=<span class=\"number\">100</span>, n_features=<span class=\"number\">2</span>, n_informative=<span class=\"number\">2</span>, n_redundant=<span class=\"number\">0</span>, n_clusters_per_class=<span class=\"number\">1</span>, random_state=<span class=\"number\">42</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Train a logistic regression model on the data</span></span><br><span class=\"line\">clf = LogisticRegression(random_state=<span class=\"number\">42</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data points and the decision boundary</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">4</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">ax = plt.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], c=y, cmap=<span class=\"string\">'bwr'</span>)</span><br><span class=\"line\">x_min, x_max = X[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">y_min, y_max = X[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>), np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\">Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class=\"line\">Z = Z.reshape(xx.shape)</span><br><span class=\"line\">plt.contour(xx, yy, Z, colors=<span class=\"string\">'black'</span>, levels=[<span class=\"number\">0.5</span>])</span><br><span class=\"line\">plt.title(<span class=\"string\">'Binary Classification Problem in 2D'</span>)</span><br><span class=\"line\">plt.axis(<span class=\"string\">'off'</span>)</span><br><span class=\"line\">plt.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binary_classification_problem_in_2d.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">   <img alt=\"binary_classification_problem_in_2d\" style=\"zoom: 33%;\" data-src=\"/2023/03/28/Hyperplane/binary_classification_problem_in_2d.png\"> </p>\n\n\n\n<p>In a 3D environment, the task of binary classification is similar, but the decision boundary is now a plane that separates the two classes. Similarly, in higher-dimensional spaces, the decision boundary is a hyperplane that separates the two classes.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate random 3D points</span></span><br><span class=\"line\">np.random.seed(<span class=\"number\">42</span>)</span><br><span class=\"line\">n_samples = <span class=\"number\">300</span></span><br><span class=\"line\">X = np.random.randn(n_samples, <span class=\"number\">3</span>)</span><br><span class=\"line\">y = (X[:, <span class=\"number\">0</span>] + <span class=\"number\">2</span> * X[:, <span class=\"number\">1</span>] - <span class=\"number\">0.5</span> * X[:, <span class=\"number\">2</span>] &gt; <span class=\"number\">0</span>).astype(<span class=\"built_in\">int</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Find a hyperplane to separate the points</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"></span><br><span class=\"line\">clf = SVC(kernel=<span class=\"string\">'linear'</span>, C=<span class=\"number\">10</span>)</span><br><span class=\"line\">clf.fit(X, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the 3D points and the hyperplane</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax.scatter(X[:, <span class=\"number\">0</span>], X[:, <span class=\"number\">1</span>], X[:, <span class=\"number\">2</span>], c=y, cmap=<span class=\"string\">'bwr'</span>)</span><br><span class=\"line\">x_min, x_max = X[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">y_min, y_max = X[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">z_min, z_max = X[:, <span class=\"number\">2</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">0.5</span>, X[:, <span class=\"number\">2</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">0.5</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>), np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\">zz = (-clf.intercept_[<span class=\"number\">0</span>] - clf.coef_[<span class=\"number\">0</span>][<span class=\"number\">0</span>] * xx - clf.coef_[<span class=\"number\">0</span>][<span class=\"number\">1</span>] * yy) / clf.coef_[<span class=\"number\">0</span>][<span class=\"number\">2</span>]</span><br><span class=\"line\">ax.plot_surface(xx, yy, zz, alpha=<span class=\"number\">0.2</span>, color=<span class=\"string\">\"green\"</span>)</span><br><span class=\"line\">ax.set_title(<span class=\"string\">'Binary Classification Problem in 3D'</span>)</span><br><span class=\"line\">ax.axis(<span class=\"string\">'off'</span>)</span><br><span class=\"line\">ax.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\">ax.view_init(<span class=\"number\">30</span>, <span class=\"number\">30</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'binary_classification_problem_in_3d.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">   <img alt=\"binary_classification_problem_in_3d\" style=\"zoom:30%;\" data-src=\"/2023/03/28/Hyperplane/binary_classification_problem_in_3d.png\">  </p>\n\n</body></html>"},{"mathjax":true,"title":"Image processing using Numpy","date":"2023-03-28T07:10:36.000Z","_content":"\n### Change the oder of RGB\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 10:06\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Read image and convert it to a 3D array\nimg = plt.imread('bean.png')\n\nplt.figure(figsize=(8, 10))  # Create a figure with size 10x10\n\n# Show the original image\nplt.subplot(2, 2, 1)  # Create a subplot for the original image\nplt.imshow(img)       # Show the original image\nplt.title('Original image(RGB)\\n image.shape = {}'.format(img.shape))\n\n# Rearrange the RGB channels to GBR order\nimg_gbr = img[:,:,[1,2,0]]\nplt.subplot(2, 2, 2)  # Create a subplot for the GBR image\nplt.imshow(img_gbr)   # Show the GBR image\nplt.title('GBR order\\n image.shape = {}'.format(img_gbr.shape))\n\n# Rearrange the RGB channels to BRG order\nimg_brg = img[:,:,[2,0,1]]\nplt.subplot(2, 2, 3)  # Create a subplot for the BRG image\nplt.imshow(img_brg)   # Show the BRG image\nplt.title('BRG order\\n image.shape = {}'.format(img_brg.shape))\n\n\n# Rearrange the RGB channels to RBG order\nimg_rbg = img[:,:,[0,2,1]]\nplt.subplot(2, 2, 4)  # Create a subplot for the RBG image\nplt.title('RBG order\\n image.shape = {}'.format(img_rbg.shape))\nplt.imshow(img_rbg)   # Show the RBG image\n\nplt.savefig(\"rose_chanel_order.png\", dpi=300, bbox_inches='tight', pad_inches=0)\nplt.show()            # Show the figure with all the subplots\n```\n\n![rose_chanel_order](Image-processing-using-Numpy/rose_chanel_order.png)\n\n### Single channel \n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 10:06\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Read image and convert it to a 3D array\nimg = plt.imread('rose.png')\nprint(\"Image shape: \", img.shape)\n\nplt.figure(figsize=(8, 9))\n\n# Convert the color image to grayscale\ngray_img = np.dot(img[..., :3], [0.2989, 0.5870, 0.1140])\n\n# Show the red, green, and blue channels separately\nplt.subplot(2, 2, 1)            # Create a subplot for the red channel\nplt.imshow(img[:, :, 0], cmap='Reds')   # Show the red channel by indexing the first dimension\nplt.title('Red channel\\nShape: {}'.format(img[:, :, 0].shape))  # Add a title for the subplot with the shape of the channel\n\nplt.subplot(2, 2, 2)            # Create a subplot for the green channel\nplt.imshow(img[:, :, 1], cmap='Greens')  # Show the green channel by indexing the second dimension\nplt.title('Green channel\\nShape: {}'.format(img[:, :, 1].shape)) # Add a title for the subplot with the shape of the channel\n\nplt.subplot(2, 2, 3)            # Create a subplot for the blue channel\nplt.imshow(img[:, :, 2], cmap='Blues')   # Show the blue channel by indexing the third dimension\nplt.title('Blue channel\\nShape: {}'.format(img[:, :, 2].shape))  # Add a title for the subplot with the shape of the channel\n\n# Show the grayscale image\nplt.subplot(2, 2, 4)  # Create a subplot for the grayscale image\nplt.imshow(gray_img, cmap='gray')  # Show the grayscale image using the 'gray' colormap\nplt.title('Grayscale image\\nShape: {}'.format(gray_img.shape))  # Add a title for the subplot with the shape of the image\n\nplt.savefig('rose_channels.png', dpi=300, bbox_inches='tight', pad_inches=0.0)  # Save the figure\n\nplt.show()  # Show the figure with all the subplots\n```\n\n![rose_channels](Image-processing-using-Numpy/rose_channels.png)\n","source":"_posts/Image-processing-using-Numpy.md","raw":"---\nmathjax: true\ntitle: Image processing using Numpy\ndate: 2023-03-28 07:10:36\ntags: [Python, Numpy, Image processing]\n---\n\n### Change the oder of RGB\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 10:06\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Read image and convert it to a 3D array\nimg = plt.imread('bean.png')\n\nplt.figure(figsize=(8, 10))  # Create a figure with size 10x10\n\n# Show the original image\nplt.subplot(2, 2, 1)  # Create a subplot for the original image\nplt.imshow(img)       # Show the original image\nplt.title('Original image(RGB)\\n image.shape = {}'.format(img.shape))\n\n# Rearrange the RGB channels to GBR order\nimg_gbr = img[:,:,[1,2,0]]\nplt.subplot(2, 2, 2)  # Create a subplot for the GBR image\nplt.imshow(img_gbr)   # Show the GBR image\nplt.title('GBR order\\n image.shape = {}'.format(img_gbr.shape))\n\n# Rearrange the RGB channels to BRG order\nimg_brg = img[:,:,[2,0,1]]\nplt.subplot(2, 2, 3)  # Create a subplot for the BRG image\nplt.imshow(img_brg)   # Show the BRG image\nplt.title('BRG order\\n image.shape = {}'.format(img_brg.shape))\n\n\n# Rearrange the RGB channels to RBG order\nimg_rbg = img[:,:,[0,2,1]]\nplt.subplot(2, 2, 4)  # Create a subplot for the RBG image\nplt.title('RBG order\\n image.shape = {}'.format(img_rbg.shape))\nplt.imshow(img_rbg)   # Show the RBG image\n\nplt.savefig(\"rose_chanel_order.png\", dpi=300, bbox_inches='tight', pad_inches=0)\nplt.show()            # Show the figure with all the subplots\n```\n\n![rose_chanel_order](Image-processing-using-Numpy/rose_chanel_order.png)\n\n### Single channel \n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 10:06\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Read image and convert it to a 3D array\nimg = plt.imread('rose.png')\nprint(\"Image shape: \", img.shape)\n\nplt.figure(figsize=(8, 9))\n\n# Convert the color image to grayscale\ngray_img = np.dot(img[..., :3], [0.2989, 0.5870, 0.1140])\n\n# Show the red, green, and blue channels separately\nplt.subplot(2, 2, 1)            # Create a subplot for the red channel\nplt.imshow(img[:, :, 0], cmap='Reds')   # Show the red channel by indexing the first dimension\nplt.title('Red channel\\nShape: {}'.format(img[:, :, 0].shape))  # Add a title for the subplot with the shape of the channel\n\nplt.subplot(2, 2, 2)            # Create a subplot for the green channel\nplt.imshow(img[:, :, 1], cmap='Greens')  # Show the green channel by indexing the second dimension\nplt.title('Green channel\\nShape: {}'.format(img[:, :, 1].shape)) # Add a title for the subplot with the shape of the channel\n\nplt.subplot(2, 2, 3)            # Create a subplot for the blue channel\nplt.imshow(img[:, :, 2], cmap='Blues')   # Show the blue channel by indexing the third dimension\nplt.title('Blue channel\\nShape: {}'.format(img[:, :, 2].shape))  # Add a title for the subplot with the shape of the channel\n\n# Show the grayscale image\nplt.subplot(2, 2, 4)  # Create a subplot for the grayscale image\nplt.imshow(gray_img, cmap='gray')  # Show the grayscale image using the 'gray' colormap\nplt.title('Grayscale image\\nShape: {}'.format(gray_img.shape))  # Add a title for the subplot with the shape of the image\n\nplt.savefig('rose_channels.png', dpi=300, bbox_inches='tight', pad_inches=0.0)  # Save the figure\n\nplt.show()  # Show the figure with all the subplots\n```\n\n![rose_channels](Image-processing-using-Numpy/rose_channels.png)\n","slug":"Image-processing-using-Numpy","published":1,"updated":"2023-04-07T02:43:50.752Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73gz000iozpi50gu7ymx","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Change-the-oder-of-RGB\"><a href=\"#Change-the-oder-of-RGB\" class=\"headerlink\" title=\"Change the oder of RGB\"></a>Change the oder of RGB</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 10:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Read image and convert it to a 3D array</span></span><br><span class=\"line\">img = plt.imread(<span class=\"string\">'bean.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">10</span>))  <span class=\"comment\"># Create a figure with size 10x10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the original image</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)  <span class=\"comment\"># Create a subplot for the original image</span></span><br><span class=\"line\">plt.imshow(img)       <span class=\"comment\"># Show the original image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Original image(RGB)\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img.shape))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Rearrange the RGB channels to GBR order</span></span><br><span class=\"line\">img_gbr = img[:,:,[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>]]</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)  <span class=\"comment\"># Create a subplot for the GBR image</span></span><br><span class=\"line\">plt.imshow(img_gbr)   <span class=\"comment\"># Show the GBR image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'GBR order\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img_gbr.shape))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Rearrange the RGB channels to BRG order</span></span><br><span class=\"line\">img_brg = img[:,:,[<span class=\"number\">2</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>]]</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># Create a subplot for the BRG image</span></span><br><span class=\"line\">plt.imshow(img_brg)   <span class=\"comment\"># Show the BRG image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'BRG order\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img_brg.shape))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Rearrange the RGB channels to RBG order</span></span><br><span class=\"line\">img_rbg = img[:,:,[<span class=\"number\">0</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>]]</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)  <span class=\"comment\"># Create a subplot for the RBG image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'RBG order\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img_rbg.shape))</span><br><span class=\"line\">plt.imshow(img_rbg)   <span class=\"comment\"># Show the RBG image</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"rose_chanel_order.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.show()            <span class=\"comment\"># Show the figure with all the subplots</span></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"rose_chanel_order\" data-src=\"/2023/03/28/Image-processing-using-Numpy/rose_chanel_order.png\"></p>\n<h3 id=\"Single-channel\"><a href=\"#Single-channel\" class=\"headerlink\" title=\"Single channel\"></a>Single channel</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 10:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Read image and convert it to a 3D array</span></span><br><span class=\"line\">img = plt.imread(<span class=\"string\">'rose.png'</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Image shape: \"</span>, img.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">9</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Convert the color image to grayscale</span></span><br><span class=\"line\">gray_img = np.dot(img[..., :<span class=\"number\">3</span>], [<span class=\"number\">0.2989</span>, <span class=\"number\">0.5870</span>, <span class=\"number\">0.1140</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the red, green, and blue channels separately</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)            <span class=\"comment\"># Create a subplot for the red channel</span></span><br><span class=\"line\">plt.imshow(img[:, :, <span class=\"number\">0</span>], cmap=<span class=\"string\">'Reds'</span>)   <span class=\"comment\"># Show the red channel by indexing the first dimension</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Red channel\\nShape: {}'</span>.<span class=\"built_in\">format</span>(img[:, :, <span class=\"number\">0</span>].shape))  <span class=\"comment\"># Add a title for the subplot with the shape of the channel</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)            <span class=\"comment\"># Create a subplot for the green channel</span></span><br><span class=\"line\">plt.imshow(img[:, :, <span class=\"number\">1</span>], cmap=<span class=\"string\">'Greens'</span>)  <span class=\"comment\"># Show the green channel by indexing the second dimension</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Green channel\\nShape: {}'</span>.<span class=\"built_in\">format</span>(img[:, :, <span class=\"number\">1</span>].shape)) <span class=\"comment\"># Add a title for the subplot with the shape of the channel</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)            <span class=\"comment\"># Create a subplot for the blue channel</span></span><br><span class=\"line\">plt.imshow(img[:, :, <span class=\"number\">2</span>], cmap=<span class=\"string\">'Blues'</span>)   <span class=\"comment\"># Show the blue channel by indexing the third dimension</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Blue channel\\nShape: {}'</span>.<span class=\"built_in\">format</span>(img[:, :, <span class=\"number\">2</span>].shape))  <span class=\"comment\"># Add a title for the subplot with the shape of the channel</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the grayscale image</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)  <span class=\"comment\"># Create a subplot for the grayscale image</span></span><br><span class=\"line\">plt.imshow(gray_img, cmap=<span class=\"string\">'gray'</span>)  <span class=\"comment\"># Show the grayscale image using the 'gray' colormap</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Grayscale image\\nShape: {}'</span>.<span class=\"built_in\">format</span>(gray_img.shape))  <span class=\"comment\"># Add a title for the subplot with the shape of the image</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'rose_channels.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.0</span>)  <span class=\"comment\"># Save the figure</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()  <span class=\"comment\"># Show the figure with all the subplots</span></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"rose_channels\" data-src=\"/2023/03/28/Image-processing-using-Numpy/rose_channels.png\"></p>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/28/Numpy-Basics/","2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/","2023/03/27/Linear-Algebra-Basics/"],"length":464,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Change-the-oder-of-RGB\"><a href=\"#Change-the-oder-of-RGB\" class=\"headerlink\" title=\"Change the oder of RGB\"></a>Change the oder of RGB</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 10:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Read image and convert it to a 3D array</span></span><br><span class=\"line\">img = plt.imread(<span class=\"string\">'bean.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">10</span>))  <span class=\"comment\"># Create a figure with size 10x10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the original image</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)  <span class=\"comment\"># Create a subplot for the original image</span></span><br><span class=\"line\">plt.imshow(img)       <span class=\"comment\"># Show the original image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Original image(RGB)\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img.shape))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Rearrange the RGB channels to GBR order</span></span><br><span class=\"line\">img_gbr = img[:,:,[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>]]</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)  <span class=\"comment\"># Create a subplot for the GBR image</span></span><br><span class=\"line\">plt.imshow(img_gbr)   <span class=\"comment\"># Show the GBR image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'GBR order\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img_gbr.shape))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Rearrange the RGB channels to BRG order</span></span><br><span class=\"line\">img_brg = img[:,:,[<span class=\"number\">2</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>]]</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># Create a subplot for the BRG image</span></span><br><span class=\"line\">plt.imshow(img_brg)   <span class=\"comment\"># Show the BRG image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'BRG order\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img_brg.shape))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Rearrange the RGB channels to RBG order</span></span><br><span class=\"line\">img_rbg = img[:,:,[<span class=\"number\">0</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>]]</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)  <span class=\"comment\"># Create a subplot for the RBG image</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'RBG order\\n image.shape = {}'</span>.<span class=\"built_in\">format</span>(img_rbg.shape))</span><br><span class=\"line\">plt.imshow(img_rbg)   <span class=\"comment\"># Show the RBG image</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"rose_chanel_order.png\"</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.show()            <span class=\"comment\"># Show the figure with all the subplots</span></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"rose_chanel_order\" data-src=\"/2023/03/28/Image-processing-using-Numpy/rose_chanel_order.png\"></p>\n<h3 id=\"Single-channel\"><a href=\"#Single-channel\" class=\"headerlink\" title=\"Single channel\"></a>Single channel</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 10:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Read image and convert it to a 3D array</span></span><br><span class=\"line\">img = plt.imread(<span class=\"string\">'rose.png'</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Image shape: \"</span>, img.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">9</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Convert the color image to grayscale</span></span><br><span class=\"line\">gray_img = np.dot(img[..., :<span class=\"number\">3</span>], [<span class=\"number\">0.2989</span>, <span class=\"number\">0.5870</span>, <span class=\"number\">0.1140</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the red, green, and blue channels separately</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)            <span class=\"comment\"># Create a subplot for the red channel</span></span><br><span class=\"line\">plt.imshow(img[:, :, <span class=\"number\">0</span>], cmap=<span class=\"string\">'Reds'</span>)   <span class=\"comment\"># Show the red channel by indexing the first dimension</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Red channel\\nShape: {}'</span>.<span class=\"built_in\">format</span>(img[:, :, <span class=\"number\">0</span>].shape))  <span class=\"comment\"># Add a title for the subplot with the shape of the channel</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)            <span class=\"comment\"># Create a subplot for the green channel</span></span><br><span class=\"line\">plt.imshow(img[:, :, <span class=\"number\">1</span>], cmap=<span class=\"string\">'Greens'</span>)  <span class=\"comment\"># Show the green channel by indexing the second dimension</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Green channel\\nShape: {}'</span>.<span class=\"built_in\">format</span>(img[:, :, <span class=\"number\">1</span>].shape)) <span class=\"comment\"># Add a title for the subplot with the shape of the channel</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)            <span class=\"comment\"># Create a subplot for the blue channel</span></span><br><span class=\"line\">plt.imshow(img[:, :, <span class=\"number\">2</span>], cmap=<span class=\"string\">'Blues'</span>)   <span class=\"comment\"># Show the blue channel by indexing the third dimension</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Blue channel\\nShape: {}'</span>.<span class=\"built_in\">format</span>(img[:, :, <span class=\"number\">2</span>].shape))  <span class=\"comment\"># Add a title for the subplot with the shape of the channel</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Show the grayscale image</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">4</span>)  <span class=\"comment\"># Create a subplot for the grayscale image</span></span><br><span class=\"line\">plt.imshow(gray_img, cmap=<span class=\"string\">'gray'</span>)  <span class=\"comment\"># Show the grayscale image using the 'gray' colormap</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'Grayscale image\\nShape: {}'</span>.<span class=\"built_in\">format</span>(gray_img.shape))  <span class=\"comment\"># Add a title for the subplot with the shape of the image</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'rose_channels.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.0</span>)  <span class=\"comment\"># Save the figure</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()  <span class=\"comment\"># Show the figure with all the subplots</span></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"rose_channels\" data-src=\"/2023/03/28/Image-processing-using-Numpy/rose_channels.png\"></p>\n</body></html>"},{"mathjax":true,"title":"Scalar, Vector, Matrix, Tensor","date":"2023-03-27T18:03:48.000Z","_content":"\nScalars: A scalar is a quantity that has only magnitude and no direction. It is a single value that can be represented by a number. \n\nVectors: A vector is a mathematical object that has both magnitude and direction. It can be represented by an ordered list of numbers, or coordinates, that describe the vector's components in a particular coordinate system.\n$$\n\\begin{equation}\n\\text { Column vector } v \\quad v=\\left[\\begin{array}{l}\nv_1 \\\\\nv_2\n\\end{array}\\right] \\quad \\begin{aligned}\n& v_1=\\text { first component of } \\boldsymbol{v} \\\\\n& v_2=\\text { second component of } \\boldsymbol{v}\n\\end{aligned}\n\\end{equation}\n$$\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 20:27\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the 2D vector\nv = np.array([3, 4])\n\n# Define the starting point of the vector\nstart = np.array([0, 0])\n\n# Plot the vector\nfig, ax = plt.subplots(figsize=(5, 5))\nax.quiver(*start, *v, scale=1, scale_units='xy', angles='xy', color='r', width=0.005)\nax.set_xlim(0, 5)\nax.set_ylim(0, 5)\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_aspect('equal')\nplt.grid()\n# annotate the vector\nax.annotate('(3,4)', v, ha='center', va='center', fontsize=15)\n# title\nplt.title('2D Vector')\n# save the figure\nplt.savefig('2d_vector.png', dpi=300, bbox_inches='tight', pad_inches=0)\nplt.show()\n```\n\n<p align=\"center\">\n<img src=\"Linear-Algebra-Basics/2d_vector.png\" alt=\"2d_vector\" style=\"zoom:30%;\" />\n</p>\n\nThe formula to calculate the length of a $2 D$ vector with components $(x, y)$ is:\n$$\n|\\boldsymbol{v}|=\\sqrt{x^2+y^2}\n$$\nMatrices: A matrix is a rectangular array of numbers, arranged in rows and columns. It can be used to represent data, systems of linear equations, and transformations in linear algebra.\n$$\n\n\\begin{equation}\nA=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right] \\text { is a } 3 \\text { by } 2 \\text { matrix : } m=3 \\text { rows and } n=2 \\text { columns. }\n\\end{equation}\n$$\nTensors: A tensor is a generalization of vectors and matrices, and is used to represent higher-order data or multidimensional arrays. Tensors can have any number of dimensions, and can be used to represent complex systems, such as those found in physics, engineering, and machine learning.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 20:27\n\nimport numpy as np\n\n# Scalars\nscalar = 5\nprint(\"Scalar:\", scalar)\n# Scalars have no dimensions, so they do not have a shape.\n\n# Vectors\nvector = np.array([1, 2, 3])\nprint(\"Vector:\", vector)\nprint(\"Vector shape:\", vector.shape)\n# 1-dimensional vector with 3 elements\n\n# Matrices\nmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(\"Matrix:\\n\", matrix)\nprint(\"Matrix shape:\", matrix.shape)\n# 2-dimensional matrix with 3 rows and 3 columns\n\n# Tensors\ntensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\nprint(\"Tensor:\\n\", tensor)\nprint(\"Tensor shape:\", tensor.shape)\n# 3-dimensional tensor with 2 matrices, each with 2 rows and 2 columns\n```\n\n","source":"_posts/Linear-Algebra-Basics.md","raw":"---\nmathjax: true\ntitle: Scalar, Vector, Matrix, Tensor\ndate: 2023-03-27 18:03:48\ntags: [Linear algebra, Matrix, Python, Basics]\n---\n\nScalars: A scalar is a quantity that has only magnitude and no direction. It is a single value that can be represented by a number. \n\nVectors: A vector is a mathematical object that has both magnitude and direction. It can be represented by an ordered list of numbers, or coordinates, that describe the vector's components in a particular coordinate system.\n$$\n\\begin{equation}\n\\text { Column vector } v \\quad v=\\left[\\begin{array}{l}\nv_1 \\\\\nv_2\n\\end{array}\\right] \\quad \\begin{aligned}\n& v_1=\\text { first component of } \\boldsymbol{v} \\\\\n& v_2=\\text { second component of } \\boldsymbol{v}\n\\end{aligned}\n\\end{equation}\n$$\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 20:27\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the 2D vector\nv = np.array([3, 4])\n\n# Define the starting point of the vector\nstart = np.array([0, 0])\n\n# Plot the vector\nfig, ax = plt.subplots(figsize=(5, 5))\nax.quiver(*start, *v, scale=1, scale_units='xy', angles='xy', color='r', width=0.005)\nax.set_xlim(0, 5)\nax.set_ylim(0, 5)\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_aspect('equal')\nplt.grid()\n# annotate the vector\nax.annotate('(3,4)', v, ha='center', va='center', fontsize=15)\n# title\nplt.title('2D Vector')\n# save the figure\nplt.savefig('2d_vector.png', dpi=300, bbox_inches='tight', pad_inches=0)\nplt.show()\n```\n\n<p align=\"center\">\n<img src=\"Linear-Algebra-Basics/2d_vector.png\" alt=\"2d_vector\" style=\"zoom:30%;\" />\n</p>\n\nThe formula to calculate the length of a $2 D$ vector with components $(x, y)$ is:\n$$\n|\\boldsymbol{v}|=\\sqrt{x^2+y^2}\n$$\nMatrices: A matrix is a rectangular array of numbers, arranged in rows and columns. It can be used to represent data, systems of linear equations, and transformations in linear algebra.\n$$\n\n\\begin{equation}\nA=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right] \\text { is a } 3 \\text { by } 2 \\text { matrix : } m=3 \\text { rows and } n=2 \\text { columns. }\n\\end{equation}\n$$\nTensors: A tensor is a generalization of vectors and matrices, and is used to represent higher-order data or multidimensional arrays. Tensors can have any number of dimensions, and can be used to represent complex systems, such as those found in physics, engineering, and machine learning.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 20:27\n\nimport numpy as np\n\n# Scalars\nscalar = 5\nprint(\"Scalar:\", scalar)\n# Scalars have no dimensions, so they do not have a shape.\n\n# Vectors\nvector = np.array([1, 2, 3])\nprint(\"Vector:\", vector)\nprint(\"Vector shape:\", vector.shape)\n# 1-dimensional vector with 3 elements\n\n# Matrices\nmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(\"Matrix:\\n\", matrix)\nprint(\"Matrix shape:\", matrix.shape)\n# 2-dimensional matrix with 3 rows and 3 columns\n\n# Tensors\ntensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\nprint(\"Tensor:\\n\", tensor)\nprint(\"Tensor shape:\", tensor.shape)\n# 3-dimensional tensor with 2 matrices, each with 2 rows and 2 columns\n```\n\n","slug":"Linear-Algebra-Basics","published":1,"updated":"2023-04-07T02:43:50.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73h0000kozpig3zy1gp4","content":"<html><head></head><body></body></html><html><head></head><body><p>Scalars: A scalar is a quantity that has only magnitude and no direction. It is a single value that can be represented by a number. </p>\n<p>Vectors: A vector is a mathematical object that has both magnitude and direction. It can be represented by an ordered list of numbers, or coordinates, that describe the vectors components in a particular coordinate system.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { Column vector } v \\quad v=\\left[\\begin{array}{l}\nv_1 \\\\\nv_2\n\\end{array}\\right] \\quad \\begin{aligned}\n& v_1=\\text { first component of } \\boldsymbol{v} \\\\\n& v_2=\\text { second component of } \\boldsymbol{v}\n\\end{aligned}\n\\end{equation}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 20:27</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the 2D vector</span></span><br><span class=\"line\">v = np.array([<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the starting point of the vector</span></span><br><span class=\"line\">start = np.array([<span class=\"number\">0</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the vector</span></span><br><span class=\"line\">fig, ax = plt.subplots(figsize=(<span class=\"number\">5</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">ax.quiver(*start, *v, scale=<span class=\"number\">1</span>, scale_units=<span class=\"string\">'xy'</span>, angles=<span class=\"string\">'xy'</span>, color=<span class=\"string\">'r'</span>, width=<span class=\"number\">0.005</span>)</span><br><span class=\"line\">ax.set_xlim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_ylim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">ax.set_aspect(<span class=\"string\">'equal'</span>)</span><br><span class=\"line\">plt.grid()</span><br><span class=\"line\"><span class=\"comment\"># annotate the vector</span></span><br><span class=\"line\">ax.annotate(<span class=\"string\">'(3,4)'</span>, v, ha=<span class=\"string\">'center'</span>, va=<span class=\"string\">'center'</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\"><span class=\"comment\"># title</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'2D Vector'</span>)</span><br><span class=\"line\"><span class=\"comment\"># save the figure</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'2d_vector.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n<img alt=\"2d_vector\" style=\"zoom:30%;\" data-src=\"/2023/03/27/Linear-Algebra-Basics/2d_vector.png\">\n</p>\n\n<p>The formula to calculate the length of a <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.005ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1328 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(500,0)\"><path data-c=\"1D437\" d=\"M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z\"></path></g></g></g></svg></mjx-container> vector with components <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.169ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 2284.7 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(961,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1405.7,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1895.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container> is:</p>\n<script type=\"math/tex; mode=display\">\n|\\boldsymbol{v}|=\\sqrt{x^2+y^2}</script><p>Matrices: A matrix is a rectangular array of numbers, arranged in rows and columns. It can be used to represent data, systems of linear equations, and transformations in linear algebra.</p>\n<script type=\"math/tex; mode=display\">\n\n\\begin{equation}\nA=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right] \\text { is a } 3 \\text { by } 2 \\text { matrix : } m=3 \\text { rows and } n=2 \\text { columns. }\n\\end{equation}</script><p>Tensors: A tensor is a generalization of vectors and matrices, and is used to represent higher-order data or multidimensional arrays. Tensors can have any number of dimensions, and can be used to represent complex systems, such as those found in physics, engineering, and machine learning.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 20:27</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Scalars</span></span><br><span class=\"line\">scalar = <span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar:\"</span>, scalar)</span><br><span class=\"line\"><span class=\"comment\"># Scalars have no dimensions, so they do not have a shape.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Vectors</span></span><br><span class=\"line\">vector = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector:\"</span>, vector)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector shape:\"</span>, vector.shape)</span><br><span class=\"line\"><span class=\"comment\"># 1-dimensional vector with 3 elements</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrices</span></span><br><span class=\"line\">matrix = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix:\\n\"</span>, matrix)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix shape:\"</span>, matrix.shape)</span><br><span class=\"line\"><span class=\"comment\"># 2-dimensional matrix with 3 rows and 3 columns</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Tensors</span></span><br><span class=\"line\">tensor = np.array([[[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]], [[<span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>]]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Tensor:\\n\"</span>, tensor)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Tensor shape:\"</span>, tensor.shape)</span><br><span class=\"line\"><span class=\"comment\"># 3-dimensional tensor with 2 matrices, each with 2 rows and 2 columns</span></span><br></pre></td></tr></tbody></table></figure>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/27/Basic-operations-of-Matrix/","2023/03/28/Linear-equations/","2023/03/28/Numpy-Basics/","2023/03/28/Functions-Plot/","2023/03/27/Norms/"],"length":469,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>Scalars: A scalar is a quantity that has only magnitude and no direction. It is a single value that can be represented by a number. </p>\n<p>Vectors: A vector is a mathematical object that has both magnitude and direction. It can be represented by an ordered list of numbers, or coordinates, that describe the vectors components in a particular coordinate system.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { Column vector } v \\quad v=\\left[\\begin{array}{l}\nv_1 \\\\\nv_2\n\\end{array}\\right] \\quad \\begin{aligned}\n& v_1=\\text { first component of } \\boldsymbol{v} \\\\\n& v_2=\\text { second component of } \\boldsymbol{v}\n\\end{aligned}\n\\end{equation}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 20:27</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the 2D vector</span></span><br><span class=\"line\">v = np.array([<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the starting point of the vector</span></span><br><span class=\"line\">start = np.array([<span class=\"number\">0</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the vector</span></span><br><span class=\"line\">fig, ax = plt.subplots(figsize=(<span class=\"number\">5</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">ax.quiver(*start, *v, scale=<span class=\"number\">1</span>, scale_units=<span class=\"string\">'xy'</span>, angles=<span class=\"string\">'xy'</span>, color=<span class=\"string\">'r'</span>, width=<span class=\"number\">0.005</span>)</span><br><span class=\"line\">ax.set_xlim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_ylim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">ax.set_aspect(<span class=\"string\">'equal'</span>)</span><br><span class=\"line\">plt.grid()</span><br><span class=\"line\"><span class=\"comment\"># annotate the vector</span></span><br><span class=\"line\">ax.annotate(<span class=\"string\">'(3,4)'</span>, v, ha=<span class=\"string\">'center'</span>, va=<span class=\"string\">'center'</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\"><span class=\"comment\"># title</span></span><br><span class=\"line\">plt.title(<span class=\"string\">'2D Vector'</span>)</span><br><span class=\"line\"><span class=\"comment\"># save the figure</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'2d_vector.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n<img alt=\"2d_vector\" style=\"zoom:30%;\" data-src=\"/2023/03/27/Linear-Algebra-Basics/2d_vector.png\">\n</p>\n\n<p>The formula to calculate the length of a <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.005ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 1328 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(500,0)\"><path data-c=\"1D437\" d=\"M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z\"></path></g></g></g></svg></mjx-container> vector with components <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.169ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 2284.7 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(961,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1405.7,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1895.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container> is:</p>\n<script type=\"math/tex; mode=display\">\n|\\boldsymbol{v}|=\\sqrt{x^2+y^2}</script><p>Matrices: A matrix is a rectangular array of numbers, arranged in rows and columns. It can be used to represent data, systems of linear equations, and transformations in linear algebra.</p>\n<script type=\"math/tex; mode=display\">\n\n\\begin{equation}\nA=\\left[\\begin{array}{ll}\n1 & 4 \\\\\n2 & 5 \\\\\n3 & 6\n\\end{array}\\right] \\text { is a } 3 \\text { by } 2 \\text { matrix : } m=3 \\text { rows and } n=2 \\text { columns. }\n\\end{equation}</script><p>Tensors: A tensor is a generalization of vectors and matrices, and is used to represent higher-order data or multidimensional arrays. Tensors can have any number of dimensions, and can be used to represent complex systems, such as those found in physics, engineering, and machine learning.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 20:27</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Scalars</span></span><br><span class=\"line\">scalar = <span class=\"number\">5</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Scalar:\"</span>, scalar)</span><br><span class=\"line\"><span class=\"comment\"># Scalars have no dimensions, so they do not have a shape.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Vectors</span></span><br><span class=\"line\">vector = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector:\"</span>, vector)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vector shape:\"</span>, vector.shape)</span><br><span class=\"line\"><span class=\"comment\"># 1-dimensional vector with 3 elements</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Matrices</span></span><br><span class=\"line\">matrix = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix:\\n\"</span>, matrix)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Matrix shape:\"</span>, matrix.shape)</span><br><span class=\"line\"><span class=\"comment\"># 2-dimensional matrix with 3 rows and 3 columns</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Tensors</span></span><br><span class=\"line\">tensor = np.array([[[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]], [[<span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>]]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Tensor:\\n\"</span>, tensor)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Tensor shape:\"</span>, tensor.shape)</span><br><span class=\"line\"><span class=\"comment\"># 3-dimensional tensor with 2 matrices, each with 2 rows and 2 columns</span></span><br></pre></td></tr></tbody></table></figure>\n</body></html>"},{"mathjax":true,"title":"Linear equations","date":"2023-03-28T09:47:39.000Z","_content":"\n### Linear system\n\n**The number of equations is the same as the number of unknowns.**\n\n#### Example: Two equations in Two unknowns\n\n$$\n\\begin{aligned}\nx-2 y & =1 \\\\\n3 x+2 y & =11\n\\end{aligned}\n$$\nWe can solve the system of linear equations by adding the two equations together to eliminate the $y$ variable:\n\n$$\n\\begin{aligned}\n(x - 2y) + (3x + 2y) &= 1 + 11 \\\\\n4x &= 12 \\\\\nx &= 3\n\\end{aligned}\n$$\nThen we can substitute $x = 3$ back into one of the original equations to solve for $y$:\n\n$$\n\\begin{aligned}\n3 - 2y &= 1 \\\\\n-2y &= -2 \\\\\ny &= 1\n\\end{aligned}\n$$\nTherefore, the solution to the system of linear equations is $x = 3$ and $y = 1$.\n\nWe can also solve the system of equations using matrices. The system of equations can be represented in matrix form as:\n$$\n\\begin{aligned} \\begin{bmatrix} 1 & -2 \\\\ 3 & 2 \\ \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\ \\end{bmatrix} &= \\begin{bmatrix} 1 \\\\ 11 \\ \\end{bmatrix} \\end{aligned}\n$$\nWe can solve this matrix equation by finding the inverse of the coefficient matrix and multiplying it with the constant matrix:\n$$\n\\begin{aligned}\n\\begin{bmatrix}\nx \\\\\ny \\\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n1 & -2 \\\\\n3 & 2 \\\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n1 \\\\\n11 \\\n\\end{bmatrix} \\\\\n&=\n\\begin{bmatrix}\n3 \\\\\n1\\\n\\end{bmatrix}\n\\end{aligned}\n$$\n\n```python\n# Define the system of linear equations\nA = np.array([[3, 2], [1, -2]])\nb = np.array([11, 1])\n\n# Solve the system of linear equations\nx = np.linalg.inv(A).dot(b)\n# x = np.linalg.solve(A, b)\n\n# Print the solution\nprint('x =', x[0])\nprint('y =', x[1])\n```\n\n```\nx = 3.0\ny = 1.0\n```\n\n### Singular system\n\nA singular system of linear equations is a system of equations that has no unique solution or has infinitely many solutions.\n$$\n\\begin{aligned}\nx + y &= 3 \\\\\n2x + 2y &= 6 \\\n\\end{aligned}\n$$\n","source":"_posts/Linear-equations.md","raw":"---\nmathjax: true\ntitle: Linear equations\ndate: 2023-03-28 09:47:39\ntags: [Linear algebra, linear regression, Linear equations]\n---\n\n### Linear system\n\n**The number of equations is the same as the number of unknowns.**\n\n#### Example: Two equations in Two unknowns\n\n$$\n\\begin{aligned}\nx-2 y & =1 \\\\\n3 x+2 y & =11\n\\end{aligned}\n$$\nWe can solve the system of linear equations by adding the two equations together to eliminate the $y$ variable:\n\n$$\n\\begin{aligned}\n(x - 2y) + (3x + 2y) &= 1 + 11 \\\\\n4x &= 12 \\\\\nx &= 3\n\\end{aligned}\n$$\nThen we can substitute $x = 3$ back into one of the original equations to solve for $y$:\n\n$$\n\\begin{aligned}\n3 - 2y &= 1 \\\\\n-2y &= -2 \\\\\ny &= 1\n\\end{aligned}\n$$\nTherefore, the solution to the system of linear equations is $x = 3$ and $y = 1$.\n\nWe can also solve the system of equations using matrices. The system of equations can be represented in matrix form as:\n$$\n\\begin{aligned} \\begin{bmatrix} 1 & -2 \\\\ 3 & 2 \\ \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\ \\end{bmatrix} &= \\begin{bmatrix} 1 \\\\ 11 \\ \\end{bmatrix} \\end{aligned}\n$$\nWe can solve this matrix equation by finding the inverse of the coefficient matrix and multiplying it with the constant matrix:\n$$\n\\begin{aligned}\n\\begin{bmatrix}\nx \\\\\ny \\\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n1 & -2 \\\\\n3 & 2 \\\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n1 \\\\\n11 \\\n\\end{bmatrix} \\\\\n&=\n\\begin{bmatrix}\n3 \\\\\n1\\\n\\end{bmatrix}\n\\end{aligned}\n$$\n\n```python\n# Define the system of linear equations\nA = np.array([[3, 2], [1, -2]])\nb = np.array([11, 1])\n\n# Solve the system of linear equations\nx = np.linalg.inv(A).dot(b)\n# x = np.linalg.solve(A, b)\n\n# Print the solution\nprint('x =', x[0])\nprint('y =', x[1])\n```\n\n```\nx = 3.0\ny = 1.0\n```\n\n### Singular system\n\nA singular system of linear equations is a system of equations that has no unique solution or has infinitely many solutions.\n$$\n\\begin{aligned}\nx + y &= 3 \\\\\n2x + 2y &= 6 \\\n\\end{aligned}\n$$\n","slug":"Linear-equations","published":1,"updated":"2023-04-07T02:43:50.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73h2000nozpi668b2jet","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Linear-system\"><a href=\"#Linear-system\" class=\"headerlink\" title=\"Linear system\"></a>Linear system</h3><p><strong>The number of equations is the same as the number of unknowns.</strong></p>\n<h4 id=\"Example-Two-equations-in-Two-unknowns\"><a href=\"#Example-Two-equations-in-Two-unknowns\" class=\"headerlink\" title=\"Example: Two equations in Two unknowns\"></a>Example: Two equations in Two unknowns</h4><script type=\"math/tex; mode=display\">\n\\begin{aligned}\nx-2 y & =1 \\\\\n3 x+2 y & =11\n\\end{aligned}</script><p>We can solve the system of linear equations by adding the two equations together to eliminate the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.109ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 490 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> variable:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n(x - 2y) + (3x + 2y) &= 1 + 11 \\\\\n4x &= 12 \\\\\nx &= 3\n\\end{aligned}</script><p>Then we can substitute <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.442ex\" height=\"1.69ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2405.6 747\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(849.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1905.6,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> back into one of the original equations to solve for <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.109ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 490 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n3 - 2y &= 1 \\\\\n-2y &= -2 \\\\\ny &= 1\n\\end{aligned}</script><p>Therefore, the solution to the system of linear equations is <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.442ex\" height=\"1.69ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2405.6 747\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(849.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1905.6,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.257ex\" height=\"1.971ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2323.6 871\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(767.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1823.6,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>.</p>\n<p>We can also solve the system of equations using matrices. The system of equations can be represented in matrix form as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned} \\begin{bmatrix} 1 & -2 \\\\ 3 & 2 \\ \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\ \\end{bmatrix} &= \\begin{bmatrix} 1 \\\\ 11 \\ \\end{bmatrix} \\end{aligned}</script><p>We can solve this matrix equation by finding the inverse of the coefficient matrix and multiplying it with the constant matrix:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n\\begin{bmatrix}\nx \\\\\ny \\\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n1 & -2 \\\\\n3 & 2 \\\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n1 \\\\\n11 \\\n\\end{bmatrix} \\\\\n&=\n\\begin{bmatrix}\n3 \\\\\n1\\\n\\end{bmatrix}\n\\end{aligned}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define the system of linear equations</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">3</span>, <span class=\"number\">2</span>], [<span class=\"number\">1</span>, -<span class=\"number\">2</span>]])</span><br><span class=\"line\">b = np.array([<span class=\"number\">11</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Solve the system of linear equations</span></span><br><span class=\"line\">x = np.linalg.inv(A).dot(b)</span><br><span class=\"line\"><span class=\"comment\"># x = np.linalg.solve(A, b)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print the solution</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'x ='</span>, x[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'y ='</span>, x[<span class=\"number\">1</span>])</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = 3.0</span><br><span class=\"line\">y = 1.0</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Singular-system\"><a href=\"#Singular-system\" class=\"headerlink\" title=\"Singular system\"></a>Singular system</h3><p>A singular system of linear equations is a system of equations that has no unique solution or has infinitely many solutions.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\nx + y &= 3 \\\\\n2x + 2y &= 6 \\\n\\end{aligned}</script></body></html>","site":{"data":{}},"related_posts":["2023/03/27/Linear-Algebra-Basics/","2023/03/27/Basic-operations-of-Matrix/","2023/03/27/Norms/","2023/03/28/Regression/","2023/04/03/Relationships-between-two-Sets/"],"length":286,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Linear-system\"><a href=\"#Linear-system\" class=\"headerlink\" title=\"Linear system\"></a>Linear system</h3><p><strong>The number of equations is the same as the number of unknowns.</strong></p>\n<h4 id=\"Example-Two-equations-in-Two-unknowns\"><a href=\"#Example-Two-equations-in-Two-unknowns\" class=\"headerlink\" title=\"Example: Two equations in Two unknowns\"></a>Example: Two equations in Two unknowns</h4><script type=\"math/tex; mode=display\">\n\\begin{aligned}\nx-2 y & =1 \\\\\n3 x+2 y & =11\n\\end{aligned}</script><p>We can solve the system of linear equations by adding the two equations together to eliminate the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.109ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 490 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> variable:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n(x - 2y) + (3x + 2y) &= 1 + 11 \\\\\n4x &= 12 \\\\\nx &= 3\n\\end{aligned}</script><p>Then we can substitute <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.442ex\" height=\"1.69ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2405.6 747\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(849.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1905.6,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> back into one of the original equations to solve for <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.109ex\" height=\"1.464ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 490 647\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n3 - 2y &= 1 \\\\\n-2y &= -2 \\\\\ny &= 1\n\\end{aligned}</script><p>Therefore, the solution to the system of linear equations is <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.442ex\" height=\"1.69ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -665 2405.6 747\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(849.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1905.6,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.257ex\" height=\"1.971ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2323.6 871\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(767.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1823.6,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>.</p>\n<p>We can also solve the system of equations using matrices. The system of equations can be represented in matrix form as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned} \\begin{bmatrix} 1 & -2 \\\\ 3 & 2 \\ \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\ \\end{bmatrix} &= \\begin{bmatrix} 1 \\\\ 11 \\ \\end{bmatrix} \\end{aligned}</script><p>We can solve this matrix equation by finding the inverse of the coefficient matrix and multiplying it with the constant matrix:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n\\begin{bmatrix}\nx \\\\\ny \\\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n1 & -2 \\\\\n3 & 2 \\\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n1 \\\\\n11 \\\n\\end{bmatrix} \\\\\n&=\n\\begin{bmatrix}\n3 \\\\\n1\\\n\\end{bmatrix}\n\\end{aligned}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Define the system of linear equations</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">3</span>, <span class=\"number\">2</span>], [<span class=\"number\">1</span>, -<span class=\"number\">2</span>]])</span><br><span class=\"line\">b = np.array([<span class=\"number\">11</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Solve the system of linear equations</span></span><br><span class=\"line\">x = np.linalg.inv(A).dot(b)</span><br><span class=\"line\"><span class=\"comment\"># x = np.linalg.solve(A, b)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print the solution</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'x ='</span>, x[<span class=\"number\">0</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'y ='</span>, x[<span class=\"number\">1</span>])</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = 3.0</span><br><span class=\"line\">y = 1.0</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Singular-system\"><a href=\"#Singular-system\" class=\"headerlink\" title=\"Singular system\"></a>Singular system</h3><p>A singular system of linear equations is a system of equations that has no unique solution or has infinitely many solutions.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\nx + y &= 3 \\\\\n2x + 2y &= 6 \\\n\\end{aligned}</script></body></html>"},{"mathjax":true,"title":"Norm","date":"2023-03-27T20:31:29.000Z","_content":"\n### Norm for a vector\n\nIn linear algebra, the p-norm of a vector $\\mathrm{x}$ is a way of measuring the size or magnitude of the vector. The p-norm is defined as:\n$$\n\\begin{equation}\n\\|\\mathrm {x}\\|_p=\\left(\\sum_{i=1}^n\\left|x_i\\right|^p\\right)^{1 / p}\n\\end{equation}\n$$\nwhere $\\mathrm{x} = [x_1, x_2, \\ldots, x_n]$ is an n-dimensional vector, and $p$ is a positive real number. When $p=2$, the p-norm is known as the Euclidean norm, and when $p=1$, it is known as the Manhattan or taxicab norm.\n\nThe Euclidean norm of a vector $\\mathrm{x}$ is defined as:\n$$\n\\begin{equation}\n\\|\\mathrm{x}\\|_2=\\sqrt{\\sum_{i=1}^n x_i^2}\n\\end{equation}\n$$\nThe Manhattan norm of a vector $\\mathrm{x}$ is defined as:\n$$\n\\begin{equation}\n\\|\\mathrm{x}\\|_1=\\sum_{i=1}^n\\left|x_i\\right|\n\\end{equation}\n$$\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 22:34\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the two points\nx1 = np.array([1, 2])\nx2 = np.array([3, 4])\n\n# Calculate the absolute and Euclidean distance\nd1 = np.sum(np.abs(x1 - x2))\nd2 = np.sqrt(np.sum((x1 - x2)**2))\n\n# Print the distances\nprint(\"Absolute distance:\", d1)\nprint(\"Euclidean distance:\", d2)\n\n# Plot the two points and the distances\nfig, ax = plt.subplots()\nax.plot([x1[0], x2[0]], [x1[1], x2[1]], 'bo-', label='Points')\nax.plot([x1[0], x2[0]], [x1[1], x1[1]], 'r--', label='p=1 distance')\nax.plot([x2[0], x2[0]], [x1[1], x2[1]], 'g--', label='p=1 distance')\nax.plot([x1[0], x2[0]], [x1[1], x2[1]], 'k--', label='p=2 distance')\nax.legend()\nax.set_xlim(0, 5)\nax.set_ylim(0, 5)\nax.set_xlabel('X')\nax.set_ylabel('Y')\nplt.savefig('norm.png', dpi=300, bbox_inches='tight', pad_inches=1)\nplt.show()\n```\n\n```python\nAbsolute distance: 4\nEuclidean distance: 2.8284271247461903\n```\n\n![norm](Norms/norm.png)\n\nThe red and green dashed lines represent the $p=1$ distance, which is the sum of the absolute differences between the coordinates of the two points in each dimension. The black dashed line represents the $p=2$ distance, which is the Euclidean distance between the two points.\n\n### Norm for a matrix\n\n#### Frobenius norm\n\nThe Frobenius norm of a matrix $\\mathrm{A}$ is a way of measuring the \"size\" or \"magnitude\" of the matrix. It is defined as the square root of the sum of the squares of all the elements in the matrix:\n$$\n\\begin{equation}\n\\|\\mathrm{A}\\|_F \\equiv \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n\\left|a_{i j}\\right|^2}\n\\end{equation}\n$$\nwhere $a_{ij}$ is the $(i,j)$-th entry of $\\mathrm{A}$ and $m$ and $n$ are the number of rows and columns of $\\mathrm{A}$, respectively.\n\nThe Frobenius norm is similar to the Euclidean norm for vectors, and it measures the overall \"size\" of the matrix. It is always non-negative and satisfies the following properties:\n\n- $|\\mathrm{A}|_F \\geq 0$ for any matrix $\\mathrm{A}$.\n- $|\\mathrm{A}|_F = 0$ if and only if $\\mathrm{A} = \\mathrm{0}$ (the matrix of all zeros).\n- $|\\alpha\\mathrm{A}|_F = |\\alpha||\\mathrm{A}|_F$ for any scalar $\\alpha$.\n- $|\\mathrm{A} + \\mathrm{B}|_F \\leq |\\mathrm{A}|_F + |\\mathrm{B}|_F$ (the triangle inequality).\n\n```python\nimport numpy as np\n\n# Define a matrix\nA = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Calculate the Frobenius norm\nf_norm = np.linalg.norm(A, 'fro')\nprint(\"Frobenius norm:\", f_norm)\n```\n\n```css\nFrobenius norm: 9.539392014169456\n```\n\n#### Spectral norm\n\nThe Spectral norm of a matrix $\\mathrm{A}$ is defined as the maximum singular value of $\\mathrm{A}$, denoted as:\n$$\n\\begin{equation}\n\\|\\mathrm{A}\\|_2=\\sqrt{\\lambda_{\\max }\\left(\\mathrm{A}^{\\mathrm{H}} \\mathrm{A}\\right)}=\\sigma_{\\max }(\\mathrm{A})\n\\end{equation}\n$$\nwhere, $\\mathrm{A}^\\mathrm{H}$ represents the conjugate transpose of $\\mathrm{A}$, $\\lambda_{\\max}\\left(\\mathrm{A}^\\mathrm{H}\\mathrm{~A}\\right)$ is the largest eigenvalue of $\\mathrm{A}^\\mathrm{H} \\mathrm{~A}$, and $\\sigma_{\\max }(\\mathrm{A})$ is the maximum singular value of $\\mathrm{A}$.\n\n```python\nimport numpy as np\n\n# Define a matrix\nA = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Calculate the spectral norm\ns_norm = np.linalg.norm(A, 2)\nprint(\"Spectral norm:\", s_norm)\n\n# Calculate the singular values of A\nU, s, V = np.linalg.svd(A)\n\n# Calculate the spectral norm\ns_norm = s[0]\nprint(\"Spectral norm:\", s_norm)\n```\n\n```python\nSpectral norm: 9.525518091565107\n```\n\n#### Other norms\n\n$$\n\\begin{equation}\n\\|A\\|_1=\\max _{1 \\leq j \\leq n} \\sum_{i=1}^m\\left|a_{i j}\\right|_{,} \\quad \\text { \"max column sum\"}\n\\end{equation}\n$$\n\n$$\n\\begin{equation}\n\\|A\\|_{\\infty}=\\max _{1 \\leq i \\leq m} \\sum_{j=1}^n\\left|a_{i j}\\right|, \\quad \\text { \"max row sum\" }\n\\end{equation}\n$$\n\nFor example, for\n$$\nA=\\left[\\begin{array}{ccc}\n-3 & 5 & 7 \\\\\n2 & 6 & 4 \\\\\n0 & 2 & 8\n\\end{array}\\right],\n$$\nwe have that\n$$\n\\begin{aligned}\n& \\|A\\|_1=\\max (|-3|+2+0 ; 5+6+2 ; 7+4+8)=\\max (5,13,19)=19, \\\\\n& \\|A\\|_{\\infty}=\\max (|-3|+5+7 ; 2+6+4 ; 0+2+8)=\\max (15,12,10)=15 .\n\\end{aligned}\n$$\n\n### Reference\n\n1. Wikipedia contributors. (2022, March 27). Matrix norm. In Wikipedia. Retrieved March 27, 2022, from https://en.wikipedia.org/wiki/Matrix_norm\n2. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\n\n\n\n\n\n\n\n","source":"_posts/Norms.md","raw":"---\nmathjax: true\ntitle: Norm\ndate: 2023-03-27 20:31:29\ntags: [Matrix, Norm, Basics]\n---\n\n### Norm for a vector\n\nIn linear algebra, the p-norm of a vector $\\mathrm{x}$ is a way of measuring the size or magnitude of the vector. The p-norm is defined as:\n$$\n\\begin{equation}\n\\|\\mathrm {x}\\|_p=\\left(\\sum_{i=1}^n\\left|x_i\\right|^p\\right)^{1 / p}\n\\end{equation}\n$$\nwhere $\\mathrm{x} = [x_1, x_2, \\ldots, x_n]$ is an n-dimensional vector, and $p$ is a positive real number. When $p=2$, the p-norm is known as the Euclidean norm, and when $p=1$, it is known as the Manhattan or taxicab norm.\n\nThe Euclidean norm of a vector $\\mathrm{x}$ is defined as:\n$$\n\\begin{equation}\n\\|\\mathrm{x}\\|_2=\\sqrt{\\sum_{i=1}^n x_i^2}\n\\end{equation}\n$$\nThe Manhattan norm of a vector $\\mathrm{x}$ is defined as:\n$$\n\\begin{equation}\n\\|\\mathrm{x}\\|_1=\\sum_{i=1}^n\\left|x_i\\right|\n\\end{equation}\n$$\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/27/23 22:34\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the two points\nx1 = np.array([1, 2])\nx2 = np.array([3, 4])\n\n# Calculate the absolute and Euclidean distance\nd1 = np.sum(np.abs(x1 - x2))\nd2 = np.sqrt(np.sum((x1 - x2)**2))\n\n# Print the distances\nprint(\"Absolute distance:\", d1)\nprint(\"Euclidean distance:\", d2)\n\n# Plot the two points and the distances\nfig, ax = plt.subplots()\nax.plot([x1[0], x2[0]], [x1[1], x2[1]], 'bo-', label='Points')\nax.plot([x1[0], x2[0]], [x1[1], x1[1]], 'r--', label='p=1 distance')\nax.plot([x2[0], x2[0]], [x1[1], x2[1]], 'g--', label='p=1 distance')\nax.plot([x1[0], x2[0]], [x1[1], x2[1]], 'k--', label='p=2 distance')\nax.legend()\nax.set_xlim(0, 5)\nax.set_ylim(0, 5)\nax.set_xlabel('X')\nax.set_ylabel('Y')\nplt.savefig('norm.png', dpi=300, bbox_inches='tight', pad_inches=1)\nplt.show()\n```\n\n```python\nAbsolute distance: 4\nEuclidean distance: 2.8284271247461903\n```\n\n![norm](Norms/norm.png)\n\nThe red and green dashed lines represent the $p=1$ distance, which is the sum of the absolute differences between the coordinates of the two points in each dimension. The black dashed line represents the $p=2$ distance, which is the Euclidean distance between the two points.\n\n### Norm for a matrix\n\n#### Frobenius norm\n\nThe Frobenius norm of a matrix $\\mathrm{A}$ is a way of measuring the \"size\" or \"magnitude\" of the matrix. It is defined as the square root of the sum of the squares of all the elements in the matrix:\n$$\n\\begin{equation}\n\\|\\mathrm{A}\\|_F \\equiv \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n\\left|a_{i j}\\right|^2}\n\\end{equation}\n$$\nwhere $a_{ij}$ is the $(i,j)$-th entry of $\\mathrm{A}$ and $m$ and $n$ are the number of rows and columns of $\\mathrm{A}$, respectively.\n\nThe Frobenius norm is similar to the Euclidean norm for vectors, and it measures the overall \"size\" of the matrix. It is always non-negative and satisfies the following properties:\n\n- $|\\mathrm{A}|_F \\geq 0$ for any matrix $\\mathrm{A}$.\n- $|\\mathrm{A}|_F = 0$ if and only if $\\mathrm{A} = \\mathrm{0}$ (the matrix of all zeros).\n- $|\\alpha\\mathrm{A}|_F = |\\alpha||\\mathrm{A}|_F$ for any scalar $\\alpha$.\n- $|\\mathrm{A} + \\mathrm{B}|_F \\leq |\\mathrm{A}|_F + |\\mathrm{B}|_F$ (the triangle inequality).\n\n```python\nimport numpy as np\n\n# Define a matrix\nA = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Calculate the Frobenius norm\nf_norm = np.linalg.norm(A, 'fro')\nprint(\"Frobenius norm:\", f_norm)\n```\n\n```css\nFrobenius norm: 9.539392014169456\n```\n\n#### Spectral norm\n\nThe Spectral norm of a matrix $\\mathrm{A}$ is defined as the maximum singular value of $\\mathrm{A}$, denoted as:\n$$\n\\begin{equation}\n\\|\\mathrm{A}\\|_2=\\sqrt{\\lambda_{\\max }\\left(\\mathrm{A}^{\\mathrm{H}} \\mathrm{A}\\right)}=\\sigma_{\\max }(\\mathrm{A})\n\\end{equation}\n$$\nwhere, $\\mathrm{A}^\\mathrm{H}$ represents the conjugate transpose of $\\mathrm{A}$, $\\lambda_{\\max}\\left(\\mathrm{A}^\\mathrm{H}\\mathrm{~A}\\right)$ is the largest eigenvalue of $\\mathrm{A}^\\mathrm{H} \\mathrm{~A}$, and $\\sigma_{\\max }(\\mathrm{A})$ is the maximum singular value of $\\mathrm{A}$.\n\n```python\nimport numpy as np\n\n# Define a matrix\nA = np.array([[1, 2], [3, 4], [5, 6]])\n\n# Calculate the spectral norm\ns_norm = np.linalg.norm(A, 2)\nprint(\"Spectral norm:\", s_norm)\n\n# Calculate the singular values of A\nU, s, V = np.linalg.svd(A)\n\n# Calculate the spectral norm\ns_norm = s[0]\nprint(\"Spectral norm:\", s_norm)\n```\n\n```python\nSpectral norm: 9.525518091565107\n```\n\n#### Other norms\n\n$$\n\\begin{equation}\n\\|A\\|_1=\\max _{1 \\leq j \\leq n} \\sum_{i=1}^m\\left|a_{i j}\\right|_{,} \\quad \\text { \"max column sum\"}\n\\end{equation}\n$$\n\n$$\n\\begin{equation}\n\\|A\\|_{\\infty}=\\max _{1 \\leq i \\leq m} \\sum_{j=1}^n\\left|a_{i j}\\right|, \\quad \\text { \"max row sum\" }\n\\end{equation}\n$$\n\nFor example, for\n$$\nA=\\left[\\begin{array}{ccc}\n-3 & 5 & 7 \\\\\n2 & 6 & 4 \\\\\n0 & 2 & 8\n\\end{array}\\right],\n$$\nwe have that\n$$\n\\begin{aligned}\n& \\|A\\|_1=\\max (|-3|+2+0 ; 5+6+2 ; 7+4+8)=\\max (5,13,19)=19, \\\\\n& \\|A\\|_{\\infty}=\\max (|-3|+5+7 ; 2+6+4 ; 0+2+8)=\\max (15,12,10)=15 .\n\\end{aligned}\n$$\n\n### Reference\n\n1. Wikipedia contributors. (2022, March 27). Matrix norm. In Wikipedia. Retrieved March 27, 2022, from https://en.wikipedia.org/wiki/Matrix_norm\n2. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\n\n\n\n\n\n\n\n","slug":"Norms","published":1,"updated":"2023-04-07T02:43:50.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73h3000pozpi6dsu0x4s","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Norm-for-a-vector\"><a href=\"#Norm-for-a-vector\" class=\"headerlink\" title=\"Norm for a vector\"></a>Norm for a vector</h3><p>In linear algebra, the p-norm of a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.195ex\" height=\"0.975ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 528 431\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g></g></g></svg></mjx-container> is a way of measuring the size or magnitude of the vector. The p-norm is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm {x}\\|_p=\\left(\\sum_{i=1}^n\\left|x_i\\right|^p\\right)^{1 / p}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.522ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 8186.6 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(805.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1861.6,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2139.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3148.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3592.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4601.3,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5046,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6384.7,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6829.3,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(7908.6,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g></g></g></svg></mjx-container> is an n-dimensional vector, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.138ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 503 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g></svg></mjx-container> is a positive real number. When <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container>, the p-norm is known as the Euclidean norm, and when <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>, it is known as the Manhattan or taxicab norm.</p>\n<p>The Euclidean norm of a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.195ex\" height=\"0.975ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 528 431\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g></g></g></svg></mjx-container> is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{x}\\|_2=\\sqrt{\\sum_{i=1}^n x_i^2}\n\\end{equation}</script><p>The Manhattan norm of a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.195ex\" height=\"0.975ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 528 431\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g></g></g></svg></mjx-container> is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{x}\\|_1=\\sum_{i=1}^n\\left|x_i\\right|\n\\end{equation}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 22:34</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the two points</span></span><br><span class=\"line\">x1 = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">x2 = np.array([<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the absolute and Euclidean distance</span></span><br><span class=\"line\">d1 = np.<span class=\"built_in\">sum</span>(np.<span class=\"built_in\">abs</span>(x1 - x2))</span><br><span class=\"line\">d2 = np.sqrt(np.<span class=\"built_in\">sum</span>((x1 - x2)**<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print the distances</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Absolute distance:\"</span>, d1)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Euclidean distance:\"</span>, d2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the two points and the distances</span></span><br><span class=\"line\">fig, ax = plt.subplots()</span><br><span class=\"line\">ax.plot([x1[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x2[<span class=\"number\">1</span>]], <span class=\"string\">'bo-'</span>, label=<span class=\"string\">'Points'</span>)</span><br><span class=\"line\">ax.plot([x1[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x1[<span class=\"number\">1</span>]], <span class=\"string\">'r--'</span>, label=<span class=\"string\">'p=1 distance'</span>)</span><br><span class=\"line\">ax.plot([x2[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x2[<span class=\"number\">1</span>]], <span class=\"string\">'g--'</span>, label=<span class=\"string\">'p=1 distance'</span>)</span><br><span class=\"line\">ax.plot([x1[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x2[<span class=\"number\">1</span>]], <span class=\"string\">'k--'</span>, label=<span class=\"string\">'p=2 distance'</span>)</span><br><span class=\"line\">ax.legend()</span><br><span class=\"line\">ax.set_xlim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_ylim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'norm.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Absolute distance: <span class=\"number\">4</span></span><br><span class=\"line\">Euclidean distance: <span class=\"number\">2.8284271247461903</span></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"norm\" data-src=\"/2023/03/27/Norms/norm.png\"></p>\n<p>The red and green dashed lines represent the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> distance, which is the sum of the absolute differences between the coordinates of the two points in each dimension. The black dashed line represents the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container> distance, which is the Euclidean distance between the two points.</p>\n<h3 id=\"Norm-for-a-matrix\"><a href=\"#Norm-for-a-matrix\" class=\"headerlink\" title=\"Norm for a matrix\"></a>Norm for a matrix</h3><h4 id=\"Frobenius-norm\"><a href=\"#Frobenius-norm\" class=\"headerlink\" title=\"Frobenius norm\"></a>Frobenius norm</h4><p>The Frobenius norm of a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> is a way of measuring the size or magnitude of the matrix. It is defined as the square root of the sum of the squares of all the elements in the matrix:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{A}\\|_F \\equiv \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n\\left|a_{i j}\\right|^2}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.666ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.596ex\" height=\"1.663ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -441 1147.3 735.2\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(562,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.479ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 1979.7 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1178.7,0)\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1590.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>-th entry of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.986ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 878 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> are the number of rows and columns of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>, respectively.</p>\n<p>The Frobenius norm is similar to the Euclidean norm for vectors, and it measures the overall size of the matrix. It is always non-negative and satisfies the following properties:</p>\n<ul>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.489ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 3752.2 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(1028,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2196.4,0)\"><path data-c=\"2265\" d=\"M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(3252.2,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container> for any matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>.</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.489ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 3752.2 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(1028,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2196.4,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(3252.2,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container> if and only if <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.845ex\" height=\"1.805ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 2583.6 798\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1027.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2083.6,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></g></svg></mjx-container> (the matrix of all zeros).</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"15.852ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 7006.8 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(278,0)\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(918,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(1668,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2836.4,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3892.2,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4170.2,0)\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4810.2,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5088.2,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(5366.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(6116.2,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g></g></g></svg></mjx-container> for any scalar <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.448ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 640 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"></path></g></g></g></svg></mjx-container>.</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"23.078ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 10200.3 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1250.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2250.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(2958.4,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4126.8,0)\"><path data-c=\"2264\" d=\"M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5182.6,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(5460.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(6210.6,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(7323.5,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8323.7,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(8601.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(9309.7,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g></g></g></svg></mjx-container> (the triangle inequality).</li>\n</ul>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a matrix</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the Frobenius norm</span></span><br><span class=\"line\">f_norm = np.linalg.norm(A, <span class=\"string\">'fro'</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Frobenius norm:\"</span>, f_norm)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight css\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Frobenius norm: <span class=\"number\">9.539392014169456</span></span><br></pre></td></tr></tbody></table></figure>\n<h4 id=\"Spectral-norm\"><a href=\"#Spectral-norm\" class=\"headerlink\" title=\"Spectral norm\"></a>Spectral norm</h4><p>The Spectral norm of a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> is defined as the maximum singular value of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>, denoted as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{A}\\|_2=\\sqrt{\\lambda_{\\max }\\left(\\mathrm{A}^{\\mathrm{H}} \\mathrm{A}\\right)}=\\sigma_{\\max }(\\mathrm{A})\n\\end{equation}</script><p>where, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.084ex\" height=\"1.914ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -846 1363.3 846\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"48\" d=\"M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z\"></path></g></g></g></g></g></svg></mjx-container> represents the conjugate transpose of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>, $\\lambda<em>{\\max}\\left(\\mathrm{A}^\\mathrm{H}\\mathrm{~A}\\right)<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"24.903ex\" height=\"2.059ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 11007 910\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(814,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1175,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1751,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2217,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2515,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3044,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3495,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3972,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4438,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4907,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5268,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5734,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6079,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6556,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7022,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7622,0)\"><path data-c=\"1D463\" d=\"M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8107,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8636,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8934,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9506,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9972,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10457,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g></g></svg></mjx-container>\\mathrm{A}^\\mathrm{H} \\mathrm{~A}<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.737ex\" height=\"2.009ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 2093.7 888\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(444.7,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(973.7,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1573.7,0)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\"></path></g></g></g></svg></mjx-container>\\sigma</em>{\\max }(\\mathrm{A})<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"31.663ex\" height=\"2.059ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 13995 910\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(814,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1175,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1751,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2217,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3095,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3624,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4196,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4541,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5419,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5991,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6869,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7338,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7683,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8283,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8760,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9332,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9630,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10159,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10610,0)\"><path data-c=\"1D463\" d=\"M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11095,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11624,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11922,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(12494,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(12960,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13445,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g></g></svg></mjx-container>\\mathrm{A}$.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a matrix</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the spectral norm</span></span><br><span class=\"line\">s_norm = np.linalg.norm(A, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Spectral norm:\"</span>, s_norm)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the singular values of A</span></span><br><span class=\"line\">U, s, V = np.linalg.svd(A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the spectral norm</span></span><br><span class=\"line\">s_norm = s[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Spectral norm:\"</span>, s_norm)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Spectral norm: <span class=\"number\">9.525518091565107</span></span><br></pre></td></tr></tbody></table></figure>\n<h4 id=\"Other-norms\"><a href=\"#Other-norms\" class=\"headerlink\" title=\"Other norms\"></a>Other norms</h4><script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|A\\|_1=\\max _{1 \\leq j \\leq n} \\sum_{i=1}^m\\left|a_{i j}\\right|_{,} \\quad \\text { \"max column sum\"}\n\\end{equation}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|A\\|_{\\infty}=\\max _{1 \\leq i \\leq m} \\sum_{j=1}^n\\left|a_{i j}\\right|, \\quad \\text { \"max row sum\" }\n\\end{equation}</script><p>For example, for</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{ccc}\n-3 & 5 & 7 \\\\\n2 & 6 & 4 \\\\\n0 & 2 & 8\n\\end{array}\\right],</script><p>we have that</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n& \\|A\\|_1=\\max (|-3|+2+0 ; 5+6+2 ; 7+4+8)=\\max (5,13,19)=19, \\\\\n& \\|A\\|_{\\infty}=\\max (|-3|+5+7 ; 2+6+4 ; 0+2+8)=\\max (15,12,10)=15 .\n\\end{aligned}</script><h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Wikipedia contributors. (2022, March 27). Matrix norm. In Wikipedia. Retrieved March 27, 2022, from <a href=\"https://en.wikipedia.org/wiki/Matrix_norm\">https://en.wikipedia.org/wiki/Matrix_norm</a></li>\n<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/29/From-linear-regression-to-binary-classification/","2023/03/27/Basic-operations-of-Matrix/","2023/03/28/Linear-equations/","2023/03/27/Linear-Algebra-Basics/","2023/03/28/Functions-Plot/"],"length":847,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Norm-for-a-vector\"><a href=\"#Norm-for-a-vector\" class=\"headerlink\" title=\"Norm for a vector\"></a>Norm for a vector</h3><p>In linear algebra, the p-norm of a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.195ex\" height=\"0.975ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 528 431\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g></g></g></svg></mjx-container> is a way of measuring the size or magnitude of the vector. The p-norm is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm {x}\\|_p=\\left(\\sum_{i=1}^n\\left|x_i\\right|^p\\right)^{1 / p}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.522ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 8186.6 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(805.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1861.6,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2139.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3148.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3592.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4601.3,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5046,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6384.7,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6829.3,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(7908.6,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g></g></g></svg></mjx-container> is an n-dimensional vector, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.138ex\" height=\"1.439ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 503 636\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g></g></g></svg></mjx-container> is a positive real number. When <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container>, the p-norm is known as the Euclidean norm, and when <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container>, it is known as the Manhattan or taxicab norm.</p>\n<p>The Euclidean norm of a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.195ex\" height=\"0.975ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 528 431\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g></g></g></svg></mjx-container> is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{x}\\|_2=\\sqrt{\\sum_{i=1}^n x_i^2}\n\\end{equation}</script><p>The Manhattan norm of a vector <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.195ex\" height=\"0.975ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 528 431\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"78\" d=\"M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z\"></path></g></g></g></g></svg></mjx-container> is defined as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{x}\\|_1=\\sum_{i=1}^n\\left|x_i\\right|\n\\end{equation}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/27/23 22:34</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the two points</span></span><br><span class=\"line\">x1 = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">x2 = np.array([<span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the absolute and Euclidean distance</span></span><br><span class=\"line\">d1 = np.<span class=\"built_in\">sum</span>(np.<span class=\"built_in\">abs</span>(x1 - x2))</span><br><span class=\"line\">d2 = np.sqrt(np.<span class=\"built_in\">sum</span>((x1 - x2)**<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print the distances</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Absolute distance:\"</span>, d1)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Euclidean distance:\"</span>, d2)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the two points and the distances</span></span><br><span class=\"line\">fig, ax = plt.subplots()</span><br><span class=\"line\">ax.plot([x1[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x2[<span class=\"number\">1</span>]], <span class=\"string\">'bo-'</span>, label=<span class=\"string\">'Points'</span>)</span><br><span class=\"line\">ax.plot([x1[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x1[<span class=\"number\">1</span>]], <span class=\"string\">'r--'</span>, label=<span class=\"string\">'p=1 distance'</span>)</span><br><span class=\"line\">ax.plot([x2[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x2[<span class=\"number\">1</span>]], <span class=\"string\">'g--'</span>, label=<span class=\"string\">'p=1 distance'</span>)</span><br><span class=\"line\">ax.plot([x1[<span class=\"number\">0</span>], x2[<span class=\"number\">0</span>]], [x1[<span class=\"number\">1</span>], x2[<span class=\"number\">1</span>]], <span class=\"string\">'k--'</span>, label=<span class=\"string\">'p=2 distance'</span>)</span><br><span class=\"line\">ax.legend()</span><br><span class=\"line\">ax.set_xlim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_ylim(<span class=\"number\">0</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'X'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'Y'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'norm.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Absolute distance: <span class=\"number\">4</span></span><br><span class=\"line\">Euclidean distance: <span class=\"number\">2.8284271247461903</span></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"norm\" data-src=\"/2023/03/27/Norms/norm.png\"></p>\n<p>The red and green dashed lines represent the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> distance, which is the sum of the absolute differences between the coordinates of the two points in each dimension. The black dashed line represents the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.286ex\" height=\"1.946ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2336.6 860\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(780.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1836.6,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></svg></mjx-container> distance, which is the Euclidean distance between the two points.</p>\n<h3 id=\"Norm-for-a-matrix\"><a href=\"#Norm-for-a-matrix\" class=\"headerlink\" title=\"Norm for a matrix\"></a>Norm for a matrix</h3><h4 id=\"Frobenius-norm\"><a href=\"#Frobenius-norm\" class=\"headerlink\" title=\"Frobenius norm\"></a>Frobenius norm</h4><p>The Frobenius norm of a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> is a way of measuring the size or magnitude of the matrix. It is defined as the square root of the sum of the squares of all the elements in the matrix:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{A}\\|_F \\equiv \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n\\left|a_{i j}\\right|^2}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.666ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.596ex\" height=\"1.663ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -441 1147.3 735.2\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(562,-150) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.479ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 1979.7 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1178.7,0)\"><path data-c=\"1D457\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1590.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>-th entry of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.986ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 878 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.357ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 600 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container> are the number of rows and columns of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>, respectively.</p>\n<p>The Frobenius norm is similar to the Euclidean norm for vectors, and it measures the overall size of the matrix. It is always non-negative and satisfies the following properties:</p>\n<ul>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.489ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 3752.2 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(1028,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2196.4,0)\"><path data-c=\"2265\" d=\"M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(3252.2,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container> for any matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>.</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.489ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 3752.2 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(1028,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2196.4,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(3252.2,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></svg></mjx-container> if and only if <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.845ex\" height=\"1.805ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 2583.6 798\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1027.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2083.6,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g></g></svg></mjx-container> (the matrix of all zeros).</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"15.852ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 7006.8 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(278,0)\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(918,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(1668,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2836.4,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3892.2,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4170.2,0)\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4810.2,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5088.2,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(5366.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(6116.2,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g></g></g></svg></mjx-container> for any scalar <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.448ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 640 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D6FC\" d=\"M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z\"></path></g></g></g></svg></mjx-container>.</li>\n<li><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"23.078ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 10200.3 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1250.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2250.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(2958.4,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4126.8,0)\"><path data-c=\"2264\" d=\"M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5182.6,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(5460.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(6210.6,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(7323.5,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8323.7,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(8601.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(9309.7,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(311,-150) scale(0.707)\"><path data-c=\"1D439\" d=\"M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z\"></path></g></g></g></g></svg></mjx-container> (the triangle inequality).</li>\n</ul>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a matrix</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the Frobenius norm</span></span><br><span class=\"line\">f_norm = np.linalg.norm(A, <span class=\"string\">'fro'</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Frobenius norm:\"</span>, f_norm)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight css\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Frobenius norm: <span class=\"number\">9.539392014169456</span></span><br></pre></td></tr></tbody></table></figure>\n<h4 id=\"Spectral-norm\"><a href=\"#Spectral-norm\" class=\"headerlink\" title=\"Spectral norm\"></a>Spectral norm</h4><p>The Spectral norm of a matrix <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container> is defined as the maximum singular value of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>, denoted as:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|\\mathrm{A}\\|_2=\\sqrt{\\lambda_{\\max }\\left(\\mathrm{A}^{\\mathrm{H}} \\mathrm{A}\\right)}=\\sigma_{\\max }(\\mathrm{A})\n\\end{equation}</script><p>where, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.084ex\" height=\"1.914ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -846 1363.3 846\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(783,363) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"48\" d=\"M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 500V378H517V622Q510 629 506 631T490 634T447 637H414V683H425Q446 680 569 680Q704 680 713 683H724V637H691Q651 636 640 634T622 622V61Q628 51 639 49T691 46H724V0H713Q692 3 569 3Q434 3 425 0H414V46H447Q489 47 498 49T517 61V332H232V197L233 61Q239 51 250 49T302 46H335V0H324Q303 3 180 3Q45 3 36 0H25V46H58Q100 47 109 49T128 61V622Z\"></path></g></g></g></g></g></svg></mjx-container> represents the conjugate transpose of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"41\" d=\"M255 0Q240 3 140 3Q48 3 39 0H32V46H47Q119 49 139 88Q140 91 192 245T295 553T348 708Q351 716 366 716H376Q396 715 400 709Q402 707 508 390L617 67Q624 54 636 51T687 46H717V0H708Q699 3 581 3Q458 3 437 0H427V46H440Q510 46 510 64Q510 66 486 138L462 209H229L209 150Q189 91 189 85Q189 72 209 59T259 46H264V0H255ZM447 255L345 557L244 256Q244 255 345 255H447Z\"></path></g></g></g></g></svg></mjx-container>, $\\lambda<em>{\\max}\\left(\\mathrm{A}^\\mathrm{H}\\mathrm{~A}\\right)<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"24.903ex\" height=\"2.059ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 11007 910\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(814,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1175,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1751,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2217,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2515,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3044,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3495,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3972,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4438,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4907,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5268,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5734,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6079,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6556,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7022,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7622,0)\"><path data-c=\"1D463\" d=\"M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8107,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8636,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8934,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9506,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9972,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10457,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g></g></svg></mjx-container>\\mathrm{A}^\\mathrm{H} \\mathrm{~A}<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.737ex\" height=\"2.009ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 2093.7 888\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(444.7,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(973.7,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1573.7,0)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\"></path></g></g></g></svg></mjx-container>\\sigma</em>{\\max }(\\mathrm{A})<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"31.663ex\" height=\"2.059ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 13995 910\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(814,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1175,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1751,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2217,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3095,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3624,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4196,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4541,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5419,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5991,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6869,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7338,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7683,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8283,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8760,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9332,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9630,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10159,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10610,0)\"><path data-c=\"1D463\" d=\"M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11095,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11624,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11922,0)\"><path data-c=\"1D462\" d=\"M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(12494,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(12960,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13445,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g></g></g></svg></mjx-container>\\mathrm{A}$.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a matrix</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>], [<span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the spectral norm</span></span><br><span class=\"line\">s_norm = np.linalg.norm(A, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Spectral norm:\"</span>, s_norm)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the singular values of A</span></span><br><span class=\"line\">U, s, V = np.linalg.svd(A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the spectral norm</span></span><br><span class=\"line\">s_norm = s[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Spectral norm:\"</span>, s_norm)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Spectral norm: <span class=\"number\">9.525518091565107</span></span><br></pre></td></tr></tbody></table></figure>\n<h4 id=\"Other-norms\"><a href=\"#Other-norms\" class=\"headerlink\" title=\"Other norms\"></a>Other norms</h4><script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|A\\|_1=\\max _{1 \\leq j \\leq n} \\sum_{i=1}^m\\left|a_{i j}\\right|_{,} \\quad \\text { \"max column sum\"}\n\\end{equation}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\|A\\|_{\\infty}=\\max _{1 \\leq i \\leq m} \\sum_{j=1}^n\\left|a_{i j}\\right|, \\quad \\text { \"max row sum\" }\n\\end{equation}</script><p>For example, for</p>\n<script type=\"math/tex; mode=display\">\nA=\\left[\\begin{array}{ccc}\n-3 & 5 & 7 \\\\\n2 & 6 & 4 \\\\\n0 & 2 & 8\n\\end{array}\\right],</script><p>we have that</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n& \\|A\\|_1=\\max (|-3|+2+0 ; 5+6+2 ; 7+4+8)=\\max (5,13,19)=19, \\\\\n& \\|A\\|_{\\infty}=\\max (|-3|+5+7 ; 2+6+4 ; 0+2+8)=\\max (15,12,10)=15 .\n\\end{aligned}</script><h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Wikipedia contributors. (2022, March 27). Matrix norm. In Wikipedia. Retrieved March 27, 2022, from <a href=\"https://en.wikipedia.org/wiki/Matrix_norm\">https://en.wikipedia.org/wiki/Matrix_norm</a></li>\n<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Numpy Basics","date":"2023-03-28T06:14:24.000Z","_content":"\n### Create 1D array using Numpy\n\n```python\nimport numpy as np\n\n# Create 1D arrays using different methods\na = np.array([1, 2, 3, 4, 5])        # Create 1D array from a list\n# [1 2 3 4 5]\nb = np.arange(10)                   # Create 1D array using range\n# [0 1 2 3 4 5 6 7 8 9]\nc = np.linspace(0, 1, 5)             # Create 1D array with equally spaced values\n# [0.   0.25 0.5  0.75 1.  ]\nd = np.random.rand(5)               # Create 1D array with random values\n# [0.785179   0.05506288 0.83677954 0.98587586 0.52964397]\ne = np.zeros(5)                     # Create 1D array of zeros\n# [0. 0. 0. 0. 0.]\nf = np.ones(5)                      # Create 1D array of ones\n# [1. 1. 1. 1. 1.]\ng = np.full(5, 2)                   # Create 1D array of a specific value\n# [2 2 2 2 2]\nh = np.empty(5)                     # Create 1D array without initializing its values\n# [0. 0. 0. 0. 0.]\n```\n\n### Create 2D array using Numpy\n\n```python\nimport numpy as np\n\n# Create 2D arrays using different methods\na = np.array([[1, 2, 3], [4, 5, 6]])         # Create 2D array from nested lists\nb = np.zeros((3, 3))                        # Create 2D array of zeros\nc = np.ones((2, 2))                         # Create 2D array of ones\nd = np.eye(3)                               # Create 2D identity matrix\ne = np.random.rand(2, 3)                    # Create 2D array with random values\nf = np.array([[1, 2], [3, 4]])              # Create 2D array from a list of lists\ng = np.empty((2, 2))                        # Create uninitialized 2D array\n```\n\n```\n# a\n[[1 2 3]\n [4 5 6]]\n # b\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n # c\n[[1. 1.]\n [1. 1.]]\n # d\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n # e\n[[0.23691216 0.7258241  0.25003681]\n [0.52863985 0.92896228 0.81953756]]\n # f\n[[1 2]\n [3 4]]\n # g\n[[0. 0.]\n [0. 0.]]\n```\n\n### Checking attributes of a 2D array\n\n```python\nimport numpy as np\n\n# Create a 2D array\na = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Check the size, shape, and number of dimensions of the array\nprint(\"Size of the array: \", a.size)\nprint(\"Shape of the array: \", a.shape)\nprint(\"Number of dimensions: \", a.ndim)\n\n# Check the data type of the array\nprint(\"Data type of the array: \", a.dtype)\n\n# Check the number of bytes used by each element in the array\nprint(\"Bytes per element: \", a.itemsize)\n\n# Check the total number of bytes used by the array\nprint(\"Total number of bytes used by the array: \", a.nbytes)\n```\n\n```\nSize of the array:  6\nShape of the array:  (2, 3)\nNumber of dimensions:  2\nData type of the array:  int64\nBytes per element:  8\nTotal number of bytes used by the array:  48\n```\n\n### Comprehension\n\n```python\n# List comprehension example\n# Create a list of squares of numbers from 1 to 10\nsquares = [x**2 for x in range(1, 11)]\nprint(\"List of squares: \", squares)\n\n# Dictionary comprehension example\n# Create a dictionary of squares of numbers from 1 to 10\nsquares_dict = {x: x**2 for x in range(1, 11)}\nprint(\"Dictionary of squares: \", squares_dict)\n\n# Set comprehension example\n# Create a set of squares of numbers from 1 to 10\nsquares_set = {x**2 for x in range(1, 11)}\nprint(\"Set of squares: \", squares_set)\n```\n\n```python\nList of squares:  [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nDictionary of squares:  {1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81, 10: 100}\nSet of squares:  {64, 1, 4, 36, 100, 9, 16, 49, 81, 25}\n```\n\n### Basic operations of a Matrix\n\n```python\nimport numpy as np\n\n# Create a 2D array\na = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Perform some basic operations on the array\nprint(\"Array to the power of 2: \", a ** 2)        # Exponentiation\nprint(\"Array divided by 2: \", a / 2)              # Division\nprint(\"Array modulo 2: \", a % 2)                  # Modulo\nprint(\"Array integer divided by 2: \", a // 2)     # Integer division\nprint(\"Array greater than 5: \", a > 5)            # Comparison\nprint(\"Array equal to 6: \", a == 6)               # Comparison\nprint(\"Array plus 100: \", a + 100)               # Addition\n```\n\n```\nArray to the power of 2:  [[ 1  4  9]\n [16 25 36]]\nArray divided by 2:  [[0.5 1.  1.5]\n [2.  2.5 3. ]]\nArray modulo 2:  [[1 0 1]\n [0 1 0]]\nArray integer divided by 2:  [[0 1 1]\n [2 2 3]]\nArray greater than 5:  [[False False False]\n [False False  True]]\nArray equal to 6:  [[False False False]\n [False False  True]]\nArray plus 100:  [[101 102 103]\n [104 105 106]]\n```\n\n### Index and slice for 1D array\n\n```python\nimport numpy as np\n\n# Create a 1D array\na = np.array([1, 2, 3, 4, 5])\n\n# Indexing the array\nprint(\"Element at index 0: \", a[0])         # Indexing by position\nprint(\"Element at index -1: \", a[-1])       # Indexing by negative position\nprint(\"Element at index 2: \", a[2])         # Indexing by position\nprint(\"Element at index -3: \", a[-3])       # Indexing by negative position\n\n# Slicing the array\nprint(\"Elements from index 1 to 3: \", a[1:4])    # Slicing using start and end positions\nprint(\"Elements from index 0 to end: \", a[:])     # Slicing from start to end\nprint(\"Every second element: \", a[::2])           # Slicing with a step of 2\nprint(\"Reversed array: \", a[::-1])                # Slicing with a negative step\n```\n\n```\nElement at index 0:  1\nElement at index -1:  5\nElement at index 2:  3\nElement at index -3:  3\nElements from index 1 to 3:  [2 3 4]\nElements from index 0 to end:  [1 2 3 4 5]\nEvery second element:  [1 3 5]\nReversed array:  [5 4 3 2 1]\n```\n\n### Index and slice for 2D array\n\n```python\nimport numpy as np\n\n# Create a 2D array\na = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Indexing the array\nprint(\"Element at row 0, column 1: \", a[0, 1])        # Indexing a single element\nprint(\"Element at row -1, column -2: \", a[-1, -2])    # Indexing a single element using negative indices\nprint(\"First row: \", a[0, :])                          # Indexing a row\nprint(\"Second column: \", a[:, 1])                      # Indexing a column\n\n# Slicing the array\nprint(\"Subarray from rows 0 to 1, columns 1 to 2: \")\nprint(a[0:2, 1:3])                                    # Slicing a subarray\nprint(\"First two rows: \")\nprint(a[:2, :])                                        # Slicing the first two rows\nprint(\"Last two columns: \")\nprint(a[:, -2:])                                       # Slicing the last two columns\n```\n\n```\nElement at row 0, column 1:  2\nElement at row -1, column -2:  8\nFirst row:  [1 2 3]\nSecond column:  [2 5 8]\nSubarray from rows 0 to 1, columns 1 to 2: \n[[2 3]\n [5 6]]\nFirst two rows: \n[[1 2 3]\n [4 5 6]]\nLast two columns: \n[[2 3]\n [5 6]\n [8 9]]\n```\n\n### Index and slice for 3D array\n\n```python\nimport numpy as np\n\n# Create a 3D array\na = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\n# Indexing the array\nprint(\"Element at position 1, 0, 1: \", a[1, 0, 1])     # Indexing a single element\nprint(\"Last element in the last row of the last matrix: \", a[-1, -1, -1])  # Indexing a single element using negative indices\nprint(\"First matrix: \")\nprint(a[0, :, :])                                      # Indexing the first matrix\nprint(\"Second row of the second matrix: \")\nprint(a[1, 1, :])                                      # Indexing the second row of the second matrix\n\n# Slicing the array\nprint(\"Subarray from the first matrix: \")\nprint(a[0, :, :])                                      # Slicing a subarray\nprint(\"Subarray from the second matrix, rows 0 to 1, columns 0 to 1: \")\nprint(a[1, 0:2, 0:2])                                  # Slicing a subarray\nprint(\"Last row of the last matrix: \")\nprint(a[-1, -1, :])                                     # Slicing the last row of the last matrix\n```\n\n```\nElement at position 1, 0, 1:  6\nLast element in the last row of the last matrix:  8\nFirst matrix: \n[[1 2]\n [3 4]]\nSecond row of the second matrix: \n[7 8]\nSubarray from the first matrix: \n[[1 2]\n [3 4]]\nSubarray from the second matrix, rows 0 to 1, columns 0 to 1: \n[[5 6]\n [7 8]]\nLast row of the last matrix: \n[7 8]\n```\n\n### Stack and split\n\n```py\nimport numpy as np\n\n# Create two 2D arrays\na = np.array([[1, 2, 3], [4, 5, 6]])\nb = np.array([[7, 8, 9], [10, 11, 12]])\n\n# vstack: Stack arrays vertically (row-wise)\nc = np.vstack((a, b))\nprint(\"Vertically stacked array: \")\nprint(c)\n\n# hstack: Stack arrays horizontally (column-wise)\nd = np.hstack((a, b))\nprint(\"Horizontally stacked array: \")\nprint(d)\n\n# dstack: Stack arrays depth-wise (along third axis)\ne = np.dstack((a, b))\nprint(\"Depth-wise stacked array: \")\nprint(e)\n\n# concatenate: Join arrays along an existing axis\nf = np.concatenate((a, b), axis=0)\nprint(\"Concatenated array along axis 0: \")\nprint(f)\n\n# row_stack: Stack arrays vertically (row-wise)\ng = np.row_stack((a, b))\nprint(\"Vertically stacked array using row_stack: \")\nprint(g)\n\n# column_stack: Stack arrays horizontally (column-wise)\nh = np.column_stack((a, b))\nprint(\"Horizontally stacked array using column_stack: \")\nprint(h)\n\n# hsplit: Split arrays horizontally (column-wise)\ni = np.hsplit(d, 2)\nprint(\"Horizontally split arrays: \")\nprint(i)\n\n# vsplit: Split arrays vertically (row-wise)\nj = np.vsplit(c, 2)\nprint(\"Vertically split arrays: \")\nprint(j)\n\n# dsplit: Split arrays depth-wise (along third axis)\nk = np.dsplit(e, 2)\nprint(\"Depth-wise split arrays: \")\nprint(k)\n```\n\n```\nVertically stacked array: \n[[ 1  2  3]\n [ 4  5  6]\n [ 7  8  9]\n [10 11 12]]\nHorizontally stacked array: \n[[ 1  2  3  7  8  9]\n [ 4  5  6 10 11 12]]\nDepth-wise stacked array: \n[[[ 1  7]\n  [ 2  8]\n  [ 3  9]]\n\n [[ 4 10]\n  [ 5 11]\n  [ 6 12]]]\nConcatenated array along axis 0: \n[[ 1  2  3]\n [ 4  5  6]\n [ 7  8  9]\n [10 11 12]]\nVertically stacked array using row_stack: \n[[ 1  2  3]\n [ 4  5  6]\n [ 7  8  9]\n [10 11 12]]\nHorizontally stacked array using column_stack: \n[[ 1  2  3  7  8  9]\n [ 4  5  6 10 11 12]]\nHorizontally split arrays: \n[array([[1, 2, 3],\n       [4, 5, 6]]), array([[ 7,  8,  9],\n       [10, 11, 12]])]\nVertically split arrays: \n[array([[1, 2, 3],\n       [4, 5, 6]]), array([[ 7,  8,  9],\n       [10, 11, 12]])]\nDepth-wise split arrays: \n[array([[[1],\n        [2],\n        [3]],\n\n       [[4],\n        [5],\n        [6]]]), array([[[ 7],\n        [ 8],\n        [ 9]],\n\n       [[10],\n        [11],\n        [12]]])]\n```\n\n### Broadcasting\n\n```python\nimport numpy as np\n\n# Broadcasting with scalars\na = np.array([1, 2, 3, 4])\nb = 2\nprint(a + b)  # Output: [3 4 5 6]\n\n# Broadcasting with arrays of different shapes\nc = np.array([[1, 2, 3], [4, 5, 6]])\nd = np.array([10, 20, 30])\nprint(c + d)  # Output: [[11 22 33] [14 25 36]]\n\n# Broadcasting with arrays of different ranks\ne = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nf = np.array([10, 20, 30])\nprint(e + f)  # Output: [[11 22 33] [14 25 36] [17 28 39]]\n\n# Broadcasting with arrays of different sizes\ng = np.array([[1, 2, 3], [4, 5, 6]])\nh = np.array([10])\nprint(g + h)  # Output: [[11 12 13] [14 15 16]]\n\n# Broadcasting with arrays of different sizes and shapes\ni = np.array([[1, 2, 3], [4, 5, 6]])\nj = np.array([[10], [20]])\nprint(i + j)  # Output: [[11 12 13] [24 25 26]]\n```\n\n","source":"_posts/Numpy-Basics.md","raw":"---\nmathjax: true\ntitle: Numpy Basics\ndate: 2023-03-28 06:14:24\ntags: [Python, Numpy, Basics, Array]\n---\n\n### Create 1D array using Numpy\n\n```python\nimport numpy as np\n\n# Create 1D arrays using different methods\na = np.array([1, 2, 3, 4, 5])        # Create 1D array from a list\n# [1 2 3 4 5]\nb = np.arange(10)                   # Create 1D array using range\n# [0 1 2 3 4 5 6 7 8 9]\nc = np.linspace(0, 1, 5)             # Create 1D array with equally spaced values\n# [0.   0.25 0.5  0.75 1.  ]\nd = np.random.rand(5)               # Create 1D array with random values\n# [0.785179   0.05506288 0.83677954 0.98587586 0.52964397]\ne = np.zeros(5)                     # Create 1D array of zeros\n# [0. 0. 0. 0. 0.]\nf = np.ones(5)                      # Create 1D array of ones\n# [1. 1. 1. 1. 1.]\ng = np.full(5, 2)                   # Create 1D array of a specific value\n# [2 2 2 2 2]\nh = np.empty(5)                     # Create 1D array without initializing its values\n# [0. 0. 0. 0. 0.]\n```\n\n### Create 2D array using Numpy\n\n```python\nimport numpy as np\n\n# Create 2D arrays using different methods\na = np.array([[1, 2, 3], [4, 5, 6]])         # Create 2D array from nested lists\nb = np.zeros((3, 3))                        # Create 2D array of zeros\nc = np.ones((2, 2))                         # Create 2D array of ones\nd = np.eye(3)                               # Create 2D identity matrix\ne = np.random.rand(2, 3)                    # Create 2D array with random values\nf = np.array([[1, 2], [3, 4]])              # Create 2D array from a list of lists\ng = np.empty((2, 2))                        # Create uninitialized 2D array\n```\n\n```\n# a\n[[1 2 3]\n [4 5 6]]\n # b\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n # c\n[[1. 1.]\n [1. 1.]]\n # d\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n # e\n[[0.23691216 0.7258241  0.25003681]\n [0.52863985 0.92896228 0.81953756]]\n # f\n[[1 2]\n [3 4]]\n # g\n[[0. 0.]\n [0. 0.]]\n```\n\n### Checking attributes of a 2D array\n\n```python\nimport numpy as np\n\n# Create a 2D array\na = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Check the size, shape, and number of dimensions of the array\nprint(\"Size of the array: \", a.size)\nprint(\"Shape of the array: \", a.shape)\nprint(\"Number of dimensions: \", a.ndim)\n\n# Check the data type of the array\nprint(\"Data type of the array: \", a.dtype)\n\n# Check the number of bytes used by each element in the array\nprint(\"Bytes per element: \", a.itemsize)\n\n# Check the total number of bytes used by the array\nprint(\"Total number of bytes used by the array: \", a.nbytes)\n```\n\n```\nSize of the array:  6\nShape of the array:  (2, 3)\nNumber of dimensions:  2\nData type of the array:  int64\nBytes per element:  8\nTotal number of bytes used by the array:  48\n```\n\n### Comprehension\n\n```python\n# List comprehension example\n# Create a list of squares of numbers from 1 to 10\nsquares = [x**2 for x in range(1, 11)]\nprint(\"List of squares: \", squares)\n\n# Dictionary comprehension example\n# Create a dictionary of squares of numbers from 1 to 10\nsquares_dict = {x: x**2 for x in range(1, 11)}\nprint(\"Dictionary of squares: \", squares_dict)\n\n# Set comprehension example\n# Create a set of squares of numbers from 1 to 10\nsquares_set = {x**2 for x in range(1, 11)}\nprint(\"Set of squares: \", squares_set)\n```\n\n```python\nList of squares:  [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nDictionary of squares:  {1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81, 10: 100}\nSet of squares:  {64, 1, 4, 36, 100, 9, 16, 49, 81, 25}\n```\n\n### Basic operations of a Matrix\n\n```python\nimport numpy as np\n\n# Create a 2D array\na = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Perform some basic operations on the array\nprint(\"Array to the power of 2: \", a ** 2)        # Exponentiation\nprint(\"Array divided by 2: \", a / 2)              # Division\nprint(\"Array modulo 2: \", a % 2)                  # Modulo\nprint(\"Array integer divided by 2: \", a // 2)     # Integer division\nprint(\"Array greater than 5: \", a > 5)            # Comparison\nprint(\"Array equal to 6: \", a == 6)               # Comparison\nprint(\"Array plus 100: \", a + 100)               # Addition\n```\n\n```\nArray to the power of 2:  [[ 1  4  9]\n [16 25 36]]\nArray divided by 2:  [[0.5 1.  1.5]\n [2.  2.5 3. ]]\nArray modulo 2:  [[1 0 1]\n [0 1 0]]\nArray integer divided by 2:  [[0 1 1]\n [2 2 3]]\nArray greater than 5:  [[False False False]\n [False False  True]]\nArray equal to 6:  [[False False False]\n [False False  True]]\nArray plus 100:  [[101 102 103]\n [104 105 106]]\n```\n\n### Index and slice for 1D array\n\n```python\nimport numpy as np\n\n# Create a 1D array\na = np.array([1, 2, 3, 4, 5])\n\n# Indexing the array\nprint(\"Element at index 0: \", a[0])         # Indexing by position\nprint(\"Element at index -1: \", a[-1])       # Indexing by negative position\nprint(\"Element at index 2: \", a[2])         # Indexing by position\nprint(\"Element at index -3: \", a[-3])       # Indexing by negative position\n\n# Slicing the array\nprint(\"Elements from index 1 to 3: \", a[1:4])    # Slicing using start and end positions\nprint(\"Elements from index 0 to end: \", a[:])     # Slicing from start to end\nprint(\"Every second element: \", a[::2])           # Slicing with a step of 2\nprint(\"Reversed array: \", a[::-1])                # Slicing with a negative step\n```\n\n```\nElement at index 0:  1\nElement at index -1:  5\nElement at index 2:  3\nElement at index -3:  3\nElements from index 1 to 3:  [2 3 4]\nElements from index 0 to end:  [1 2 3 4 5]\nEvery second element:  [1 3 5]\nReversed array:  [5 4 3 2 1]\n```\n\n### Index and slice for 2D array\n\n```python\nimport numpy as np\n\n# Create a 2D array\na = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Indexing the array\nprint(\"Element at row 0, column 1: \", a[0, 1])        # Indexing a single element\nprint(\"Element at row -1, column -2: \", a[-1, -2])    # Indexing a single element using negative indices\nprint(\"First row: \", a[0, :])                          # Indexing a row\nprint(\"Second column: \", a[:, 1])                      # Indexing a column\n\n# Slicing the array\nprint(\"Subarray from rows 0 to 1, columns 1 to 2: \")\nprint(a[0:2, 1:3])                                    # Slicing a subarray\nprint(\"First two rows: \")\nprint(a[:2, :])                                        # Slicing the first two rows\nprint(\"Last two columns: \")\nprint(a[:, -2:])                                       # Slicing the last two columns\n```\n\n```\nElement at row 0, column 1:  2\nElement at row -1, column -2:  8\nFirst row:  [1 2 3]\nSecond column:  [2 5 8]\nSubarray from rows 0 to 1, columns 1 to 2: \n[[2 3]\n [5 6]]\nFirst two rows: \n[[1 2 3]\n [4 5 6]]\nLast two columns: \n[[2 3]\n [5 6]\n [8 9]]\n```\n\n### Index and slice for 3D array\n\n```python\nimport numpy as np\n\n# Create a 3D array\na = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\n# Indexing the array\nprint(\"Element at position 1, 0, 1: \", a[1, 0, 1])     # Indexing a single element\nprint(\"Last element in the last row of the last matrix: \", a[-1, -1, -1])  # Indexing a single element using negative indices\nprint(\"First matrix: \")\nprint(a[0, :, :])                                      # Indexing the first matrix\nprint(\"Second row of the second matrix: \")\nprint(a[1, 1, :])                                      # Indexing the second row of the second matrix\n\n# Slicing the array\nprint(\"Subarray from the first matrix: \")\nprint(a[0, :, :])                                      # Slicing a subarray\nprint(\"Subarray from the second matrix, rows 0 to 1, columns 0 to 1: \")\nprint(a[1, 0:2, 0:2])                                  # Slicing a subarray\nprint(\"Last row of the last matrix: \")\nprint(a[-1, -1, :])                                     # Slicing the last row of the last matrix\n```\n\n```\nElement at position 1, 0, 1:  6\nLast element in the last row of the last matrix:  8\nFirst matrix: \n[[1 2]\n [3 4]]\nSecond row of the second matrix: \n[7 8]\nSubarray from the first matrix: \n[[1 2]\n [3 4]]\nSubarray from the second matrix, rows 0 to 1, columns 0 to 1: \n[[5 6]\n [7 8]]\nLast row of the last matrix: \n[7 8]\n```\n\n### Stack and split\n\n```py\nimport numpy as np\n\n# Create two 2D arrays\na = np.array([[1, 2, 3], [4, 5, 6]])\nb = np.array([[7, 8, 9], [10, 11, 12]])\n\n# vstack: Stack arrays vertically (row-wise)\nc = np.vstack((a, b))\nprint(\"Vertically stacked array: \")\nprint(c)\n\n# hstack: Stack arrays horizontally (column-wise)\nd = np.hstack((a, b))\nprint(\"Horizontally stacked array: \")\nprint(d)\n\n# dstack: Stack arrays depth-wise (along third axis)\ne = np.dstack((a, b))\nprint(\"Depth-wise stacked array: \")\nprint(e)\n\n# concatenate: Join arrays along an existing axis\nf = np.concatenate((a, b), axis=0)\nprint(\"Concatenated array along axis 0: \")\nprint(f)\n\n# row_stack: Stack arrays vertically (row-wise)\ng = np.row_stack((a, b))\nprint(\"Vertically stacked array using row_stack: \")\nprint(g)\n\n# column_stack: Stack arrays horizontally (column-wise)\nh = np.column_stack((a, b))\nprint(\"Horizontally stacked array using column_stack: \")\nprint(h)\n\n# hsplit: Split arrays horizontally (column-wise)\ni = np.hsplit(d, 2)\nprint(\"Horizontally split arrays: \")\nprint(i)\n\n# vsplit: Split arrays vertically (row-wise)\nj = np.vsplit(c, 2)\nprint(\"Vertically split arrays: \")\nprint(j)\n\n# dsplit: Split arrays depth-wise (along third axis)\nk = np.dsplit(e, 2)\nprint(\"Depth-wise split arrays: \")\nprint(k)\n```\n\n```\nVertically stacked array: \n[[ 1  2  3]\n [ 4  5  6]\n [ 7  8  9]\n [10 11 12]]\nHorizontally stacked array: \n[[ 1  2  3  7  8  9]\n [ 4  5  6 10 11 12]]\nDepth-wise stacked array: \n[[[ 1  7]\n  [ 2  8]\n  [ 3  9]]\n\n [[ 4 10]\n  [ 5 11]\n  [ 6 12]]]\nConcatenated array along axis 0: \n[[ 1  2  3]\n [ 4  5  6]\n [ 7  8  9]\n [10 11 12]]\nVertically stacked array using row_stack: \n[[ 1  2  3]\n [ 4  5  6]\n [ 7  8  9]\n [10 11 12]]\nHorizontally stacked array using column_stack: \n[[ 1  2  3  7  8  9]\n [ 4  5  6 10 11 12]]\nHorizontally split arrays: \n[array([[1, 2, 3],\n       [4, 5, 6]]), array([[ 7,  8,  9],\n       [10, 11, 12]])]\nVertically split arrays: \n[array([[1, 2, 3],\n       [4, 5, 6]]), array([[ 7,  8,  9],\n       [10, 11, 12]])]\nDepth-wise split arrays: \n[array([[[1],\n        [2],\n        [3]],\n\n       [[4],\n        [5],\n        [6]]]), array([[[ 7],\n        [ 8],\n        [ 9]],\n\n       [[10],\n        [11],\n        [12]]])]\n```\n\n### Broadcasting\n\n```python\nimport numpy as np\n\n# Broadcasting with scalars\na = np.array([1, 2, 3, 4])\nb = 2\nprint(a + b)  # Output: [3 4 5 6]\n\n# Broadcasting with arrays of different shapes\nc = np.array([[1, 2, 3], [4, 5, 6]])\nd = np.array([10, 20, 30])\nprint(c + d)  # Output: [[11 22 33] [14 25 36]]\n\n# Broadcasting with arrays of different ranks\ne = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nf = np.array([10, 20, 30])\nprint(e + f)  # Output: [[11 22 33] [14 25 36] [17 28 39]]\n\n# Broadcasting with arrays of different sizes\ng = np.array([[1, 2, 3], [4, 5, 6]])\nh = np.array([10])\nprint(g + h)  # Output: [[11 12 13] [14 15 16]]\n\n# Broadcasting with arrays of different sizes and shapes\ni = np.array([[1, 2, 3], [4, 5, 6]])\nj = np.array([[10], [20]])\nprint(i + j)  # Output: [[11 12 13] [24 25 26]]\n```\n\n","slug":"Numpy-Basics","published":1,"updated":"2023-04-07T02:43:50.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73h4000qozpi9itdhuza","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Create-1D-array-using-Numpy\"><a href=\"#Create-1D-array-using-Numpy\" class=\"headerlink\" title=\"Create 1D array using Numpy\"></a>Create 1D array using Numpy</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create 1D arrays using different methods</span></span><br><span class=\"line\">a = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])        <span class=\"comment\"># Create 1D array from a list</span></span><br><span class=\"line\"><span class=\"comment\"># [1 2 3 4 5]</span></span><br><span class=\"line\">b = np.arange(<span class=\"number\">10</span>)                   <span class=\"comment\"># Create 1D array using range</span></span><br><span class=\"line\"><span class=\"comment\"># [0 1 2 3 4 5 6 7 8 9]</span></span><br><span class=\"line\">c = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">5</span>)             <span class=\"comment\"># Create 1D array with equally spaced values</span></span><br><span class=\"line\"><span class=\"comment\"># [0.   0.25 0.5  0.75 1.  ]</span></span><br><span class=\"line\">d = np.random.rand(<span class=\"number\">5</span>)               <span class=\"comment\"># Create 1D array with random values</span></span><br><span class=\"line\"><span class=\"comment\"># [0.785179   0.05506288 0.83677954 0.98587586 0.52964397]</span></span><br><span class=\"line\">e = np.zeros(<span class=\"number\">5</span>)                     <span class=\"comment\"># Create 1D array of zeros</span></span><br><span class=\"line\"><span class=\"comment\"># [0. 0. 0. 0. 0.]</span></span><br><span class=\"line\">f = np.ones(<span class=\"number\">5</span>)                      <span class=\"comment\"># Create 1D array of ones</span></span><br><span class=\"line\"><span class=\"comment\"># [1. 1. 1. 1. 1.]</span></span><br><span class=\"line\">g = np.full(<span class=\"number\">5</span>, <span class=\"number\">2</span>)                   <span class=\"comment\"># Create 1D array of a specific value</span></span><br><span class=\"line\"><span class=\"comment\"># [2 2 2 2 2]</span></span><br><span class=\"line\">h = np.empty(<span class=\"number\">5</span>)                     <span class=\"comment\"># Create 1D array without initializing its values</span></span><br><span class=\"line\"><span class=\"comment\"># [0. 0. 0. 0. 0.]</span></span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Create-2D-array-using-Numpy\"><a href=\"#Create-2D-array-using-Numpy\" class=\"headerlink\" title=\"Create 2D array using Numpy\"></a>Create 2D array using Numpy</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create 2D arrays using different methods</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])         <span class=\"comment\"># Create 2D array from nested lists</span></span><br><span class=\"line\">b = np.zeros((<span class=\"number\">3</span>, <span class=\"number\">3</span>))                        <span class=\"comment\"># Create 2D array of zeros</span></span><br><span class=\"line\">c = np.ones((<span class=\"number\">2</span>, <span class=\"number\">2</span>))                         <span class=\"comment\"># Create 2D array of ones</span></span><br><span class=\"line\">d = np.eye(<span class=\"number\">3</span>)                               <span class=\"comment\"># Create 2D identity matrix</span></span><br><span class=\"line\">e = np.random.rand(<span class=\"number\">2</span>, <span class=\"number\">3</span>)                    <span class=\"comment\"># Create 2D array with random values</span></span><br><span class=\"line\">f = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]])              <span class=\"comment\"># Create 2D array from a list of lists</span></span><br><span class=\"line\">g = np.empty((<span class=\"number\">2</span>, <span class=\"number\">2</span>))                        <span class=\"comment\"># Create uninitialized 2D array</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># a</span><br><span class=\"line\">[[1 2 3]</span><br><span class=\"line\"> [4 5 6]]</span><br><span class=\"line\"> # b</span><br><span class=\"line\">[[0. 0. 0.]</span><br><span class=\"line\"> [0. 0. 0.]</span><br><span class=\"line\"> [0. 0. 0.]]</span><br><span class=\"line\"> # c</span><br><span class=\"line\">[[1. 1.]</span><br><span class=\"line\"> [1. 1.]]</span><br><span class=\"line\"> # d</span><br><span class=\"line\">[[1. 0. 0.]</span><br><span class=\"line\"> [0. 1. 0.]</span><br><span class=\"line\"> [0. 0. 1.]]</span><br><span class=\"line\"> # e</span><br><span class=\"line\">[[0.23691216 0.7258241  0.25003681]</span><br><span class=\"line\"> [0.52863985 0.92896228 0.81953756]]</span><br><span class=\"line\"> # f</span><br><span class=\"line\">[[1 2]</span><br><span class=\"line\"> [3 4]]</span><br><span class=\"line\"> # g</span><br><span class=\"line\">[[0. 0.]</span><br><span class=\"line\"> [0. 0.]]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Checking-attributes-of-a-2D-array\"><a href=\"#Checking-attributes-of-a-2D-array\" class=\"headerlink\" title=\"Checking attributes of a 2D array\"></a>Checking attributes of a 2D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 2D array</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the size, shape, and number of dimensions of the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Size of the array: \"</span>, a.size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Shape of the array: \"</span>, a.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Number of dimensions: \"</span>, a.ndim)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the data type of the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Data type of the array: \"</span>, a.dtype)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the number of bytes used by each element in the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Bytes per element: \"</span>, a.itemsize)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the total number of bytes used by the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Total number of bytes used by the array: \"</span>, a.nbytes)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Size of the array:  6</span><br><span class=\"line\">Shape of the array:  (2, 3)</span><br><span class=\"line\">Number of dimensions:  2</span><br><span class=\"line\">Data type of the array:  int64</span><br><span class=\"line\">Bytes per element:  8</span><br><span class=\"line\">Total number of bytes used by the array:  48</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Comprehension\"><a href=\"#Comprehension\" class=\"headerlink\" title=\"Comprehension\"></a>Comprehension</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># List comprehension example</span></span><br><span class=\"line\"><span class=\"comment\"># Create a list of squares of numbers from 1 to 10</span></span><br><span class=\"line\">squares = [x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">11</span>)]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"List of squares: \"</span>, squares)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dictionary comprehension example</span></span><br><span class=\"line\"><span class=\"comment\"># Create a dictionary of squares of numbers from 1 to 10</span></span><br><span class=\"line\">squares_dict = {x: x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">11</span>)}</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Dictionary of squares: \"</span>, squares_dict)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set comprehension example</span></span><br><span class=\"line\"><span class=\"comment\"># Create a set of squares of numbers from 1 to 10</span></span><br><span class=\"line\">squares_set = {x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">11</span>)}</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Set of squares: \"</span>, squares_set)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">List</span> of squares:  [<span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">9</span>, <span class=\"number\">16</span>, <span class=\"number\">25</span>, <span class=\"number\">36</span>, <span class=\"number\">49</span>, <span class=\"number\">64</span>, <span class=\"number\">81</span>, <span class=\"number\">100</span>]</span><br><span class=\"line\">Dictionary of squares:  {<span class=\"number\">1</span>: <span class=\"number\">1</span>, <span class=\"number\">2</span>: <span class=\"number\">4</span>, <span class=\"number\">3</span>: <span class=\"number\">9</span>, <span class=\"number\">4</span>: <span class=\"number\">16</span>, <span class=\"number\">5</span>: <span class=\"number\">25</span>, <span class=\"number\">6</span>: <span class=\"number\">36</span>, <span class=\"number\">7</span>: <span class=\"number\">49</span>, <span class=\"number\">8</span>: <span class=\"number\">64</span>, <span class=\"number\">9</span>: <span class=\"number\">81</span>, <span class=\"number\">10</span>: <span class=\"number\">100</span>}</span><br><span class=\"line\"><span class=\"type\">Set</span> of squares:  {<span class=\"number\">64</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">36</span>, <span class=\"number\">100</span>, <span class=\"number\">9</span>, <span class=\"number\">16</span>, <span class=\"number\">49</span>, <span class=\"number\">81</span>, <span class=\"number\">25</span>}</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Basic-operations-of-a-Matrix\"><a href=\"#Basic-operations-of-a-Matrix\" class=\"headerlink\" title=\"Basic operations of a Matrix\"></a>Basic operations of a Matrix</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 2D array</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Perform some basic operations on the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array to the power of 2: \"</span>, a ** <span class=\"number\">2</span>)        <span class=\"comment\"># Exponentiation</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array divided by 2: \"</span>, a / <span class=\"number\">2</span>)              <span class=\"comment\"># Division</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array modulo 2: \"</span>, a % <span class=\"number\">2</span>)                  <span class=\"comment\"># Modulo</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array integer divided by 2: \"</span>, a // <span class=\"number\">2</span>)     <span class=\"comment\"># Integer division</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array greater than 5: \"</span>, a &gt; <span class=\"number\">5</span>)            <span class=\"comment\"># Comparison</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array equal to 6: \"</span>, a == <span class=\"number\">6</span>)               <span class=\"comment\"># Comparison</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array plus 100: \"</span>, a + <span class=\"number\">100</span>)               <span class=\"comment\"># Addition</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Array to the power of 2:  [[ 1  4  9]</span><br><span class=\"line\"> [16 25 36]]</span><br><span class=\"line\">Array divided by 2:  [[0.5 1.  1.5]</span><br><span class=\"line\"> [2.  2.5 3. ]]</span><br><span class=\"line\">Array modulo 2:  [[1 0 1]</span><br><span class=\"line\"> [0 1 0]]</span><br><span class=\"line\">Array integer divided by 2:  [[0 1 1]</span><br><span class=\"line\"> [2 2 3]]</span><br><span class=\"line\">Array greater than 5:  [[False False False]</span><br><span class=\"line\"> [False False  True]]</span><br><span class=\"line\">Array equal to 6:  [[False False False]</span><br><span class=\"line\"> [False False  True]]</span><br><span class=\"line\">Array plus 100:  [[101 102 103]</span><br><span class=\"line\"> [104 105 106]]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Index-and-slice-for-1D-array\"><a href=\"#Index-and-slice-for-1D-array\" class=\"headerlink\" title=\"Index and slice for 1D array\"></a>Index and slice for 1D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 1D array</span></span><br><span class=\"line\">a = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Indexing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index 0: \"</span>, a[<span class=\"number\">0</span>])         <span class=\"comment\"># Indexing by position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index -1: \"</span>, a[-<span class=\"number\">1</span>])       <span class=\"comment\"># Indexing by negative position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index 2: \"</span>, a[<span class=\"number\">2</span>])         <span class=\"comment\"># Indexing by position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index -3: \"</span>, a[-<span class=\"number\">3</span>])       <span class=\"comment\"># Indexing by negative position</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Slicing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Elements from index 1 to 3: \"</span>, a[<span class=\"number\">1</span>:<span class=\"number\">4</span>])    <span class=\"comment\"># Slicing using start and end positions</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Elements from index 0 to end: \"</span>, a[:])     <span class=\"comment\"># Slicing from start to end</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Every second element: \"</span>, a[::<span class=\"number\">2</span>])           <span class=\"comment\"># Slicing with a step of 2</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Reversed array: \"</span>, a[::-<span class=\"number\">1</span>])                <span class=\"comment\"># Slicing with a negative step</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Element at index 0:  1</span><br><span class=\"line\">Element at index -1:  5</span><br><span class=\"line\">Element at index 2:  3</span><br><span class=\"line\">Element at index -3:  3</span><br><span class=\"line\">Elements from index 1 to 3:  [2 3 4]</span><br><span class=\"line\">Elements from index 0 to end:  [1 2 3 4 5]</span><br><span class=\"line\">Every second element:  [1 3 5]</span><br><span class=\"line\">Reversed array:  [5 4 3 2 1]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Index-and-slice-for-2D-array\"><a href=\"#Index-and-slice-for-2D-array\" class=\"headerlink\" title=\"Index and slice for 2D array\"></a>Index and slice for 2D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 2D array</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Indexing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at row 0, column 1: \"</span>, a[<span class=\"number\">0</span>, <span class=\"number\">1</span>])        <span class=\"comment\"># Indexing a single element</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at row -1, column -2: \"</span>, a[-<span class=\"number\">1</span>, -<span class=\"number\">2</span>])    <span class=\"comment\"># Indexing a single element using negative indices</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"First row: \"</span>, a[<span class=\"number\">0</span>, :])                          <span class=\"comment\"># Indexing a row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Second column: \"</span>, a[:, <span class=\"number\">1</span>])                      <span class=\"comment\"># Indexing a column</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Slicing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Subarray from rows 0 to 1, columns 1 to 2: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">0</span>:<span class=\"number\">2</span>, <span class=\"number\">1</span>:<span class=\"number\">3</span>])                                    <span class=\"comment\"># Slicing a subarray</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"First two rows: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[:<span class=\"number\">2</span>, :])                                        <span class=\"comment\"># Slicing the first two rows</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Last two columns: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[:, -<span class=\"number\">2</span>:])                                       <span class=\"comment\"># Slicing the last two columns</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Element at row 0, column 1:  2</span><br><span class=\"line\">Element at row -1, column -2:  8</span><br><span class=\"line\">First row:  [1 2 3]</span><br><span class=\"line\">Second column:  [2 5 8]</span><br><span class=\"line\">Subarray from rows 0 to 1, columns 1 to 2: </span><br><span class=\"line\">[[2 3]</span><br><span class=\"line\"> [5 6]]</span><br><span class=\"line\">First two rows: </span><br><span class=\"line\">[[1 2 3]</span><br><span class=\"line\"> [4 5 6]]</span><br><span class=\"line\">Last two columns: </span><br><span class=\"line\">[[2 3]</span><br><span class=\"line\"> [5 6]</span><br><span class=\"line\"> [8 9]]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Index-and-slice-for-3D-array\"><a href=\"#Index-and-slice-for-3D-array\" class=\"headerlink\" title=\"Index and slice for 3D array\"></a>Index and slice for 3D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 3D array</span></span><br><span class=\"line\">a = np.array([[[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]], [[<span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>]]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Indexing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at position 1, 0, 1: \"</span>, a[<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>])     <span class=\"comment\"># Indexing a single element</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Last element in the last row of the last matrix: \"</span>, a[-<span class=\"number\">1</span>, -<span class=\"number\">1</span>, -<span class=\"number\">1</span>])  <span class=\"comment\"># Indexing a single element using negative indices</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"First matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">0</span>, :, :])                                      <span class=\"comment\"># Indexing the first matrix</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Second row of the second matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">1</span>, <span class=\"number\">1</span>, :])                                      <span class=\"comment\"># Indexing the second row of the second matrix</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Slicing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Subarray from the first matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">0</span>, :, :])                                      <span class=\"comment\"># Slicing a subarray</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Subarray from the second matrix, rows 0 to 1, columns 0 to 1: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">1</span>, <span class=\"number\">0</span>:<span class=\"number\">2</span>, <span class=\"number\">0</span>:<span class=\"number\">2</span>])                                  <span class=\"comment\"># Slicing a subarray</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Last row of the last matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[-<span class=\"number\">1</span>, -<span class=\"number\">1</span>, :])                                     <span class=\"comment\"># Slicing the last row of the last matrix</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Element at position 1, 0, 1:  6</span><br><span class=\"line\">Last element in the last row of the last matrix:  8</span><br><span class=\"line\">First matrix: </span><br><span class=\"line\">[[1 2]</span><br><span class=\"line\"> [3 4]]</span><br><span class=\"line\">Second row of the second matrix: </span><br><span class=\"line\">[7 8]</span><br><span class=\"line\">Subarray from the first matrix: </span><br><span class=\"line\">[[1 2]</span><br><span class=\"line\"> [3 4]]</span><br><span class=\"line\">Subarray from the second matrix, rows 0 to 1, columns 0 to 1: </span><br><span class=\"line\">[[5 6]</span><br><span class=\"line\"> [7 8]]</span><br><span class=\"line\">Last row of the last matrix: </span><br><span class=\"line\">[7 8]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Stack-and-split\"><a href=\"#Stack-and-split\" class=\"headerlink\" title=\"Stack and split\"></a>Stack and split</h3><figure class=\"highlight py\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create two 2D arrays</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">b = np.array([[<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># vstack: Stack arrays vertically (row-wise)</span></span><br><span class=\"line\">c = np.vstack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vertically stacked array: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(c)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># hstack: Stack arrays horizontally (column-wise)</span></span><br><span class=\"line\">d = np.hstack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Horizontally stacked array: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(d)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dstack: Stack arrays depth-wise (along third axis)</span></span><br><span class=\"line\">e = np.dstack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Depth-wise stacked array: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(e)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># concatenate: Join arrays along an existing axis</span></span><br><span class=\"line\">f = np.concatenate((a, b), axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Concatenated array along axis 0: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># row_stack: Stack arrays vertically (row-wise)</span></span><br><span class=\"line\">g = np.row_stack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vertically stacked array using row_stack: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(g)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># column_stack: Stack arrays horizontally (column-wise)</span></span><br><span class=\"line\">h = np.column_stack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Horizontally stacked array using column_stack: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(h)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># hsplit: Split arrays horizontally (column-wise)</span></span><br><span class=\"line\">i = np.hsplit(d, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Horizontally split arrays: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(i)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># vsplit: Split arrays vertically (row-wise)</span></span><br><span class=\"line\">j = np.vsplit(c, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vertically split arrays: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(j)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dsplit: Split arrays depth-wise (along third axis)</span></span><br><span class=\"line\">k = np.dsplit(e, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Depth-wise split arrays: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(k)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Vertically stacked array: </span><br><span class=\"line\">[[ 1  2  3]</span><br><span class=\"line\"> [ 4  5  6]</span><br><span class=\"line\"> [ 7  8  9]</span><br><span class=\"line\"> [10 11 12]]</span><br><span class=\"line\">Horizontally stacked array: </span><br><span class=\"line\">[[ 1  2  3  7  8  9]</span><br><span class=\"line\"> [ 4  5  6 10 11 12]]</span><br><span class=\"line\">Depth-wise stacked array: </span><br><span class=\"line\">[[[ 1  7]</span><br><span class=\"line\">  [ 2  8]</span><br><span class=\"line\">  [ 3  9]]</span><br><span class=\"line\"></span><br><span class=\"line\"> [[ 4 10]</span><br><span class=\"line\">  [ 5 11]</span><br><span class=\"line\">  [ 6 12]]]</span><br><span class=\"line\">Concatenated array along axis 0: </span><br><span class=\"line\">[[ 1  2  3]</span><br><span class=\"line\"> [ 4  5  6]</span><br><span class=\"line\"> [ 7  8  9]</span><br><span class=\"line\"> [10 11 12]]</span><br><span class=\"line\">Vertically stacked array using row_stack: </span><br><span class=\"line\">[[ 1  2  3]</span><br><span class=\"line\"> [ 4  5  6]</span><br><span class=\"line\"> [ 7  8  9]</span><br><span class=\"line\"> [10 11 12]]</span><br><span class=\"line\">Horizontally stacked array using column_stack: </span><br><span class=\"line\">[[ 1  2  3  7  8  9]</span><br><span class=\"line\"> [ 4  5  6 10 11 12]]</span><br><span class=\"line\">Horizontally split arrays: </span><br><span class=\"line\">[array([[1, 2, 3],</span><br><span class=\"line\">       [4, 5, 6]]), array([[ 7,  8,  9],</span><br><span class=\"line\">       [10, 11, 12]])]</span><br><span class=\"line\">Vertically split arrays: </span><br><span class=\"line\">[array([[1, 2, 3],</span><br><span class=\"line\">       [4, 5, 6]]), array([[ 7,  8,  9],</span><br><span class=\"line\">       [10, 11, 12]])]</span><br><span class=\"line\">Depth-wise split arrays: </span><br><span class=\"line\">[array([[[1],</span><br><span class=\"line\">        [2],</span><br><span class=\"line\">        [3]],</span><br><span class=\"line\"></span><br><span class=\"line\">       [[4],</span><br><span class=\"line\">        [5],</span><br><span class=\"line\">        [6]]]), array([[[ 7],</span><br><span class=\"line\">        [ 8],</span><br><span class=\"line\">        [ 9]],</span><br><span class=\"line\"></span><br><span class=\"line\">       [[10],</span><br><span class=\"line\">        [11],</span><br><span class=\"line\">        [12]]])]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Broadcasting\"><a href=\"#Broadcasting\" class=\"headerlink\" title=\"Broadcasting\"></a>Broadcasting</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with scalars</span></span><br><span class=\"line\">a = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\">b = <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a + b)  <span class=\"comment\"># Output: [3 4 5 6]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different shapes</span></span><br><span class=\"line\">c = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">d = np.array([<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(c + d)  <span class=\"comment\"># Output: [[11 22 33] [14 25 36]]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different ranks</span></span><br><span class=\"line\">e = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\">f = np.array([<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(e + f)  <span class=\"comment\"># Output: [[11 22 33] [14 25 36] [17 28 39]]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different sizes</span></span><br><span class=\"line\">g = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">h = np.array([<span class=\"number\">10</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(g + h)  <span class=\"comment\"># Output: [[11 12 13] [14 15 16]]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different sizes and shapes</span></span><br><span class=\"line\">i = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">j = np.array([[<span class=\"number\">10</span>], [<span class=\"number\">20</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(i + j)  <span class=\"comment\"># Output: [[11 12 13] [24 25 26]]</span></span><br></pre></td></tr></tbody></table></figure>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/27/Basic-operations-of-Matrix/","2023/03/28/Image-processing-using-Numpy/","2023/03/27/Linear-Algebra-Basics/","2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/","2023/03/28/Regression/"],"length":1760,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Create-1D-array-using-Numpy\"><a href=\"#Create-1D-array-using-Numpy\" class=\"headerlink\" title=\"Create 1D array using Numpy\"></a>Create 1D array using Numpy</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create 1D arrays using different methods</span></span><br><span class=\"line\">a = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])        <span class=\"comment\"># Create 1D array from a list</span></span><br><span class=\"line\"><span class=\"comment\"># [1 2 3 4 5]</span></span><br><span class=\"line\">b = np.arange(<span class=\"number\">10</span>)                   <span class=\"comment\"># Create 1D array using range</span></span><br><span class=\"line\"><span class=\"comment\"># [0 1 2 3 4 5 6 7 8 9]</span></span><br><span class=\"line\">c = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">5</span>)             <span class=\"comment\"># Create 1D array with equally spaced values</span></span><br><span class=\"line\"><span class=\"comment\"># [0.   0.25 0.5  0.75 1.  ]</span></span><br><span class=\"line\">d = np.random.rand(<span class=\"number\">5</span>)               <span class=\"comment\"># Create 1D array with random values</span></span><br><span class=\"line\"><span class=\"comment\"># [0.785179   0.05506288 0.83677954 0.98587586 0.52964397]</span></span><br><span class=\"line\">e = np.zeros(<span class=\"number\">5</span>)                     <span class=\"comment\"># Create 1D array of zeros</span></span><br><span class=\"line\"><span class=\"comment\"># [0. 0. 0. 0. 0.]</span></span><br><span class=\"line\">f = np.ones(<span class=\"number\">5</span>)                      <span class=\"comment\"># Create 1D array of ones</span></span><br><span class=\"line\"><span class=\"comment\"># [1. 1. 1. 1. 1.]</span></span><br><span class=\"line\">g = np.full(<span class=\"number\">5</span>, <span class=\"number\">2</span>)                   <span class=\"comment\"># Create 1D array of a specific value</span></span><br><span class=\"line\"><span class=\"comment\"># [2 2 2 2 2]</span></span><br><span class=\"line\">h = np.empty(<span class=\"number\">5</span>)                     <span class=\"comment\"># Create 1D array without initializing its values</span></span><br><span class=\"line\"><span class=\"comment\"># [0. 0. 0. 0. 0.]</span></span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Create-2D-array-using-Numpy\"><a href=\"#Create-2D-array-using-Numpy\" class=\"headerlink\" title=\"Create 2D array using Numpy\"></a>Create 2D array using Numpy</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create 2D arrays using different methods</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])         <span class=\"comment\"># Create 2D array from nested lists</span></span><br><span class=\"line\">b = np.zeros((<span class=\"number\">3</span>, <span class=\"number\">3</span>))                        <span class=\"comment\"># Create 2D array of zeros</span></span><br><span class=\"line\">c = np.ones((<span class=\"number\">2</span>, <span class=\"number\">2</span>))                         <span class=\"comment\"># Create 2D array of ones</span></span><br><span class=\"line\">d = np.eye(<span class=\"number\">3</span>)                               <span class=\"comment\"># Create 2D identity matrix</span></span><br><span class=\"line\">e = np.random.rand(<span class=\"number\">2</span>, <span class=\"number\">3</span>)                    <span class=\"comment\"># Create 2D array with random values</span></span><br><span class=\"line\">f = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]])              <span class=\"comment\"># Create 2D array from a list of lists</span></span><br><span class=\"line\">g = np.empty((<span class=\"number\">2</span>, <span class=\"number\">2</span>))                        <span class=\"comment\"># Create uninitialized 2D array</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># a</span><br><span class=\"line\">[[1 2 3]</span><br><span class=\"line\"> [4 5 6]]</span><br><span class=\"line\"> # b</span><br><span class=\"line\">[[0. 0. 0.]</span><br><span class=\"line\"> [0. 0. 0.]</span><br><span class=\"line\"> [0. 0. 0.]]</span><br><span class=\"line\"> # c</span><br><span class=\"line\">[[1. 1.]</span><br><span class=\"line\"> [1. 1.]]</span><br><span class=\"line\"> # d</span><br><span class=\"line\">[[1. 0. 0.]</span><br><span class=\"line\"> [0. 1. 0.]</span><br><span class=\"line\"> [0. 0. 1.]]</span><br><span class=\"line\"> # e</span><br><span class=\"line\">[[0.23691216 0.7258241  0.25003681]</span><br><span class=\"line\"> [0.52863985 0.92896228 0.81953756]]</span><br><span class=\"line\"> # f</span><br><span class=\"line\">[[1 2]</span><br><span class=\"line\"> [3 4]]</span><br><span class=\"line\"> # g</span><br><span class=\"line\">[[0. 0.]</span><br><span class=\"line\"> [0. 0.]]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Checking-attributes-of-a-2D-array\"><a href=\"#Checking-attributes-of-a-2D-array\" class=\"headerlink\" title=\"Checking attributes of a 2D array\"></a>Checking attributes of a 2D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 2D array</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the size, shape, and number of dimensions of the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Size of the array: \"</span>, a.size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Shape of the array: \"</span>, a.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Number of dimensions: \"</span>, a.ndim)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the data type of the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Data type of the array: \"</span>, a.dtype)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the number of bytes used by each element in the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Bytes per element: \"</span>, a.itemsize)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check the total number of bytes used by the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Total number of bytes used by the array: \"</span>, a.nbytes)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Size of the array:  6</span><br><span class=\"line\">Shape of the array:  (2, 3)</span><br><span class=\"line\">Number of dimensions:  2</span><br><span class=\"line\">Data type of the array:  int64</span><br><span class=\"line\">Bytes per element:  8</span><br><span class=\"line\">Total number of bytes used by the array:  48</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Comprehension\"><a href=\"#Comprehension\" class=\"headerlink\" title=\"Comprehension\"></a>Comprehension</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># List comprehension example</span></span><br><span class=\"line\"><span class=\"comment\"># Create a list of squares of numbers from 1 to 10</span></span><br><span class=\"line\">squares = [x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">11</span>)]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"List of squares: \"</span>, squares)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dictionary comprehension example</span></span><br><span class=\"line\"><span class=\"comment\"># Create a dictionary of squares of numbers from 1 to 10</span></span><br><span class=\"line\">squares_dict = {x: x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">11</span>)}</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Dictionary of squares: \"</span>, squares_dict)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set comprehension example</span></span><br><span class=\"line\"><span class=\"comment\"># Create a set of squares of numbers from 1 to 10</span></span><br><span class=\"line\">squares_set = {x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, <span class=\"number\">11</span>)}</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Set of squares: \"</span>, squares_set)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">List</span> of squares:  [<span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">9</span>, <span class=\"number\">16</span>, <span class=\"number\">25</span>, <span class=\"number\">36</span>, <span class=\"number\">49</span>, <span class=\"number\">64</span>, <span class=\"number\">81</span>, <span class=\"number\">100</span>]</span><br><span class=\"line\">Dictionary of squares:  {<span class=\"number\">1</span>: <span class=\"number\">1</span>, <span class=\"number\">2</span>: <span class=\"number\">4</span>, <span class=\"number\">3</span>: <span class=\"number\">9</span>, <span class=\"number\">4</span>: <span class=\"number\">16</span>, <span class=\"number\">5</span>: <span class=\"number\">25</span>, <span class=\"number\">6</span>: <span class=\"number\">36</span>, <span class=\"number\">7</span>: <span class=\"number\">49</span>, <span class=\"number\">8</span>: <span class=\"number\">64</span>, <span class=\"number\">9</span>: <span class=\"number\">81</span>, <span class=\"number\">10</span>: <span class=\"number\">100</span>}</span><br><span class=\"line\"><span class=\"type\">Set</span> of squares:  {<span class=\"number\">64</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">36</span>, <span class=\"number\">100</span>, <span class=\"number\">9</span>, <span class=\"number\">16</span>, <span class=\"number\">49</span>, <span class=\"number\">81</span>, <span class=\"number\">25</span>}</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Basic-operations-of-a-Matrix\"><a href=\"#Basic-operations-of-a-Matrix\" class=\"headerlink\" title=\"Basic operations of a Matrix\"></a>Basic operations of a Matrix</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 2D array</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Perform some basic operations on the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array to the power of 2: \"</span>, a ** <span class=\"number\">2</span>)        <span class=\"comment\"># Exponentiation</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array divided by 2: \"</span>, a / <span class=\"number\">2</span>)              <span class=\"comment\"># Division</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array modulo 2: \"</span>, a % <span class=\"number\">2</span>)                  <span class=\"comment\"># Modulo</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array integer divided by 2: \"</span>, a // <span class=\"number\">2</span>)     <span class=\"comment\"># Integer division</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array greater than 5: \"</span>, a &gt; <span class=\"number\">5</span>)            <span class=\"comment\"># Comparison</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array equal to 6: \"</span>, a == <span class=\"number\">6</span>)               <span class=\"comment\"># Comparison</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Array plus 100: \"</span>, a + <span class=\"number\">100</span>)               <span class=\"comment\"># Addition</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Array to the power of 2:  [[ 1  4  9]</span><br><span class=\"line\"> [16 25 36]]</span><br><span class=\"line\">Array divided by 2:  [[0.5 1.  1.5]</span><br><span class=\"line\"> [2.  2.5 3. ]]</span><br><span class=\"line\">Array modulo 2:  [[1 0 1]</span><br><span class=\"line\"> [0 1 0]]</span><br><span class=\"line\">Array integer divided by 2:  [[0 1 1]</span><br><span class=\"line\"> [2 2 3]]</span><br><span class=\"line\">Array greater than 5:  [[False False False]</span><br><span class=\"line\"> [False False  True]]</span><br><span class=\"line\">Array equal to 6:  [[False False False]</span><br><span class=\"line\"> [False False  True]]</span><br><span class=\"line\">Array plus 100:  [[101 102 103]</span><br><span class=\"line\"> [104 105 106]]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Index-and-slice-for-1D-array\"><a href=\"#Index-and-slice-for-1D-array\" class=\"headerlink\" title=\"Index and slice for 1D array\"></a>Index and slice for 1D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 1D array</span></span><br><span class=\"line\">a = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Indexing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index 0: \"</span>, a[<span class=\"number\">0</span>])         <span class=\"comment\"># Indexing by position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index -1: \"</span>, a[-<span class=\"number\">1</span>])       <span class=\"comment\"># Indexing by negative position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index 2: \"</span>, a[<span class=\"number\">2</span>])         <span class=\"comment\"># Indexing by position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at index -3: \"</span>, a[-<span class=\"number\">3</span>])       <span class=\"comment\"># Indexing by negative position</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Slicing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Elements from index 1 to 3: \"</span>, a[<span class=\"number\">1</span>:<span class=\"number\">4</span>])    <span class=\"comment\"># Slicing using start and end positions</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Elements from index 0 to end: \"</span>, a[:])     <span class=\"comment\"># Slicing from start to end</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Every second element: \"</span>, a[::<span class=\"number\">2</span>])           <span class=\"comment\"># Slicing with a step of 2</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Reversed array: \"</span>, a[::-<span class=\"number\">1</span>])                <span class=\"comment\"># Slicing with a negative step</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Element at index 0:  1</span><br><span class=\"line\">Element at index -1:  5</span><br><span class=\"line\">Element at index 2:  3</span><br><span class=\"line\">Element at index -3:  3</span><br><span class=\"line\">Elements from index 1 to 3:  [2 3 4]</span><br><span class=\"line\">Elements from index 0 to end:  [1 2 3 4 5]</span><br><span class=\"line\">Every second element:  [1 3 5]</span><br><span class=\"line\">Reversed array:  [5 4 3 2 1]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Index-and-slice-for-2D-array\"><a href=\"#Index-and-slice-for-2D-array\" class=\"headerlink\" title=\"Index and slice for 2D array\"></a>Index and slice for 2D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 2D array</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Indexing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at row 0, column 1: \"</span>, a[<span class=\"number\">0</span>, <span class=\"number\">1</span>])        <span class=\"comment\"># Indexing a single element</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at row -1, column -2: \"</span>, a[-<span class=\"number\">1</span>, -<span class=\"number\">2</span>])    <span class=\"comment\"># Indexing a single element using negative indices</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"First row: \"</span>, a[<span class=\"number\">0</span>, :])                          <span class=\"comment\"># Indexing a row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Second column: \"</span>, a[:, <span class=\"number\">1</span>])                      <span class=\"comment\"># Indexing a column</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Slicing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Subarray from rows 0 to 1, columns 1 to 2: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">0</span>:<span class=\"number\">2</span>, <span class=\"number\">1</span>:<span class=\"number\">3</span>])                                    <span class=\"comment\"># Slicing a subarray</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"First two rows: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[:<span class=\"number\">2</span>, :])                                        <span class=\"comment\"># Slicing the first two rows</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Last two columns: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[:, -<span class=\"number\">2</span>:])                                       <span class=\"comment\"># Slicing the last two columns</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Element at row 0, column 1:  2</span><br><span class=\"line\">Element at row -1, column -2:  8</span><br><span class=\"line\">First row:  [1 2 3]</span><br><span class=\"line\">Second column:  [2 5 8]</span><br><span class=\"line\">Subarray from rows 0 to 1, columns 1 to 2: </span><br><span class=\"line\">[[2 3]</span><br><span class=\"line\"> [5 6]]</span><br><span class=\"line\">First two rows: </span><br><span class=\"line\">[[1 2 3]</span><br><span class=\"line\"> [4 5 6]]</span><br><span class=\"line\">Last two columns: </span><br><span class=\"line\">[[2 3]</span><br><span class=\"line\"> [5 6]</span><br><span class=\"line\"> [8 9]]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Index-and-slice-for-3D-array\"><a href=\"#Index-and-slice-for-3D-array\" class=\"headerlink\" title=\"Index and slice for 3D array\"></a>Index and slice for 3D array</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a 3D array</span></span><br><span class=\"line\">a = np.array([[[<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">4</span>]], [[<span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>]]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Indexing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Element at position 1, 0, 1: \"</span>, a[<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>])     <span class=\"comment\"># Indexing a single element</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Last element in the last row of the last matrix: \"</span>, a[-<span class=\"number\">1</span>, -<span class=\"number\">1</span>, -<span class=\"number\">1</span>])  <span class=\"comment\"># Indexing a single element using negative indices</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"First matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">0</span>, :, :])                                      <span class=\"comment\"># Indexing the first matrix</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Second row of the second matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">1</span>, <span class=\"number\">1</span>, :])                                      <span class=\"comment\"># Indexing the second row of the second matrix</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Slicing the array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Subarray from the first matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">0</span>, :, :])                                      <span class=\"comment\"># Slicing a subarray</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Subarray from the second matrix, rows 0 to 1, columns 0 to 1: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[<span class=\"number\">1</span>, <span class=\"number\">0</span>:<span class=\"number\">2</span>, <span class=\"number\">0</span>:<span class=\"number\">2</span>])                                  <span class=\"comment\"># Slicing a subarray</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Last row of the last matrix: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(a[-<span class=\"number\">1</span>, -<span class=\"number\">1</span>, :])                                     <span class=\"comment\"># Slicing the last row of the last matrix</span></span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Element at position 1, 0, 1:  6</span><br><span class=\"line\">Last element in the last row of the last matrix:  8</span><br><span class=\"line\">First matrix: </span><br><span class=\"line\">[[1 2]</span><br><span class=\"line\"> [3 4]]</span><br><span class=\"line\">Second row of the second matrix: </span><br><span class=\"line\">[7 8]</span><br><span class=\"line\">Subarray from the first matrix: </span><br><span class=\"line\">[[1 2]</span><br><span class=\"line\"> [3 4]]</span><br><span class=\"line\">Subarray from the second matrix, rows 0 to 1, columns 0 to 1: </span><br><span class=\"line\">[[5 6]</span><br><span class=\"line\"> [7 8]]</span><br><span class=\"line\">Last row of the last matrix: </span><br><span class=\"line\">[7 8]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Stack-and-split\"><a href=\"#Stack-and-split\" class=\"headerlink\" title=\"Stack and split\"></a>Stack and split</h3><figure class=\"highlight py\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create two 2D arrays</span></span><br><span class=\"line\">a = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">b = np.array([[<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>], [<span class=\"number\">10</span>, <span class=\"number\">11</span>, <span class=\"number\">12</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># vstack: Stack arrays vertically (row-wise)</span></span><br><span class=\"line\">c = np.vstack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vertically stacked array: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(c)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># hstack: Stack arrays horizontally (column-wise)</span></span><br><span class=\"line\">d = np.hstack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Horizontally stacked array: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(d)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dstack: Stack arrays depth-wise (along third axis)</span></span><br><span class=\"line\">e = np.dstack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Depth-wise stacked array: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(e)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># concatenate: Join arrays along an existing axis</span></span><br><span class=\"line\">f = np.concatenate((a, b), axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Concatenated array along axis 0: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(f)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># row_stack: Stack arrays vertically (row-wise)</span></span><br><span class=\"line\">g = np.row_stack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vertically stacked array using row_stack: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(g)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># column_stack: Stack arrays horizontally (column-wise)</span></span><br><span class=\"line\">h = np.column_stack((a, b))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Horizontally stacked array using column_stack: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(h)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># hsplit: Split arrays horizontally (column-wise)</span></span><br><span class=\"line\">i = np.hsplit(d, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Horizontally split arrays: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(i)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># vsplit: Split arrays vertically (row-wise)</span></span><br><span class=\"line\">j = np.vsplit(c, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Vertically split arrays: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(j)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dsplit: Split arrays depth-wise (along third axis)</span></span><br><span class=\"line\">k = np.dsplit(e, <span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Depth-wise split arrays: \"</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(k)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Vertically stacked array: </span><br><span class=\"line\">[[ 1  2  3]</span><br><span class=\"line\"> [ 4  5  6]</span><br><span class=\"line\"> [ 7  8  9]</span><br><span class=\"line\"> [10 11 12]]</span><br><span class=\"line\">Horizontally stacked array: </span><br><span class=\"line\">[[ 1  2  3  7  8  9]</span><br><span class=\"line\"> [ 4  5  6 10 11 12]]</span><br><span class=\"line\">Depth-wise stacked array: </span><br><span class=\"line\">[[[ 1  7]</span><br><span class=\"line\">  [ 2  8]</span><br><span class=\"line\">  [ 3  9]]</span><br><span class=\"line\"></span><br><span class=\"line\"> [[ 4 10]</span><br><span class=\"line\">  [ 5 11]</span><br><span class=\"line\">  [ 6 12]]]</span><br><span class=\"line\">Concatenated array along axis 0: </span><br><span class=\"line\">[[ 1  2  3]</span><br><span class=\"line\"> [ 4  5  6]</span><br><span class=\"line\"> [ 7  8  9]</span><br><span class=\"line\"> [10 11 12]]</span><br><span class=\"line\">Vertically stacked array using row_stack: </span><br><span class=\"line\">[[ 1  2  3]</span><br><span class=\"line\"> [ 4  5  6]</span><br><span class=\"line\"> [ 7  8  9]</span><br><span class=\"line\"> [10 11 12]]</span><br><span class=\"line\">Horizontally stacked array using column_stack: </span><br><span class=\"line\">[[ 1  2  3  7  8  9]</span><br><span class=\"line\"> [ 4  5  6 10 11 12]]</span><br><span class=\"line\">Horizontally split arrays: </span><br><span class=\"line\">[array([[1, 2, 3],</span><br><span class=\"line\">       [4, 5, 6]]), array([[ 7,  8,  9],</span><br><span class=\"line\">       [10, 11, 12]])]</span><br><span class=\"line\">Vertically split arrays: </span><br><span class=\"line\">[array([[1, 2, 3],</span><br><span class=\"line\">       [4, 5, 6]]), array([[ 7,  8,  9],</span><br><span class=\"line\">       [10, 11, 12]])]</span><br><span class=\"line\">Depth-wise split arrays: </span><br><span class=\"line\">[array([[[1],</span><br><span class=\"line\">        [2],</span><br><span class=\"line\">        [3]],</span><br><span class=\"line\"></span><br><span class=\"line\">       [[4],</span><br><span class=\"line\">        [5],</span><br><span class=\"line\">        [6]]]), array([[[ 7],</span><br><span class=\"line\">        [ 8],</span><br><span class=\"line\">        [ 9]],</span><br><span class=\"line\"></span><br><span class=\"line\">       [[10],</span><br><span class=\"line\">        [11],</span><br><span class=\"line\">        [12]]])]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Broadcasting\"><a href=\"#Broadcasting\" class=\"headerlink\" title=\"Broadcasting\"></a>Broadcasting</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with scalars</span></span><br><span class=\"line\">a = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>])</span><br><span class=\"line\">b = <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(a + b)  <span class=\"comment\"># Output: [3 4 5 6]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different shapes</span></span><br><span class=\"line\">c = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">d = np.array([<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(c + d)  <span class=\"comment\"># Output: [[11 22 33] [14 25 36]]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different ranks</span></span><br><span class=\"line\">e = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>], [<span class=\"number\">7</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\">f = np.array([<span class=\"number\">10</span>, <span class=\"number\">20</span>, <span class=\"number\">30</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(e + f)  <span class=\"comment\"># Output: [[11 22 33] [14 25 36] [17 28 39]]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different sizes</span></span><br><span class=\"line\">g = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">h = np.array([<span class=\"number\">10</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(g + h)  <span class=\"comment\"># Output: [[11 12 13] [14 15 16]]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Broadcasting with arrays of different sizes and shapes</span></span><br><span class=\"line\">i = np.array([[<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>], [<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>]])</span><br><span class=\"line\">j = np.array([[<span class=\"number\">10</span>], [<span class=\"number\">20</span>]])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(i + j)  <span class=\"comment\"># Output: [[11 12 13] [24 25 26]]</span></span><br></pre></td></tr></tbody></table></figure>\n</body></html>"},{"mathjax":true,"title":"OpenCV Hand Tracking to Count Fingers","date":"2023-04-01T16:18:59.000Z","_content":"\nThis program uses OpenCV and the Hand Tracking Module to detect and count the number of fingers visible in a camera feed. It can detect up to two hands simultaneously and displays the number of fingers for each hand as well as the total number of fingers on the screen.\n\nSteps:\n\n1. The program initializes the HandDetector object with the specified detection confidence and maximum number of hands to detect.\n2. The camera is opened and its resolution is set.\n3. The program enters a loop where it continuously reads the camera feed, detects and draws the hands on the image, and displays the finger count for each hand.\n4. If there is only one hand visible, the program calculates the finger count for that hand and sets the finger count for the other hand to 0.\n5. If two hands are visible, the program calculates the finger count for each hand and adds them together to get the total finger count.\n6. The finger counts are displayed on the screen using OpenCV's putText function.\n7. The loop stops when the user presses the 'q' key, and the camera is released and all windows are closed.\n\n```python\nimport cv2\nfrom cvzone.HandTrackingModule import HandDetector\n\n# initialize hand detector\ndetector = HandDetector(detectionCon=0.8, maxHands=2)\n\n# open camera\ncap = cv2.VideoCapture(0)\n\n# set camera resolution\ncap.set(3, 1280) # width\ncap.set(4, 720)  # height\n\n# initialize left and right hand variables\nleftHand = None\nrightHand = None\n\nwhile True:\n    # read camera feed\n    success, img = cap.read()\n    if not success:\n        print(\"Unable to read camera feed\")\n        break\n    if img is None:\n        continue\n    img = cv2.flip(img, 1)\n\n    # detect and draw the hands\n    hands, img = detector.findHands(img)\n\n    if hands:\n        if len(hands) == 1:\n            # if only one hand is detected, get the number of fingers up\n            if hands[0]['type'] == 'Left':\n                leftHand = hands[0]\n                leftFingers = detector.fingersUp(leftHand)\n                rightFingers = [0] * 5\n            elif hands[0]['type'] == 'Right':\n                rightHand = hands[0]\n                rightFingers = detector.fingersUp(rightHand)\n                leftFingers = [0] * 5\n        elif len(hands) == 2:\n            # if two hands are detected, get the number of fingers up for each hand\n            leftHand = hands[0] if hands[0]['type'] == 'Left' else hands[1]\n            rightHand = hands[0] if hands[0]['type'] == 'Right' else hands[1]\n            leftFingers = detector.fingersUp(leftHand)\n            rightFingers = detector.fingersUp(rightHand)\n\n        fingerSum = sum(leftFingers) + sum(rightFingers)\n\n        # draw the number of fingers up on the screen\n        cv2.putText(img, f\"L:{leftFingers} R:{rightFingers} Sum:{fingerSum}\", (10, 70), cv2.FONT_HERSHEY_PLAIN,\n                    2, (255, 0, 255), 2)\n\n    # show the camera feed\n    cv2.imshow(\"Image\", img)\n\n    # if the 'q' key is pressed, stop the loop\n    if cv2.waitKey(1) == ord('q'):\n        break\n\n# release the camera and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\">\n  <img src=\"OpenCV-Hand-Tracking-to-Count-Fingers/image-20230401192321128.png\" alt=\"image-20230401192321128\" style=\"zoom:20%;\" />\n</p>\n\nA video demonstration of the final program can be found at the following link: https://drive.google.com/file/d/1WAxcclJO9HlfqIIzZvn3XCFV8l6c7-xB/view?usp=sharing\n\n### Reference\n\n1. *Virtual Calculator Based On OpenCV And Cvzone Using Python With A Full Source Code*. (2021, December 13). YouTube. https://www.youtube.com/watch?v=vOaurBYMovQ\n","source":"_posts/OpenCV-Hand-Tracking-to-Count-Fingers.md","raw":"---\nmathjax: true\ntitle: OpenCV Hand Tracking to Count Fingers\ndate: 2023-04-01 16:18:59\ntags:\n  - Opencv\n  - Python\n  - Video processing\n  - Image processing\n  - Detection\n---\n\nThis program uses OpenCV and the Hand Tracking Module to detect and count the number of fingers visible in a camera feed. It can detect up to two hands simultaneously and displays the number of fingers for each hand as well as the total number of fingers on the screen.\n\nSteps:\n\n1. The program initializes the HandDetector object with the specified detection confidence and maximum number of hands to detect.\n2. The camera is opened and its resolution is set.\n3. The program enters a loop where it continuously reads the camera feed, detects and draws the hands on the image, and displays the finger count for each hand.\n4. If there is only one hand visible, the program calculates the finger count for that hand and sets the finger count for the other hand to 0.\n5. If two hands are visible, the program calculates the finger count for each hand and adds them together to get the total finger count.\n6. The finger counts are displayed on the screen using OpenCV's putText function.\n7. The loop stops when the user presses the 'q' key, and the camera is released and all windows are closed.\n\n```python\nimport cv2\nfrom cvzone.HandTrackingModule import HandDetector\n\n# initialize hand detector\ndetector = HandDetector(detectionCon=0.8, maxHands=2)\n\n# open camera\ncap = cv2.VideoCapture(0)\n\n# set camera resolution\ncap.set(3, 1280) # width\ncap.set(4, 720)  # height\n\n# initialize left and right hand variables\nleftHand = None\nrightHand = None\n\nwhile True:\n    # read camera feed\n    success, img = cap.read()\n    if not success:\n        print(\"Unable to read camera feed\")\n        break\n    if img is None:\n        continue\n    img = cv2.flip(img, 1)\n\n    # detect and draw the hands\n    hands, img = detector.findHands(img)\n\n    if hands:\n        if len(hands) == 1:\n            # if only one hand is detected, get the number of fingers up\n            if hands[0]['type'] == 'Left':\n                leftHand = hands[0]\n                leftFingers = detector.fingersUp(leftHand)\n                rightFingers = [0] * 5\n            elif hands[0]['type'] == 'Right':\n                rightHand = hands[0]\n                rightFingers = detector.fingersUp(rightHand)\n                leftFingers = [0] * 5\n        elif len(hands) == 2:\n            # if two hands are detected, get the number of fingers up for each hand\n            leftHand = hands[0] if hands[0]['type'] == 'Left' else hands[1]\n            rightHand = hands[0] if hands[0]['type'] == 'Right' else hands[1]\n            leftFingers = detector.fingersUp(leftHand)\n            rightFingers = detector.fingersUp(rightHand)\n\n        fingerSum = sum(leftFingers) + sum(rightFingers)\n\n        # draw the number of fingers up on the screen\n        cv2.putText(img, f\"L:{leftFingers} R:{rightFingers} Sum:{fingerSum}\", (10, 70), cv2.FONT_HERSHEY_PLAIN,\n                    2, (255, 0, 255), 2)\n\n    # show the camera feed\n    cv2.imshow(\"Image\", img)\n\n    # if the 'q' key is pressed, stop the loop\n    if cv2.waitKey(1) == ord('q'):\n        break\n\n# release the camera and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\">\n  <img src=\"OpenCV-Hand-Tracking-to-Count-Fingers/image-20230401192321128.png\" alt=\"image-20230401192321128\" style=\"zoom:20%;\" />\n</p>\n\nA video demonstration of the final program can be found at the following link: https://drive.google.com/file/d/1WAxcclJO9HlfqIIzZvn3XCFV8l6c7-xB/view?usp=sharing\n\n### Reference\n\n1. *Virtual Calculator Based On OpenCV And Cvzone Using Python With A Full Source Code*. (2021, December 13). YouTube. https://www.youtube.com/watch?v=vOaurBYMovQ\n","slug":"OpenCV-Hand-Tracking-to-Count-Fingers","published":1,"updated":"2023-04-07T02:43:50.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73h5000sozpi9r2fejj7","content":"<html><head></head><body></body></html><html><head></head><body><p>This program uses OpenCV and the Hand Tracking Module to detect and count the number of fingers visible in a camera feed. It can detect up to two hands simultaneously and displays the number of fingers for each hand as well as the total number of fingers on the screen.</p>\n<p>Steps:</p>\n<ol>\n<li>The program initializes the HandDetector object with the specified detection confidence and maximum number of hands to detect.</li>\n<li>The camera is opened and its resolution is set.</li>\n<li>The program enters a loop where it continuously reads the camera feed, detects and draws the hands on the image, and displays the finger count for each hand.</li>\n<li>If there is only one hand visible, the program calculates the finger count for that hand and sets the finger count for the other hand to 0.</li>\n<li>If two hands are visible, the program calculates the finger count for each hand and adds them together to get the total finger count.</li>\n<li>The finger counts are displayed on the screen using OpenCVs putText function.</li>\n<li>The loop stops when the user presses the q key, and the camera is released and all windows are closed.</li>\n</ol>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">from</span> cvzone.HandTrackingModule <span class=\"keyword\">import</span> HandDetector</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize hand detector</span></span><br><span class=\"line\">detector = HandDetector(detectionCon=<span class=\"number\">0.8</span>, maxHands=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># open camera</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set camera resolution</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">3</span>, <span class=\"number\">1280</span>) <span class=\"comment\"># width</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">4</span>, <span class=\"number\">720</span>)  <span class=\"comment\"># height</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize left and right hand variables</span></span><br><span class=\"line\">leftHand = <span class=\"literal\">None</span></span><br><span class=\"line\">rightHand = <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># read camera feed</span></span><br><span class=\"line\">    success, img = cap.read()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"Unable to read camera feed\"</span>)</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> img <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    img = cv2.flip(img, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># detect and draw the hands</span></span><br><span class=\"line\">    hands, img = detector.findHands(img)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> hands:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(hands) == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"comment\"># if only one hand is detected, get the number of fingers up</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Left'</span>:</span><br><span class=\"line\">                leftHand = hands[<span class=\"number\">0</span>]</span><br><span class=\"line\">                leftFingers = detector.fingersUp(leftHand)</span><br><span class=\"line\">                rightFingers = [<span class=\"number\">0</span>] * <span class=\"number\">5</span></span><br><span class=\"line\">            <span class=\"keyword\">elif</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Right'</span>:</span><br><span class=\"line\">                rightHand = hands[<span class=\"number\">0</span>]</span><br><span class=\"line\">                rightFingers = detector.fingersUp(rightHand)</span><br><span class=\"line\">                leftFingers = [<span class=\"number\">0</span>] * <span class=\"number\">5</span></span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"built_in\">len</span>(hands) == <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"comment\"># if two hands are detected, get the number of fingers up for each hand</span></span><br><span class=\"line\">            leftHand = hands[<span class=\"number\">0</span>] <span class=\"keyword\">if</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Left'</span> <span class=\"keyword\">else</span> hands[<span class=\"number\">1</span>]</span><br><span class=\"line\">            rightHand = hands[<span class=\"number\">0</span>] <span class=\"keyword\">if</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Right'</span> <span class=\"keyword\">else</span> hands[<span class=\"number\">1</span>]</span><br><span class=\"line\">            leftFingers = detector.fingersUp(leftHand)</span><br><span class=\"line\">            rightFingers = detector.fingersUp(rightHand)</span><br><span class=\"line\"></span><br><span class=\"line\">        fingerSum = <span class=\"built_in\">sum</span>(leftFingers) + <span class=\"built_in\">sum</span>(rightFingers)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># draw the number of fingers up on the screen</span></span><br><span class=\"line\">        cv2.putText(img, <span class=\"string\">f\"L:<span class=\"subst\">{leftFingers}</span> R:<span class=\"subst\">{rightFingers}</span> Sum:<span class=\"subst\">{fingerSum}</span>\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">70</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                    <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># show the camera feed</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">\"Image\"</span>, img)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># if the 'q' key is pressed, stop the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) == <span class=\"built_in\">ord</span>(<span class=\"string\">'q'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># release the camera and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"image-20230401192321128\" style=\"zoom:20%;\" data-src=\"/2023/04/01/OpenCV-Hand-Tracking-to-Count-Fingers/image-20230401192321128.png\">\n</p>\n\n<p>A video demonstration of the final program can be found at the following link: <a href=\"https://drive.google.com/file/d/1WAxcclJO9HlfqIIzZvn3XCFV8l6c7-xB/view?usp=sharing\">https://drive.google.com/file/d/1WAxcclJO9HlfqIIzZvn3XCFV8l6c7-xB/view?usp=sharing</a></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>Virtual Calculator Based On OpenCV And Cvzone Using Python With A Full Source Code</em>. (2021, December 13). YouTube. <a href=\"https://www.youtube.com/watch?v=vOaurBYMovQ\">https://www.youtube.com/watch?v=vOaurBYMovQ</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/","2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/"],"length":504,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>This program uses OpenCV and the Hand Tracking Module to detect and count the number of fingers visible in a camera feed. It can detect up to two hands simultaneously and displays the number of fingers for each hand as well as the total number of fingers on the screen.</p>\n<p>Steps:</p>\n<ol>\n<li>The program initializes the HandDetector object with the specified detection confidence and maximum number of hands to detect.</li>\n<li>The camera is opened and its resolution is set.</li>\n<li>The program enters a loop where it continuously reads the camera feed, detects and draws the hands on the image, and displays the finger count for each hand.</li>\n<li>If there is only one hand visible, the program calculates the finger count for that hand and sets the finger count for the other hand to 0.</li>\n<li>If two hands are visible, the program calculates the finger count for each hand and adds them together to get the total finger count.</li>\n<li>The finger counts are displayed on the screen using OpenCVs putText function.</li>\n<li>The loop stops when the user presses the q key, and the camera is released and all windows are closed.</li>\n</ol>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">from</span> cvzone.HandTrackingModule <span class=\"keyword\">import</span> HandDetector</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize hand detector</span></span><br><span class=\"line\">detector = HandDetector(detectionCon=<span class=\"number\">0.8</span>, maxHands=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># open camera</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set camera resolution</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">3</span>, <span class=\"number\">1280</span>) <span class=\"comment\"># width</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">4</span>, <span class=\"number\">720</span>)  <span class=\"comment\"># height</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># initialize left and right hand variables</span></span><br><span class=\"line\">leftHand = <span class=\"literal\">None</span></span><br><span class=\"line\">rightHand = <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># read camera feed</span></span><br><span class=\"line\">    success, img = cap.read()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> success:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">\"Unable to read camera feed\"</span>)</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> img <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        <span class=\"keyword\">continue</span></span><br><span class=\"line\">    img = cv2.flip(img, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># detect and draw the hands</span></span><br><span class=\"line\">    hands, img = detector.findHands(img)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> hands:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(hands) == <span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"comment\"># if only one hand is detected, get the number of fingers up</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Left'</span>:</span><br><span class=\"line\">                leftHand = hands[<span class=\"number\">0</span>]</span><br><span class=\"line\">                leftFingers = detector.fingersUp(leftHand)</span><br><span class=\"line\">                rightFingers = [<span class=\"number\">0</span>] * <span class=\"number\">5</span></span><br><span class=\"line\">            <span class=\"keyword\">elif</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Right'</span>:</span><br><span class=\"line\">                rightHand = hands[<span class=\"number\">0</span>]</span><br><span class=\"line\">                rightFingers = detector.fingersUp(rightHand)</span><br><span class=\"line\">                leftFingers = [<span class=\"number\">0</span>] * <span class=\"number\">5</span></span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"built_in\">len</span>(hands) == <span class=\"number\">2</span>:</span><br><span class=\"line\">            <span class=\"comment\"># if two hands are detected, get the number of fingers up for each hand</span></span><br><span class=\"line\">            leftHand = hands[<span class=\"number\">0</span>] <span class=\"keyword\">if</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Left'</span> <span class=\"keyword\">else</span> hands[<span class=\"number\">1</span>]</span><br><span class=\"line\">            rightHand = hands[<span class=\"number\">0</span>] <span class=\"keyword\">if</span> hands[<span class=\"number\">0</span>][<span class=\"string\">'type'</span>] == <span class=\"string\">'Right'</span> <span class=\"keyword\">else</span> hands[<span class=\"number\">1</span>]</span><br><span class=\"line\">            leftFingers = detector.fingersUp(leftHand)</span><br><span class=\"line\">            rightFingers = detector.fingersUp(rightHand)</span><br><span class=\"line\"></span><br><span class=\"line\">        fingerSum = <span class=\"built_in\">sum</span>(leftFingers) + <span class=\"built_in\">sum</span>(rightFingers)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># draw the number of fingers up on the screen</span></span><br><span class=\"line\">        cv2.putText(img, <span class=\"string\">f\"L:<span class=\"subst\">{leftFingers}</span> R:<span class=\"subst\">{rightFingers}</span> Sum:<span class=\"subst\">{fingerSum}</span>\"</span>, (<span class=\"number\">10</span>, <span class=\"number\">70</span>), cv2.FONT_HERSHEY_PLAIN,</span><br><span class=\"line\">                    <span class=\"number\">2</span>, (<span class=\"number\">255</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># show the camera feed</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">\"Image\"</span>, img)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># if the 'q' key is pressed, stop the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) == <span class=\"built_in\">ord</span>(<span class=\"string\">'q'</span>):</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># release the camera and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"image-20230401192321128\" style=\"zoom:20%;\" data-src=\"/2023/04/01/OpenCV-Hand-Tracking-to-Count-Fingers/image-20230401192321128.png\">\n</p>\n\n<p>A video demonstration of the final program can be found at the following link: <a href=\"https://drive.google.com/file/d/1WAxcclJO9HlfqIIzZvn3XCFV8l6c7-xB/view?usp=sharing\">https://drive.google.com/file/d/1WAxcclJO9HlfqIIzZvn3XCFV8l6c7-xB/view?usp=sharing</a></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>Virtual Calculator Based On OpenCV And Cvzone Using Python With A Full Source Code</em>. (2021, December 13). YouTube. <a href=\"https://www.youtube.com/watch?v=vOaurBYMovQ\">https://www.youtube.com/watch?v=vOaurBYMovQ</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Pandas Basics","date":"2023-03-28T08:57:53.000Z","_content":"\nThe iris dataset is a well-known multivariate dataset that contains 150 observations of iris flowers. Each observation includes four features: sepal length, sepal width, petal length, and petal width. The dataset also includes the species of the flower, which serves as the response variable. There are three species of iris in the dataset: setosa, versicolor, and virginica. Overall, the iris dataset is commonly used for classification and machine learning tasks, as well as for data visualization and exploratory analysis.\n\n### Basic Operations of Pandas on Iris Dataset\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# load iris dataset from seaborn\ndata = sns.load_dataset('iris')\n\n# covert data to dataframe\ndf = pd.DataFrame(data)\n\n# Display the first 10 rows of the dataframe\nprint(df.head(10))\n\n# Display the last 5 rows of the dataframe\nprint(df.tail())\n\n# Display the shape of the dataframe\nprint(df.shape)\n\n# Display the data types of the columns\nprint(df.dtypes)\n\n# Display the row index of the dataframe\nprint(df.index)\n\n# Display the column index of the dataframe\nprint(df.columns)\n\n# Display the values of the dataframe as a 2D ndarray array\nprint(df.values)\n\n# Display summary statistics for the numeric columns of the dataframe\nprint(df.describe())\n\n# Display information about the dataframe including column index, data types, non-null counts and memory usage\nprint(df.info())\n\n# Plot the distribution of each column in the dataframe\nsns.set(style=\"ticks\")\nsns.pairplot(df, hue=\"species\")\nplt.savefig('iris.png', dpi=300, bbox_inches='tight', pad_inches=0.0)\nplt.show()\n```\n\n![iris](Pandas-Basics/iris.png)\n\n```python\n# Use loc to select specific rows and columns by label\nprint(df.loc[0:4, ['sepal_length', 'species']])\n\n# Select the first row\nprint(df.iloc[0])\n\n# Select the second row\nprint(df.iloc[1])\n\n# Select the last row\nprint(df.iloc[-1])\n\n# Select the last column\nprint(df.iloc[:,-1])\n\n# Select the value in the third row and second column\nprint(df.iloc[2,1])\n\n# Use iloc to select specific rows and columns by integer position\nprint(df.iloc[0:5, [0, 4]])\n\n# Select rows where sepal_width > 3.0\nprint(df[df['sepal_width'] > 3.0])\n\n# Select rows where petal_length is null\nprint(df[df['petal_length'].isnull()])\n\n# Select rows where species is not virginica\nprint(df[df['species'] != 'virginica'])\n\n# Select rows where sepal_width > 3.0 and petal_width < 1.0\nprint(df[(df['sepal_width'] > 3.0) & (df['petal_width'] < 1.0)])\n\n# Check if there are any missing values in the dataframe\nprint(df.isnull().values.any())\n```\n\n### Reference\n\n1. Seaborn. (n.d.). Scatterplot matrix. Retrieved March 28, 2023, from https://seaborn.pydata.org/examples/scatterplot_matrix.html\n2. pandas. (2023). Pandas documentation (Version 1.5.3). Retrieved from https://pandas.pydata.org/docs/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Pandas-Basics.md","raw":"---\nmathjax: true\ntitle: Pandas Basics\ndate: 2023-03-28 08:57:53\ntags: [Pandas, Python, Basics]\n---\n\nThe iris dataset is a well-known multivariate dataset that contains 150 observations of iris flowers. Each observation includes four features: sepal length, sepal width, petal length, and petal width. The dataset also includes the species of the flower, which serves as the response variable. There are three species of iris in the dataset: setosa, versicolor, and virginica. Overall, the iris dataset is commonly used for classification and machine learning tasks, as well as for data visualization and exploratory analysis.\n\n### Basic Operations of Pandas on Iris Dataset\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# load iris dataset from seaborn\ndata = sns.load_dataset('iris')\n\n# covert data to dataframe\ndf = pd.DataFrame(data)\n\n# Display the first 10 rows of the dataframe\nprint(df.head(10))\n\n# Display the last 5 rows of the dataframe\nprint(df.tail())\n\n# Display the shape of the dataframe\nprint(df.shape)\n\n# Display the data types of the columns\nprint(df.dtypes)\n\n# Display the row index of the dataframe\nprint(df.index)\n\n# Display the column index of the dataframe\nprint(df.columns)\n\n# Display the values of the dataframe as a 2D ndarray array\nprint(df.values)\n\n# Display summary statistics for the numeric columns of the dataframe\nprint(df.describe())\n\n# Display information about the dataframe including column index, data types, non-null counts and memory usage\nprint(df.info())\n\n# Plot the distribution of each column in the dataframe\nsns.set(style=\"ticks\")\nsns.pairplot(df, hue=\"species\")\nplt.savefig('iris.png', dpi=300, bbox_inches='tight', pad_inches=0.0)\nplt.show()\n```\n\n![iris](Pandas-Basics/iris.png)\n\n```python\n# Use loc to select specific rows and columns by label\nprint(df.loc[0:4, ['sepal_length', 'species']])\n\n# Select the first row\nprint(df.iloc[0])\n\n# Select the second row\nprint(df.iloc[1])\n\n# Select the last row\nprint(df.iloc[-1])\n\n# Select the last column\nprint(df.iloc[:,-1])\n\n# Select the value in the third row and second column\nprint(df.iloc[2,1])\n\n# Use iloc to select specific rows and columns by integer position\nprint(df.iloc[0:5, [0, 4]])\n\n# Select rows where sepal_width > 3.0\nprint(df[df['sepal_width'] > 3.0])\n\n# Select rows where petal_length is null\nprint(df[df['petal_length'].isnull()])\n\n# Select rows where species is not virginica\nprint(df[df['species'] != 'virginica'])\n\n# Select rows where sepal_width > 3.0 and petal_width < 1.0\nprint(df[(df['sepal_width'] > 3.0) & (df['petal_width'] < 1.0)])\n\n# Check if there are any missing values in the dataframe\nprint(df.isnull().values.any())\n```\n\n### Reference\n\n1. Seaborn. (n.d.). Scatterplot matrix. Retrieved March 28, 2023, from https://seaborn.pydata.org/examples/scatterplot_matrix.html\n2. pandas. (2023). Pandas documentation (Version 1.5.3). Retrieved from https://pandas.pydata.org/docs/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Pandas-Basics","published":1,"updated":"2023-04-07T02:43:50.800Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73h6000tozpi9haeb2gx","content":"<html><head></head><body></body></html><html><head></head><body><p>The iris dataset is a well-known multivariate dataset that contains 150 observations of iris flowers. Each observation includes four features: sepal length, sepal width, petal length, and petal width. The dataset also includes the species of the flower, which serves as the response variable. There are three species of iris in the dataset: setosa, versicolor, and virginica. Overall, the iris dataset is commonly used for classification and machine learning tasks, as well as for data visualization and exploratory analysis.</p>\n<h3 id=\"Basic-Operations-of-Pandas-on-Iris-Dataset\"><a href=\"#Basic-Operations-of-Pandas-on-Iris-Dataset\" class=\"headerlink\" title=\"Basic Operations of Pandas on Iris Dataset\"></a>Basic Operations of Pandas on Iris Dataset</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">'ignore'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load iris dataset from seaborn</span></span><br><span class=\"line\">data = sns.load_dataset(<span class=\"string\">'iris'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># covert data to dataframe</span></span><br><span class=\"line\">df = pd.DataFrame(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the first 10 rows of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.head(<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the last 5 rows of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.tail())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the shape of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the data types of the columns</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.dtypes)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the row index of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.index)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the column index of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.columns)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the values of the dataframe as a 2D ndarray array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display summary statistics for the numeric columns of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.describe())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display information about the dataframe including column index, data types, non-null counts and memory usage</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.info())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the distribution of each column in the dataframe</span></span><br><span class=\"line\">sns.<span class=\"built_in\">set</span>(style=<span class=\"string\">\"ticks\"</span>)</span><br><span class=\"line\">sns.pairplot(df, hue=<span class=\"string\">\"species\"</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'iris.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.0</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"iris\" data-src=\"/2023/03/28/Pandas-Basics/iris.png\"></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Use loc to select specific rows and columns by label</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.loc[<span class=\"number\">0</span>:<span class=\"number\">4</span>, [<span class=\"string\">'sepal_length'</span>, <span class=\"string\">'species'</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the first row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the second row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the last row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[-<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the last column</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[:,-<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the value in the third row and second column</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">2</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use iloc to select specific rows and columns by integer position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">0</span>:<span class=\"number\">5</span>, [<span class=\"number\">0</span>, <span class=\"number\">4</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where sepal_width &gt; 3.0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[df[<span class=\"string\">'sepal_width'</span>] &gt; <span class=\"number\">3.0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where petal_length is null</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[df[<span class=\"string\">'petal_length'</span>].isnull()])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where species is not virginica</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[df[<span class=\"string\">'species'</span>] != <span class=\"string\">'virginica'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where sepal_width &gt; 3.0 and petal_width &lt; 1.0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[(df[<span class=\"string\">'sepal_width'</span>] &gt; <span class=\"number\">3.0</span>) &amp; (df[<span class=\"string\">'petal_width'</span>] &lt; <span class=\"number\">1.0</span>)])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check if there are any missing values in the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.isnull().values.<span class=\"built_in\">any</span>())</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Seaborn. (n.d.). Scatterplot matrix. Retrieved March 28, 2023, from <a href=\"https://seaborn.pydata.org/examples/scatterplot_matrix.html\">https://seaborn.pydata.org/examples/scatterplot_matrix.html</a></li>\n<li>pandas. (2023). Pandas documentation (Version 1.5.3). Retrieved from <a href=\"https://pandas.pydata.org/docs/\">https://pandas.pydata.org/docs/</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/28/Numpy-Basics/"],"length":412,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>The iris dataset is a well-known multivariate dataset that contains 150 observations of iris flowers. Each observation includes four features: sepal length, sepal width, petal length, and petal width. The dataset also includes the species of the flower, which serves as the response variable. There are three species of iris in the dataset: setosa, versicolor, and virginica. Overall, the iris dataset is commonly used for classification and machine learning tasks, as well as for data visualization and exploratory analysis.</p>\n<h3 id=\"Basic-Operations-of-Pandas-on-Iris-Dataset\"><a href=\"#Basic-Operations-of-Pandas-on-Iris-Dataset\" class=\"headerlink\" title=\"Basic Operations of Pandas on Iris Dataset\"></a>Basic Operations of Pandas on Iris Dataset</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">'ignore'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load iris dataset from seaborn</span></span><br><span class=\"line\">data = sns.load_dataset(<span class=\"string\">'iris'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># covert data to dataframe</span></span><br><span class=\"line\">df = pd.DataFrame(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the first 10 rows of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.head(<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the last 5 rows of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.tail())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the shape of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the data types of the columns</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.dtypes)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the row index of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.index)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the column index of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.columns)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the values of the dataframe as a 2D ndarray array</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display summary statistics for the numeric columns of the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.describe())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display information about the dataframe including column index, data types, non-null counts and memory usage</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.info())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the distribution of each column in the dataframe</span></span><br><span class=\"line\">sns.<span class=\"built_in\">set</span>(style=<span class=\"string\">\"ticks\"</span>)</span><br><span class=\"line\">sns.pairplot(df, hue=<span class=\"string\">\"species\"</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'iris.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.0</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"iris\" data-src=\"/2023/03/28/Pandas-Basics/iris.png\"></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Use loc to select specific rows and columns by label</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.loc[<span class=\"number\">0</span>:<span class=\"number\">4</span>, [<span class=\"string\">'sepal_length'</span>, <span class=\"string\">'species'</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the first row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the second row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the last row</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[-<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the last column</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[:,-<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select the value in the third row and second column</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">2</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use iloc to select specific rows and columns by integer position</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.iloc[<span class=\"number\">0</span>:<span class=\"number\">5</span>, [<span class=\"number\">0</span>, <span class=\"number\">4</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where sepal_width &gt; 3.0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[df[<span class=\"string\">'sepal_width'</span>] &gt; <span class=\"number\">3.0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where petal_length is null</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[df[<span class=\"string\">'petal_length'</span>].isnull()])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where species is not virginica</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[df[<span class=\"string\">'species'</span>] != <span class=\"string\">'virginica'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Select rows where sepal_width &gt; 3.0 and petal_width &lt; 1.0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df[(df[<span class=\"string\">'sepal_width'</span>] &gt; <span class=\"number\">3.0</span>) &amp; (df[<span class=\"string\">'petal_width'</span>] &lt; <span class=\"number\">1.0</span>)])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check if there are any missing values in the dataframe</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(df.isnull().values.<span class=\"built_in\">any</span>())</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Seaborn. (n.d.). Scatterplot matrix. Retrieved March 28, 2023, from <a href=\"https://seaborn.pydata.org/examples/scatterplot_matrix.html\">https://seaborn.pydata.org/examples/scatterplot_matrix.html</a></li>\n<li>pandas. (2023). Pandas documentation (Version 1.5.3). Retrieved from <a href=\"https://pandas.pydata.org/docs/\">https://pandas.pydata.org/docs/</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"RGB color","date":"2023-03-04T14:09:37.000Z","_content":"\n#### RGB Basics\n\nRGB stands for Red, Green, and Blue, which are the three primary colors of light. The RGB color model works by combining these three primary colors in different ways to create a wide range of colors.\n\nIn the RGB color model, each color is represented by a combination of three numbers between 0 and 255, representing the intensity of the red, green, and blue components respectively. For example, pure red is represented as (255, 0, 0), pure green as (0, 255, 0), and pure blue as (0, 0, 255).\n\nIn Matplotlib, the RGB color values are defined on a scale of 0 to 1 instead of 0 to 255. This means that the red, green, and blue components of a color are represented as a decimal value between 0 and 1 instead of an integer value between 0 and 255.For example, pure red in Matplotlib is represented as (1, 0, 0), pure green as (0, 1, 0), and pure blue as (0, 0, 1). \n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/3/23 21:35\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the RGB colors\nred = [1, 0, 0]\ngreen = [0, 1, 0]\nblue = [0, 0, 1]\n\n# Create a figure with three subplots\nfig, axs = plt.subplots(1, 3, figsize=(10, 4))\n\n# Plot the RGB colors in the first subplot\naxs[0].bar(np.arange(3), [1, 1, 1], color=[red, green, blue])\naxs[0].set_title('RGB Colors')\naxs[0].set_xticks(np.arange(3))\naxs[0].set_xticklabels(['Red', 'Green', 'Blue'])\n\n# Create the white and black colors by combining RGB colors\nwhite = [1, 1, 1]\nblack = [0, 0, 0]\ngrey = np.linspace(0, 1, 256)\ngrey_color = np.transpose([grey, grey, grey])\n\n# Plot the white and black colors in the second subplot\naxs[1].bar(np.arange(2), [1, 1], color=[white, black])\naxs[1].set_title('White and Black')\naxs[1].set_xticks(np.arange(2))\naxs[1].set_xticklabels(['White', 'Black'])\n\n# Plot the grey colors in the third subplot\naxs[2].bar(np.arange(len(grey)), [1]*len(grey), color=grey_color)\naxs[2].set_title('Grey Scale')\naxs[2].set_xticks(np.arange(0, len(grey), 5))\naxs[2].set_xticklabels([str(g) for g in grey[::5]])\n\n# Add a title and save the figure\nfig.suptitle('RGB Color Examples')\n# add a blank space between the title and the subplots\nfig.subplots_adjust(top=0.8)\nplt.savefig('rgb_colors.png')\n\n# Display the figure\nplt.show()\n\n```\n\n![rgb_colors](RGB-color/rgb_colors.png)\n\n#### 3D RGB color space\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/3/23 23:44\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_subplot(111, projection='3d')\n\n# Generate tight RGB values\nr = np.arange(0, 1, 0.01)\ng = np.arange(0, 1, 0.01)\nb = np.arange(0, 1, 0.01)\n\n# Create meshgrid of RGB values\nR, G, B = np.meshgrid(r, g, b)\n\n# Flatten RGB values and convert to 1D arrays\nr = R.flatten()\ng = G.flatten()\nb = B.flatten()\n\n# Plot the RGB values\nax.scatter(r, g, b, color=np.column_stack((r,g,b)), s=10)\n\n# Set axis labels\nax.set_xlabel('R')\nax.set_ylabel('G')\nax.set_zlabel('B')\n\n# remove grid lines\nax.grid(False)\n\n# save figure\nplt.savefig('rgb_cubic.png', dpi=600, bbox_inches='tight')\nplt.show()\n```\n\n<p align=\"center\">\n   <img src=\"RGB-color/rgb_cubic.png\" alt=\"rgb_cubic\" style=\"zoom:13%;\"/>\n</p>\n\n\n\n","source":"_posts/RGB-color.md","raw":"---\nmathjax: true\ntitle: RGB color\ndate: 2023-03-04 14:09:37\ntags: [Data visualization, Image processing, Basics]\n---\n\n#### RGB Basics\n\nRGB stands for Red, Green, and Blue, which are the three primary colors of light. The RGB color model works by combining these three primary colors in different ways to create a wide range of colors.\n\nIn the RGB color model, each color is represented by a combination of three numbers between 0 and 255, representing the intensity of the red, green, and blue components respectively. For example, pure red is represented as (255, 0, 0), pure green as (0, 255, 0), and pure blue as (0, 0, 255).\n\nIn Matplotlib, the RGB color values are defined on a scale of 0 to 1 instead of 0 to 255. This means that the red, green, and blue components of a color are represented as a decimal value between 0 and 1 instead of an integer value between 0 and 255.For example, pure red in Matplotlib is represented as (1, 0, 0), pure green as (0, 1, 0), and pure blue as (0, 0, 1). \n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/3/23 21:35\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the RGB colors\nred = [1, 0, 0]\ngreen = [0, 1, 0]\nblue = [0, 0, 1]\n\n# Create a figure with three subplots\nfig, axs = plt.subplots(1, 3, figsize=(10, 4))\n\n# Plot the RGB colors in the first subplot\naxs[0].bar(np.arange(3), [1, 1, 1], color=[red, green, blue])\naxs[0].set_title('RGB Colors')\naxs[0].set_xticks(np.arange(3))\naxs[0].set_xticklabels(['Red', 'Green', 'Blue'])\n\n# Create the white and black colors by combining RGB colors\nwhite = [1, 1, 1]\nblack = [0, 0, 0]\ngrey = np.linspace(0, 1, 256)\ngrey_color = np.transpose([grey, grey, grey])\n\n# Plot the white and black colors in the second subplot\naxs[1].bar(np.arange(2), [1, 1], color=[white, black])\naxs[1].set_title('White and Black')\naxs[1].set_xticks(np.arange(2))\naxs[1].set_xticklabels(['White', 'Black'])\n\n# Plot the grey colors in the third subplot\naxs[2].bar(np.arange(len(grey)), [1]*len(grey), color=grey_color)\naxs[2].set_title('Grey Scale')\naxs[2].set_xticks(np.arange(0, len(grey), 5))\naxs[2].set_xticklabels([str(g) for g in grey[::5]])\n\n# Add a title and save the figure\nfig.suptitle('RGB Color Examples')\n# add a blank space between the title and the subplots\nfig.subplots_adjust(top=0.8)\nplt.savefig('rgb_colors.png')\n\n# Display the figure\nplt.show()\n\n```\n\n![rgb_colors](RGB-color/rgb_colors.png)\n\n#### 3D RGB color space\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/3/23 23:44\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_subplot(111, projection='3d')\n\n# Generate tight RGB values\nr = np.arange(0, 1, 0.01)\ng = np.arange(0, 1, 0.01)\nb = np.arange(0, 1, 0.01)\n\n# Create meshgrid of RGB values\nR, G, B = np.meshgrid(r, g, b)\n\n# Flatten RGB values and convert to 1D arrays\nr = R.flatten()\ng = G.flatten()\nb = B.flatten()\n\n# Plot the RGB values\nax.scatter(r, g, b, color=np.column_stack((r,g,b)), s=10)\n\n# Set axis labels\nax.set_xlabel('R')\nax.set_ylabel('G')\nax.set_zlabel('B')\n\n# remove grid lines\nax.grid(False)\n\n# save figure\nplt.savefig('rgb_cubic.png', dpi=600, bbox_inches='tight')\nplt.show()\n```\n\n<p align=\"center\">\n   <img src=\"RGB-color/rgb_cubic.png\" alt=\"rgb_cubic\" style=\"zoom:13%;\"/>\n</p>\n\n\n\n","slug":"RGB-color","published":1,"updated":"2023-04-07T02:43:50.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73h9000vozpi9b5a8cgz","content":"<html><head></head><body></body></html><html><head></head><body><h4 id=\"RGB-Basics\"><a href=\"#RGB-Basics\" class=\"headerlink\" title=\"RGB Basics\"></a>RGB Basics</h4><p>RGB stands for Red, Green, and Blue, which are the three primary colors of light. The RGB color model works by combining these three primary colors in different ways to create a wide range of colors.</p>\n<p>In the RGB color model, each color is represented by a combination of three numbers between 0 and 255, representing the intensity of the red, green, and blue components respectively. For example, pure red is represented as (255, 0, 0), pure green as (0, 255, 0), and pure blue as (0, 0, 255).</p>\n<p>In Matplotlib, the RGB color values are defined on a scale of 0 to 1 instead of 0 to 255. This means that the red, green, and blue components of a color are represented as a decimal value between 0 and 1 instead of an integer value between 0 and 255.For example, pure red in Matplotlib is represented as (1, 0, 0), pure green as (0, 1, 0), and pure blue as (0, 0, 1). </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/3/23 21:35</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the RGB colors</span></span><br><span class=\"line\">red = [<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">green = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">blue = [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a figure with three subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">3</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the RGB colors in the first subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].bar(np.arange(<span class=\"number\">3</span>), [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], color=[red, green, blue])</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'RGB Colors'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xticks(np.arange(<span class=\"number\">3</span>))</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xticklabels([<span class=\"string\">'Red'</span>, <span class=\"string\">'Green'</span>, <span class=\"string\">'Blue'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create the white and black colors by combining RGB colors</span></span><br><span class=\"line\">white = [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">black = [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">grey = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">256</span>)</span><br><span class=\"line\">grey_color = np.transpose([grey, grey, grey])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the white and black colors in the second subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].bar(np.arange(<span class=\"number\">2</span>), [<span class=\"number\">1</span>, <span class=\"number\">1</span>], color=[white, black])</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'White and Black'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xticks(np.arange(<span class=\"number\">2</span>))</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xticklabels([<span class=\"string\">'White'</span>, <span class=\"string\">'Black'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the grey colors in the third subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">2</span>].bar(np.arange(<span class=\"built_in\">len</span>(grey)), [<span class=\"number\">1</span>]*<span class=\"built_in\">len</span>(grey), color=grey_color)</span><br><span class=\"line\">axs[<span class=\"number\">2</span>].set_title(<span class=\"string\">'Grey Scale'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">2</span>].set_xticks(np.arange(<span class=\"number\">0</span>, <span class=\"built_in\">len</span>(grey), <span class=\"number\">5</span>))</span><br><span class=\"line\">axs[<span class=\"number\">2</span>].set_xticklabels([<span class=\"built_in\">str</span>(g) <span class=\"keyword\">for</span> g <span class=\"keyword\">in</span> grey[::<span class=\"number\">5</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add a title and save the figure</span></span><br><span class=\"line\">fig.suptitle(<span class=\"string\">'RGB Color Examples'</span>)</span><br><span class=\"line\"><span class=\"comment\"># add a blank space between the title and the subplots</span></span><br><span class=\"line\">fig.subplots_adjust(top=<span class=\"number\">0.8</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'rgb_colors.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the figure</span></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"rgb_colors\" data-src=\"/2023/03/04/RGB-color/rgb_colors.png\"></p>\n<h4 id=\"3D-RGB-color-space\"><a href=\"#3D-RGB-color-space\" class=\"headerlink\" title=\"3D RGB color space\"></a>3D RGB color space</h4><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/3/23 23:44</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">6</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate tight RGB values</span></span><br><span class=\"line\">r = np.arange(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.01</span>)</span><br><span class=\"line\">g = np.arange(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b = np.arange(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create meshgrid of RGB values</span></span><br><span class=\"line\">R, G, B = np.meshgrid(r, g, b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Flatten RGB values and convert to 1D arrays</span></span><br><span class=\"line\">r = R.flatten()</span><br><span class=\"line\">g = G.flatten()</span><br><span class=\"line\">b = B.flatten()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the RGB values</span></span><br><span class=\"line\">ax.scatter(r, g, b, color=np.column_stack((r,g,b)), s=<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set axis labels</span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'R'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'G'</span>)</span><br><span class=\"line\">ax.set_zlabel(<span class=\"string\">'B'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># remove grid lines</span></span><br><span class=\"line\">ax.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># save figure</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'rgb_cubic.png'</span>, dpi=<span class=\"number\">600</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n   <img alt=\"rgb_cubic\" style=\"zoom:13%;\" data-src=\"/2023/03/04/RGB-color/rgb_cubic.png\">\n</p>\n\n\n\n</body></html>","site":{"data":{}},"related_posts":["2023/03/27/Linear-Algebra-Basics/"],"length":531,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h4 id=\"RGB-Basics\"><a href=\"#RGB-Basics\" class=\"headerlink\" title=\"RGB Basics\"></a>RGB Basics</h4><p>RGB stands for Red, Green, and Blue, which are the three primary colors of light. The RGB color model works by combining these three primary colors in different ways to create a wide range of colors.</p>\n<p>In the RGB color model, each color is represented by a combination of three numbers between 0 and 255, representing the intensity of the red, green, and blue components respectively. For example, pure red is represented as (255, 0, 0), pure green as (0, 255, 0), and pure blue as (0, 0, 255).</p>\n<p>In Matplotlib, the RGB color values are defined on a scale of 0 to 1 instead of 0 to 255. This means that the red, green, and blue components of a color are represented as a decimal value between 0 and 1 instead of an integer value between 0 and 255.For example, pure red in Matplotlib is represented as (1, 0, 0), pure green as (0, 1, 0), and pure blue as (0, 0, 1). </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/3/23 21:35</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the RGB colors</span></span><br><span class=\"line\">red = [<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">green = [<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">blue = [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a figure with three subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">3</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the RGB colors in the first subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].bar(np.arange(<span class=\"number\">3</span>), [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>], color=[red, green, blue])</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'RGB Colors'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xticks(np.arange(<span class=\"number\">3</span>))</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_xticklabels([<span class=\"string\">'Red'</span>, <span class=\"string\">'Green'</span>, <span class=\"string\">'Blue'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create the white and black colors by combining RGB colors</span></span><br><span class=\"line\">white = [<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">black = [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">grey = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">256</span>)</span><br><span class=\"line\">grey_color = np.transpose([grey, grey, grey])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the white and black colors in the second subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].bar(np.arange(<span class=\"number\">2</span>), [<span class=\"number\">1</span>, <span class=\"number\">1</span>], color=[white, black])</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'White and Black'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xticks(np.arange(<span class=\"number\">2</span>))</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xticklabels([<span class=\"string\">'White'</span>, <span class=\"string\">'Black'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the grey colors in the third subplot</span></span><br><span class=\"line\">axs[<span class=\"number\">2</span>].bar(np.arange(<span class=\"built_in\">len</span>(grey)), [<span class=\"number\">1</span>]*<span class=\"built_in\">len</span>(grey), color=grey_color)</span><br><span class=\"line\">axs[<span class=\"number\">2</span>].set_title(<span class=\"string\">'Grey Scale'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">2</span>].set_xticks(np.arange(<span class=\"number\">0</span>, <span class=\"built_in\">len</span>(grey), <span class=\"number\">5</span>))</span><br><span class=\"line\">axs[<span class=\"number\">2</span>].set_xticklabels([<span class=\"built_in\">str</span>(g) <span class=\"keyword\">for</span> g <span class=\"keyword\">in</span> grey[::<span class=\"number\">5</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add a title and save the figure</span></span><br><span class=\"line\">fig.suptitle(<span class=\"string\">'RGB Color Examples'</span>)</span><br><span class=\"line\"><span class=\"comment\"># add a blank space between the title and the subplots</span></span><br><span class=\"line\">fig.subplots_adjust(top=<span class=\"number\">0.8</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'rgb_colors.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Display the figure</span></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"rgb_colors\" data-src=\"/2023/03/04/RGB-color/rgb_colors.png\"></p>\n<h4 id=\"3D-RGB-color-space\"><a href=\"#3D-RGB-color-space\" class=\"headerlink\" title=\"3D RGB color space\"></a>3D RGB color space</h4><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/3/23 23:44</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">6</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate tight RGB values</span></span><br><span class=\"line\">r = np.arange(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.01</span>)</span><br><span class=\"line\">g = np.arange(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.01</span>)</span><br><span class=\"line\">b = np.arange(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.01</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create meshgrid of RGB values</span></span><br><span class=\"line\">R, G, B = np.meshgrid(r, g, b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Flatten RGB values and convert to 1D arrays</span></span><br><span class=\"line\">r = R.flatten()</span><br><span class=\"line\">g = G.flatten()</span><br><span class=\"line\">b = B.flatten()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the RGB values</span></span><br><span class=\"line\">ax.scatter(r, g, b, color=np.column_stack((r,g,b)), s=<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set axis labels</span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'R'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'G'</span>)</span><br><span class=\"line\">ax.set_zlabel(<span class=\"string\">'B'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># remove grid lines</span></span><br><span class=\"line\">ax.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># save figure</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'rgb_cubic.png'</span>, dpi=<span class=\"number\">600</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n   <img alt=\"rgb_cubic\" style=\"zoom:13%;\" data-src=\"/2023/03/04/RGB-color/rgb_cubic.png\">\n</p>\n\n\n\n</body></html>"},{"mathjax":true,"title":"Regression","date":"2023-03-28T15:08:31.000Z","_content":"\n### Rank\n\nIn linear algebra, the rank of a matrix is the number of linearly independent rows or columns in the matrix.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 17:23\nimport numpy as np\n\n# Define a matrix\nA = np.array([[1, 0, 3],\n              [-1, 9, 6],\n              [3, 2, 9]])\n\n# Compute the rank of the matrix\nrank = np.linalg.matrix_rank(A)\n\n# Print the rank of the matrix\nprint(\"Rank of the matrix: \", rank)\n```\n\n```\nRank of the matrix:  3\n```\n\nTo find the rank, we need to :\n$$\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n-1 & 9 & 6 \\\\\n3 & 2 & 9\n\\end{array}\\right]\n\\end{equation}\n$$\nThe solution is:\n\nAdd row 1 to row $2: R_2=R_2+R_1$.\n$$\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n3 & 2 & 9\n\\end{array}\\right]\n$$\nSubtract row 1 multiplied by 3 from row 3 : $R_3=R_3-3 R_1$.\n$$\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 2 & 0\n\\end{array}\\right]\n$$\nSubtract row 2 multiplied by $\\frac{2}{9}$ from row 3 : $R_3=R_3-\\frac{2 R_2}{9}$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]\n$$\n\n$$\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]\n\\end{equation}\n$$\n\n**It means that all three rows or columns are linearly independent**. In other words, none of the rows or columns can be expressed as a linear combination of the other rows or columns.\n\n**If a 3x3 matrix has rank 3, it means that its rows (or columns) span the entire 3D space**, and any vector in 3D can be expressed as a linear combination of the rows (or columns) of the matrix.\n\nOkay, another example\n$$\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{array}\\right]\n\\end{equation}\n$$\nSubtract row 1 multiplied by 4 from row $2: R_2=R_2-4 R_1$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n7 & 8 & 9\n\\end{array}\\right]\n$$\nSubtract row 1 multiplied by 7 from row $3: R_3=R_3-7 R_1$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & -6 & -12\n\\end{array}\\right]\n$$\nSubtract row 2 multiplied by 2 from row $3: R_3=R_3-2 R_2$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]\n$$\nSince the element at row 3 and column 3 (pivot element) equals 0 , we need to swap the rows.\nFind the first nonzero element in column 3 under the pivot entry.\nAs can be seen, there are no such entries.\n$$\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]\n\\end{equation}\n$$\nso the rank is 2.\n\n**If a 3 x 3 matrix has a rank of 2, it means that only two of its rows or columns are linearly independent, and the third row or column can be expressed as a linear combination of the other two.**\n\n**Geometrically, this means that the rows or columns of the matrix lie in a plane in three-dimensional space.**\n\n### Easy to remember Rank\n\nIn simpler terms, imagine that you're going out and you bring three items with you: an umbrella, a raincoat, and a loaf of bread. However, the umbrella and raincoat serve the same purpose of keeping you dry in the rain, so one of them is unnecessary. Therefore, you are effectively only bringing two items with you. This is similar to a 3 x 3 matrix with a rank of 2, where one row or column is redundant and can be expressed as a linear combination of the other two.\n\n### Span\n\nIn linear algebra, the span of a set of vectors $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$ is the set of all possible linear combinations of those vectors. Formally, the span is defined as follows:\n$$\n\\begin{equation}\n\\operatorname{span}\\left(\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n\\right)=\\left\\{\\sum_{i=1}^n c_i \\mathbf{v}_i \\mid c_i \\in \\mathbb{R}\\right\\}\n\\end{equation}\n$$\nIn words, the span is the set of all possible vectors that can be formed by scaling and adding the given vectors. It can be thought of as a \"subspace\" of the vector space that contains the given vectors.\n\nGeometrically, the span of a set of vectors is the smallest subspace that contains all those vectors. For example, the span of two non-collinear vectors in $\\mathbb{R}^2$ is the entire plane, while the span of two parallel vectors is the line they lie on.\n\n### Features\n\nThe Boston dataset contains information on various housing features in 506 neighborhoods around Boston, which can be used to evaluate the price of a house (target) based on different attributes. The dataset includes 13 attributes, and median value of owner-occupied homes in thousands of dollars, is provided in attribute 14.\n\n```python\n# load a dataset for prediction from library\nfrom sklearn.datasets import load_boston\nboston = load_boston()\nprint(boston.DESCR)\nprint(boston.data.shape)\nprint(boston.feature_names)\nprint(boston.target)\n```\n\n```\nNumber of Instances: 506 \nNumber of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\nAttribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n```\n\nFor example, for the first row, it means given the first row of data, the MEDV is 24. we have 506 rows.\n\n```\n      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n```\n\nGiven a matrix of size 506 x 13, the rank of the matrix must be less than or equal to 13, since the maximum rank of a 506 x 13 matrix is 13. \n\n**If the rank is equal to 13, then there are indeed 13 independent features in the dataset, and each feature provides unique information that is not redundant with the other features. If the rank is less than 13, for example, if the rank is 10, then it means that some of the features are redundant or can be expressed as linear combinations of other features.** For example, it is intuitive that there might be a relationship between two features, such as the number of convenience stores and the accessibility of transportation, where areas with better transportation tend to have more convenience stores. Then, they are not completely independent of each other and can be considered redundant or providing similar information.\n\nIn real-world engineering applications, the relationship between two features may not be completely independent or dependent, but may exist somewhere in between. These relationships can be measured using correlation coefficients or other statistical measures, such as mutual information or covariance.\n\n### Correlation coefficients\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 17:23\n\n# load a dataset for prediction from library\nfrom sklearn.datasets import load_boston\nboston = load_boston()\ndf = pd.DataFrame(boston.data, columns=boston.feature_names)\ndf['MEDV'] = boston.target\n\n# plot Correlation coefficients\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# give a mask for the upper triangle\nmask = np.zeros_like(df.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# set font as times new roman\nplt.rcParams['font.family'] = 'Times New Roman'\n# plot heatmap\nplt.figure(figsize=(10, 10))\nsns.heatmap(df.corr(), mask=mask, annot=True, fmt='.2f', cmap='viridis')\nplt.savefig('Correlation coefficients.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Correlation coefficients](Regression/Correlation%20coefficients.png)\n\nThe heatmap provides a visual representation of the strength and direction of the correlation between variables, ranging from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no correlation.\n\n### Linear system\n\n```\n      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n```\n\nlet's recall this dataset. It just shows the first 5 rows, but actually we have 506 rows.\n\n**The Boston housing dataset can be represented as a linear system with 13 unknown variables and 506 equations.**\n\nLet $\\mathbf{X}$ be the $506 \\times 13$ matrix of input features, where each row corresponds to an observation, and each column corresponds to a feature. The feature columns are denoted as $\\mathbf{X} = [\\mathbf{x_1}, \\mathbf{x_2}, \\ldots, \\mathbf{x_{13}}]$.\n\nLet $\\mathbf{y}$ be the $506 \\times 1$ vector of target values, which corresponds to the median value of owner-occupied homes in $1000's$.\n\nThe linear regression model can be written as:\n$$\n\\mathbf{y} = \\theta_0 + \\theta_1 \\mathbf{x_1} + \\theta_2 \\mathbf{x_2} + \\cdots + \\theta_{13} \\mathbf{x_{13}}\n$$\nwhere $\\theta_0$ is the intercept or bias term, $\\theta_1, \\theta_2, \\ldots, \\theta_{13}$ are the model coefficients or weights, $\\mathbf{x_1}, \\mathbf{x_2}, \\ldots, \\mathbf{x_{13}}$ are the input feature columns.\n\nIn matrix notation, the linear regression model can be written as:\n$$\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta}\n$$\nwhere $\\mathbf{X}$ is the $506 \\times 13$ matrix of input features, $\\mathbf{\\theta}$ is the $13 \\times 1$ vector of model coefficients, and $\\mathbf{\\epsilon}$ is the $506 \\times 1$ vector of errors.\n\nThe goal is to find $\\mathbf{\\theta}$.\n\n### Normal equation\n\nThe solution for the model coefficients $\\mathbf{\\theta}$ using the normal equation is given by:\n$$\n\\mathbf{\\theta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n$$\nIn order to find the values of $\\mathbf{\\theta}$, we need to first compute the matrix product $\\mathbf{X}^T\\mathbf{X}$ and the vector product $\\mathbf{X}^T\\mathbf{y}$, and then apply matrix inversion to $(\\mathbf{X}^T\\mathbf{X})$.\n\n```python\nimport numpy as np\nimport pandas as pd\n\n# load a dataset for prediction from library\nfrom sklearn.datasets import load_boston\nboston = load_boston()\ndf = pd.DataFrame(boston.data, columns=boston.feature_names)\ndf['MEDV'] = boston.target\n\n# solve this problem by normal equation\n# define X and y, X 13 features, y 1 target\nX = df.drop('MEDV', axis=1).values\ny = df['MEDV'].values\n# add a column of 1 to X, why?\n# because the first element of theta is the intercept\nX = np.hstack((np.ones((X.shape[0], 1)), X))\n# compute the normal equation\ntheta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n# print the result\nprint('theta: ', theta)\n```\n\n```\ntheta:  [ 3.64594884e+01 -1.08011358e-01  4.64204584e-02  2.05586264e-02\n  2.68673382e+00 -1.77666112e+01  3.80986521e+00  6.92224640e-04\n -1.47556685e+00  3.06049479e-01 -1.23345939e-02 -9.52747232e-01\n  9.31168327e-03 -5.24758378e-01]\n```\n\n### Notation\n\nIn a linear regression model, there is typically an error term $\\mathbf{\\epsilon}$ that represents the difference between the predicted target values and the true target values.\n\nThe linear regression model should be written as:\n$$\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta} + \\mathbf{\\epsilon}\n$$\nwhere $\\mathbf{y}$ is a vector of observed target values, $\\mathbf{X}$ is a matrix of input feature values, $\\mathbf{\\theta}$ is a vector of model coefficients, and $\\mathbf{\\epsilon}$ is a vector of errors.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data points\nx = np.array([1, 2, 3, 4, 5, 6])\ny = np.array([2, 3, 5, 6, 8, 9])\n\n# Calculate the slope and intercept of the regression line using the least squares method\nA = np.vstack([x, np.ones(len(x))]).T\nm, b = np.linalg.lstsq(A, y, rcond=None)[0]\n\n# Plot the data points and the regression line\nplt.scatter(x, y)\nplt.plot(x, m*x + b, 'r')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Linear Regression')\nplt.savefig('Linear Regression.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Regression/Linear%20Regression.png\" alt=\"Linear Regression\" style=\"zoom:30%;\" />\n</p>\n\nThe error term in a linear regression model accounts for the fact that the predicted values may not perfectly align with the actual values, due to the inherent variability in the data. In other words, the error term allows for some deviation between the predicted values and the true values.\n\n### Polynomial regression\n\nPolynomial regression and linear regression are similar in that they both aim to model the relationship between an input variable and a target variable. However, they differ in the functional form of the model that they use to capture this relationship.\n\nLinear regression models the relationship between the input variable and target variable as a linear function, represented by a straight line. Polynomial regression, on the other hand, models the relationship between the input variable and target variable as a polynomial function of degree n, where n is the highest power of the input variable in the model.\n\nIn other words, polynomial regression allows for a more flexible and non-linear relationship between the input and target variables than linear regression. By fitting a polynomial curve to the data, polynomial regression can capture more complex patterns and relationships that may not be apparent in a linear model.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Generate some sample data\nx = np.linspace(0, 2*np.pi, 100)\ny = np.sin(x)\n\n# Reshape the data into a column vector\nx = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\n\n# Fit a polynomial regression model to the data\npoly = PolynomialFeatures(degree=3)\nX_poly = poly.fit_transform(x)\npoly_reg = LinearRegression()\npoly_reg.fit(X_poly, y)\n\n# Plot the original data and the fitted curve\nplt.scatter(x, y, color='blue')\nplt.plot(x, poly_reg.predict(poly.fit_transform(x)), color='red')\nplt.title('Polynomial Regression of Sin(x)')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.savefig('Polynomial Regression of Sin(x).png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Regression/Polynomial Regression of Sin(x).png\" alt=\"Polynomial Regression of Sin(x)\" style=\"zoom:30%;\" />\n</p>\n\n### Reference\n\n1. UCI Machine Learning Repository (2018). Housing Data Set [Data File]. Retrieved from https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n2. Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.\n\n\n\n\n\n\n\n","source":"_posts/Regression.md","raw":"---\nmathjax: true\ntitle: Regression\ndate: 2023-03-28 15:08:31\ntags: \n  - Linear regression\n  - Polynomial regression \n  - Linear algebra\n  - Span\n  - Rank\n---\n\n### Rank\n\nIn linear algebra, the rank of a matrix is the number of linearly independent rows or columns in the matrix.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 17:23\nimport numpy as np\n\n# Define a matrix\nA = np.array([[1, 0, 3],\n              [-1, 9, 6],\n              [3, 2, 9]])\n\n# Compute the rank of the matrix\nrank = np.linalg.matrix_rank(A)\n\n# Print the rank of the matrix\nprint(\"Rank of the matrix: \", rank)\n```\n\n```\nRank of the matrix:  3\n```\n\nTo find the rank, we need to :\n$$\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n-1 & 9 & 6 \\\\\n3 & 2 & 9\n\\end{array}\\right]\n\\end{equation}\n$$\nThe solution is:\n\nAdd row 1 to row $2: R_2=R_2+R_1$.\n$$\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n3 & 2 & 9\n\\end{array}\\right]\n$$\nSubtract row 1 multiplied by 3 from row 3 : $R_3=R_3-3 R_1$.\n$$\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 2 & 0\n\\end{array}\\right]\n$$\nSubtract row 2 multiplied by $\\frac{2}{9}$ from row 3 : $R_3=R_3-\\frac{2 R_2}{9}$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]\n$$\n\n$$\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]\n\\end{equation}\n$$\n\n**It means that all three rows or columns are linearly independent**. In other words, none of the rows or columns can be expressed as a linear combination of the other rows or columns.\n\n**If a 3x3 matrix has rank 3, it means that its rows (or columns) span the entire 3D space**, and any vector in 3D can be expressed as a linear combination of the rows (or columns) of the matrix.\n\nOkay, another example\n$$\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{array}\\right]\n\\end{equation}\n$$\nSubtract row 1 multiplied by 4 from row $2: R_2=R_2-4 R_1$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n7 & 8 & 9\n\\end{array}\\right]\n$$\nSubtract row 1 multiplied by 7 from row $3: R_3=R_3-7 R_1$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & -6 & -12\n\\end{array}\\right]\n$$\nSubtract row 2 multiplied by 2 from row $3: R_3=R_3-2 R_2$.\n$$\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]\n$$\nSince the element at row 3 and column 3 (pivot element) equals 0 , we need to swap the rows.\nFind the first nonzero element in column 3 under the pivot entry.\nAs can be seen, there are no such entries.\n$$\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]\n\\end{equation}\n$$\nso the rank is 2.\n\n**If a 3 x 3 matrix has a rank of 2, it means that only two of its rows or columns are linearly independent, and the third row or column can be expressed as a linear combination of the other two.**\n\n**Geometrically, this means that the rows or columns of the matrix lie in a plane in three-dimensional space.**\n\n### Easy to remember Rank\n\nIn simpler terms, imagine that you're going out and you bring three items with you: an umbrella, a raincoat, and a loaf of bread. However, the umbrella and raincoat serve the same purpose of keeping you dry in the rain, so one of them is unnecessary. Therefore, you are effectively only bringing two items with you. This is similar to a 3 x 3 matrix with a rank of 2, where one row or column is redundant and can be expressed as a linear combination of the other two.\n\n### Span\n\nIn linear algebra, the span of a set of vectors $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$ is the set of all possible linear combinations of those vectors. Formally, the span is defined as follows:\n$$\n\\begin{equation}\n\\operatorname{span}\\left(\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n\\right)=\\left\\{\\sum_{i=1}^n c_i \\mathbf{v}_i \\mid c_i \\in \\mathbb{R}\\right\\}\n\\end{equation}\n$$\nIn words, the span is the set of all possible vectors that can be formed by scaling and adding the given vectors. It can be thought of as a \"subspace\" of the vector space that contains the given vectors.\n\nGeometrically, the span of a set of vectors is the smallest subspace that contains all those vectors. For example, the span of two non-collinear vectors in $\\mathbb{R}^2$ is the entire plane, while the span of two parallel vectors is the line they lie on.\n\n### Features\n\nThe Boston dataset contains information on various housing features in 506 neighborhoods around Boston, which can be used to evaluate the price of a house (target) based on different attributes. The dataset includes 13 attributes, and median value of owner-occupied homes in thousands of dollars, is provided in attribute 14.\n\n```python\n# load a dataset for prediction from library\nfrom sklearn.datasets import load_boston\nboston = load_boston()\nprint(boston.DESCR)\nprint(boston.data.shape)\nprint(boston.feature_names)\nprint(boston.target)\n```\n\n```\nNumber of Instances: 506 \nNumber of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\nAttribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n```\n\nFor example, for the first row, it means given the first row of data, the MEDV is 24. we have 506 rows.\n\n```\n      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n```\n\nGiven a matrix of size 506 x 13, the rank of the matrix must be less than or equal to 13, since the maximum rank of a 506 x 13 matrix is 13. \n\n**If the rank is equal to 13, then there are indeed 13 independent features in the dataset, and each feature provides unique information that is not redundant with the other features. If the rank is less than 13, for example, if the rank is 10, then it means that some of the features are redundant or can be expressed as linear combinations of other features.** For example, it is intuitive that there might be a relationship between two features, such as the number of convenience stores and the accessibility of transportation, where areas with better transportation tend to have more convenience stores. Then, they are not completely independent of each other and can be considered redundant or providing similar information.\n\nIn real-world engineering applications, the relationship between two features may not be completely independent or dependent, but may exist somewhere in between. These relationships can be measured using correlation coefficients or other statistical measures, such as mutual information or covariance.\n\n### Correlation coefficients\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 17:23\n\n# load a dataset for prediction from library\nfrom sklearn.datasets import load_boston\nboston = load_boston()\ndf = pd.DataFrame(boston.data, columns=boston.feature_names)\ndf['MEDV'] = boston.target\n\n# plot Correlation coefficients\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# give a mask for the upper triangle\nmask = np.zeros_like(df.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# set font as times new roman\nplt.rcParams['font.family'] = 'Times New Roman'\n# plot heatmap\nplt.figure(figsize=(10, 10))\nsns.heatmap(df.corr(), mask=mask, annot=True, fmt='.2f', cmap='viridis')\nplt.savefig('Correlation coefficients.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![Correlation coefficients](Regression/Correlation%20coefficients.png)\n\nThe heatmap provides a visual representation of the strength and direction of the correlation between variables, ranging from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no correlation.\n\n### Linear system\n\n```\n      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n```\n\nlet's recall this dataset. It just shows the first 5 rows, but actually we have 506 rows.\n\n**The Boston housing dataset can be represented as a linear system with 13 unknown variables and 506 equations.**\n\nLet $\\mathbf{X}$ be the $506 \\times 13$ matrix of input features, where each row corresponds to an observation, and each column corresponds to a feature. The feature columns are denoted as $\\mathbf{X} = [\\mathbf{x_1}, \\mathbf{x_2}, \\ldots, \\mathbf{x_{13}}]$.\n\nLet $\\mathbf{y}$ be the $506 \\times 1$ vector of target values, which corresponds to the median value of owner-occupied homes in $1000's$.\n\nThe linear regression model can be written as:\n$$\n\\mathbf{y} = \\theta_0 + \\theta_1 \\mathbf{x_1} + \\theta_2 \\mathbf{x_2} + \\cdots + \\theta_{13} \\mathbf{x_{13}}\n$$\nwhere $\\theta_0$ is the intercept or bias term, $\\theta_1, \\theta_2, \\ldots, \\theta_{13}$ are the model coefficients or weights, $\\mathbf{x_1}, \\mathbf{x_2}, \\ldots, \\mathbf{x_{13}}$ are the input feature columns.\n\nIn matrix notation, the linear regression model can be written as:\n$$\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta}\n$$\nwhere $\\mathbf{X}$ is the $506 \\times 13$ matrix of input features, $\\mathbf{\\theta}$ is the $13 \\times 1$ vector of model coefficients, and $\\mathbf{\\epsilon}$ is the $506 \\times 1$ vector of errors.\n\nThe goal is to find $\\mathbf{\\theta}$.\n\n### Normal equation\n\nThe solution for the model coefficients $\\mathbf{\\theta}$ using the normal equation is given by:\n$$\n\\mathbf{\\theta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n$$\nIn order to find the values of $\\mathbf{\\theta}$, we need to first compute the matrix product $\\mathbf{X}^T\\mathbf{X}$ and the vector product $\\mathbf{X}^T\\mathbf{y}$, and then apply matrix inversion to $(\\mathbf{X}^T\\mathbf{X})$.\n\n```python\nimport numpy as np\nimport pandas as pd\n\n# load a dataset for prediction from library\nfrom sklearn.datasets import load_boston\nboston = load_boston()\ndf = pd.DataFrame(boston.data, columns=boston.feature_names)\ndf['MEDV'] = boston.target\n\n# solve this problem by normal equation\n# define X and y, X 13 features, y 1 target\nX = df.drop('MEDV', axis=1).values\ny = df['MEDV'].values\n# add a column of 1 to X, why?\n# because the first element of theta is the intercept\nX = np.hstack((np.ones((X.shape[0], 1)), X))\n# compute the normal equation\ntheta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n# print the result\nprint('theta: ', theta)\n```\n\n```\ntheta:  [ 3.64594884e+01 -1.08011358e-01  4.64204584e-02  2.05586264e-02\n  2.68673382e+00 -1.77666112e+01  3.80986521e+00  6.92224640e-04\n -1.47556685e+00  3.06049479e-01 -1.23345939e-02 -9.52747232e-01\n  9.31168327e-03 -5.24758378e-01]\n```\n\n### Notation\n\nIn a linear regression model, there is typically an error term $\\mathbf{\\epsilon}$ that represents the difference between the predicted target values and the true target values.\n\nThe linear regression model should be written as:\n$$\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta} + \\mathbf{\\epsilon}\n$$\nwhere $\\mathbf{y}$ is a vector of observed target values, $\\mathbf{X}$ is a matrix of input feature values, $\\mathbf{\\theta}$ is a vector of model coefficients, and $\\mathbf{\\epsilon}$ is a vector of errors.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate some random data points\nx = np.array([1, 2, 3, 4, 5, 6])\ny = np.array([2, 3, 5, 6, 8, 9])\n\n# Calculate the slope and intercept of the regression line using the least squares method\nA = np.vstack([x, np.ones(len(x))]).T\nm, b = np.linalg.lstsq(A, y, rcond=None)[0]\n\n# Plot the data points and the regression line\nplt.scatter(x, y)\nplt.plot(x, m*x + b, 'r')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Linear Regression')\nplt.savefig('Linear Regression.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Regression/Linear%20Regression.png\" alt=\"Linear Regression\" style=\"zoom:30%;\" />\n</p>\n\nThe error term in a linear regression model accounts for the fact that the predicted values may not perfectly align with the actual values, due to the inherent variability in the data. In other words, the error term allows for some deviation between the predicted values and the true values.\n\n### Polynomial regression\n\nPolynomial regression and linear regression are similar in that they both aim to model the relationship between an input variable and a target variable. However, they differ in the functional form of the model that they use to capture this relationship.\n\nLinear regression models the relationship between the input variable and target variable as a linear function, represented by a straight line. Polynomial regression, on the other hand, models the relationship between the input variable and target variable as a polynomial function of degree n, where n is the highest power of the input variable in the model.\n\nIn other words, polynomial regression allows for a more flexible and non-linear relationship between the input and target variables than linear regression. By fitting a polynomial curve to the data, polynomial regression can capture more complex patterns and relationships that may not be apparent in a linear model.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Generate some sample data\nx = np.linspace(0, 2*np.pi, 100)\ny = np.sin(x)\n\n# Reshape the data into a column vector\nx = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\n\n# Fit a polynomial regression model to the data\npoly = PolynomialFeatures(degree=3)\nX_poly = poly.fit_transform(x)\npoly_reg = LinearRegression()\npoly_reg.fit(X_poly, y)\n\n# Plot the original data and the fitted curve\nplt.scatter(x, y, color='blue')\nplt.plot(x, poly_reg.predict(poly.fit_transform(x)), color='red')\nplt.title('Polynomial Regression of Sin(x)')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.savefig('Polynomial Regression of Sin(x).png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<p align=\"center\">\n  <img src=\"Regression/Polynomial Regression of Sin(x).png\" alt=\"Polynomial Regression of Sin(x)\" style=\"zoom:30%;\" />\n</p>\n\n### Reference\n\n1. UCI Machine Learning Repository (2018). Housing Data Set [Data File]. Retrieved from https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n2. Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.\n\n\n\n\n\n\n\n","slug":"Regression","published":1,"updated":"2023-04-07T02:43:50.820Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73ha000xozpi243i79hn","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Rank\"><a href=\"#Rank\" class=\"headerlink\" title=\"Rank\"></a>Rank</h3><p>In linear algebra, the rank of a matrix is the number of linearly independent rows or columns in the matrix.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 17:23</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a matrix</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">3</span>],</span><br><span class=\"line\">              [-<span class=\"number\">1</span>, <span class=\"number\">9</span>, <span class=\"number\">6</span>],</span><br><span class=\"line\">              [<span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Compute the rank of the matrix</span></span><br><span class=\"line\">rank = np.linalg.matrix_rank(A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print the rank of the matrix</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Rank of the matrix: \"</span>, rank)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Rank of the matrix:  3</span><br></pre></td></tr></tbody></table></figure>\n<p>To find the rank, we need to :</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n-1 & 9 & 6 \\\\\n3 & 2 & 9\n\\end{array}\\right]\n\\end{equation}</script><p>The solution is:</p>\n<p>Add row 1 to row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"16.915ex\" height=\"1.885ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7476.2 833\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6280.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n3 & 2 & 9\n\\end{array}\\right]</script><p>Subtract row 1 multiplied by 3 from row 3 : <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"15.029ex\" height=\"1.92ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 6642.7 848.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1473.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2529.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3946.9,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(4947.1,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(5447.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 2 & 0\n\\end{array}\\right]</script><p>Subtract row 2 multiplied by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.816ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.795ex\" height=\"2.773ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -864.9 793.6 1225.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mfrac\"><g data-mml-node=\"mn\" transform=\"translate(220,394) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(220,-345) scale(0.707)\"><path data-c=\"39\" d=\"M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z\"></path></g><rect width=\"553.6\" height=\"60\" x=\"120\" y=\"220\"></rect></g></g></g></svg></mjx-container> from row 3 : <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.816ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"14.901ex\" height=\"2.918ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -929 6586 1289.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1473.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2529.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3946.9,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(4947.1,0)\"><g data-mml-node=\"mrow\" transform=\"translate(220,446.1) scale(0.707)\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(500,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g><g data-mml-node=\"mn\" transform=\"translate(642.7,-345) scale(0.707)\"><path data-c=\"39\" d=\"M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z\"></path></g><rect width=\"1398.9\" height=\"60\" x=\"120\" y=\"220\"></rect></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]\n\\end{equation}</script><p><strong>It means that all three rows or columns are linearly independent</strong>. In other words, none of the rows or columns can be expressed as a linear combination of the other rows or columns.</p>\n<p><strong>If a 3x3 matrix has rank 3, it means that its rows (or columns) span the entire 3D space</strong>, and any vector in 3D can be expressed as a linear combination of the rows (or columns) of the matrix.</p>\n<p>Okay, another example</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{array}\\right]\n\\end{equation}</script><p>Subtract row 1 multiplied by 4 from row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.046ex\" height=\"1.885ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7976.2 833\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6280.7,0)\"><path data-c=\"34\" d=\"M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6780.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n7 & 8 & 9\n\\end{array}\\right]</script><p>Subtract row 1 multiplied by 7 from row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.046ex\" height=\"1.92ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7976.2 848.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6280.7,0)\"><path data-c=\"37\" d=\"M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6780.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & -6 & -12\n\\end{array}\\right]</script><p>Subtract row 2 multiplied by 2 from row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.046ex\" height=\"1.92ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7976.2 848.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6280.7,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6780.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]</script><p>Since the element at row 3 and column 3 (pivot element) equals 0 , we need to swap the rows.<br>Find the first nonzero element in column 3 under the pivot entry.<br>As can be seen, there are no such entries.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]\n\\end{equation}</script><p>so the rank is 2.</p>\n<p><strong>If a 3 x 3 matrix has a rank of 2, it means that only two of its rows or columns are linearly independent, and the third row or column can be expressed as a linear combination of the other two.</strong></p>\n<p><strong>Geometrically, this means that the rows or columns of the matrix lie in a plane in three-dimensional space.</strong></p>\n<h3 id=\"Easy-to-remember-Rank\"><a href=\"#Easy-to-remember-Rank\" class=\"headerlink\" title=\"Easy to remember Rank\"></a>Easy to remember Rank</h3><p>In simpler terms, imagine that youre going out and you bring three items with you: an umbrella, a raincoat, and a loaf of bread. However, the umbrella and raincoat serve the same purpose of keeping you dry in the rain, so one of them is unnecessary. Therefore, you are effectively only bringing two items with you. This is similar to a 3 x 3 matrix with a rank of 2, where one row or column is redundant and can be expressed as a linear combination of the other two.</p>\n<h3 id=\"Span\"><a href=\"#Span\" class=\"headerlink\" title=\"Span\"></a>Span</h3><p>In linear algebra, the span of a set of vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.29ex\" height=\"1.443ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -444 5874 638\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D42F\" d=\"M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(640,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1043.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1488.2,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D42F\" d=\"M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(640,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2531.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2976.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4315.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4759.8,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D42F\" d=\"M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(640,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the set of all possible linear combinations of those vectors. Formally, the span is defined as follows:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\operatorname{span}\\left(\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n\\right)=\\left\\{\\sum_{i=1}^n c_i \\mathbf{v}_i \\mid c_i \\in \\mathbb{R}\\right\\}\n\\end{equation}</script><p>In words, the span is the set of all possible vectors that can be formed by scaling and adding the given vectors. It can be thought of as a subspace of the vector space that contains the given vectors.</p>\n<p>Geometrically, the span of a set of vectors is the smallest subspace that contains all those vectors. For example, the span of two non-collinear vectors in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.621ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1158.6 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(755,363) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container> is the entire plane, while the span of two parallel vectors is the line they lie on.</p>\n<h3 id=\"Features\"><a href=\"#Features\" class=\"headerlink\" title=\"Features\"></a>Features</h3><p>The Boston dataset contains information on various housing features in 506 neighborhoods around Boston, which can be used to evaluate the price of a house (target) based on different attributes. The dataset includes 13 attributes, and median value of owner-occupied homes in thousands of dollars, is provided in attribute 14.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># load a dataset for prediction from library</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_boston</span><br><span class=\"line\">boston = load_boston()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.DESCR)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.data.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.feature_names)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.target)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Number of Instances: 506 </span><br><span class=\"line\">Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.</span><br><span class=\"line\">Attribute Information (in order):</span><br><span class=\"line\">        - CRIM     per capita crime rate by town</span><br><span class=\"line\">        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.</span><br><span class=\"line\">        - INDUS    proportion of non-retail business acres per town</span><br><span class=\"line\">        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</span><br><span class=\"line\">        - NOX      nitric oxides concentration (parts per 10 million)</span><br><span class=\"line\">        - RM       average number of rooms per dwelling</span><br><span class=\"line\">        - AGE      proportion of owner-occupied units built prior to 1940</span><br><span class=\"line\">        - DIS      weighted distances to five Boston employment centres</span><br><span class=\"line\">        - RAD      index of accessibility to radial highways</span><br><span class=\"line\">        - TAX      full-value property-tax rate per $10,000</span><br><span class=\"line\">        - PTRATIO  pupil-teacher ratio by town</span><br><span class=\"line\">        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town</span><br><span class=\"line\">        - LSTAT    % lower status of the population</span><br><span class=\"line\">        - MEDV     Median value of owner-occupied homes in $1000's</span><br></pre></td></tr></tbody></table></figure>\n<p>For example, for the first row, it means given the first row of data, the MEDV is 24. we have 506 rows.</p>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV</span><br><span class=\"line\">0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0</span><br><span class=\"line\">1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6</span><br><span class=\"line\">2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7</span><br><span class=\"line\">3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4</span><br><span class=\"line\">4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2</span><br></pre></td></tr></tbody></table></figure>\n<p>Given a matrix of size 506 x 13, the rank of the matrix must be less than or equal to 13, since the maximum rank of a 506 x 13 matrix is 13. </p>\n<p><strong>If the rank is equal to 13, then there are indeed 13 independent features in the dataset, and each feature provides unique information that is not redundant with the other features. If the rank is less than 13, for example, if the rank is 10, then it means that some of the features are redundant or can be expressed as linear combinations of other features.</strong> For example, it is intuitive that there might be a relationship between two features, such as the number of convenience stores and the accessibility of transportation, where areas with better transportation tend to have more convenience stores. Then, they are not completely independent of each other and can be considered redundant or providing similar information.</p>\n<p>In real-world engineering applications, the relationship between two features may not be completely independent or dependent, but may exist somewhere in between. These relationships can be measured using correlation coefficients or other statistical measures, such as mutual information or covariance.</p>\n<h3 id=\"Correlation-coefficients\"><a href=\"#Correlation-coefficients\" class=\"headerlink\" title=\"Correlation coefficients\"></a>Correlation coefficients</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 17:23</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load a dataset for prediction from library</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_boston</span><br><span class=\"line\">boston = load_boston()</span><br><span class=\"line\">df = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class=\"line\">df[<span class=\"string\">'MEDV'</span>] = boston.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot Correlation coefficients</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\"># give a mask for the upper triangle</span></span><br><span class=\"line\">mask = np.zeros_like(df.corr(), dtype=np.<span class=\"built_in\">bool</span>)</span><br><span class=\"line\">mask[np.triu_indices_from(mask)] = <span class=\"literal\">True</span></span><br><span class=\"line\"><span class=\"comment\"># set font as times new roman</span></span><br><span class=\"line\">plt.rcParams[<span class=\"string\">'font.family'</span>] = <span class=\"string\">'Times New Roman'</span></span><br><span class=\"line\"><span class=\"comment\"># plot heatmap</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">sns.heatmap(df.corr(), mask=mask, annot=<span class=\"literal\">True</span>, fmt=<span class=\"string\">'.2f'</span>, cmap=<span class=\"string\">'viridis'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Correlation coefficients.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Correlation coefficients\" data-src=\"/2023/03/28/Regression/Correlation%20coefficients.png\"></p>\n<p>The heatmap provides a visual representation of the strength and direction of the correlation between variables, ranging from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no correlation.</p>\n<h3 id=\"Linear-system\"><a href=\"#Linear-system\" class=\"headerlink\" title=\"Linear system\"></a>Linear system</h3><figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV</span><br><span class=\"line\">0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0</span><br><span class=\"line\">1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6</span><br><span class=\"line\">2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7</span><br><span class=\"line\">3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4</span><br><span class=\"line\">4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2</span><br></pre></td></tr></tbody></table></figure>\n<p>lets recall this dataset. It just shows the first 5 rows, but actually we have 506 rows.</p>\n<p><strong>The Boston housing dataset can be represented as a linear system with 13 unknown variables and 506 equations.</strong></p>\n<p>Let <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.552ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 869 686\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> be the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.422ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3722.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\" transform=\"translate(500,0)\"></path></g></g></g></svg></mjx-container> matrix of input features, where each row corresponds to an observation, and each column corresponds to a feature. The feature columns are denoted as $\\mathbf{X} = [\\mathbf{x<em>1}, \\mathbf{x_2}, \\ldots, \\mathbf{x</em>{13}}]$.</p>\n<p>Let <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.373ex\" height=\"1.457ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -444 607 644\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g></g></g></svg></mjx-container> be the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.291ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> vector of target values, which corresponds to the median value of owner-occupied homes in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.214ex\" height=\"1.835ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -789 2746.5 811\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(1000,0)\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(1500,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2033,393.1) scale(0.707)\"><path data-c=\"2032\" d=\"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(2277.5,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g></g></g></svg></mjx-container>.</p>\n<p>The linear regression model can be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y} = \\theta_0 + \\theta_1 \\mathbf{x_1} + \\theta_2 \\mathbf{x_2} + \\cdots + \\theta_{13} \\mathbf{x_{13}}</script><p>where $\\theta<em>0<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"25.667ex\" height=\"2.009ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 11345 888\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(814,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1175,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1751,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2217,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2562,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3162,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3523,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3989,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4440,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4873,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5339,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5842,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6203,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6688,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7139,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7568,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7913,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8442,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8911,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9272,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9738,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10189,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(11067,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g></g></g></svg></mjx-container>\\theta_1, \\theta_2, \\ldots, \\theta</em>{13}<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"35.346ex\" height=\"2.059ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 15623 910\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(529,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(980,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1446,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1807,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2383,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2849,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3727,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4212,0)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4732,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5198,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5496,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5929,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6414,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6880,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7430,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7980,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8325,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8758,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9103,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9569,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10169,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10530,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10999,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11484,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11935,0)\"><path data-c=\"1D464\" d=\"M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(12651,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13117,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13462,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13939,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(14515,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(14876,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(15345,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g></g></g></svg></mjx-container>\\mathbf{x<em>1}, \\mathbf{x_2}, \\ldots, \\mathbf{x</em>{13}}$ are the input feature columns.</p>\n<p>In matrix notation, the linear regression model can be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.552ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 869 686\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.422ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3722.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\" transform=\"translate(500,0)\"></path></g></g></g></svg></mjx-container> matrix of input features, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.159ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2722.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\" transform=\"translate(500,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1222.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2222.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> vector of model coefficients, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.919ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 406 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D716\" d=\"M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z\"></path></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.291ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> vector of errors.</p>\n<p>The goal is to find <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<h3 id=\"Normal-equation\"><a href=\"#Normal-equation\" class=\"headerlink\" title=\"Normal equation\"></a>Normal equation</h3><p>The solution for the model coefficients <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container> using the normal equation is given by:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{\\theta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}</script><p>In order to find the values of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container>, we need to first compute the matrix product <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.246ex\" height=\"1.904ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 2318.8 841.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1449.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> and the vector product <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.653ex\" height=\"2.357ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 2056.8 1041.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1449.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g></g></g></svg></mjx-container>, and then apply matrix inversion to <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.006ex\" height=\"2.47ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 3096.8 1091.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(389,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1838.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2707.8,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load a dataset for prediction from library</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_boston</span><br><span class=\"line\">boston = load_boston()</span><br><span class=\"line\">df = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class=\"line\">df[<span class=\"string\">'MEDV'</span>] = boston.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># solve this problem by normal equation</span></span><br><span class=\"line\"><span class=\"comment\"># define X and y, X 13 features, y 1 target</span></span><br><span class=\"line\">X = df.drop(<span class=\"string\">'MEDV'</span>, axis=<span class=\"number\">1</span>).values</span><br><span class=\"line\">y = df[<span class=\"string\">'MEDV'</span>].values</span><br><span class=\"line\"><span class=\"comment\"># add a column of 1 to X, why?</span></span><br><span class=\"line\"><span class=\"comment\"># because the first element of theta is the intercept</span></span><br><span class=\"line\">X = np.hstack((np.ones((X.shape[<span class=\"number\">0</span>], <span class=\"number\">1</span>)), X))</span><br><span class=\"line\"><span class=\"comment\"># compute the normal equation</span></span><br><span class=\"line\">theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)</span><br><span class=\"line\"><span class=\"comment\"># print the result</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'theta: '</span>, theta)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">theta:  [ 3.64594884e+01 -1.08011358e-01  4.64204584e-02  2.05586264e-02</span><br><span class=\"line\">  2.68673382e+00 -1.77666112e+01  3.80986521e+00  6.92224640e-04</span><br><span class=\"line\"> -1.47556685e+00  3.06049479e-01 -1.23345939e-02 -9.52747232e-01</span><br><span class=\"line\">  9.31168327e-03 -5.24758378e-01]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Notation\"><a href=\"#Notation\" class=\"headerlink\" title=\"Notation\"></a>Notation</h3><p>In a linear regression model, there is typically an error term <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.919ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 406 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D716\" d=\"M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z\"></path></g></g></g></g></svg></mjx-container> that represents the difference between the predicted target values and the true target values.</p>\n<p>The linear regression model should be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta} + \\mathbf{\\epsilon}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.373ex\" height=\"1.457ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -444 607 644\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g></g></g></svg></mjx-container> is a vector of observed target values, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.552ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 869 686\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> is a matrix of input feature values, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container> is a vector of model coefficients, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.919ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 406 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D716\" d=\"M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z\"></path></g></g></g></g></svg></mjx-container> is a vector of errors.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data points</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the slope and intercept of the regression line using the least squares method</span></span><br><span class=\"line\">A = np.vstack([x, np.ones(<span class=\"built_in\">len</span>(x))]).T</span><br><span class=\"line\">m, b = np.linalg.lstsq(A, y, rcond=<span class=\"literal\">None</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data points and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y)</span><br><span class=\"line\">plt.plot(x, m*x + b, <span class=\"string\">'r'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Linear Regression.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"Linear Regression\" style=\"zoom:30%;\" data-src=\"/2023/03/28/Regression/Linear%20Regression.png\">\n</p>\n\n<p>The error term in a linear regression model accounts for the fact that the predicted values may not perfectly align with the actual values, due to the inherent variability in the data. In other words, the error term allows for some deviation between the predicted values and the true values.</p>\n<h3 id=\"Polynomial-regression\"><a href=\"#Polynomial-regression\" class=\"headerlink\" title=\"Polynomial regression\"></a>Polynomial regression</h3><p>Polynomial regression and linear regression are similar in that they both aim to model the relationship between an input variable and a target variable. However, they differ in the functional form of the model that they use to capture this relationship.</p>\n<p>Linear regression models the relationship between the input variable and target variable as a linear function, represented by a straight line. Polynomial regression, on the other hand, models the relationship between the input variable and target variable as a polynomial function of degree n, where n is the highest power of the input variable in the model.</p>\n<p>In other words, polynomial regression allows for a more flexible and non-linear relationship between the input and target variables than linear regression. By fitting a polynomial curve to the data, polynomial regression can capture more complex patterns and relationships that may not be apparent in a linear model.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some sample data</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">2</span>*np.pi, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.sin(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Reshape the data into a column vector</span></span><br><span class=\"line\">x = x.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">y = y.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a polynomial regression model to the data</span></span><br><span class=\"line\">poly = PolynomialFeatures(degree=<span class=\"number\">3</span>)</span><br><span class=\"line\">X_poly = poly.fit_transform(x)</span><br><span class=\"line\">poly_reg = LinearRegression()</span><br><span class=\"line\">poly_reg.fit(X_poly, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the original data and the fitted curve</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>)</span><br><span class=\"line\">plt.plot(x, poly_reg.predict(poly.fit_transform(x)), color=<span class=\"string\">'red'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Polynomial Regression of Sin(x)'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Polynomial Regression of Sin(x).png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"Polynomial Regression of Sin(x)\" style=\"zoom:30%;\" data-src=\"/2023/03/28/Regression/Polynomial Regression of Sin(x).png\">\n</p>\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>UCI Machine Learning Repository (2018). Housing Data Set [Data File]. Retrieved from <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\">https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</a></li>\n<li>Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.</li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/03/27/Basic-operations-of-Matrix/","2023/03/27/Linear-Algebra-Basics/","2023/03/28/Numpy-Basics/","2023/03/28/Linear-equations/","2023/03/28/Functions-Plot/"],"length":2473,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Rank\"><a href=\"#Rank\" class=\"headerlink\" title=\"Rank\"></a>Rank</h3><p>In linear algebra, the rank of a matrix is the number of linearly independent rows or columns in the matrix.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 17:23</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a matrix</span></span><br><span class=\"line\">A = np.array([[<span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">3</span>],</span><br><span class=\"line\">              [-<span class=\"number\">1</span>, <span class=\"number\">9</span>, <span class=\"number\">6</span>],</span><br><span class=\"line\">              [<span class=\"number\">3</span>, <span class=\"number\">2</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Compute the rank of the matrix</span></span><br><span class=\"line\">rank = np.linalg.matrix_rank(A)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print the rank of the matrix</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"Rank of the matrix: \"</span>, rank)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Rank of the matrix:  3</span><br></pre></td></tr></tbody></table></figure>\n<p>To find the rank, we need to :</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n-1 & 9 & 6 \\\\\n3 & 2 & 9\n\\end{array}\\right]\n\\end{equation}</script><p>The solution is:</p>\n<p>Add row 1 to row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"16.915ex\" height=\"1.885ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7476.2 833\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6280.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n3 & 2 & 9\n\\end{array}\\right]</script><p>Subtract row 1 multiplied by 3 from row 3 : <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"15.029ex\" height=\"1.92ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 6642.7 848.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1473.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2529.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3946.9,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(4947.1,0)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(5447.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{lll}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 2 & 0\n\\end{array}\\right]</script><p>Subtract row 2 multiplied by <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.816ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.795ex\" height=\"2.773ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -864.9 793.6 1225.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mfrac\"><g data-mml-node=\"mn\" transform=\"translate(220,394) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(220,-345) scale(0.707)\"><path data-c=\"39\" d=\"M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z\"></path></g><rect width=\"553.6\" height=\"60\" x=\"120\" y=\"220\"></rect></g></g></g></svg></mjx-container> from row 3 : <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.816ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"14.901ex\" height=\"2.918ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -929 6586 1289.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1473.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(2529.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3946.9,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(4947.1,0)\"><g data-mml-node=\"mrow\" transform=\"translate(220,446.1) scale(0.707)\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(500,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g><g data-mml-node=\"mn\" transform=\"translate(642.7,-345) scale(0.707)\"><path data-c=\"39\" d=\"M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z\"></path></g><rect width=\"1398.9\" height=\"60\" x=\"120\" y=\"220\"></rect></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 0 & 3 \\\\\n0 & 9 & 9 \\\\\n0 & 0 & -2\n\\end{array}\\right]\n\\end{equation}</script><p><strong>It means that all three rows or columns are linearly independent</strong>. In other words, none of the rows or columns can be expressed as a linear combination of the other rows or columns.</p>\n<p><strong>If a 3x3 matrix has rank 3, it means that its rows (or columns) span the entire 3D space</strong>, and any vector in 3D can be expressed as a linear combination of the rows (or columns) of the matrix.</p>\n<p>Okay, another example</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { Find the row echelon form of }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{array}\\right]\n\\end{equation}</script><p>Subtract row 1 multiplied by 4 from row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.339ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.046ex\" height=\"1.885ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7976.2 833\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6280.7,0)\"><path data-c=\"34\" d=\"M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6780.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n7 & 8 & 9\n\\end{array}\\right]</script><p>Subtract row 1 multiplied by 7 from row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.046ex\" height=\"1.92ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7976.2 848.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6280.7,0)\"><path data-c=\"37\" d=\"M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6780.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & -6 & -12\n\\end{array}\\right]</script><p>Subtract row 2 multiplied by 2 from row <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.375ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"18.046ex\" height=\"1.92ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 7976.2 848.6\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(777.8,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1333.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2806.9,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(3862.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5280.4,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6280.7,0)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(6780.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D445\" d=\"M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(792,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<script type=\"math/tex; mode=display\">\n\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]</script><p>Since the element at row 3 and column 3 (pivot element) equals 0 , we need to swap the rows.<br>Find the first nonzero element in column 3 under the pivot entry.<br>As can be seen, there are no such entries.</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\text { The row echelon form is }\\left[\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n0 & -3 & -6 \\\\\n0 & 0 & 0\n\\end{array}\\right]\n\\end{equation}</script><p>so the rank is 2.</p>\n<p><strong>If a 3 x 3 matrix has a rank of 2, it means that only two of its rows or columns are linearly independent, and the third row or column can be expressed as a linear combination of the other two.</strong></p>\n<p><strong>Geometrically, this means that the rows or columns of the matrix lie in a plane in three-dimensional space.</strong></p>\n<h3 id=\"Easy-to-remember-Rank\"><a href=\"#Easy-to-remember-Rank\" class=\"headerlink\" title=\"Easy to remember Rank\"></a>Easy to remember Rank</h3><p>In simpler terms, imagine that youre going out and you bring three items with you: an umbrella, a raincoat, and a loaf of bread. However, the umbrella and raincoat serve the same purpose of keeping you dry in the rain, so one of them is unnecessary. Therefore, you are effectively only bringing two items with you. This is similar to a 3 x 3 matrix with a rank of 2, where one row or column is redundant and can be expressed as a linear combination of the other two.</p>\n<h3 id=\"Span\"><a href=\"#Span\" class=\"headerlink\" title=\"Span\"></a>Span</h3><p>In linear algebra, the span of a set of vectors <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.29ex\" height=\"1.443ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -444 5874 638\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msub\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D42F\" d=\"M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(640,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1043.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1488.2,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D42F\" d=\"M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(640,-150) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2531.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2976.4,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4315.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4759.8,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D42F\" d=\"M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(640,-150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container> is the set of all possible linear combinations of those vectors. Formally, the span is defined as follows:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n\\operatorname{span}\\left(\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n\\right)=\\left\\{\\sum_{i=1}^n c_i \\mathbf{v}_i \\mid c_i \\in \\mathbb{R}\\right\\}\n\\end{equation}</script><p>In words, the span is the set of all possible vectors that can be formed by scaling and adding the given vectors. It can be thought of as a subspace of the vector space that contains the given vectors.</p>\n<p>Geometrically, the span of a set of vectors is the smallest subspace that contains all those vectors. For example, the span of two non-collinear vectors in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.621ex\" height=\"1.887ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 1158.6 833.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(755,363) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container> is the entire plane, while the span of two parallel vectors is the line they lie on.</p>\n<h3 id=\"Features\"><a href=\"#Features\" class=\"headerlink\" title=\"Features\"></a>Features</h3><p>The Boston dataset contains information on various housing features in 506 neighborhoods around Boston, which can be used to evaluate the price of a house (target) based on different attributes. The dataset includes 13 attributes, and median value of owner-occupied homes in thousands of dollars, is provided in attribute 14.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># load a dataset for prediction from library</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_boston</span><br><span class=\"line\">boston = load_boston()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.DESCR)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.data.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.feature_names)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(boston.target)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Number of Instances: 506 </span><br><span class=\"line\">Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.</span><br><span class=\"line\">Attribute Information (in order):</span><br><span class=\"line\">        - CRIM     per capita crime rate by town</span><br><span class=\"line\">        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.</span><br><span class=\"line\">        - INDUS    proportion of non-retail business acres per town</span><br><span class=\"line\">        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</span><br><span class=\"line\">        - NOX      nitric oxides concentration (parts per 10 million)</span><br><span class=\"line\">        - RM       average number of rooms per dwelling</span><br><span class=\"line\">        - AGE      proportion of owner-occupied units built prior to 1940</span><br><span class=\"line\">        - DIS      weighted distances to five Boston employment centres</span><br><span class=\"line\">        - RAD      index of accessibility to radial highways</span><br><span class=\"line\">        - TAX      full-value property-tax rate per $10,000</span><br><span class=\"line\">        - PTRATIO  pupil-teacher ratio by town</span><br><span class=\"line\">        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town</span><br><span class=\"line\">        - LSTAT    % lower status of the population</span><br><span class=\"line\">        - MEDV     Median value of owner-occupied homes in $1000's</span><br></pre></td></tr></tbody></table></figure>\n<p>For example, for the first row, it means given the first row of data, the MEDV is 24. we have 506 rows.</p>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV</span><br><span class=\"line\">0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0</span><br><span class=\"line\">1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6</span><br><span class=\"line\">2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7</span><br><span class=\"line\">3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4</span><br><span class=\"line\">4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2</span><br></pre></td></tr></tbody></table></figure>\n<p>Given a matrix of size 506 x 13, the rank of the matrix must be less than or equal to 13, since the maximum rank of a 506 x 13 matrix is 13. </p>\n<p><strong>If the rank is equal to 13, then there are indeed 13 independent features in the dataset, and each feature provides unique information that is not redundant with the other features. If the rank is less than 13, for example, if the rank is 10, then it means that some of the features are redundant or can be expressed as linear combinations of other features.</strong> For example, it is intuitive that there might be a relationship between two features, such as the number of convenience stores and the accessibility of transportation, where areas with better transportation tend to have more convenience stores. Then, they are not completely independent of each other and can be considered redundant or providing similar information.</p>\n<p>In real-world engineering applications, the relationship between two features may not be completely independent or dependent, but may exist somewhere in between. These relationships can be measured using correlation coefficients or other statistical measures, such as mutual information or covariance.</p>\n<h3 id=\"Correlation-coefficients\"><a href=\"#Correlation-coefficients\" class=\"headerlink\" title=\"Correlation coefficients\"></a>Correlation coefficients</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 17:23</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load a dataset for prediction from library</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_boston</span><br><span class=\"line\">boston = load_boston()</span><br><span class=\"line\">df = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class=\"line\">df[<span class=\"string\">'MEDV'</span>] = boston.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot Correlation coefficients</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\"># give a mask for the upper triangle</span></span><br><span class=\"line\">mask = np.zeros_like(df.corr(), dtype=np.<span class=\"built_in\">bool</span>)</span><br><span class=\"line\">mask[np.triu_indices_from(mask)] = <span class=\"literal\">True</span></span><br><span class=\"line\"><span class=\"comment\"># set font as times new roman</span></span><br><span class=\"line\">plt.rcParams[<span class=\"string\">'font.family'</span>] = <span class=\"string\">'Times New Roman'</span></span><br><span class=\"line\"><span class=\"comment\"># plot heatmap</span></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">sns.heatmap(df.corr(), mask=mask, annot=<span class=\"literal\">True</span>, fmt=<span class=\"string\">'.2f'</span>, cmap=<span class=\"string\">'viridis'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Correlation coefficients.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"Correlation coefficients\" data-src=\"/2023/03/28/Regression/Correlation%20coefficients.png\"></p>\n<p>The heatmap provides a visual representation of the strength and direction of the correlation between variables, ranging from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no correlation.</p>\n<h3 id=\"Linear-system\"><a href=\"#Linear-system\" class=\"headerlink\" title=\"Linear system\"></a>Linear system</h3><figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV</span><br><span class=\"line\">0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98  24.0</span><br><span class=\"line\">1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14  21.6</span><br><span class=\"line\">2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03  34.7</span><br><span class=\"line\">3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94  33.4</span><br><span class=\"line\">4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33  36.2</span><br></pre></td></tr></tbody></table></figure>\n<p>lets recall this dataset. It just shows the first 5 rows, but actually we have 506 rows.</p>\n<p><strong>The Boston housing dataset can be represented as a linear system with 13 unknown variables and 506 equations.</strong></p>\n<p>Let <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.552ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 869 686\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> be the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.422ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3722.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\" transform=\"translate(500,0)\"></path></g></g></g></svg></mjx-container> matrix of input features, where each row corresponds to an observation, and each column corresponds to a feature. The feature columns are denoted as $\\mathbf{X} = [\\mathbf{x<em>1}, \\mathbf{x_2}, \\ldots, \\mathbf{x</em>{13}}]$.</p>\n<p>Let <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.373ex\" height=\"1.457ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -444 607 644\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g></g></g></svg></mjx-container> be the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.291ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> vector of target values, which corresponds to the median value of owner-occupied homes in <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.214ex\" height=\"1.835ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -789 2746.5 811\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(1000,0)\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(1500,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2033,393.1) scale(0.707)\"><path data-c=\"2032\" d=\"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(2277.5,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g></g></g></svg></mjx-container>.</p>\n<p>The linear regression model can be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y} = \\theta_0 + \\theta_1 \\mathbf{x_1} + \\theta_2 \\mathbf{x_2} + \\cdots + \\theta_{13} \\mathbf{x_{13}}</script><p>where $\\theta<em>0<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.439ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"25.667ex\" height=\"2.009ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 11345 888\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(345,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(814,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1175,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1751,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2217,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2562,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3162,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3523,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3989,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4440,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4873,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5339,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5842,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6203,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6688,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7139,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7568,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7913,0)\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8442,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8911,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9272,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9738,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10189,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(11067,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g></g></g></svg></mjx-container>\\theta_1, \\theta_2, \\ldots, \\theta</em>{13}<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"35.346ex\" height=\"2.059ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 15623 910\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D44E\" d=\"M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(529,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(980,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1446,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1807,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2383,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2849,0)\"><path data-c=\"1D45A\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3727,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4212,0)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4732,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5198,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5496,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5929,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6414,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6880,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7430,0)\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7980,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8325,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8758,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9103,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9569,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10169,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10530,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10999,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11484,0)\"><path data-c=\"1D45F\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11935,0)\"><path data-c=\"1D464\" d=\"M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(12651,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13117,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13462,0)\"><path data-c=\"1D454\" d=\"M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(13939,0)\"><path data-c=\"210E\" d=\"M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(14515,0)\"><path data-c=\"1D461\" d=\"M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(14876,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(15345,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g></g></g></svg></mjx-container>\\mathbf{x<em>1}, \\mathbf{x_2}, \\ldots, \\mathbf{x</em>{13}}$ are the input feature columns.</p>\n<p>In matrix notation, the linear regression model can be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.552ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 869 686\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"8.422ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3722.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\" transform=\"translate(500,0)\"></path></g></g></g></svg></mjx-container> matrix of input features, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.159ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 2722.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path data-c=\"33\" d=\"M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z\" transform=\"translate(500,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1222.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2222.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> vector of model coefficients, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.919ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 406 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D716\" d=\"M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z\"></path></g></g></g></g></svg></mjx-container> is the <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.291ex\" height=\"1.557ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -666 3222.4 688\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mn\"><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\"></path><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\" transform=\"translate(500,0)\"></path><path data-c=\"36\" d=\"M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z\" transform=\"translate(1000,0)\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(2722.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></svg></mjx-container> vector of errors.</p>\n<p>The goal is to find <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container>.</p>\n<h3 id=\"Normal-equation\"><a href=\"#Normal-equation\" class=\"headerlink\" title=\"Normal equation\"></a>Normal equation</h3><p>The solution for the model coefficients <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container> using the normal equation is given by:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{\\theta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}</script><p>In order to find the values of <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container>, we need to first compute the matrix product <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"5.246ex\" height=\"1.904ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 2318.8 841.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1449.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> and the vector product <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.653ex\" height=\"2.357ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 2056.8 1041.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1449.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g></g></g></svg></mjx-container>, and then apply matrix inversion to <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"7.006ex\" height=\"2.47ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -841.7 3096.8 1091.7\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(389,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,363) scale(0.707)\"><path data-c=\"1D447\" d=\"M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1838.8,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2707.8,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container>.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load a dataset for prediction from library</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_boston</span><br><span class=\"line\">boston = load_boston()</span><br><span class=\"line\">df = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class=\"line\">df[<span class=\"string\">'MEDV'</span>] = boston.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># solve this problem by normal equation</span></span><br><span class=\"line\"><span class=\"comment\"># define X and y, X 13 features, y 1 target</span></span><br><span class=\"line\">X = df.drop(<span class=\"string\">'MEDV'</span>, axis=<span class=\"number\">1</span>).values</span><br><span class=\"line\">y = df[<span class=\"string\">'MEDV'</span>].values</span><br><span class=\"line\"><span class=\"comment\"># add a column of 1 to X, why?</span></span><br><span class=\"line\"><span class=\"comment\"># because the first element of theta is the intercept</span></span><br><span class=\"line\">X = np.hstack((np.ones((X.shape[<span class=\"number\">0</span>], <span class=\"number\">1</span>)), X))</span><br><span class=\"line\"><span class=\"comment\"># compute the normal equation</span></span><br><span class=\"line\">theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)</span><br><span class=\"line\"><span class=\"comment\"># print the result</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'theta: '</span>, theta)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">theta:  [ 3.64594884e+01 -1.08011358e-01  4.64204584e-02  2.05586264e-02</span><br><span class=\"line\">  2.68673382e+00 -1.77666112e+01  3.80986521e+00  6.92224640e-04</span><br><span class=\"line\"> -1.47556685e+00  3.06049479e-01 -1.23345939e-02 -9.52747232e-01</span><br><span class=\"line\">  9.31168327e-03 -5.24758378e-01]</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Notation\"><a href=\"#Notation\" class=\"headerlink\" title=\"Notation\"></a>Notation</h3><p>In a linear regression model, there is typically an error term <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.919ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 406 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D716\" d=\"M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z\"></path></g></g></g></g></svg></mjx-container> that represents the difference between the predicted target values and the true target values.</p>\n<p>The linear regression model should be written as:</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta} + \\mathbf{\\epsilon}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.373ex\" height=\"1.457ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -444 607 644\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g></g></g></svg></mjx-container> is a vector of observed target values, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.966ex\" height=\"1.552ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -686 869 686\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g></g></g></svg></mjx-container> is a matrix of input feature values, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.023ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.061ex\" height=\"1.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 469 715\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g></g></g></g></svg></mjx-container> is a vector of model coefficients, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.919ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 406 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D716\" d=\"M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z\"></path></g></g></g></g></svg></mjx-container> is a vector of errors.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some random data points</span></span><br><span class=\"line\">x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\">y = np.array([<span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">9</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Calculate the slope and intercept of the regression line using the least squares method</span></span><br><span class=\"line\">A = np.vstack([x, np.ones(<span class=\"built_in\">len</span>(x))]).T</span><br><span class=\"line\">m, b = np.linalg.lstsq(A, y, rcond=<span class=\"literal\">None</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the data points and the regression line</span></span><br><span class=\"line\">plt.scatter(x, y)</span><br><span class=\"line\">plt.plot(x, m*x + b, <span class=\"string\">'r'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Linear Regression'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Linear Regression.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"Linear Regression\" style=\"zoom:30%;\" data-src=\"/2023/03/28/Regression/Linear%20Regression.png\">\n</p>\n\n<p>The error term in a linear regression model accounts for the fact that the predicted values may not perfectly align with the actual values, due to the inherent variability in the data. In other words, the error term allows for some deviation between the predicted values and the true values.</p>\n<h3 id=\"Polynomial-regression\"><a href=\"#Polynomial-regression\" class=\"headerlink\" title=\"Polynomial regression\"></a>Polynomial regression</h3><p>Polynomial regression and linear regression are similar in that they both aim to model the relationship between an input variable and a target variable. However, they differ in the functional form of the model that they use to capture this relationship.</p>\n<p>Linear regression models the relationship between the input variable and target variable as a linear function, represented by a straight line. Polynomial regression, on the other hand, models the relationship between the input variable and target variable as a polynomial function of degree n, where n is the highest power of the input variable in the model.</p>\n<p>In other words, polynomial regression allows for a more flexible and non-linear relationship between the input and target variables than linear regression. By fitting a polynomial curve to the data, polynomial regression can capture more complex patterns and relationships that may not be apparent in a linear model.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate some sample data</span></span><br><span class=\"line\">x = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">2</span>*np.pi, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.sin(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Reshape the data into a column vector</span></span><br><span class=\"line\">x = x.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">y = y.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Fit a polynomial regression model to the data</span></span><br><span class=\"line\">poly = PolynomialFeatures(degree=<span class=\"number\">3</span>)</span><br><span class=\"line\">X_poly = poly.fit_transform(x)</span><br><span class=\"line\">poly_reg = LinearRegression()</span><br><span class=\"line\">poly_reg.fit(X_poly, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the original data and the fitted curve</span></span><br><span class=\"line\">plt.scatter(x, y, color=<span class=\"string\">'blue'</span>)</span><br><span class=\"line\">plt.plot(x, poly_reg.predict(poly.fit_transform(x)), color=<span class=\"string\">'red'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Polynomial Regression of Sin(x)'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Polynomial Regression of Sin(x).png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\">\n  <img alt=\"Polynomial Regression of Sin(x)\" style=\"zoom:30%;\" data-src=\"/2023/03/28/Regression/Polynomial Regression of Sin(x).png\">\n</p>\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>UCI Machine Learning Repository (2018). Housing Data Set [Data File]. Retrieved from <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\">https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</a></li>\n<li>Strang, G. (2016). Introduction to linear algebra (5th ed.). Wellesley, MA: Wellesley-Cambridge Press.</li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Relationships between two Sets","date":"2023-04-03T15:21:07.000Z","_content":"### Unions, intersections, and complements\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 16:59\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\n# create sets A and B\nA = set([1, 2, 3])\nB = set([4, 5, 6, 7, 8])\n\n# create subplots\nfig, axs = plt.subplots(nrows=2, ncols=2)\n\n# plot 1: A and B are independent\nvenn2([A, B], set_labels=('A', 'B'),set_colors=('skyblue', 'orange'), ax=axs[0, 0])\naxs[0, 0].set_title('Independent Sets')\n\n# plot 2: A and B have some common parts\nA = set([1, 2, 3, 4, 5])\nB = set([4, 5, 6, 7, 8])\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7, ax=axs[0, 1])\naxs[0, 1].set_title('Overlapping Sets')\n\n# plot 3: A and B are equal\nA = set([1, 2, 3, 4, 5])\nB = set([1, 2, 3, 4, 5])\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7, ax=axs[1, 0])\naxs[1, 0].set_title('Equal Sets')\n\n# plot 4: A belongs to B\nA = set([1, 2, 3])\nB = set([1, 2, 3, 4, 5])\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7, ax=axs[1, 1])\naxs[1, 1].set_title('Subset')\n\n# adjust layout\nplt.tight_layout()\n\n# show plots\nplt.savefig('Venn Diagrams for numbers.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\">\n    <img src=\"Relationships-between-two-Sets/Venn%20Diagrams%20for%20numbers.png\" alt=\"Venn Diagrams for numbers\" style=\"zoom:67%;\" />\n</div>\n###  Cardinality\n\n$$\n\\begin{equation}\n|A \\cup B|=|A|+|B|-|A \\cap B| \\text {. }\n\\end{equation}\n$$\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:10\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\n# create sets A and B\nA = set([1, 2, 3, 4, 5])\nB = set([4, 5, 6, 7, 8])\n\n# calculate cardinality using the equation |A  B| = |A| + |B| - |A  B|\ncardinality_union = len(A.union(B))\ncardinality_A = len(A)\ncardinality_B = len(B)\ncardinality_intersection = len(A.intersection(B))\ncardinality_sum = cardinality_A + cardinality_B - cardinality_intersection\n\n# print the cardinality values\nprint(\"|A| =\", cardinality_A)\nprint(\"|B| =\", cardinality_B)\nprint(\"|A  B| =\", cardinality_intersection)\nprint(\"|A  B| =\", cardinality_union)\nprint(\"|A| + |B| - |A  B| =\", cardinality_sum)\n\n# plot the equation using Venn diagrams\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7)\nplt.title('|A  B| = |A| + |B| - |A  B|')\nplt.annotate('|A|', xy=(-0.6, 0), fontsize=14)\nplt.annotate('|B|', xy=(0.5, 0), fontsize=14)\nplt.savefig('Venn Diagrams for cardinality.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\"> <img src=\"Relationships-between-two-Sets/Venn%20Diagrams%20for%20cardinality.png\" alt=\"Venn Diagrams for cardinality\" style=\"zoom:37%;\" /> </div>\n\n\n\n```\n|A| = 5\n|B| = 5\n|A  B| = 2\n|A  B| = 8\n|A| + |B| - |A  B| = 8\n```\n\n### Cartesian product\n\n> The Cartesian product of two sets $A$ and $B$ is the set\n> $$\n> A \\times B=\\{(a, b): a \\in A, b \\in B\\}\n> $$\n> For example, $[0,1] \\times[0,1]$ is the square $\\{(x, y): x, y \\in[0,1]\\}$, and $\\mathbb{R} \\times \\mathbb{R}=\\mathbb{R}^2$ is two-dimensional Euclidean space.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:37\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# create two sets A and B\nA = np.linspace(0, 1, 11)\nB = np.linspace(0, 1, 11)\n\n# compute the Cartesian product of A and B\nC = [(a, b) for a in A for b in B]\n\n# plot the resulting set\nx, y = zip(*C)\nplt.scatter(x, y, s=5)\n\n# set plot limits and labels\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.xlabel('A')\nplt.ylabel('B')\nplt.savefig('Cartesian Product of A and B.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.title('Cartesian Product of A and B')\n\n# show plot\nplt.show()\n```\n\n<div style=\"text-align:center\"> <img src=\"Relationships-between-two-Sets/Cartesian%20Product%20of%20A%20and%20B.png\" alt=\"Cartesian Product of A and B\" style=\"zoom:33%;\" /> </div>\n\n\n### Reference\n\n1. Blitzstein, J. K., & Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.\n\n","source":"_posts/Relationships-between-two-Sets.md","raw":"---\nmathjax: true\ntitle: Relationships between two Sets\ndate: 2023-04-03 15:21:07\ntags:\n  - Set\n  - Math\n  - Probability\n  - Python\n  - Basics\n---\n### Unions, intersections, and complements\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 16:59\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\n# create sets A and B\nA = set([1, 2, 3])\nB = set([4, 5, 6, 7, 8])\n\n# create subplots\nfig, axs = plt.subplots(nrows=2, ncols=2)\n\n# plot 1: A and B are independent\nvenn2([A, B], set_labels=('A', 'B'),set_colors=('skyblue', 'orange'), ax=axs[0, 0])\naxs[0, 0].set_title('Independent Sets')\n\n# plot 2: A and B have some common parts\nA = set([1, 2, 3, 4, 5])\nB = set([4, 5, 6, 7, 8])\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7, ax=axs[0, 1])\naxs[0, 1].set_title('Overlapping Sets')\n\n# plot 3: A and B are equal\nA = set([1, 2, 3, 4, 5])\nB = set([1, 2, 3, 4, 5])\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7, ax=axs[1, 0])\naxs[1, 0].set_title('Equal Sets')\n\n# plot 4: A belongs to B\nA = set([1, 2, 3])\nB = set([1, 2, 3, 4, 5])\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7, ax=axs[1, 1])\naxs[1, 1].set_title('Subset')\n\n# adjust layout\nplt.tight_layout()\n\n# show plots\nplt.savefig('Venn Diagrams for numbers.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\">\n    <img src=\"Relationships-between-two-Sets/Venn%20Diagrams%20for%20numbers.png\" alt=\"Venn Diagrams for numbers\" style=\"zoom:67%;\" />\n</div>\n###  Cardinality\n\n$$\n\\begin{equation}\n|A \\cup B|=|A|+|B|-|A \\cap B| \\text {. }\n\\end{equation}\n$$\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:10\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\n# create sets A and B\nA = set([1, 2, 3, 4, 5])\nB = set([4, 5, 6, 7, 8])\n\n# calculate cardinality using the equation |A  B| = |A| + |B| - |A  B|\ncardinality_union = len(A.union(B))\ncardinality_A = len(A)\ncardinality_B = len(B)\ncardinality_intersection = len(A.intersection(B))\ncardinality_sum = cardinality_A + cardinality_B - cardinality_intersection\n\n# print the cardinality values\nprint(\"|A| =\", cardinality_A)\nprint(\"|B| =\", cardinality_B)\nprint(\"|A  B| =\", cardinality_intersection)\nprint(\"|A  B| =\", cardinality_union)\nprint(\"|A| + |B| - |A  B| =\", cardinality_sum)\n\n# plot the equation using Venn diagrams\nvenn2([A, B], set_labels=('A', 'B'), set_colors=('skyblue', 'orange'), alpha=0.7)\nplt.title('|A  B| = |A| + |B| - |A  B|')\nplt.annotate('|A|', xy=(-0.6, 0), fontsize=14)\nplt.annotate('|B|', xy=(0.5, 0), fontsize=14)\nplt.savefig('Venn Diagrams for cardinality.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n<div style=\"text-align:center\"> <img src=\"Relationships-between-two-Sets/Venn%20Diagrams%20for%20cardinality.png\" alt=\"Venn Diagrams for cardinality\" style=\"zoom:37%;\" /> </div>\n\n\n\n```\n|A| = 5\n|B| = 5\n|A  B| = 2\n|A  B| = 8\n|A| + |B| - |A  B| = 8\n```\n\n### Cartesian product\n\n> The Cartesian product of two sets $A$ and $B$ is the set\n> $$\n> A \\times B=\\{(a, b): a \\in A, b \\in B\\}\n> $$\n> For example, $[0,1] \\times[0,1]$ is the square $\\{(x, y): x, y \\in[0,1]\\}$, and $\\mathbb{R} \\times \\mathbb{R}=\\mathbb{R}^2$ is two-dimensional Euclidean space.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 17:37\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# create two sets A and B\nA = np.linspace(0, 1, 11)\nB = np.linspace(0, 1, 11)\n\n# compute the Cartesian product of A and B\nC = [(a, b) for a in A for b in B]\n\n# plot the resulting set\nx, y = zip(*C)\nplt.scatter(x, y, s=5)\n\n# set plot limits and labels\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.xlabel('A')\nplt.ylabel('B')\nplt.savefig('Cartesian Product of A and B.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.title('Cartesian Product of A and B')\n\n# show plot\nplt.show()\n```\n\n<div style=\"text-align:center\"> <img src=\"Relationships-between-two-Sets/Cartesian%20Product%20of%20A%20and%20B.png\" alt=\"Cartesian Product of A and B\" style=\"zoom:33%;\" /> </div>\n\n\n### Reference\n\n1. Blitzstein, J. K., & Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.\n\n","slug":"Relationships-between-two-Sets","published":1,"updated":"2023-04-07T02:43:50.824Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73hb0010ozpi4gnb5h6u","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Unions-intersections-and-complements\"><a href=\"#Unions-intersections-and-complements\" class=\"headerlink\" title=\"Unions, intersections, and complements\"></a>Unions, intersections, and complements</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 16:59</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib_venn <span class=\"keyword\">import</span> venn2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create sets A and B</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">2</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 1: A and B are independent</span></span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>),set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), ax=axs[<span class=\"number\">0</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\">axs[<span class=\"number\">0</span>, <span class=\"number\">0</span>].set_title(<span class=\"string\">'Independent Sets'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 2: A and B have some common parts</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>])</span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>, ax=axs[<span class=\"number\">0</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">axs[<span class=\"number\">0</span>, <span class=\"number\">1</span>].set_title(<span class=\"string\">'Overlapping Sets'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 3: A and B are equal</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>, ax=axs[<span class=\"number\">1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\">axs[<span class=\"number\">1</span>, <span class=\"number\">0</span>].set_title(<span class=\"string\">'Equal Sets'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 4: A belongs to B</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>, ax=axs[<span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">axs[<span class=\"number\">1</span>, <span class=\"number\">1</span>].set_title(<span class=\"string\">'Subset'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Venn Diagrams for numbers.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">\n    <img alt=\"Venn Diagrams for numbers\" style=\"zoom:67%;\" data-src=\"/2023/04/03/Relationships-between-two-Sets/Venn%20Diagrams%20for%20numbers.png\">\n</div>\n###  Cardinality\n\n<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"30.046ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 13280.3 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(278,0)\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1250.2,0)\"><path data-c=\"222A\" d=\"M591 598H592Q604 598 611 583V376Q611 345 611 296Q610 162 606 148Q605 146 605 145Q586 68 507 23T333 -22Q268 -22 209 -1T106 66T56 173Q55 180 55 384L56 585Q66 598 75 598Q85 598 95 585V378L96 172L98 162Q112 95 181 57T332 18Q415 18 487 58T570 175Q571 180 571 383V583Q579 598 591 598Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2139.4,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2898.4,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3454.2,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4510,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4788,0)\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5538,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6038.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(7038.4,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7316.4,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8075.4,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8575.7,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(9575.9,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9853.9,0)\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10826.1,0)\"><path data-c=\"2229\" d=\"M88 -21T75 -21T55 -7V200Q55 231 55 280Q56 414 60 428Q61 430 61 431Q77 500 152 549T332 598Q443 598 522 544T610 405Q611 399 611 194V-7Q604 -22 591 -22Q582 -22 572 -9L570 405Q563 433 556 449T529 485Q498 519 445 538T334 558Q251 558 179 518T96 401Q95 396 95 193V-7Q88 -21 75 -21Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11715.3,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(12474.3,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mtext\" transform=\"translate(12752.3,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path><path data-c=\"A0\" d=\"\" transform=\"translate(278,0)\"></path></g></g></g></svg></mjx-container>\n\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib_venn <span class=\"keyword\">import</span> venn2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create sets A and B</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># calculate cardinality using the equation |A  B| = |A| + |B| - |A  B|</span></span><br><span class=\"line\">cardinality_union = <span class=\"built_in\">len</span>(A.union(B))</span><br><span class=\"line\">cardinality_A = <span class=\"built_in\">len</span>(A)</span><br><span class=\"line\">cardinality_B = <span class=\"built_in\">len</span>(B)</span><br><span class=\"line\">cardinality_intersection = <span class=\"built_in\">len</span>(A.intersection(B))</span><br><span class=\"line\">cardinality_sum = cardinality_A + cardinality_B - cardinality_intersection</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print the cardinality values</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A| =\"</span>, cardinality_A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|B| =\"</span>, cardinality_B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A  B| =\"</span>, cardinality_intersection)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A  B| =\"</span>, cardinality_union)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A| + |B| - |A  B| =\"</span>, cardinality_sum)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the equation using Venn diagrams</span></span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'|A  B| = |A| + |B| - |A  B|'</span>)</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'|A|'</span>, xy=(-<span class=\"number\">0.6</span>, <span class=\"number\">0</span>), fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'|B|'</span>, xy=(<span class=\"number\">0.5</span>, <span class=\"number\">0</span>), fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Venn Diagrams for cardinality.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n\n<div style=\"text-align:center\"> <img alt=\"Venn Diagrams for cardinality\" style=\"zoom:37%;\" data-src=\"/2023/04/03/Relationships-between-two-Sets/Venn%20Diagrams%20for%20cardinality.png\"> </div>\n\n\n\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">|A| = 5</span><br><span class=\"line\">|B| = 5</span><br><span class=\"line\">|A  B| = 2</span><br><span class=\"line\">|A  B| = 8</span><br><span class=\"line\">|A| + |B| - |A  B| = 8</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Cartesian-product\"><a href=\"#Cartesian-product\" class=\"headerlink\" title=\"Cartesian product\"></a>Cartesian product</h3><blockquote>\n<p>The Cartesian product of two sets <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container> is the set</p>\n<script type=\"math/tex; mode=display\">\nA \\times B=\\{(a, b): a \\in A, b \\in B\\}</script><p>For example, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"11.819ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 5223.8 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(278,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(778,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1222.7,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.7,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2222.9,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3223.1,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(3501.1,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4001.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(4445.8,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4945.8,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g></g></g></svg></mjx-container> is the square <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"17.756ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 7848.1 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(961,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1405.7,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1895.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2562.4,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3118.2,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3690.2,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4134.9,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4902.7,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5847.4,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6125.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6625.4,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(7070.1,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(7570.1,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g></g></g></g></svg></mjx-container>, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"11.671ex\" height=\"2.072ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 5158.6 915.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(944.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1944.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2944.2,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(4000,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(755,363) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container> is two-dimensional Euclidean space.</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:37</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create two sets A and B</span></span><br><span class=\"line\">A = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">11</span>)</span><br><span class=\"line\">B = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">11</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># compute the Cartesian product of A and B</span></span><br><span class=\"line\">C = [(a, b) <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> A <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> B]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the resulting set</span></span><br><span class=\"line\">x, y = <span class=\"built_in\">zip</span>(*C)</span><br><span class=\"line\">plt.scatter(x, y, s=<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set plot limits and labels</span></span><br><span class=\"line\">plt.xlim([<span class=\"number\">0</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">plt.ylim([<span class=\"number\">0</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'A'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'B'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Cartesian Product of A and B.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Cartesian Product of A and B'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plot</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"> <img alt=\"Cartesian Product of A and B\" style=\"zoom:33%;\" data-src=\"/2023/04/03/Relationships-between-two-Sets/Cartesian%20Product%20of%20A%20and%20B.png\"> </div>\n\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Blitzstein, J. K., &amp; Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.</li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/03/Functions/","2023/03/28/Hyperplane/","2023/03/27/Basic-operations-of-Matrix/","2023/03/27/Norms/","2023/03/28/Linear-equations/"],"length":644,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Unions-intersections-and-complements\"><a href=\"#Unions-intersections-and-complements\" class=\"headerlink\" title=\"Unions, intersections, and complements\"></a>Unions, intersections, and complements</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 16:59</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib_venn <span class=\"keyword\">import</span> venn2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create sets A and B</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create subplots</span></span><br><span class=\"line\">fig, axs = plt.subplots(nrows=<span class=\"number\">2</span>, ncols=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 1: A and B are independent</span></span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>),set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), ax=axs[<span class=\"number\">0</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\">axs[<span class=\"number\">0</span>, <span class=\"number\">0</span>].set_title(<span class=\"string\">'Independent Sets'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 2: A and B have some common parts</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>])</span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>, ax=axs[<span class=\"number\">0</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">axs[<span class=\"number\">0</span>, <span class=\"number\">1</span>].set_title(<span class=\"string\">'Overlapping Sets'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 3: A and B are equal</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>, ax=axs[<span class=\"number\">1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\">axs[<span class=\"number\">1</span>, <span class=\"number\">0</span>].set_title(<span class=\"string\">'Equal Sets'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot 4: A belongs to B</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>, ax=axs[<span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">axs[<span class=\"number\">1</span>, <span class=\"number\">1</span>].set_title(<span class=\"string\">'Subset'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># adjust layout</span></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plots</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Venn Diagrams for numbers.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\">\n    <img alt=\"Venn Diagrams for numbers\" style=\"zoom:67%;\" data-src=\"/2023/04/03/Relationships-between-two-Sets/Venn%20Diagrams%20for%20numbers.png\">\n</div>\n###  Cardinality\n\n<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"30.046ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 13280.3 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(278,0)\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1250.2,0)\"><path data-c=\"222A\" d=\"M591 598H592Q604 598 611 583V376Q611 345 611 296Q610 162 606 148Q605 146 605 145Q586 68 507 23T333 -22Q268 -22 209 -1T106 66T56 173Q55 180 55 384L56 585Q66 598 75 598Q85 598 95 585V378L96 172L98 162Q112 95 181 57T332 18Q415 18 487 58T570 175Q571 180 571 383V583Q579 598 591 598Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2139.4,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2898.4,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3454.2,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4510,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4788,0)\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5538,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6038.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(7038.4,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7316.4,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8075.4,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8575.7,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(9575.9,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9853.9,0)\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10826.1,0)\"><path data-c=\"2229\" d=\"M88 -21T75 -21T55 -7V200Q55 231 55 280Q56 414 60 428Q61 430 61 431Q77 500 152 549T332 598Q443 598 522 544T610 405Q611 399 611 194V-7Q604 -22 591 -22Q582 -22 572 -9L570 405Q563 433 556 449T529 485Q498 519 445 538T334 558Q251 558 179 518T96 401Q95 396 95 193V-7Q88 -21 75 -21Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11715.3,0)\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(12474.3,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mtext\" transform=\"translate(12752.3,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path><path data-c=\"A0\" d=\"\" transform=\"translate(278,0)\"></path></g></g></g></svg></mjx-container>\n\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib_venn <span class=\"keyword\">import</span> venn2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create sets A and B</span></span><br><span class=\"line\">A = <span class=\"built_in\">set</span>([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>])</span><br><span class=\"line\">B = <span class=\"built_in\">set</span>([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>, <span class=\"number\">8</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># calculate cardinality using the equation |A  B| = |A| + |B| - |A  B|</span></span><br><span class=\"line\">cardinality_union = <span class=\"built_in\">len</span>(A.union(B))</span><br><span class=\"line\">cardinality_A = <span class=\"built_in\">len</span>(A)</span><br><span class=\"line\">cardinality_B = <span class=\"built_in\">len</span>(B)</span><br><span class=\"line\">cardinality_intersection = <span class=\"built_in\">len</span>(A.intersection(B))</span><br><span class=\"line\">cardinality_sum = cardinality_A + cardinality_B - cardinality_intersection</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print the cardinality values</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A| =\"</span>, cardinality_A)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|B| =\"</span>, cardinality_B)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A  B| =\"</span>, cardinality_intersection)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A  B| =\"</span>, cardinality_union)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">\"|A| + |B| - |A  B| =\"</span>, cardinality_sum)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the equation using Venn diagrams</span></span><br><span class=\"line\">venn2([A, B], set_labels=(<span class=\"string\">'A'</span>, <span class=\"string\">'B'</span>), set_colors=(<span class=\"string\">'skyblue'</span>, <span class=\"string\">'orange'</span>), alpha=<span class=\"number\">0.7</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'|A  B| = |A| + |B| - |A  B|'</span>)</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'|A|'</span>, xy=(-<span class=\"number\">0.6</span>, <span class=\"number\">0</span>), fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.annotate(<span class=\"string\">'|B|'</span>, xy=(<span class=\"number\">0.5</span>, <span class=\"number\">0</span>), fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Venn Diagrams for cardinality.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n\n<div style=\"text-align:center\"> <img alt=\"Venn Diagrams for cardinality\" style=\"zoom:37%;\" data-src=\"/2023/04/03/Relationships-between-two-Sets/Venn%20Diagrams%20for%20cardinality.png\"> </div>\n\n\n\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">|A| = 5</span><br><span class=\"line\">|B| = 5</span><br><span class=\"line\">|A  B| = 2</span><br><span class=\"line\">|A  B| = 8</span><br><span class=\"line\">|A| + |B| - |A  B| = 8</span><br></pre></td></tr></tbody></table></figure>\n<h3 id=\"Cartesian-product\"><a href=\"#Cartesian-product\" class=\"headerlink\" title=\"Cartesian product\"></a>Cartesian product</h3><blockquote>\n<p>The Cartesian product of two sets <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.697ex\" height=\"1.62ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -716 750 716\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D434\" d=\"M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z\"></path></g></g></g></svg></mjx-container> and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: 0;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.717ex\" height=\"1.545ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -683 759 683\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D435\" d=\"M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z\"></path></g></g></g></svg></mjx-container> is the set</p>\n<script type=\"math/tex; mode=display\">\nA \\times B=\\{(a, b): a \\in A, b \\in B\\}</script><p>For example, <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"11.819ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 5223.8 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(278,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(778,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1222.7,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1722.7,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2222.9,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3223.1,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(3501.1,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4001.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(4445.8,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4945.8,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g></g></g></svg></mjx-container> is the square <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"17.756ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 7848.1 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(961,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1405.7,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1895.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2562.4,0)\"><path data-c=\"3A\" d=\"M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3118.2,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3690.2,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4134.9,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4902.7,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5847.4,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6125.4,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6625.4,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(7070.1,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(7570.1,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g></g></g></g></svg></mjx-container>, and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.186ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"11.671ex\" height=\"2.072ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -833.9 5158.6 915.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(944.2,0)\"><path data-c=\"D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1944.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2944.2,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(4000,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(755,363) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container> is two-dimensional Euclidean space.</p>\n</blockquote>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 17:37</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create two sets A and B</span></span><br><span class=\"line\">A = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">11</span>)</span><br><span class=\"line\">B = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">11</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># compute the Cartesian product of A and B</span></span><br><span class=\"line\">C = [(a, b) <span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> A <span class=\"keyword\">for</span> b <span class=\"keyword\">in</span> B]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># plot the resulting set</span></span><br><span class=\"line\">x, y = <span class=\"built_in\">zip</span>(*C)</span><br><span class=\"line\">plt.scatter(x, y, s=<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># set plot limits and labels</span></span><br><span class=\"line\">plt.xlim([<span class=\"number\">0</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">plt.ylim([<span class=\"number\">0</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'A'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'B'</span>)</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'Cartesian Product of A and B.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Cartesian Product of A and B'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># show plot</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<div style=\"text-align:center\"> <img alt=\"Cartesian Product of A and B\" style=\"zoom:33%;\" data-src=\"/2023/04/03/Relationships-between-two-Sets/Cartesian%20Product%20of%20A%20and%20B.png\"> </div>\n\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Blitzstein, J. K., &amp; Hwang, J. (2019). Introduction to Probability (2nd ed.). CRC Press.</li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Scipy optimization","date":"2023-04-03T19:57:07.000Z","_content":"\n### Brents method on a quadratic function\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:49\n\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return (x - 2) ** 2 + 1\n\ndef f_with_callback(x):\n    f_with_callback.f_values.append(f(x))\n    return f(x)\n\nf_with_callback.f_values = []\n\nres = minimize_scalar(f_with_callback, method='brent')\n\nx = np.linspace(-5, 5, 100)\ny = f(x)\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\naxs[0].plot(x, y, label='f(x)')\naxs[0].plot(res.x, res.fun, 'ro', label='global minima')\naxs[0].legend()\naxs[0].set_title('Quadratic convex function with global minima')\n\naxs[1].plot(f_with_callback.f_values, 'bo-')\naxs[1].set_xlabel('Iteration')\naxs[1].set_ylabel('f(x)')\naxs[1].set_title('f(x) after each iteration')\n\nplt.tight_layout()\nplt.savefig('minimize_scalar.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![minimize_scalar](Scipy-optimization/minimize_scalar.png)\n\n### Brents method on a non-convex function\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 22:01\n\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nimport matplotlib.pyplot as plt\n\n\ndef f(x):\n    return np.sin(5*x) * (1 - np.tanh(x**2))\n\n\ndef f_with_callback(x):\n    f_with_callback.f_values.append(f(x))\n    return f(x)\n\n\nf_with_callback.f_values = []\n\n# Run optimization\nres = minimize_scalar(f_with_callback, method='brent')\n\n# Print optimization results\nprint(res)\n\n# Plot function and optimization progress\nx = np.linspace(-2, 2, 1000)\ny = f(x)\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot function and global minima\naxs[0].plot(x, y, label='f(x)')\naxs[0].plot(res.x, res.fun, 'ro', label='global minima')\naxs[0].legend()\naxs[0].set_title('Non-convex function with global minima')\n\n# Plot optimization progress\naxs[1].plot(f_with_callback.f_values, 'bo-')\naxs[1].set_xlabel('Iteration')\naxs[1].set_ylabel('f(x)')\naxs[1].set_title('f(x) after each iteration')\n\nplt.tight_layout()\nplt.savefig('minimize_scalar1.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![minimize_scalar1](Scipy-optimization/minimize_scalar1.png)\n\n### Minimizing Rosenbrock Function with Conjugate Gradient (CG) Method\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 22:09\n\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\ndef rosenbrock(x):\n    return (1 - x[0]) ** 2 + 100 * (x[1] - x[0] ** 2) ** 2\n\n\n# Define a callback function to track the function value at each iteration\ndef callback(x):\n    global iterates, f_values\n    iterates.append(x)\n    f_values.append(rosenbrock(x))\n\n\n# Define the starting point for the optimization\nx0 = np.array([-1, 1])\n\n# Minimize the Rosenbrock function using the \"CG\" method and the callback function\niterates = []\nf_values = []\nres = minimize(rosenbrock, x0, method='CG', callback=callback)\n\n# Define a meshgrid for the surface and contour plots\nx = np.linspace(-2, 2, 100)\ny = np.linspace(-1, 3, 100)\nX, Y = np.meshgrid(x, y)\nZ = rosenbrock([X, Y])\n\n# Plot the results\nfig = plt.figure(figsize=(15, 4))\nfig.suptitle('Minimizing Rosenbrock Function with CG Method')\n\n# 3D surface plot\nax1 = fig.add_subplot(131, projection='3d')\nax1.plot_surface(X, Y, Z, cmap='coolwarm', alpha=0.5)\nax1.scatter(res.x[0], res.x[1], rosenbrock(res.x), color='r')\nax1.set_title('3D Surface')\n\n# Contour plot\nax2 = fig.add_subplot(132)\nax2.contourf(X, Y, Z, levels=np.logspace(-1, 3, 10), cmap='coolwarm', alpha=0.5)\nax2.scatter(res.x[0], res.x[1], color='r')\nax2.set_title('Contourf')\n\n# Iteration plot\nax3 = fig.add_subplot(133)\nax3.plot(range(len(f_values)), f_values)\nax3.scatter(range(len(f_values)), f_values, color='r')\nax3.set_xlabel('Iteration')\nax3.set_ylabel('f(x)')\nax3.set_title('Iterations')\n\nplt.tight_layout()\nplt.savefig('minimize_rosenbrock.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n\nplt.show()\n```\n\n![minimize_rosenbrock](Scipy-optimization/minimize_rosenbrock.png)\n\n### Optimization of the Rosenbrock function using various methods\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 23:02\nimport time\n\nimport numpy as np\nfrom scipy.optimize import minimize, differential_evolution, shgo, Bounds, dual_annealing, basinhopping\nimport matplotlib.pyplot as plt\n\n\n# Define the Rosenbrock function\ndef rosenbrock(x):\n    return (1 - x[0]) ** 2 + 100 * (x[1] - x[0] ** 2) ** 2\n\n\n# Define the gradient and hessian of the Rosenbrock function\ndef rosenbrock_grad(x):\n    return np.array([-2 * (1 - x[0]) - 400 * x[0] * (x[1] - x[0] ** 2),\n                     200 * (x[1] - x[0] ** 2)])\n\n\ndef rosenbrock_hess(x):\n    return np.array([[2 - 400 * (x[1] - 3 * x[0] ** 2), -400 * x[0]],\n                     [-400 * x[0], 200]])\n\n\nglobal iterates, f_values\n\n# Define the starting point for the optimization\nx0 = np.array([-1.5, 1])\n\n\n# Define a callback function to track the function value at each iteration\ndef callback(x, convergence=None, *_):\n    # starting point is included in the iterates\n    iterates.append(x)\n    f_values.append(rosenbrock(x))\n\n\n# Run each optimization method and plot the iterations and function values\nmethods = ['Nelder-Mead', 'Powell', 'CG', 'BFGS', 'Newton-CG', 'L-BFGS-B',\n           'TNC', 'SLSQP', 'dogleg', 'trust-ncg', 'trust-krylov', 'trust-exact',\n           'trust-constr', 'differential_evolution', 'shgo', 'dual_annealing']\n\nnum_plots = len(methods)\nnum_cols = 3\nnum_rows = num_plots // num_cols + (num_plots % num_cols > 0)\nfig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 7 * num_rows))\n\nfinal_iterates = []\nfinal_f_values = []\n\n# create a dictionary to store the computing time for each method\ntime_dict = {}\n\nfor i, method in enumerate(methods):\n    print(f\"Running optimization with {method}...\")\n    # time the optimization,ms\n    start = time.time()\n    # append the starting point to the iterates\n    iterates = [x0]\n    f_values = [rosenbrock(x0)]\n\n    if method in ['Nelder-Mead', 'Powell']:\n        res = minimize(rosenbrock, x0, method=method, callback=callback)\n    elif method == 'CG':\n        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback)\n    elif method in ['BFGS', 'L-BFGS-B', 'TNC', 'SLSQP']:\n        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback, options={'disp': False})\n    elif method in ['Newton-CG', 'dogleg', 'trust-ncg', 'trust-krylov', 'trust-exact', 'trust-constr']:\n        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, hess=rosenbrock_hess, callback=callback)\n    elif method == 'differential_evolution':\n        bounds = [(i, i + 2) for i in x0]\n        res = differential_evolution(rosenbrock, bounds, callback=callback)\n    elif method == 'shgo':\n        bounds = [(i, i + 2) for i in x0]\n        res = shgo(rosenbrock, bounds, callback=callback)\n    elif method == 'dual_annealing':\n        res = dual_annealing(rosenbrock, bounds=[(-2, 2), (-1, 3)], callback=callback)\n    elif method == 'basinhopping':\n        bounds = [(i, i + 2) for i in x0]\n        res = basinhopping(rosenbrock, x0, callback=callback, minimizer_kwargs={\"method\": \"BFGS\"})\n\n    final_iterates.append(iterates)\n    final_f_values.append(f_values)\n\n    # time the optimization, ms\n    end = time.time()\n    time_dict[method] = end - start\n\n# Plot the final iterates and function values for each method\nfig, axs = plt.subplots(len(methods), 2, figsize=(15, 7 * len(methods)))\n\n# Remove the empty subplot\nif len(methods) % 2 != 0:\n    fig.delaxes(axs[-1, -1])\n\nfor i, method in enumerate(methods):\n    axs[i, 0].plot(range(len(final_f_values[i])), final_f_values[i])\n    axs[i, 0].scatter(range(len(final_f_values[i])), final_f_values[i], color='b', s=25)\n    axs[i, 0].set_title('Current Optimization Progress with {}'.format(method))\n    axs[i, 0].set_xlabel('Iterations')\n    axs[i, 0].set_ylabel('Function Value')\n\n    delta = 0.025\n    x = np.arange(-2.0, 2.0, delta)\n    y = np.arange(-1.0, 3.0, delta)\n    X, Y = np.meshgrid(x, y)\n\n    Z = rosenbrock([X, Y])\n    cf = axs[i, 1].contourf(X, Y, Z, levels=50, cmap='coolwarm', alpha=0.5)\n    axs[i, 1].plot(*zip(*final_iterates[i]), '-o', label='Optimization Path', color='b')\n    axs[i, 1].scatter(*final_iterates[i][-1], s=150, color='r', label='Final Point')\n    axs[i, 1].scatter(*final_iterates[i][0], s=150, color='g', label='Starting Point')\n    axs[i, 1].set_title('Rosenbrock Function with {}'.format(method))\n    axs[i, 1].set_xlabel('x')\n    axs[i, 1].set_ylabel('y')\n    axs[i, 1].legend()\n    axs[i, 1].text(0.05, 0.65, 'Time: {:.6f} s'.format(time_dict[method]), transform=axs[i, 1].transAxes, fontsize=12,\n                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    plt.colorbar(cf, ax=axs[i, 1])\n\nplt.tight_layout()\nplt.savefig('minimize_rosenbrock_methods.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![minimize_rosenbrock_methods](Scipy-optimization/minimize_rosenbrock_methods.png)\n\n### Reference\n\n1. *Scipy Lecture Notes  Scipy lecture notes*. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\n\n\n\n","source":"_posts/Scipy-optimization.md","raw":"---\nmathjax: true\ntitle: Scipy optimization\ndate: 2023-04-03 19:57:07\ntags:\n  - Scipy\n  - Python\n  - Gradient\n  - Optimization\n---\n\n### Brents method on a quadratic function\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 21:49\n\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return (x - 2) ** 2 + 1\n\ndef f_with_callback(x):\n    f_with_callback.f_values.append(f(x))\n    return f(x)\n\nf_with_callback.f_values = []\n\nres = minimize_scalar(f_with_callback, method='brent')\n\nx = np.linspace(-5, 5, 100)\ny = f(x)\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\naxs[0].plot(x, y, label='f(x)')\naxs[0].plot(res.x, res.fun, 'ro', label='global minima')\naxs[0].legend()\naxs[0].set_title('Quadratic convex function with global minima')\n\naxs[1].plot(f_with_callback.f_values, 'bo-')\naxs[1].set_xlabel('Iteration')\naxs[1].set_ylabel('f(x)')\naxs[1].set_title('f(x) after each iteration')\n\nplt.tight_layout()\nplt.savefig('minimize_scalar.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![minimize_scalar](Scipy-optimization/minimize_scalar.png)\n\n### Brents method on a non-convex function\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 22:01\n\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nimport matplotlib.pyplot as plt\n\n\ndef f(x):\n    return np.sin(5*x) * (1 - np.tanh(x**2))\n\n\ndef f_with_callback(x):\n    f_with_callback.f_values.append(f(x))\n    return f(x)\n\n\nf_with_callback.f_values = []\n\n# Run optimization\nres = minimize_scalar(f_with_callback, method='brent')\n\n# Print optimization results\nprint(res)\n\n# Plot function and optimization progress\nx = np.linspace(-2, 2, 1000)\ny = f(x)\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot function and global minima\naxs[0].plot(x, y, label='f(x)')\naxs[0].plot(res.x, res.fun, 'ro', label='global minima')\naxs[0].legend()\naxs[0].set_title('Non-convex function with global minima')\n\n# Plot optimization progress\naxs[1].plot(f_with_callback.f_values, 'bo-')\naxs[1].set_xlabel('Iteration')\naxs[1].set_ylabel('f(x)')\naxs[1].set_title('f(x) after each iteration')\n\nplt.tight_layout()\nplt.savefig('minimize_scalar1.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![minimize_scalar1](Scipy-optimization/minimize_scalar1.png)\n\n### Minimizing Rosenbrock Function with Conjugate Gradient (CG) Method\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 22:09\n\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\ndef rosenbrock(x):\n    return (1 - x[0]) ** 2 + 100 * (x[1] - x[0] ** 2) ** 2\n\n\n# Define a callback function to track the function value at each iteration\ndef callback(x):\n    global iterates, f_values\n    iterates.append(x)\n    f_values.append(rosenbrock(x))\n\n\n# Define the starting point for the optimization\nx0 = np.array([-1, 1])\n\n# Minimize the Rosenbrock function using the \"CG\" method and the callback function\niterates = []\nf_values = []\nres = minimize(rosenbrock, x0, method='CG', callback=callback)\n\n# Define a meshgrid for the surface and contour plots\nx = np.linspace(-2, 2, 100)\ny = np.linspace(-1, 3, 100)\nX, Y = np.meshgrid(x, y)\nZ = rosenbrock([X, Y])\n\n# Plot the results\nfig = plt.figure(figsize=(15, 4))\nfig.suptitle('Minimizing Rosenbrock Function with CG Method')\n\n# 3D surface plot\nax1 = fig.add_subplot(131, projection='3d')\nax1.plot_surface(X, Y, Z, cmap='coolwarm', alpha=0.5)\nax1.scatter(res.x[0], res.x[1], rosenbrock(res.x), color='r')\nax1.set_title('3D Surface')\n\n# Contour plot\nax2 = fig.add_subplot(132)\nax2.contourf(X, Y, Z, levels=np.logspace(-1, 3, 10), cmap='coolwarm', alpha=0.5)\nax2.scatter(res.x[0], res.x[1], color='r')\nax2.set_title('Contourf')\n\n# Iteration plot\nax3 = fig.add_subplot(133)\nax3.plot(range(len(f_values)), f_values)\nax3.scatter(range(len(f_values)), f_values, color='r')\nax3.set_xlabel('Iteration')\nax3.set_ylabel('f(x)')\nax3.set_title('Iterations')\n\nplt.tight_layout()\nplt.savefig('minimize_rosenbrock.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n\nplt.show()\n```\n\n![minimize_rosenbrock](Scipy-optimization/minimize_rosenbrock.png)\n\n### Optimization of the Rosenbrock function using various methods\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/3/23 23:02\nimport time\n\nimport numpy as np\nfrom scipy.optimize import minimize, differential_evolution, shgo, Bounds, dual_annealing, basinhopping\nimport matplotlib.pyplot as plt\n\n\n# Define the Rosenbrock function\ndef rosenbrock(x):\n    return (1 - x[0]) ** 2 + 100 * (x[1] - x[0] ** 2) ** 2\n\n\n# Define the gradient and hessian of the Rosenbrock function\ndef rosenbrock_grad(x):\n    return np.array([-2 * (1 - x[0]) - 400 * x[0] * (x[1] - x[0] ** 2),\n                     200 * (x[1] - x[0] ** 2)])\n\n\ndef rosenbrock_hess(x):\n    return np.array([[2 - 400 * (x[1] - 3 * x[0] ** 2), -400 * x[0]],\n                     [-400 * x[0], 200]])\n\n\nglobal iterates, f_values\n\n# Define the starting point for the optimization\nx0 = np.array([-1.5, 1])\n\n\n# Define a callback function to track the function value at each iteration\ndef callback(x, convergence=None, *_):\n    # starting point is included in the iterates\n    iterates.append(x)\n    f_values.append(rosenbrock(x))\n\n\n# Run each optimization method and plot the iterations and function values\nmethods = ['Nelder-Mead', 'Powell', 'CG', 'BFGS', 'Newton-CG', 'L-BFGS-B',\n           'TNC', 'SLSQP', 'dogleg', 'trust-ncg', 'trust-krylov', 'trust-exact',\n           'trust-constr', 'differential_evolution', 'shgo', 'dual_annealing']\n\nnum_plots = len(methods)\nnum_cols = 3\nnum_rows = num_plots // num_cols + (num_plots % num_cols > 0)\nfig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 7 * num_rows))\n\nfinal_iterates = []\nfinal_f_values = []\n\n# create a dictionary to store the computing time for each method\ntime_dict = {}\n\nfor i, method in enumerate(methods):\n    print(f\"Running optimization with {method}...\")\n    # time the optimization,ms\n    start = time.time()\n    # append the starting point to the iterates\n    iterates = [x0]\n    f_values = [rosenbrock(x0)]\n\n    if method in ['Nelder-Mead', 'Powell']:\n        res = minimize(rosenbrock, x0, method=method, callback=callback)\n    elif method == 'CG':\n        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback)\n    elif method in ['BFGS', 'L-BFGS-B', 'TNC', 'SLSQP']:\n        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback, options={'disp': False})\n    elif method in ['Newton-CG', 'dogleg', 'trust-ncg', 'trust-krylov', 'trust-exact', 'trust-constr']:\n        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, hess=rosenbrock_hess, callback=callback)\n    elif method == 'differential_evolution':\n        bounds = [(i, i + 2) for i in x0]\n        res = differential_evolution(rosenbrock, bounds, callback=callback)\n    elif method == 'shgo':\n        bounds = [(i, i + 2) for i in x0]\n        res = shgo(rosenbrock, bounds, callback=callback)\n    elif method == 'dual_annealing':\n        res = dual_annealing(rosenbrock, bounds=[(-2, 2), (-1, 3)], callback=callback)\n    elif method == 'basinhopping':\n        bounds = [(i, i + 2) for i in x0]\n        res = basinhopping(rosenbrock, x0, callback=callback, minimizer_kwargs={\"method\": \"BFGS\"})\n\n    final_iterates.append(iterates)\n    final_f_values.append(f_values)\n\n    # time the optimization, ms\n    end = time.time()\n    time_dict[method] = end - start\n\n# Plot the final iterates and function values for each method\nfig, axs = plt.subplots(len(methods), 2, figsize=(15, 7 * len(methods)))\n\n# Remove the empty subplot\nif len(methods) % 2 != 0:\n    fig.delaxes(axs[-1, -1])\n\nfor i, method in enumerate(methods):\n    axs[i, 0].plot(range(len(final_f_values[i])), final_f_values[i])\n    axs[i, 0].scatter(range(len(final_f_values[i])), final_f_values[i], color='b', s=25)\n    axs[i, 0].set_title('Current Optimization Progress with {}'.format(method))\n    axs[i, 0].set_xlabel('Iterations')\n    axs[i, 0].set_ylabel('Function Value')\n\n    delta = 0.025\n    x = np.arange(-2.0, 2.0, delta)\n    y = np.arange(-1.0, 3.0, delta)\n    X, Y = np.meshgrid(x, y)\n\n    Z = rosenbrock([X, Y])\n    cf = axs[i, 1].contourf(X, Y, Z, levels=50, cmap='coolwarm', alpha=0.5)\n    axs[i, 1].plot(*zip(*final_iterates[i]), '-o', label='Optimization Path', color='b')\n    axs[i, 1].scatter(*final_iterates[i][-1], s=150, color='r', label='Final Point')\n    axs[i, 1].scatter(*final_iterates[i][0], s=150, color='g', label='Starting Point')\n    axs[i, 1].set_title('Rosenbrock Function with {}'.format(method))\n    axs[i, 1].set_xlabel('x')\n    axs[i, 1].set_ylabel('y')\n    axs[i, 1].legend()\n    axs[i, 1].text(0.05, 0.65, 'Time: {:.6f} s'.format(time_dict[method]), transform=axs[i, 1].transAxes, fontsize=12,\n                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    plt.colorbar(cf, ax=axs[i, 1])\n\nplt.tight_layout()\nplt.savefig('minimize_rosenbrock_methods.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\nplt.show()\n```\n\n![minimize_rosenbrock_methods](Scipy-optimization/minimize_rosenbrock_methods.png)\n\n### Reference\n\n1. *Scipy Lecture Notes  Scipy lecture notes*. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\n\n\n\n","slug":"Scipy-optimization","published":1,"updated":"2023-04-07T02:43:50.824Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73hc0012ozpi2azc1a13","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Brents-method-on-a-quadratic-function\"><a href=\"#Brents-method-on-a-quadratic-function\" class=\"headerlink\" title=\"Brents method on a quadratic function\"></a>Brents method on a quadratic function</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:49</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize_scalar</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (x - <span class=\"number\">2</span>) ** <span class=\"number\">2</span> + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f_with_callback</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    f_with_callback.f_values.append(f(x))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> f(x)</span><br><span class=\"line\"></span><br><span class=\"line\">f_with_callback.f_values = []</span><br><span class=\"line\"></span><br><span class=\"line\">res = minimize_scalar(f_with_callback, method=<span class=\"string\">'brent'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = f(x)</span><br><span class=\"line\"></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(res.x, res.fun, <span class=\"string\">'ro'</span>, label=<span class=\"string\">'global minima'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].legend()</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Quadratic convex function with global minima'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(f_with_callback.f_values, <span class=\"string\">'bo-'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'Iteration'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'f(x) after each iteration'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_scalar.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_scalar\" data-src=\"/2023/04/03/Scipy-optimization/minimize_scalar.png\"></p>\n<h3 id=\"Brents-method-on-a-non-convex-function\"><a href=\"#Brents-method-on-a-non-convex-function\" class=\"headerlink\" title=\"Brents method on a non-convex function\"></a>Brents method on a non-convex function</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 22:01</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize_scalar</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(<span class=\"number\">5</span>*x) * (<span class=\"number\">1</span> - np.tanh(x**<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f_with_callback</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    f_with_callback.f_values.append(f(x))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> f(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">f_with_callback.f_values = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Run optimization</span></span><br><span class=\"line\">res = minimize_scalar(f_with_callback, method=<span class=\"string\">'brent'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print optimization results</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot function and optimization progress</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1000</span>)</span><br><span class=\"line\">y = f(x)</span><br><span class=\"line\"></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot function and global minima</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(res.x, res.fun, <span class=\"string\">'ro'</span>, label=<span class=\"string\">'global minima'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].legend()</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Non-convex function with global minima'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot optimization progress</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(f_with_callback.f_values, <span class=\"string\">'bo-'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'Iteration'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'f(x) after each iteration'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_scalar1.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_scalar1\" data-src=\"/2023/04/03/Scipy-optimization/minimize_scalar1.png\"></p>\n<h3 id=\"Minimizing-Rosenbrock-Function-with-Conjugate-Gradient-CG-Method\"><a href=\"#Minimizing-Rosenbrock-Function-with-Conjugate-Gradient-CG-Method\" class=\"headerlink\" title=\"Minimizing Rosenbrock Function with Conjugate Gradient (CG) Method\"></a>Minimizing Rosenbrock Function with Conjugate Gradient (CG) Method</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 22:09</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"number\">1</span> - x[<span class=\"number\">0</span>]) ** <span class=\"number\">2</span> + <span class=\"number\">100</span> * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a callback function to track the function value at each iteration</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">callback</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">global</span> iterates, f_values</span><br><span class=\"line\">    iterates.append(x)</span><br><span class=\"line\">    f_values.append(rosenbrock(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the starting point for the optimization</span></span><br><span class=\"line\">x0 = np.array([-<span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Minimize the Rosenbrock function using the \"CG\" method and the callback function</span></span><br><span class=\"line\">iterates = []</span><br><span class=\"line\">f_values = []</span><br><span class=\"line\">res = minimize(rosenbrock, x0, method=<span class=\"string\">'CG'</span>, callback=callback)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a meshgrid for the surface and contour plots</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = rosenbrock([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the results</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">15</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">fig.suptitle(<span class=\"string\">'Minimizing Rosenbrock Function with CG Method'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3D surface plot</span></span><br><span class=\"line\">ax1 = fig.add_subplot(<span class=\"number\">131</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax1.plot_surface(X, Y, Z, cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">ax1.scatter(res.x[<span class=\"number\">0</span>], res.x[<span class=\"number\">1</span>], rosenbrock(res.x), color=<span class=\"string\">'r'</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'3D Surface'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Contour plot</span></span><br><span class=\"line\">ax2 = fig.add_subplot(<span class=\"number\">132</span>)</span><br><span class=\"line\">ax2.contourf(X, Y, Z, levels=np.logspace(-<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">10</span>), cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">ax2.scatter(res.x[<span class=\"number\">0</span>], res.x[<span class=\"number\">1</span>], color=<span class=\"string\">'r'</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'Contourf'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Iteration plot</span></span><br><span class=\"line\">ax3 = fig.add_subplot(<span class=\"number\">133</span>)</span><br><span class=\"line\">ax3.plot(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(f_values)), f_values)</span><br><span class=\"line\">ax3.scatter(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(f_values)), f_values, color=<span class=\"string\">'r'</span>)</span><br><span class=\"line\">ax3.set_xlabel(<span class=\"string\">'Iteration'</span>)</span><br><span class=\"line\">ax3.set_ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">ax3.set_title(<span class=\"string\">'Iterations'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_rosenbrock.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_rosenbrock\" data-src=\"/2023/04/03/Scipy-optimization/minimize_rosenbrock.png\"></p>\n<h3 id=\"Optimization-of-the-Rosenbrock-function-using-various-methods\"><a href=\"#Optimization-of-the-Rosenbrock-function-using-various-methods\" class=\"headerlink\" title=\"Optimization of the Rosenbrock function using various methods\"></a>Optimization of the Rosenbrock function using various methods</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 23:02</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize, differential_evolution, shgo, Bounds, dual_annealing, basinhopping</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the Rosenbrock function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"number\">1</span> - x[<span class=\"number\">0</span>]) ** <span class=\"number\">2</span> + <span class=\"number\">100</span> * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the gradient and hessian of the Rosenbrock function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock_grad</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.array([-<span class=\"number\">2</span> * (<span class=\"number\">1</span> - x[<span class=\"number\">0</span>]) - <span class=\"number\">400</span> * x[<span class=\"number\">0</span>] * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>),</span><br><span class=\"line\">                     <span class=\"number\">200</span> * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>)])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock_hess</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.array([[<span class=\"number\">2</span> - <span class=\"number\">400</span> * (x[<span class=\"number\">1</span>] - <span class=\"number\">3</span> * x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>), -<span class=\"number\">400</span> * x[<span class=\"number\">0</span>]],</span><br><span class=\"line\">                     [-<span class=\"number\">400</span> * x[<span class=\"number\">0</span>], <span class=\"number\">200</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">global</span> iterates, f_values</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the starting point for the optimization</span></span><br><span class=\"line\">x0 = np.array([-<span class=\"number\">1.5</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a callback function to track the function value at each iteration</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">callback</span>(<span class=\"params\">x, convergence=<span class=\"literal\">None</span>, *_</span>):</span><br><span class=\"line\">    <span class=\"comment\"># starting point is included in the iterates</span></span><br><span class=\"line\">    iterates.append(x)</span><br><span class=\"line\">    f_values.append(rosenbrock(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Run each optimization method and plot the iterations and function values</span></span><br><span class=\"line\">methods = [<span class=\"string\">'Nelder-Mead'</span>, <span class=\"string\">'Powell'</span>, <span class=\"string\">'CG'</span>, <span class=\"string\">'BFGS'</span>, <span class=\"string\">'Newton-CG'</span>, <span class=\"string\">'L-BFGS-B'</span>,</span><br><span class=\"line\">           <span class=\"string\">'TNC'</span>, <span class=\"string\">'SLSQP'</span>, <span class=\"string\">'dogleg'</span>, <span class=\"string\">'trust-ncg'</span>, <span class=\"string\">'trust-krylov'</span>, <span class=\"string\">'trust-exact'</span>,</span><br><span class=\"line\">           <span class=\"string\">'trust-constr'</span>, <span class=\"string\">'differential_evolution'</span>, <span class=\"string\">'shgo'</span>, <span class=\"string\">'dual_annealing'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">num_plots = <span class=\"built_in\">len</span>(methods)</span><br><span class=\"line\">num_cols = <span class=\"number\">3</span></span><br><span class=\"line\">num_rows = num_plots // num_cols + (num_plots % num_cols &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">fig, axs = plt.subplots(num_rows, num_cols, figsize=(<span class=\"number\">15</span>, <span class=\"number\">7</span> * num_rows))</span><br><span class=\"line\"></span><br><span class=\"line\">final_iterates = []</span><br><span class=\"line\">final_f_values = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create a dictionary to store the computing time for each method</span></span><br><span class=\"line\">time_dict = {}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, method <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(methods):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f\"Running optimization with <span class=\"subst\">{method}</span>...\"</span>)</span><br><span class=\"line\">    <span class=\"comment\"># time the optimization,ms</span></span><br><span class=\"line\">    start = time.time()</span><br><span class=\"line\">    <span class=\"comment\"># append the starting point to the iterates</span></span><br><span class=\"line\">    iterates = [x0]</span><br><span class=\"line\">    f_values = [rosenbrock(x0)]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> method <span class=\"keyword\">in</span> [<span class=\"string\">'Nelder-Mead'</span>, <span class=\"string\">'Powell'</span>]:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'CG'</span>:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method <span class=\"keyword\">in</span> [<span class=\"string\">'BFGS'</span>, <span class=\"string\">'L-BFGS-B'</span>, <span class=\"string\">'TNC'</span>, <span class=\"string\">'SLSQP'</span>]:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback, options={<span class=\"string\">'disp'</span>: <span class=\"literal\">False</span>})</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method <span class=\"keyword\">in</span> [<span class=\"string\">'Newton-CG'</span>, <span class=\"string\">'dogleg'</span>, <span class=\"string\">'trust-ncg'</span>, <span class=\"string\">'trust-krylov'</span>, <span class=\"string\">'trust-exact'</span>, <span class=\"string\">'trust-constr'</span>]:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, hess=rosenbrock_hess, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'differential_evolution'</span>:</span><br><span class=\"line\">        bounds = [(i, i + <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x0]</span><br><span class=\"line\">        res = differential_evolution(rosenbrock, bounds, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'shgo'</span>:</span><br><span class=\"line\">        bounds = [(i, i + <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x0]</span><br><span class=\"line\">        res = shgo(rosenbrock, bounds, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'dual_annealing'</span>:</span><br><span class=\"line\">        res = dual_annealing(rosenbrock, bounds=[(-<span class=\"number\">2</span>, <span class=\"number\">2</span>), (-<span class=\"number\">1</span>, <span class=\"number\">3</span>)], callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'basinhopping'</span>:</span><br><span class=\"line\">        bounds = [(i, i + <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x0]</span><br><span class=\"line\">        res = basinhopping(rosenbrock, x0, callback=callback, minimizer_kwargs={<span class=\"string\">\"method\"</span>: <span class=\"string\">\"BFGS\"</span>})</span><br><span class=\"line\"></span><br><span class=\"line\">    final_iterates.append(iterates)</span><br><span class=\"line\">    final_f_values.append(f_values)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># time the optimization, ms</span></span><br><span class=\"line\">    end = time.time()</span><br><span class=\"line\">    time_dict[method] = end - start</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the final iterates and function values for each method</span></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"built_in\">len</span>(methods), <span class=\"number\">2</span>, figsize=(<span class=\"number\">15</span>, <span class=\"number\">7</span> * <span class=\"built_in\">len</span>(methods)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Remove the empty subplot</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(methods) % <span class=\"number\">2</span> != <span class=\"number\">0</span>:</span><br><span class=\"line\">    fig.delaxes(axs[-<span class=\"number\">1</span>, -<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, method <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(methods):</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].plot(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(final_f_values[i])), final_f_values[i])</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].scatter(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(final_f_values[i])), final_f_values[i], color=<span class=\"string\">'b'</span>, s=<span class=\"number\">25</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].set_title(<span class=\"string\">'Current Optimization Progress with {}'</span>.<span class=\"built_in\">format</span>(method))</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'Iterations'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'Function Value'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    delta = <span class=\"number\">0.025</span></span><br><span class=\"line\">    x = np.arange(-<span class=\"number\">2.0</span>, <span class=\"number\">2.0</span>, delta)</span><br><span class=\"line\">    y = np.arange(-<span class=\"number\">1.0</span>, <span class=\"number\">3.0</span>, delta)</span><br><span class=\"line\">    X, Y = np.meshgrid(x, y)</span><br><span class=\"line\"></span><br><span class=\"line\">    Z = rosenbrock([X, Y])</span><br><span class=\"line\">    cf = axs[i, <span class=\"number\">1</span>].contourf(X, Y, Z, levels=<span class=\"number\">50</span>, cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].plot(*<span class=\"built_in\">zip</span>(*final_iterates[i]), <span class=\"string\">'-o'</span>, label=<span class=\"string\">'Optimization Path'</span>, color=<span class=\"string\">'b'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].scatter(*final_iterates[i][-<span class=\"number\">1</span>], s=<span class=\"number\">150</span>, color=<span class=\"string\">'r'</span>, label=<span class=\"string\">'Final Point'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].scatter(*final_iterates[i][<span class=\"number\">0</span>], s=<span class=\"number\">150</span>, color=<span class=\"string\">'g'</span>, label=<span class=\"string\">'Starting Point'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].set_title(<span class=\"string\">'Rosenbrock Function with {}'</span>.<span class=\"built_in\">format</span>(method))</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].legend()</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].text(<span class=\"number\">0.05</span>, <span class=\"number\">0.65</span>, <span class=\"string\">'Time: {:.6f} s'</span>.<span class=\"built_in\">format</span>(time_dict[method]), transform=axs[i, <span class=\"number\">1</span>].transAxes, fontsize=<span class=\"number\">12</span>,</span><br><span class=\"line\">                   verticalalignment=<span class=\"string\">'top'</span>, bbox=<span class=\"built_in\">dict</span>(boxstyle=<span class=\"string\">'round'</span>, facecolor=<span class=\"string\">'wheat'</span>, alpha=<span class=\"number\">0.5</span>))</span><br><span class=\"line\">    plt.colorbar(cf, ax=axs[i, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_rosenbrock_methods.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_rosenbrock_methods\" data-src=\"/2023/04/03/Scipy-optimization/minimize_rosenbrock_methods.png\"></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>Scipy Lecture Notes  Scipy lecture notes</em>. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. <a href=\"https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\">https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/03/Differential-equations/","2023/03/28/Functions-Plot/","2023/04/03/Functions/","2023/03/28/Gradient-descend-for-linear-regression/"],"length":1218,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Brents-method-on-a-quadratic-function\"><a href=\"#Brents-method-on-a-quadratic-function\" class=\"headerlink\" title=\"Brents method on a quadratic function\"></a>Brents method on a quadratic function</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 21:49</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize_scalar</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (x - <span class=\"number\">2</span>) ** <span class=\"number\">2</span> + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f_with_callback</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    f_with_callback.f_values.append(f(x))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> f(x)</span><br><span class=\"line\"></span><br><span class=\"line\">f_with_callback.f_values = []</span><br><span class=\"line\"></span><br><span class=\"line\">res = minimize_scalar(f_with_callback, method=<span class=\"string\">'brent'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = f(x)</span><br><span class=\"line\"></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(res.x, res.fun, <span class=\"string\">'ro'</span>, label=<span class=\"string\">'global minima'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].legend()</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Quadratic convex function with global minima'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(f_with_callback.f_values, <span class=\"string\">'bo-'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'Iteration'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'f(x) after each iteration'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_scalar.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_scalar\" data-src=\"/2023/04/03/Scipy-optimization/minimize_scalar.png\"></p>\n<h3 id=\"Brents-method-on-a-non-convex-function\"><a href=\"#Brents-method-on-a-non-convex-function\" class=\"headerlink\" title=\"Brents method on a non-convex function\"></a>Brents method on a non-convex function</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 22:01</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize_scalar</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.sin(<span class=\"number\">5</span>*x) * (<span class=\"number\">1</span> - np.tanh(x**<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">f_with_callback</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    f_with_callback.f_values.append(f(x))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> f(x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">f_with_callback.f_values = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Run optimization</span></span><br><span class=\"line\">res = minimize_scalar(f_with_callback, method=<span class=\"string\">'brent'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Print optimization results</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(res)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot function and optimization progress</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1000</span>)</span><br><span class=\"line\">y = f(x)</span><br><span class=\"line\"></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot function and global minima</span></span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(x, y, label=<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].plot(res.x, res.fun, <span class=\"string\">'ro'</span>, label=<span class=\"string\">'global minima'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].legend()</span><br><span class=\"line\">axs[<span class=\"number\">0</span>].set_title(<span class=\"string\">'Non-convex function with global minima'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot optimization progress</span></span><br><span class=\"line\">axs[<span class=\"number\">1</span>].plot(f_with_callback.f_values, <span class=\"string\">'bo-'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'Iteration'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">axs[<span class=\"number\">1</span>].set_title(<span class=\"string\">'f(x) after each iteration'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_scalar1.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_scalar1\" data-src=\"/2023/04/03/Scipy-optimization/minimize_scalar1.png\"></p>\n<h3 id=\"Minimizing-Rosenbrock-Function-with-Conjugate-Gradient-CG-Method\"><a href=\"#Minimizing-Rosenbrock-Function-with-Conjugate-Gradient-CG-Method\" class=\"headerlink\" title=\"Minimizing Rosenbrock Function with Conjugate Gradient (CG) Method\"></a>Minimizing Rosenbrock Function with Conjugate Gradient (CG) Method</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 22:09</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"number\">1</span> - x[<span class=\"number\">0</span>]) ** <span class=\"number\">2</span> + <span class=\"number\">100</span> * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a callback function to track the function value at each iteration</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">callback</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">global</span> iterates, f_values</span><br><span class=\"line\">    iterates.append(x)</span><br><span class=\"line\">    f_values.append(rosenbrock(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the starting point for the optimization</span></span><br><span class=\"line\">x0 = np.array([-<span class=\"number\">1</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Minimize the Rosenbrock function using the \"CG\" method and the callback function</span></span><br><span class=\"line\">iterates = []</span><br><span class=\"line\">f_values = []</span><br><span class=\"line\">res = minimize(rosenbrock, x0, method=<span class=\"string\">'CG'</span>, callback=callback)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a meshgrid for the surface and contour plots</span></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">y = np.linspace(-<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">100</span>)</span><br><span class=\"line\">X, Y = np.meshgrid(x, y)</span><br><span class=\"line\">Z = rosenbrock([X, Y])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the results</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">15</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">fig.suptitle(<span class=\"string\">'Minimizing Rosenbrock Function with CG Method'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3D surface plot</span></span><br><span class=\"line\">ax1 = fig.add_subplot(<span class=\"number\">131</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax1.plot_surface(X, Y, Z, cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">ax1.scatter(res.x[<span class=\"number\">0</span>], res.x[<span class=\"number\">1</span>], rosenbrock(res.x), color=<span class=\"string\">'r'</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'3D Surface'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Contour plot</span></span><br><span class=\"line\">ax2 = fig.add_subplot(<span class=\"number\">132</span>)</span><br><span class=\"line\">ax2.contourf(X, Y, Z, levels=np.logspace(-<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">10</span>), cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">ax2.scatter(res.x[<span class=\"number\">0</span>], res.x[<span class=\"number\">1</span>], color=<span class=\"string\">'r'</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'Contourf'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Iteration plot</span></span><br><span class=\"line\">ax3 = fig.add_subplot(<span class=\"number\">133</span>)</span><br><span class=\"line\">ax3.plot(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(f_values)), f_values)</span><br><span class=\"line\">ax3.scatter(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(f_values)), f_values, color=<span class=\"string\">'r'</span>)</span><br><span class=\"line\">ax3.set_xlabel(<span class=\"string\">'Iteration'</span>)</span><br><span class=\"line\">ax3.set_ylabel(<span class=\"string\">'f(x)'</span>)</span><br><span class=\"line\">ax3.set_title(<span class=\"string\">'Iterations'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_rosenbrock.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_rosenbrock\" data-src=\"/2023/04/03/Scipy-optimization/minimize_rosenbrock.png\"></p>\n<h3 id=\"Optimization-of-the-Rosenbrock-function-using-various-methods\"><a href=\"#Optimization-of-the-Rosenbrock-function-using-various-methods\" class=\"headerlink\" title=\"Optimization of the Rosenbrock function using various methods\"></a>Optimization of the Rosenbrock function using various methods</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/3/23 23:02</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.optimize <span class=\"keyword\">import</span> minimize, differential_evolution, shgo, Bounds, dual_annealing, basinhopping</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the Rosenbrock function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"number\">1</span> - x[<span class=\"number\">0</span>]) ** <span class=\"number\">2</span> + <span class=\"number\">100</span> * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the gradient and hessian of the Rosenbrock function</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock_grad</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.array([-<span class=\"number\">2</span> * (<span class=\"number\">1</span> - x[<span class=\"number\">0</span>]) - <span class=\"number\">400</span> * x[<span class=\"number\">0</span>] * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>),</span><br><span class=\"line\">                     <span class=\"number\">200</span> * (x[<span class=\"number\">1</span>] - x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>)])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rosenbrock_hess</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.array([[<span class=\"number\">2</span> - <span class=\"number\">400</span> * (x[<span class=\"number\">1</span>] - <span class=\"number\">3</span> * x[<span class=\"number\">0</span>] ** <span class=\"number\">2</span>), -<span class=\"number\">400</span> * x[<span class=\"number\">0</span>]],</span><br><span class=\"line\">                     [-<span class=\"number\">400</span> * x[<span class=\"number\">0</span>], <span class=\"number\">200</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">global</span> iterates, f_values</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the starting point for the optimization</span></span><br><span class=\"line\">x0 = np.array([-<span class=\"number\">1.5</span>, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define a callback function to track the function value at each iteration</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">callback</span>(<span class=\"params\">x, convergence=<span class=\"literal\">None</span>, *_</span>):</span><br><span class=\"line\">    <span class=\"comment\"># starting point is included in the iterates</span></span><br><span class=\"line\">    iterates.append(x)</span><br><span class=\"line\">    f_values.append(rosenbrock(x))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Run each optimization method and plot the iterations and function values</span></span><br><span class=\"line\">methods = [<span class=\"string\">'Nelder-Mead'</span>, <span class=\"string\">'Powell'</span>, <span class=\"string\">'CG'</span>, <span class=\"string\">'BFGS'</span>, <span class=\"string\">'Newton-CG'</span>, <span class=\"string\">'L-BFGS-B'</span>,</span><br><span class=\"line\">           <span class=\"string\">'TNC'</span>, <span class=\"string\">'SLSQP'</span>, <span class=\"string\">'dogleg'</span>, <span class=\"string\">'trust-ncg'</span>, <span class=\"string\">'trust-krylov'</span>, <span class=\"string\">'trust-exact'</span>,</span><br><span class=\"line\">           <span class=\"string\">'trust-constr'</span>, <span class=\"string\">'differential_evolution'</span>, <span class=\"string\">'shgo'</span>, <span class=\"string\">'dual_annealing'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">num_plots = <span class=\"built_in\">len</span>(methods)</span><br><span class=\"line\">num_cols = <span class=\"number\">3</span></span><br><span class=\"line\">num_rows = num_plots // num_cols + (num_plots % num_cols &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">fig, axs = plt.subplots(num_rows, num_cols, figsize=(<span class=\"number\">15</span>, <span class=\"number\">7</span> * num_rows))</span><br><span class=\"line\"></span><br><span class=\"line\">final_iterates = []</span><br><span class=\"line\">final_f_values = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># create a dictionary to store the computing time for each method</span></span><br><span class=\"line\">time_dict = {}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, method <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(methods):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f\"Running optimization with <span class=\"subst\">{method}</span>...\"</span>)</span><br><span class=\"line\">    <span class=\"comment\"># time the optimization,ms</span></span><br><span class=\"line\">    start = time.time()</span><br><span class=\"line\">    <span class=\"comment\"># append the starting point to the iterates</span></span><br><span class=\"line\">    iterates = [x0]</span><br><span class=\"line\">    f_values = [rosenbrock(x0)]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> method <span class=\"keyword\">in</span> [<span class=\"string\">'Nelder-Mead'</span>, <span class=\"string\">'Powell'</span>]:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'CG'</span>:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method <span class=\"keyword\">in</span> [<span class=\"string\">'BFGS'</span>, <span class=\"string\">'L-BFGS-B'</span>, <span class=\"string\">'TNC'</span>, <span class=\"string\">'SLSQP'</span>]:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, callback=callback, options={<span class=\"string\">'disp'</span>: <span class=\"literal\">False</span>})</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method <span class=\"keyword\">in</span> [<span class=\"string\">'Newton-CG'</span>, <span class=\"string\">'dogleg'</span>, <span class=\"string\">'trust-ncg'</span>, <span class=\"string\">'trust-krylov'</span>, <span class=\"string\">'trust-exact'</span>, <span class=\"string\">'trust-constr'</span>]:</span><br><span class=\"line\">        res = minimize(rosenbrock, x0, method=method, jac=rosenbrock_grad, hess=rosenbrock_hess, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'differential_evolution'</span>:</span><br><span class=\"line\">        bounds = [(i, i + <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x0]</span><br><span class=\"line\">        res = differential_evolution(rosenbrock, bounds, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'shgo'</span>:</span><br><span class=\"line\">        bounds = [(i, i + <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x0]</span><br><span class=\"line\">        res = shgo(rosenbrock, bounds, callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'dual_annealing'</span>:</span><br><span class=\"line\">        res = dual_annealing(rosenbrock, bounds=[(-<span class=\"number\">2</span>, <span class=\"number\">2</span>), (-<span class=\"number\">1</span>, <span class=\"number\">3</span>)], callback=callback)</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> method == <span class=\"string\">'basinhopping'</span>:</span><br><span class=\"line\">        bounds = [(i, i + <span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> x0]</span><br><span class=\"line\">        res = basinhopping(rosenbrock, x0, callback=callback, minimizer_kwargs={<span class=\"string\">\"method\"</span>: <span class=\"string\">\"BFGS\"</span>})</span><br><span class=\"line\"></span><br><span class=\"line\">    final_iterates.append(iterates)</span><br><span class=\"line\">    final_f_values.append(f_values)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># time the optimization, ms</span></span><br><span class=\"line\">    end = time.time()</span><br><span class=\"line\">    time_dict[method] = end - start</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the final iterates and function values for each method</span></span><br><span class=\"line\">fig, axs = plt.subplots(<span class=\"built_in\">len</span>(methods), <span class=\"number\">2</span>, figsize=(<span class=\"number\">15</span>, <span class=\"number\">7</span> * <span class=\"built_in\">len</span>(methods)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Remove the empty subplot</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(methods) % <span class=\"number\">2</span> != <span class=\"number\">0</span>:</span><br><span class=\"line\">    fig.delaxes(axs[-<span class=\"number\">1</span>, -<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i, method <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(methods):</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].plot(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(final_f_values[i])), final_f_values[i])</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].scatter(<span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(final_f_values[i])), final_f_values[i], color=<span class=\"string\">'b'</span>, s=<span class=\"number\">25</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].set_title(<span class=\"string\">'Current Optimization Progress with {}'</span>.<span class=\"built_in\">format</span>(method))</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].set_xlabel(<span class=\"string\">'Iterations'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">0</span>].set_ylabel(<span class=\"string\">'Function Value'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    delta = <span class=\"number\">0.025</span></span><br><span class=\"line\">    x = np.arange(-<span class=\"number\">2.0</span>, <span class=\"number\">2.0</span>, delta)</span><br><span class=\"line\">    y = np.arange(-<span class=\"number\">1.0</span>, <span class=\"number\">3.0</span>, delta)</span><br><span class=\"line\">    X, Y = np.meshgrid(x, y)</span><br><span class=\"line\"></span><br><span class=\"line\">    Z = rosenbrock([X, Y])</span><br><span class=\"line\">    cf = axs[i, <span class=\"number\">1</span>].contourf(X, Y, Z, levels=<span class=\"number\">50</span>, cmap=<span class=\"string\">'coolwarm'</span>, alpha=<span class=\"number\">0.5</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].plot(*<span class=\"built_in\">zip</span>(*final_iterates[i]), <span class=\"string\">'-o'</span>, label=<span class=\"string\">'Optimization Path'</span>, color=<span class=\"string\">'b'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].scatter(*final_iterates[i][-<span class=\"number\">1</span>], s=<span class=\"number\">150</span>, color=<span class=\"string\">'r'</span>, label=<span class=\"string\">'Final Point'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].scatter(*final_iterates[i][<span class=\"number\">0</span>], s=<span class=\"number\">150</span>, color=<span class=\"string\">'g'</span>, label=<span class=\"string\">'Starting Point'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].set_title(<span class=\"string\">'Rosenbrock Function with {}'</span>.<span class=\"built_in\">format</span>(method))</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].legend()</span><br><span class=\"line\">    axs[i, <span class=\"number\">1</span>].text(<span class=\"number\">0.05</span>, <span class=\"number\">0.65</span>, <span class=\"string\">'Time: {:.6f} s'</span>.<span class=\"built_in\">format</span>(time_dict[method]), transform=axs[i, <span class=\"number\">1</span>].transAxes, fontsize=<span class=\"number\">12</span>,</span><br><span class=\"line\">                   verticalalignment=<span class=\"string\">'top'</span>, bbox=<span class=\"built_in\">dict</span>(boxstyle=<span class=\"string\">'round'</span>, facecolor=<span class=\"string\">'wheat'</span>, alpha=<span class=\"number\">0.5</span>))</span><br><span class=\"line\">    plt.colorbar(cf, ax=axs[i, <span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.tight_layout()</span><br><span class=\"line\">plt.savefig(<span class=\"string\">'minimize_rosenbrock_methods.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0.1</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"minimize_rosenbrock_methods\" data-src=\"/2023/04/03/Scipy-optimization/minimize_rosenbrock_methods.png\"></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>Scipy Lecture Notes  Scipy lecture notes</em>. (n.d.). Scipy Lecture Notes  Scipy Lecture Notes. <a href=\"https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python\">https://scipy-lectures.org/index.html#one-document-to-learn-numerics-science-and-data-with-python</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Sentiment Analysis on Product Reviews","date":"2023-04-01T21:59:48.000Z","_content":"\nThis code performs sentiment analysis on product reviews using several machine learning classifiers, including MLP classifier, Naive Bayes classifier, SVM, Random Forest, Logistic Regression, K-Nearest Neighbors, Decision Tree, AdaBoost, and Gradient Boosting.\n\nThe input data is read from an Excel file, which contains three columns: the index, the comment of the product, and the review of the product (1 means positive review, 0 means negative review). The Chinese comments are tokenized using the jieba library, and the text is vectorized using CountVectorizer.\n\nThe classifiers are trained using the training data, and their accuracy scores are calculated using the test data. The learning curve and confusion matrix are plotted for each classifier. The accuracy scores of all classifiers are printed, and the predicted and actual sentiments of a randomly selected comment are displayed for each classifier.\n\nFinally, the code ranks the classifiers based on their accuracy scores, and saves the learning curve and confusion matrix plots for each classifier as images.\n\nThe input data for this code can be found at https://docs.google.com/spreadsheets/d/1p_Stbv7fXQnvGGz6ofNsl00VKQPt0C6L/edit?usp=sharing.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/23 23:59\n\nimport numpy as np\nimport pandas as pd\nimport jieba\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split, learning_curve\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Generating a random integer between 0 and 100 using numpy\nrs = np.random.RandomState(seed=1)\nrs.randint(0, 100, size=1)\n\n# Reading input data from an excel file\ndata = pd.read_excel('product_review.xlsx', sheet_name='Sheet1', header=0, index_col=0)\n\n# description of the data\n# print('The information about the data is:', data.info())\n# print('The first 5 rows of the data are:', data.head())\n# # 0: index ;1: Comment ;2: Review\n# print('The first column means the index of the data, the second column means the comment of the product, the third column means the review of the product.')\n# # review 1: positive review; review 0: negative review\n# print('The third column means the review of the product, 1 means positive review, 0 means negative review.')\n\n# Using jieba library to tokenize Chinese comments\nwords = [' '.join(jieba.cut(row['Comment'])) for _, row in data.iterrows()]\n\n# Vectorizing the text using CountVectorizer\nvect = CountVectorizer()\nX = vect.fit_transform(words)\n\n# Extracting the target variable\ny = data['Review']\n\n# Splitting the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n\n# Building all classifiers\nmlp = MLPClassifier(hidden_layer_sizes=(64, 64, 32))\nnb_clf = MultinomialNB()\nsvm = SVC(kernel='linear')\nrf = RandomForestClassifier(n_estimators=100)\nlr = LogisticRegression()\nknn = KNeighborsClassifier(n_neighbors=5)\ndt = DecisionTreeClassifier()\nada = AdaBoostClassifier()\ngb = GradientBoostingClassifier()\n\n# Plotting the learning curve for all classifiers\nclassifiers = [mlp, nb_clf, svm, rf, lr, knn, dt, ada]\ntitles = ['MLP classifier model', 'Naive Bayes classifier model', 'SVM', 'Random Forest', 'Logistic Regression',\n          'K-Nearest Neighbors', 'Decision Tree', 'AdaBoost', 'Gradient Boosting']\nscores = []\n\nfor clf, title in zip(classifiers, titles):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n    # Plotting the learning curve\n    train_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, cv=5)\n    train_scores_mean, test_scores_mean = np.mean(train_scores, axis=1), np.mean(test_scores, axis=1)\n    ax1.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n    ax1.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n    ax1.set_xlabel('Training examples')\n    ax1.set_ylabel('Score')\n    ax1.legend(loc='best')\n    ax1.set_title(f'Learning curve for {title}')\n\n    # Plotting the confusion matrix\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, ax=ax2, cmap=plt.cm.Blues, normalize='true')\n    disp.ax_.set_title(f'Confusion matrix for {title}')\n\n    plt.tight_layout()\n    plt.savefig(f'{title}.png')\n    plt.show()\n\n    # Fitting the model to the training data and predicting the target values for the test data\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n\n    # Calculating the accuracy score of the classifier model\n    score = accuracy_score(y_pred, y_test)\n    print(f'The accuracy score of the {title} is:', score)\n    scores.append([title, score])\n\n    # Selecting a random comment from the input data and performing sentiment analysis using the classifier\n    rand_idx = random.randint(0, len(data) - 1)\n    comment = [' '.join(jieba.cut(data.iloc[rand_idx]['Comment']))]\n    print('The selected comment is:', comment[0])\n    X_try = vect.transform(comment)\n    y_pred = clf.predict(X_try.toarray())\n    print(f'The predicted sentiment of the selected comment using {title} is:', y_pred[0])\n    print('The actual sentiment of the selected comment is:', data.iloc[rand_idx]['Review'])\n\nsorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\nprint('Ranking of the classifiers based on accuracy score:')\nfor i, (title, score) in enumerate(sorted_scores):\n    print(f'{i + 1}. {title}: {score:.4f}')\n```\n\n```\n.../Desktop/Sentiment Analysis on Product Reviews/Sentiment Analysis on Product Reviews.py \nBuilding prefix dict from the default dictionary ...\nLoading model from cache /var/folders/vb/bhfltf7s0n5dmrcb5r9s80mw0000gn/T/jieba.cache\nLoading model cost 0.439 seconds.\nPrefix dict has been built successfully.\nThe accuracy score of the MLP classifier model is: 0.9814814814814815\nThe selected comment is:                                \nThe predicted sentiment of the selected comment using MLP classifier model is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the Naive Bayes classifier model is: 0.8888888888888888\nThe selected comment is:                                                                  \nThe predicted sentiment of the selected comment using Naive Bayes classifier model is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the SVM is: 0.9814814814814815\nThe selected comment is:          6s   7                                  \nThe predicted sentiment of the selected comment using SVM is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the Random Forest is: 0.9722222222222222\nThe selected comment is:                       6                            \nThe predicted sentiment of the selected comment using Random Forest is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the Logistic Regression is: 0.9814814814814815\nThe selected comment is:                  64G                \nThe predicted sentiment of the selected comment using Logistic Regression is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the K-Nearest Neighbors is: 0.4537037037037037\nThe selected comment is:       618   \nThe predicted sentiment of the selected comment using K-Nearest Neighbors is: 0\nThe actual sentiment of the selected comment is: 0\nThe accuracy score of the Decision Tree is: 0.9259259259259259\nThe selected comment is:  \nThe predicted sentiment of the selected comment using Decision Tree is: 0\nThe actual sentiment of the selected comment is: 0\nThe accuracy score of the AdaBoost is: 0.9074074074074074\nThe selected comment is:                                       \nThe predicted sentiment of the selected comment using AdaBoost is: 1\nThe actual sentiment of the selected comment is: 1\nRanking of the classifiers based on accuracy score:\n1. MLP classifier model: 0.9815\n2. SVM: 0.9815\n3. Logistic Regression: 0.9815\n4. Random Forest: 0.9722\n5. Decision Tree: 0.9259\n6. AdaBoost: 0.9074\n7. Naive Bayes classifier model: 0.8889\n8. K-Nearest Neighbors: 0.4537\n\nProcess finished with exit code 0\n```\n\n<div style=\"text-align:center\">\n<img src=\"Sentiment-Analysis-on-Product-Reviews/SVM.png\" alt=\"SVM\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/AdaBoost.png\" alt=\"AdaBoost\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Decision%20Tree.png\" alt=\"Decision Tree\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/K-Nearest%20Neighbors.png\" alt=\"K-Nearest Neighbors\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Logistic%20Regression.png\" alt=\"Logistic Regression\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/MLP%20classifier%20model.png\" alt=\"MLP classifier model\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Naive%20Bayes%20classifier%20model.png\" alt=\"Naive Bayes classifier model\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Random%20Forest.png\" alt=\"Random Forest\" style=\"zoom:67%;\" />\n</div>\nA 2x2 confusion matrix is used to evaluate binary classification models that classify data into one of two possible classes. In a 2x2 confusion matrix, the actual class labels are represented by the rows, and the predicted class labels are represented by the columns. The four cells in the matrix represent:\n\n- True Positive (TP): The model predicted the sample to be positive (1), and it actually belongs to the positive class (1).\n- False Positive (FP): The model predicted the sample to be positive (1), but it actually belongs to the negative class (0).\n- False Negative (FN): The model predicted the sample to be negative (0), but it actually belongs to the positive class (1).\n- True Negative (TN): The model predicted the sample to be negative (0), and it actually belongs to the negative class (0).\n\nThe confusion matrix allows us to evaluate the performance of a binary classification model by comparing the predicted class labels to the actual class labels. The TP, FP, FN, and TN values can be used to calculate various metrics such as accuracy, precision, recall, and F1-score.\n\n### Reference\n\n1. *3.4. Validation curves: plotting scores to evaluate models*. (n.d.). Scikit-learn. https://scikit-learn/stable/modules/learning_curve.html\n2. *sklearn.metrics.confusion_matrix*. (n.d.). Scikit-learn. https://scikit-learn/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Sentiment-Analysis-on-Product-Reviews.md","raw":"---\nmathjax: true\ntitle: Sentiment Analysis on Product Reviews\ndate: 2023-04-01 21:59:48\ntags:\n  - Sentiment analysis\n  - MLP classifier\n  - Naive Bayes classifier\n  - SVM\n  - Random Forest\n  - Logistic Regression\n  - K-Nearest Neighbors\n  - Decision Tree\n  - AdaBoost\n  - Gradient Boosting\n---\n\nThis code performs sentiment analysis on product reviews using several machine learning classifiers, including MLP classifier, Naive Bayes classifier, SVM, Random Forest, Logistic Regression, K-Nearest Neighbors, Decision Tree, AdaBoost, and Gradient Boosting.\n\nThe input data is read from an Excel file, which contains three columns: the index, the comment of the product, and the review of the product (1 means positive review, 0 means negative review). The Chinese comments are tokenized using the jieba library, and the text is vectorized using CountVectorizer.\n\nThe classifiers are trained using the training data, and their accuracy scores are calculated using the test data. The learning curve and confusion matrix are plotted for each classifier. The accuracy scores of all classifiers are printed, and the predicted and actual sentiments of a randomly selected comment are displayed for each classifier.\n\nFinally, the code ranks the classifiers based on their accuracy scores, and saves the learning curve and confusion matrix plots for each classifier as images.\n\nThe input data for this code can be found at https://docs.google.com/spreadsheets/d/1p_Stbv7fXQnvGGz6ofNsl00VKQPt0C6L/edit?usp=sharing.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/23 23:59\n\nimport numpy as np\nimport pandas as pd\nimport jieba\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split, learning_curve\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Generating a random integer between 0 and 100 using numpy\nrs = np.random.RandomState(seed=1)\nrs.randint(0, 100, size=1)\n\n# Reading input data from an excel file\ndata = pd.read_excel('product_review.xlsx', sheet_name='Sheet1', header=0, index_col=0)\n\n# description of the data\n# print('The information about the data is:', data.info())\n# print('The first 5 rows of the data are:', data.head())\n# # 0: index ;1: Comment ;2: Review\n# print('The first column means the index of the data, the second column means the comment of the product, the third column means the review of the product.')\n# # review 1: positive review; review 0: negative review\n# print('The third column means the review of the product, 1 means positive review, 0 means negative review.')\n\n# Using jieba library to tokenize Chinese comments\nwords = [' '.join(jieba.cut(row['Comment'])) for _, row in data.iterrows()]\n\n# Vectorizing the text using CountVectorizer\nvect = CountVectorizer()\nX = vect.fit_transform(words)\n\n# Extracting the target variable\ny = data['Review']\n\n# Splitting the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n\n# Building all classifiers\nmlp = MLPClassifier(hidden_layer_sizes=(64, 64, 32))\nnb_clf = MultinomialNB()\nsvm = SVC(kernel='linear')\nrf = RandomForestClassifier(n_estimators=100)\nlr = LogisticRegression()\nknn = KNeighborsClassifier(n_neighbors=5)\ndt = DecisionTreeClassifier()\nada = AdaBoostClassifier()\ngb = GradientBoostingClassifier()\n\n# Plotting the learning curve for all classifiers\nclassifiers = [mlp, nb_clf, svm, rf, lr, knn, dt, ada]\ntitles = ['MLP classifier model', 'Naive Bayes classifier model', 'SVM', 'Random Forest', 'Logistic Regression',\n          'K-Nearest Neighbors', 'Decision Tree', 'AdaBoost', 'Gradient Boosting']\nscores = []\n\nfor clf, title in zip(classifiers, titles):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n    # Plotting the learning curve\n    train_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, cv=5)\n    train_scores_mean, test_scores_mean = np.mean(train_scores, axis=1), np.mean(test_scores, axis=1)\n    ax1.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n    ax1.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n    ax1.set_xlabel('Training examples')\n    ax1.set_ylabel('Score')\n    ax1.legend(loc='best')\n    ax1.set_title(f'Learning curve for {title}')\n\n    # Plotting the confusion matrix\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, ax=ax2, cmap=plt.cm.Blues, normalize='true')\n    disp.ax_.set_title(f'Confusion matrix for {title}')\n\n    plt.tight_layout()\n    plt.savefig(f'{title}.png')\n    plt.show()\n\n    # Fitting the model to the training data and predicting the target values for the test data\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n\n    # Calculating the accuracy score of the classifier model\n    score = accuracy_score(y_pred, y_test)\n    print(f'The accuracy score of the {title} is:', score)\n    scores.append([title, score])\n\n    # Selecting a random comment from the input data and performing sentiment analysis using the classifier\n    rand_idx = random.randint(0, len(data) - 1)\n    comment = [' '.join(jieba.cut(data.iloc[rand_idx]['Comment']))]\n    print('The selected comment is:', comment[0])\n    X_try = vect.transform(comment)\n    y_pred = clf.predict(X_try.toarray())\n    print(f'The predicted sentiment of the selected comment using {title} is:', y_pred[0])\n    print('The actual sentiment of the selected comment is:', data.iloc[rand_idx]['Review'])\n\nsorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\nprint('Ranking of the classifiers based on accuracy score:')\nfor i, (title, score) in enumerate(sorted_scores):\n    print(f'{i + 1}. {title}: {score:.4f}')\n```\n\n```\n.../Desktop/Sentiment Analysis on Product Reviews/Sentiment Analysis on Product Reviews.py \nBuilding prefix dict from the default dictionary ...\nLoading model from cache /var/folders/vb/bhfltf7s0n5dmrcb5r9s80mw0000gn/T/jieba.cache\nLoading model cost 0.439 seconds.\nPrefix dict has been built successfully.\nThe accuracy score of the MLP classifier model is: 0.9814814814814815\nThe selected comment is:                                \nThe predicted sentiment of the selected comment using MLP classifier model is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the Naive Bayes classifier model is: 0.8888888888888888\nThe selected comment is:                                                                  \nThe predicted sentiment of the selected comment using Naive Bayes classifier model is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the SVM is: 0.9814814814814815\nThe selected comment is:          6s   7                                  \nThe predicted sentiment of the selected comment using SVM is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the Random Forest is: 0.9722222222222222\nThe selected comment is:                       6                            \nThe predicted sentiment of the selected comment using Random Forest is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the Logistic Regression is: 0.9814814814814815\nThe selected comment is:                  64G                \nThe predicted sentiment of the selected comment using Logistic Regression is: 1\nThe actual sentiment of the selected comment is: 1\nThe accuracy score of the K-Nearest Neighbors is: 0.4537037037037037\nThe selected comment is:       618   \nThe predicted sentiment of the selected comment using K-Nearest Neighbors is: 0\nThe actual sentiment of the selected comment is: 0\nThe accuracy score of the Decision Tree is: 0.9259259259259259\nThe selected comment is:  \nThe predicted sentiment of the selected comment using Decision Tree is: 0\nThe actual sentiment of the selected comment is: 0\nThe accuracy score of the AdaBoost is: 0.9074074074074074\nThe selected comment is:                                       \nThe predicted sentiment of the selected comment using AdaBoost is: 1\nThe actual sentiment of the selected comment is: 1\nRanking of the classifiers based on accuracy score:\n1. MLP classifier model: 0.9815\n2. SVM: 0.9815\n3. Logistic Regression: 0.9815\n4. Random Forest: 0.9722\n5. Decision Tree: 0.9259\n6. AdaBoost: 0.9074\n7. Naive Bayes classifier model: 0.8889\n8. K-Nearest Neighbors: 0.4537\n\nProcess finished with exit code 0\n```\n\n<div style=\"text-align:center\">\n<img src=\"Sentiment-Analysis-on-Product-Reviews/SVM.png\" alt=\"SVM\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/AdaBoost.png\" alt=\"AdaBoost\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Decision%20Tree.png\" alt=\"Decision Tree\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/K-Nearest%20Neighbors.png\" alt=\"K-Nearest Neighbors\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Logistic%20Regression.png\" alt=\"Logistic Regression\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/MLP%20classifier%20model.png\" alt=\"MLP classifier model\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Naive%20Bayes%20classifier%20model.png\" alt=\"Naive Bayes classifier model\" style=\"zoom:67%;\" />\n<img src=\"Sentiment-Analysis-on-Product-Reviews/Random%20Forest.png\" alt=\"Random Forest\" style=\"zoom:67%;\" />\n</div>\nA 2x2 confusion matrix is used to evaluate binary classification models that classify data into one of two possible classes. In a 2x2 confusion matrix, the actual class labels are represented by the rows, and the predicted class labels are represented by the columns. The four cells in the matrix represent:\n\n- True Positive (TP): The model predicted the sample to be positive (1), and it actually belongs to the positive class (1).\n- False Positive (FP): The model predicted the sample to be positive (1), but it actually belongs to the negative class (0).\n- False Negative (FN): The model predicted the sample to be negative (0), but it actually belongs to the positive class (1).\n- True Negative (TN): The model predicted the sample to be negative (0), and it actually belongs to the negative class (0).\n\nThe confusion matrix allows us to evaluate the performance of a binary classification model by comparing the predicted class labels to the actual class labels. The TP, FP, FN, and TN values can be used to calculate various metrics such as accuracy, precision, recall, and F1-score.\n\n### Reference\n\n1. *3.4. Validation curves: plotting scores to evaluate models*. (n.d.). Scikit-learn. https://scikit-learn/stable/modules/learning_curve.html\n2. *sklearn.metrics.confusion_matrix*. (n.d.). Scikit-learn. https://scikit-learn/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Sentiment-Analysis-on-Product-Reviews","published":1,"updated":"2023-04-07T02:43:50.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73he0014ozpi17lf79un","content":"<html><head></head><body></body></html><html><head></head><body><p>This code performs sentiment analysis on product reviews using several machine learning classifiers, including MLP classifier, Naive Bayes classifier, SVM, Random Forest, Logistic Regression, K-Nearest Neighbors, Decision Tree, AdaBoost, and Gradient Boosting.</p>\n<p>The input data is read from an Excel file, which contains three columns: the index, the comment of the product, and the review of the product (1 means positive review, 0 means negative review). The Chinese comments are tokenized using the jieba library, and the text is vectorized using CountVectorizer.</p>\n<p>The classifiers are trained using the training data, and their accuracy scores are calculated using the test data. The learning curve and confusion matrix are plotted for each classifier. The accuracy scores of all classifiers are printed, and the predicted and actual sentiments of a randomly selected comment are displayed for each classifier.</p>\n<p>Finally, the code ranks the classifiers based on their accuracy scores, and saves the learning curve and confusion matrix plots for each classifier as images.</p>\n<p>The input data for this code can be found at <a href=\"https://docs.google.com/spreadsheets/d/1p_Stbv7fXQnvGGz6ofNsl00VKQPt0C6L/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1p_Stbv7fXQnvGGz6ofNsl00VKQPt0C6L/edit?usp=sharing</a>.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/23 23:59</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> jieba</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.feature_extraction.text <span class=\"keyword\">import</span> CountVectorizer</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split, learning_curve</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neural_network <span class=\"keyword\">import</span> MLPClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score, ConfusionMatrixDisplay, confusion_matrix</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generating a random integer between 0 and 100 using numpy</span></span><br><span class=\"line\">rs = np.random.RandomState(seed=<span class=\"number\">1</span>)</span><br><span class=\"line\">rs.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, size=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Reading input data from an excel file</span></span><br><span class=\"line\">data = pd.read_excel(<span class=\"string\">'product_review.xlsx'</span>, sheet_name=<span class=\"string\">'Sheet1'</span>, header=<span class=\"number\">0</span>, index_col=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># description of the data</span></span><br><span class=\"line\"><span class=\"comment\"># print('The information about the data is:', data.info())</span></span><br><span class=\"line\"><span class=\"comment\"># print('The first 5 rows of the data are:', data.head())</span></span><br><span class=\"line\"><span class=\"comment\"># # 0: index ;1: Comment ;2: Review</span></span><br><span class=\"line\"><span class=\"comment\"># print('The first column means the index of the data, the second column means the comment of the product, the third column means the review of the product.')</span></span><br><span class=\"line\"><span class=\"comment\"># # review 1: positive review; review 0: negative review</span></span><br><span class=\"line\"><span class=\"comment\"># print('The third column means the review of the product, 1 means positive review, 0 means negative review.')</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Using jieba library to tokenize Chinese comments</span></span><br><span class=\"line\">words = [<span class=\"string\">' '</span>.join(jieba.cut(row[<span class=\"string\">'Comment'</span>])) <span class=\"keyword\">for</span> _, row <span class=\"keyword\">in</span> data.iterrows()]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Vectorizing the text using CountVectorizer</span></span><br><span class=\"line\">vect = CountVectorizer()</span><br><span class=\"line\">X = vect.fit_transform(words)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Extracting the target variable</span></span><br><span class=\"line\">y = data[<span class=\"string\">'Review'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Splitting the data into train and test sets</span></span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"number\">0.1</span>, random_state=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Building all classifiers</span></span><br><span class=\"line\">mlp = MLPClassifier(hidden_layer_sizes=(<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"number\">32</span>))</span><br><span class=\"line\">nb_clf = MultinomialNB()</span><br><span class=\"line\">svm = SVC(kernel=<span class=\"string\">'linear'</span>)</span><br><span class=\"line\">rf = RandomForestClassifier(n_estimators=<span class=\"number\">100</span>)</span><br><span class=\"line\">lr = LogisticRegression()</span><br><span class=\"line\">knn = KNeighborsClassifier(n_neighbors=<span class=\"number\">5</span>)</span><br><span class=\"line\">dt = DecisionTreeClassifier()</span><br><span class=\"line\">ada = AdaBoostClassifier()</span><br><span class=\"line\">gb = GradientBoostingClassifier()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plotting the learning curve for all classifiers</span></span><br><span class=\"line\">classifiers = [mlp, nb_clf, svm, rf, lr, knn, dt, ada]</span><br><span class=\"line\">titles = [<span class=\"string\">'MLP classifier model'</span>, <span class=\"string\">'Naive Bayes classifier model'</span>, <span class=\"string\">'SVM'</span>, <span class=\"string\">'Random Forest'</span>, <span class=\"string\">'Logistic Regression'</span>,</span><br><span class=\"line\">          <span class=\"string\">'K-Nearest Neighbors'</span>, <span class=\"string\">'Decision Tree'</span>, <span class=\"string\">'AdaBoost'</span>, <span class=\"string\">'Gradient Boosting'</span>]</span><br><span class=\"line\">scores = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> clf, title <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(classifiers, titles):</span><br><span class=\"line\">    fig, (ax1, ax2) = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">    <span class=\"comment\"># Plotting the learning curve</span></span><br><span class=\"line\">    train_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, cv=<span class=\"number\">5</span>)</span><br><span class=\"line\">    train_scores_mean, test_scores_mean = np.mean(train_scores, axis=<span class=\"number\">1</span>), np.mean(test_scores, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    ax1.plot(train_sizes, train_scores_mean, <span class=\"string\">'o-'</span>, color=<span class=\"string\">'r'</span>, label=<span class=\"string\">'Training score'</span>)</span><br><span class=\"line\">    ax1.plot(train_sizes, test_scores_mean, <span class=\"string\">'o-'</span>, color=<span class=\"string\">'g'</span>, label=<span class=\"string\">'Cross-validation score'</span>)</span><br><span class=\"line\">    ax1.set_xlabel(<span class=\"string\">'Training examples'</span>)</span><br><span class=\"line\">    ax1.set_ylabel(<span class=\"string\">'Score'</span>)</span><br><span class=\"line\">    ax1.legend(loc=<span class=\"string\">'best'</span>)</span><br><span class=\"line\">    ax1.set_title(<span class=\"string\">f'Learning curve for <span class=\"subst\">{title}</span>'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Plotting the confusion matrix</span></span><br><span class=\"line\">    clf.fit(X_train, y_train)</span><br><span class=\"line\">    y_pred = clf.predict(X_test)</span><br><span class=\"line\">    cm = confusion_matrix(y_test, y_pred)</span><br><span class=\"line\">    disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, ax=ax2, cmap=plt.cm.Blues, normalize=<span class=\"string\">'true'</span>)</span><br><span class=\"line\">    disp.ax_.set_title(<span class=\"string\">f'Confusion matrix for <span class=\"subst\">{title}</span>'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.tight_layout()</span><br><span class=\"line\">    plt.savefig(<span class=\"string\">f'<span class=\"subst\">{title}</span>.png'</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Fitting the model to the training data and predicting the target values for the test data</span></span><br><span class=\"line\">    clf.fit(X_train, y_train)</span><br><span class=\"line\">    y_pred = clf.predict(X_test)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Calculating the accuracy score of the classifier model</span></span><br><span class=\"line\">    score = accuracy_score(y_pred, y_test)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'The accuracy score of the <span class=\"subst\">{title}</span> is:'</span>, score)</span><br><span class=\"line\">    scores.append([title, score])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Selecting a random comment from the input data and performing sentiment analysis using the classifier</span></span><br><span class=\"line\">    rand_idx = random.randint(<span class=\"number\">0</span>, <span class=\"built_in\">len</span>(data) - <span class=\"number\">1</span>)</span><br><span class=\"line\">    comment = [<span class=\"string\">' '</span>.join(jieba.cut(data.iloc[rand_idx][<span class=\"string\">'Comment'</span>]))]</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'The selected comment is:'</span>, comment[<span class=\"number\">0</span>])</span><br><span class=\"line\">    X_try = vect.transform(comment)</span><br><span class=\"line\">    y_pred = clf.predict(X_try.toarray())</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'The predicted sentiment of the selected comment using <span class=\"subst\">{title}</span> is:'</span>, y_pred[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'The actual sentiment of the selected comment is:'</span>, data.iloc[rand_idx][<span class=\"string\">'Review'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">sorted_scores = <span class=\"built_in\">sorted</span>(scores, key=<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">1</span>], reverse=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Ranking of the classifiers based on accuracy score:'</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, (title, score) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(sorted_scores):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'<span class=\"subst\">{i + <span class=\"number\">1</span>}</span>. <span class=\"subst\">{title}</span>: <span class=\"subst\">{score:<span class=\"number\">.4</span>f}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.../Desktop/Sentiment Analysis on Product Reviews/Sentiment Analysis on Product Reviews.py </span><br><span class=\"line\">Building prefix dict from the default dictionary ...</span><br><span class=\"line\">Loading model from cache /var/folders/vb/bhfltf7s0n5dmrcb5r9s80mw0000gn/T/jieba.cache</span><br><span class=\"line\">Loading model cost 0.439 seconds.</span><br><span class=\"line\">Prefix dict has been built successfully.</span><br><span class=\"line\">The accuracy score of the MLP classifier model is: 0.9814814814814815</span><br><span class=\"line\">The selected comment is:                                </span><br><span class=\"line\">The predicted sentiment of the selected comment using MLP classifier model is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the Naive Bayes classifier model is: 0.8888888888888888</span><br><span class=\"line\">The selected comment is:                                                                  </span><br><span class=\"line\">The predicted sentiment of the selected comment using Naive Bayes classifier model is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the SVM is: 0.9814814814814815</span><br><span class=\"line\">The selected comment is:          6s   7                                  </span><br><span class=\"line\">The predicted sentiment of the selected comment using SVM is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the Random Forest is: 0.9722222222222222</span><br><span class=\"line\">The selected comment is:                       6                            </span><br><span class=\"line\">The predicted sentiment of the selected comment using Random Forest is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the Logistic Regression is: 0.9814814814814815</span><br><span class=\"line\">The selected comment is:                  64G                </span><br><span class=\"line\">The predicted sentiment of the selected comment using Logistic Regression is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the K-Nearest Neighbors is: 0.4537037037037037</span><br><span class=\"line\">The selected comment is:       618   </span><br><span class=\"line\">The predicted sentiment of the selected comment using K-Nearest Neighbors is: 0</span><br><span class=\"line\">The actual sentiment of the selected comment is: 0</span><br><span class=\"line\">The accuracy score of the Decision Tree is: 0.9259259259259259</span><br><span class=\"line\">The selected comment is:  </span><br><span class=\"line\">The predicted sentiment of the selected comment using Decision Tree is: 0</span><br><span class=\"line\">The actual sentiment of the selected comment is: 0</span><br><span class=\"line\">The accuracy score of the AdaBoost is: 0.9074074074074074</span><br><span class=\"line\">The selected comment is:                                       </span><br><span class=\"line\">The predicted sentiment of the selected comment using AdaBoost is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">Ranking of the classifiers based on accuracy score:</span><br><span class=\"line\">1. MLP classifier model: 0.9815</span><br><span class=\"line\">2. SVM: 0.9815</span><br><span class=\"line\">3. Logistic Regression: 0.9815</span><br><span class=\"line\">4. Random Forest: 0.9722</span><br><span class=\"line\">5. Decision Tree: 0.9259</span><br><span class=\"line\">6. AdaBoost: 0.9074</span><br><span class=\"line\">7. Naive Bayes classifier model: 0.8889</span><br><span class=\"line\">8. K-Nearest Neighbors: 0.4537</span><br><span class=\"line\"></span><br><span class=\"line\">Process finished with exit code 0</span><br></pre></td></tr></tbody></table></figure>\n<p></p><div style=\"text-align:center\">\n<img alt=\"SVM\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/SVM.png\">\n<img alt=\"AdaBoost\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/AdaBoost.png\">\n<img alt=\"Decision Tree\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Decision%20Tree.png\">\n<img alt=\"K-Nearest Neighbors\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/K-Nearest%20Neighbors.png\">\n<img alt=\"Logistic Regression\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Logistic%20Regression.png\">\n<img alt=\"MLP classifier model\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/MLP%20classifier%20model.png\">\n<img alt=\"Naive Bayes classifier model\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Naive%20Bayes%20classifier%20model.png\">\n<img alt=\"Random Forest\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Random%20Forest.png\">\n</div><br>A 2x2 confusion matrix is used to evaluate binary classification models that classify data into one of two possible classes. In a 2x2 confusion matrix, the actual class labels are represented by the rows, and the predicted class labels are represented by the columns. The four cells in the matrix represent:<p></p>\n<ul>\n<li>True Positive (TP): The model predicted the sample to be positive (1), and it actually belongs to the positive class (1).</li>\n<li>False Positive (FP): The model predicted the sample to be positive (1), but it actually belongs to the negative class (0).</li>\n<li>False Negative (FN): The model predicted the sample to be negative (0), but it actually belongs to the positive class (1).</li>\n<li>True Negative (TN): The model predicted the sample to be negative (0), and it actually belongs to the negative class (0).</li>\n</ul>\n<p>The confusion matrix allows us to evaluate the performance of a binary classification model by comparing the predicted class labels to the actual class labels. The TP, FP, FN, and TN values can be used to calculate various metrics such as accuracy, precision, recall, and F1-score.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>3.4. Validation curves: plotting scores to evaluate models</em>. (n.d.). Scikit-learn. <a href=\"https://scikit-learn/stable/modules/learning_curve.html\">https://scikit-learn/stable/modules/learning_curve.html</a></li>\n<li><em>sklearn.metrics.confusion_matrix</em>. (n.d.). Scikit-learn. <a href=\"https://scikit-learn/stable/modules/generated/sklearn.metrics.confusion_matrix.html\">https://scikit-learn/stable/modules/generated/sklearn.metrics.confusion_matrix.html</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/01/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/","2023/03/28/Hyperplane/","2023/03/29/From-linear-regression-to-binary-classification/"],"length":1818,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>This code performs sentiment analysis on product reviews using several machine learning classifiers, including MLP classifier, Naive Bayes classifier, SVM, Random Forest, Logistic Regression, K-Nearest Neighbors, Decision Tree, AdaBoost, and Gradient Boosting.</p>\n<p>The input data is read from an Excel file, which contains three columns: the index, the comment of the product, and the review of the product (1 means positive review, 0 means negative review). The Chinese comments are tokenized using the jieba library, and the text is vectorized using CountVectorizer.</p>\n<p>The classifiers are trained using the training data, and their accuracy scores are calculated using the test data. The learning curve and confusion matrix are plotted for each classifier. The accuracy scores of all classifiers are printed, and the predicted and actual sentiments of a randomly selected comment are displayed for each classifier.</p>\n<p>Finally, the code ranks the classifiers based on their accuracy scores, and saves the learning curve and confusion matrix plots for each classifier as images.</p>\n<p>The input data for this code can be found at <a href=\"https://docs.google.com/spreadsheets/d/1p_Stbv7fXQnvGGz6ofNsl00VKQPt0C6L/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1p_Stbv7fXQnvGGz6ofNsl00VKQPt0C6L/edit?usp=sharing</a>.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/23 23:59</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> jieba</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.feature_extraction.text <span class=\"keyword\">import</span> CountVectorizer</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split, learning_curve</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neural_network <span class=\"keyword\">import</span> MLPClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score, ConfusionMatrixDisplay, confusion_matrix</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generating a random integer between 0 and 100 using numpy</span></span><br><span class=\"line\">rs = np.random.RandomState(seed=<span class=\"number\">1</span>)</span><br><span class=\"line\">rs.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, size=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Reading input data from an excel file</span></span><br><span class=\"line\">data = pd.read_excel(<span class=\"string\">'product_review.xlsx'</span>, sheet_name=<span class=\"string\">'Sheet1'</span>, header=<span class=\"number\">0</span>, index_col=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># description of the data</span></span><br><span class=\"line\"><span class=\"comment\"># print('The information about the data is:', data.info())</span></span><br><span class=\"line\"><span class=\"comment\"># print('The first 5 rows of the data are:', data.head())</span></span><br><span class=\"line\"><span class=\"comment\"># # 0: index ;1: Comment ;2: Review</span></span><br><span class=\"line\"><span class=\"comment\"># print('The first column means the index of the data, the second column means the comment of the product, the third column means the review of the product.')</span></span><br><span class=\"line\"><span class=\"comment\"># # review 1: positive review; review 0: negative review</span></span><br><span class=\"line\"><span class=\"comment\"># print('The third column means the review of the product, 1 means positive review, 0 means negative review.')</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Using jieba library to tokenize Chinese comments</span></span><br><span class=\"line\">words = [<span class=\"string\">' '</span>.join(jieba.cut(row[<span class=\"string\">'Comment'</span>])) <span class=\"keyword\">for</span> _, row <span class=\"keyword\">in</span> data.iterrows()]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Vectorizing the text using CountVectorizer</span></span><br><span class=\"line\">vect = CountVectorizer()</span><br><span class=\"line\">X = vect.fit_transform(words)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Extracting the target variable</span></span><br><span class=\"line\">y = data[<span class=\"string\">'Review'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Splitting the data into train and test sets</span></span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"number\">0.1</span>, random_state=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Building all classifiers</span></span><br><span class=\"line\">mlp = MLPClassifier(hidden_layer_sizes=(<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"number\">32</span>))</span><br><span class=\"line\">nb_clf = MultinomialNB()</span><br><span class=\"line\">svm = SVC(kernel=<span class=\"string\">'linear'</span>)</span><br><span class=\"line\">rf = RandomForestClassifier(n_estimators=<span class=\"number\">100</span>)</span><br><span class=\"line\">lr = LogisticRegression()</span><br><span class=\"line\">knn = KNeighborsClassifier(n_neighbors=<span class=\"number\">5</span>)</span><br><span class=\"line\">dt = DecisionTreeClassifier()</span><br><span class=\"line\">ada = AdaBoostClassifier()</span><br><span class=\"line\">gb = GradientBoostingClassifier()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plotting the learning curve for all classifiers</span></span><br><span class=\"line\">classifiers = [mlp, nb_clf, svm, rf, lr, knn, dt, ada]</span><br><span class=\"line\">titles = [<span class=\"string\">'MLP classifier model'</span>, <span class=\"string\">'Naive Bayes classifier model'</span>, <span class=\"string\">'SVM'</span>, <span class=\"string\">'Random Forest'</span>, <span class=\"string\">'Logistic Regression'</span>,</span><br><span class=\"line\">          <span class=\"string\">'K-Nearest Neighbors'</span>, <span class=\"string\">'Decision Tree'</span>, <span class=\"string\">'AdaBoost'</span>, <span class=\"string\">'Gradient Boosting'</span>]</span><br><span class=\"line\">scores = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> clf, title <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(classifiers, titles):</span><br><span class=\"line\">    fig, (ax1, ax2) = plt.subplots(<span class=\"number\">1</span>, <span class=\"number\">2</span>, figsize=(<span class=\"number\">10</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\">    <span class=\"comment\"># Plotting the learning curve</span></span><br><span class=\"line\">    train_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, cv=<span class=\"number\">5</span>)</span><br><span class=\"line\">    train_scores_mean, test_scores_mean = np.mean(train_scores, axis=<span class=\"number\">1</span>), np.mean(test_scores, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    ax1.plot(train_sizes, train_scores_mean, <span class=\"string\">'o-'</span>, color=<span class=\"string\">'r'</span>, label=<span class=\"string\">'Training score'</span>)</span><br><span class=\"line\">    ax1.plot(train_sizes, test_scores_mean, <span class=\"string\">'o-'</span>, color=<span class=\"string\">'g'</span>, label=<span class=\"string\">'Cross-validation score'</span>)</span><br><span class=\"line\">    ax1.set_xlabel(<span class=\"string\">'Training examples'</span>)</span><br><span class=\"line\">    ax1.set_ylabel(<span class=\"string\">'Score'</span>)</span><br><span class=\"line\">    ax1.legend(loc=<span class=\"string\">'best'</span>)</span><br><span class=\"line\">    ax1.set_title(<span class=\"string\">f'Learning curve for <span class=\"subst\">{title}</span>'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Plotting the confusion matrix</span></span><br><span class=\"line\">    clf.fit(X_train, y_train)</span><br><span class=\"line\">    y_pred = clf.predict(X_test)</span><br><span class=\"line\">    cm = confusion_matrix(y_test, y_pred)</span><br><span class=\"line\">    disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, ax=ax2, cmap=plt.cm.Blues, normalize=<span class=\"string\">'true'</span>)</span><br><span class=\"line\">    disp.ax_.set_title(<span class=\"string\">f'Confusion matrix for <span class=\"subst\">{title}</span>'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    plt.tight_layout()</span><br><span class=\"line\">    plt.savefig(<span class=\"string\">f'<span class=\"subst\">{title}</span>.png'</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Fitting the model to the training data and predicting the target values for the test data</span></span><br><span class=\"line\">    clf.fit(X_train, y_train)</span><br><span class=\"line\">    y_pred = clf.predict(X_test)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Calculating the accuracy score of the classifier model</span></span><br><span class=\"line\">    score = accuracy_score(y_pred, y_test)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'The accuracy score of the <span class=\"subst\">{title}</span> is:'</span>, score)</span><br><span class=\"line\">    scores.append([title, score])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Selecting a random comment from the input data and performing sentiment analysis using the classifier</span></span><br><span class=\"line\">    rand_idx = random.randint(<span class=\"number\">0</span>, <span class=\"built_in\">len</span>(data) - <span class=\"number\">1</span>)</span><br><span class=\"line\">    comment = [<span class=\"string\">' '</span>.join(jieba.cut(data.iloc[rand_idx][<span class=\"string\">'Comment'</span>]))]</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'The selected comment is:'</span>, comment[<span class=\"number\">0</span>])</span><br><span class=\"line\">    X_try = vect.transform(comment)</span><br><span class=\"line\">    y_pred = clf.predict(X_try.toarray())</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'The predicted sentiment of the selected comment using <span class=\"subst\">{title}</span> is:'</span>, y_pred[<span class=\"number\">0</span>])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">'The actual sentiment of the selected comment is:'</span>, data.iloc[rand_idx][<span class=\"string\">'Review'</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">sorted_scores = <span class=\"built_in\">sorted</span>(scores, key=<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">1</span>], reverse=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">'Ranking of the classifiers based on accuracy score:'</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, (title, score) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(sorted_scores):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f'<span class=\"subst\">{i + <span class=\"number\">1</span>}</span>. <span class=\"subst\">{title}</span>: <span class=\"subst\">{score:<span class=\"number\">.4</span>f}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.../Desktop/Sentiment Analysis on Product Reviews/Sentiment Analysis on Product Reviews.py </span><br><span class=\"line\">Building prefix dict from the default dictionary ...</span><br><span class=\"line\">Loading model from cache /var/folders/vb/bhfltf7s0n5dmrcb5r9s80mw0000gn/T/jieba.cache</span><br><span class=\"line\">Loading model cost 0.439 seconds.</span><br><span class=\"line\">Prefix dict has been built successfully.</span><br><span class=\"line\">The accuracy score of the MLP classifier model is: 0.9814814814814815</span><br><span class=\"line\">The selected comment is:                                </span><br><span class=\"line\">The predicted sentiment of the selected comment using MLP classifier model is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the Naive Bayes classifier model is: 0.8888888888888888</span><br><span class=\"line\">The selected comment is:                                                                  </span><br><span class=\"line\">The predicted sentiment of the selected comment using Naive Bayes classifier model is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the SVM is: 0.9814814814814815</span><br><span class=\"line\">The selected comment is:          6s   7                                  </span><br><span class=\"line\">The predicted sentiment of the selected comment using SVM is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the Random Forest is: 0.9722222222222222</span><br><span class=\"line\">The selected comment is:                       6                            </span><br><span class=\"line\">The predicted sentiment of the selected comment using Random Forest is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the Logistic Regression is: 0.9814814814814815</span><br><span class=\"line\">The selected comment is:                  64G                </span><br><span class=\"line\">The predicted sentiment of the selected comment using Logistic Regression is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">The accuracy score of the K-Nearest Neighbors is: 0.4537037037037037</span><br><span class=\"line\">The selected comment is:       618   </span><br><span class=\"line\">The predicted sentiment of the selected comment using K-Nearest Neighbors is: 0</span><br><span class=\"line\">The actual sentiment of the selected comment is: 0</span><br><span class=\"line\">The accuracy score of the Decision Tree is: 0.9259259259259259</span><br><span class=\"line\">The selected comment is:  </span><br><span class=\"line\">The predicted sentiment of the selected comment using Decision Tree is: 0</span><br><span class=\"line\">The actual sentiment of the selected comment is: 0</span><br><span class=\"line\">The accuracy score of the AdaBoost is: 0.9074074074074074</span><br><span class=\"line\">The selected comment is:                                       </span><br><span class=\"line\">The predicted sentiment of the selected comment using AdaBoost is: 1</span><br><span class=\"line\">The actual sentiment of the selected comment is: 1</span><br><span class=\"line\">Ranking of the classifiers based on accuracy score:</span><br><span class=\"line\">1. MLP classifier model: 0.9815</span><br><span class=\"line\">2. SVM: 0.9815</span><br><span class=\"line\">3. Logistic Regression: 0.9815</span><br><span class=\"line\">4. Random Forest: 0.9722</span><br><span class=\"line\">5. Decision Tree: 0.9259</span><br><span class=\"line\">6. AdaBoost: 0.9074</span><br><span class=\"line\">7. Naive Bayes classifier model: 0.8889</span><br><span class=\"line\">8. K-Nearest Neighbors: 0.4537</span><br><span class=\"line\"></span><br><span class=\"line\">Process finished with exit code 0</span><br></pre></td></tr></tbody></table></figure>\n<p></p><div style=\"text-align:center\">\n<img alt=\"SVM\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/SVM.png\">\n<img alt=\"AdaBoost\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/AdaBoost.png\">\n<img alt=\"Decision Tree\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Decision%20Tree.png\">\n<img alt=\"K-Nearest Neighbors\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/K-Nearest%20Neighbors.png\">\n<img alt=\"Logistic Regression\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Logistic%20Regression.png\">\n<img alt=\"MLP classifier model\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/MLP%20classifier%20model.png\">\n<img alt=\"Naive Bayes classifier model\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Naive%20Bayes%20classifier%20model.png\">\n<img alt=\"Random Forest\" style=\"zoom:67%;\" data-src=\"/2023/04/01/Sentiment-Analysis-on-Product-Reviews/Random%20Forest.png\">\n</div><br>A 2x2 confusion matrix is used to evaluate binary classification models that classify data into one of two possible classes. In a 2x2 confusion matrix, the actual class labels are represented by the rows, and the predicted class labels are represented by the columns. The four cells in the matrix represent:<p></p>\n<ul>\n<li>True Positive (TP): The model predicted the sample to be positive (1), and it actually belongs to the positive class (1).</li>\n<li>False Positive (FP): The model predicted the sample to be positive (1), but it actually belongs to the negative class (0).</li>\n<li>False Negative (FN): The model predicted the sample to be negative (0), but it actually belongs to the positive class (1).</li>\n<li>True Negative (TN): The model predicted the sample to be negative (0), and it actually belongs to the negative class (0).</li>\n</ul>\n<p>The confusion matrix allows us to evaluate the performance of a binary classification model by comparing the predicted class labels to the actual class labels. The TP, FP, FN, and TN values can be used to calculate various metrics such as accuracy, precision, recall, and F1-score.</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li><em>3.4. Validation curves: plotting scores to evaluate models</em>. (n.d.). Scikit-learn. <a href=\"https://scikit-learn/stable/modules/learning_curve.html\">https://scikit-learn/stable/modules/learning_curve.html</a></li>\n<li><em>sklearn.metrics.confusion_matrix</em>. (n.d.). Scikit-learn. <a href=\"https://scikit-learn/stable/modules/generated/sklearn.metrics.confusion_matrix.html\">https://scikit-learn/stable/modules/generated/sklearn.metrics.confusion_matrix.html</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Variables","date":"2023-03-27T22:04:26.000Z","_content":"\n### Uniform distribution\n\nThe probability density function (pdf) of the continuous uniform distribution is:\n$$\nf(x)= \\begin{cases}\\frac{1}{b-a} & \\text { for } a \\leq x \\leq b \\\\ 0 & \\text { for } x<a \\text { or } x>b\\end{cases}\n$$\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 00:10\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nx = np.linspace(-5, 5, 200)  # define x range and number\n\na_values = np.linspace(1, 5, 10)  # define a range and number\n\ncolors = cm.RdYlBu(np.linspace(0, 1, len(a_values)))  # create a color map\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\nfor idx, a in enumerate(a_values):\n    pdf = np.where(np.abs(x) <= a, 1 / (2 * a), 0)  # compute the pdf\n    ax.plot(x, pdf, color=colors[idx], label=f'a = {a:.1f}')\n\nax.legend()\nax.set_xlim(-5, 5)\nax.set_ylim(0, 0.6)\nax.set_xlabel('x')\nax.set_ylabel('PDF')\n\nplt.savefig('uniform.png', dpi=300, bbox_inches='tight', pad_inches=0)\nplt.show()\n```\n\n![uniform](Variables/uniform.png)\n\n### Normal distribution\n\nThe probability density function (PDF) of a normal distribution with mean $\\mu$ and standard deviation $\\sigma$ is given by:\n$$\n\\begin{equation}\nf(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\end{equation}\n$$\nwhere $x$ is the random variable and $f(x)$ is the probability density function at $x$. The mean $\\mu$ determines the center of the distribution, while the standard deviation $\\sigma$ determines the spread of the distribution.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/4/23 02:06\n\nfrom matplotlib.collections import LineCollection\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm  # import color map\nfrom scipy.stats import norm\n\nx_array = np.linspace(-6, 6, 200)\nsigma_array = np.linspace(0.5, 5, 10)\n# generate x and sigma arrays\n\nnum_lines = len(sigma_array)\n# probability density function\n\ncolors = cm.RdYlBu(np.linspace(0, 1, num_lines))\n# color map\n\nfig, ax = plt.subplots(figsize=(5, 4))\n\nfor idx, sigma_idx in enumerate(sigma_array):\n    pdf_idx = norm.pdf(x_array, scale=sigma_idx)\n    legend_idx = '$\\sigma$ = ' + str(sigma_idx)\n    plt.plot(x_array, pdf_idx, color=colors[idx], label=legend_idx)\n    # plot the pdf\n\nplt.legend()\n\nplt.xlim(min(x_array), max(x_array))\nplt.ylim(0, 1)\nplt.xlabel('x')\nplt.ylabel('PDF')\n\nfig.savefig('normal.png', dpi=600, bbox_inches='tight')\n```\n\n![normal](Variables/normal.png)\n\n### Bivariate\n\nThe bivariate normal distribution is a probability distribution for two random variables that have a normal distribution.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/4/23 16:19\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import multivariate_normal\n\n# Set the mean and covariance of the distribution\nmean = [0, 0]\ncov = [[1, 0], [0, 1]]\n\n# Create a grid of points to evaluate the distribution\nx, y = np.mgrid[-3:3:.01, -3:3:.01]\npos = np.empty(x.shape + (2,))\npos[:, :, 0] = x\npos[:, :, 1] = y\n\n# Generate the bivariate normal distribution\nrv = multivariate_normal(mean, cov)\n\n# Evaluate the distribution at each point on the grid\nz = rv.pdf(pos)\n\n# Plot the distribution, like a mountain\nfig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot(121, projection='3d')\nax.plot_surface(x, y, z, cmap=\"RdBu_r\", linewidth=0.1, antialiased=True)\nax.grid(False)\n# only leave the plot of the mountain\nax.set_axis_off()\n\nax = fig.add_subplot(122)\nax.contourf(x, y, z, cmap=\"RdBu_r\")\nax.set_aspect(\"equal\")\nax.set_axis_off()\n\n# save the figure\nplt.savefig(\"bivariate_normal.png\", dpi=600, bbox_inches='tight')\nplt.show()\n```\n\n![bivariate_normal](Variables/bivariate_normal.png)\n\n### Reference\n\n1. Wikipedia contributors. (2023, March 23). Normal distribution. In Wikipedia. Retrieved March 28, 2023, from https://en.wikipedia.org/wiki/Normal_distribution\n2. Pennsylvania State University. (n.d.). 4.2 - Bivariate normal distribution. In STAT 505: Applied multivariate statistical analysis. Retrieved March 28, 2023, from https://online.stat.psu.edu/stat505/lesson/4/4.2\n3. Visualize-ML. (n.d.). Book2_Beauty-of-Data-Visualization. GitHub. Retrieved March 28, 2023, from https://github.com/Visualize-ML/Book2_Beauty-of-Data-Visualization\n\n","source":"_posts/Variables.md","raw":"---\nmathjax: true\ntitle: Variables\ndate: 2023-03-27 22:04:26\ntags: [Probabilities, Variables, Uniform distribution, Normal distribution, Basics]\n---\n\n### Uniform distribution\n\nThe probability density function (pdf) of the continuous uniform distribution is:\n$$\nf(x)= \\begin{cases}\\frac{1}{b-a} & \\text { for } a \\leq x \\leq b \\\\ 0 & \\text { for } x<a \\text { or } x>b\\end{cases}\n$$\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/28/23 00:10\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nx = np.linspace(-5, 5, 200)  # define x range and number\n\na_values = np.linspace(1, 5, 10)  # define a range and number\n\ncolors = cm.RdYlBu(np.linspace(0, 1, len(a_values)))  # create a color map\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\nfor idx, a in enumerate(a_values):\n    pdf = np.where(np.abs(x) <= a, 1 / (2 * a), 0)  # compute the pdf\n    ax.plot(x, pdf, color=colors[idx], label=f'a = {a:.1f}')\n\nax.legend()\nax.set_xlim(-5, 5)\nax.set_ylim(0, 0.6)\nax.set_xlabel('x')\nax.set_ylabel('PDF')\n\nplt.savefig('uniform.png', dpi=300, bbox_inches='tight', pad_inches=0)\nplt.show()\n```\n\n![uniform](Variables/uniform.png)\n\n### Normal distribution\n\nThe probability density function (PDF) of a normal distribution with mean $\\mu$ and standard deviation $\\sigma$ is given by:\n$$\n\\begin{equation}\nf(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\end{equation}\n$$\nwhere $x$ is the random variable and $f(x)$ is the probability density function at $x$. The mean $\\mu$ determines the center of the distribution, while the standard deviation $\\sigma$ determines the spread of the distribution.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/4/23 02:06\n\nfrom matplotlib.collections import LineCollection\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm  # import color map\nfrom scipy.stats import norm\n\nx_array = np.linspace(-6, 6, 200)\nsigma_array = np.linspace(0.5, 5, 10)\n# generate x and sigma arrays\n\nnum_lines = len(sigma_array)\n# probability density function\n\ncolors = cm.RdYlBu(np.linspace(0, 1, num_lines))\n# color map\n\nfig, ax = plt.subplots(figsize=(5, 4))\n\nfor idx, sigma_idx in enumerate(sigma_array):\n    pdf_idx = norm.pdf(x_array, scale=sigma_idx)\n    legend_idx = '$\\sigma$ = ' + str(sigma_idx)\n    plt.plot(x_array, pdf_idx, color=colors[idx], label=legend_idx)\n    # plot the pdf\n\nplt.legend()\n\nplt.xlim(min(x_array), max(x_array))\nplt.ylim(0, 1)\nplt.xlabel('x')\nplt.ylabel('PDF')\n\nfig.savefig('normal.png', dpi=600, bbox_inches='tight')\n```\n\n![normal](Variables/normal.png)\n\n### Bivariate\n\nThe bivariate normal distribution is a probability distribution for two random variables that have a normal distribution.\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 3/4/23 16:19\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import multivariate_normal\n\n# Set the mean and covariance of the distribution\nmean = [0, 0]\ncov = [[1, 0], [0, 1]]\n\n# Create a grid of points to evaluate the distribution\nx, y = np.mgrid[-3:3:.01, -3:3:.01]\npos = np.empty(x.shape + (2,))\npos[:, :, 0] = x\npos[:, :, 1] = y\n\n# Generate the bivariate normal distribution\nrv = multivariate_normal(mean, cov)\n\n# Evaluate the distribution at each point on the grid\nz = rv.pdf(pos)\n\n# Plot the distribution, like a mountain\nfig = plt.figure(figsize=(10, 5))\nax = fig.add_subplot(121, projection='3d')\nax.plot_surface(x, y, z, cmap=\"RdBu_r\", linewidth=0.1, antialiased=True)\nax.grid(False)\n# only leave the plot of the mountain\nax.set_axis_off()\n\nax = fig.add_subplot(122)\nax.contourf(x, y, z, cmap=\"RdBu_r\")\nax.set_aspect(\"equal\")\nax.set_axis_off()\n\n# save the figure\nplt.savefig(\"bivariate_normal.png\", dpi=600, bbox_inches='tight')\nplt.show()\n```\n\n![bivariate_normal](Variables/bivariate_normal.png)\n\n### Reference\n\n1. Wikipedia contributors. (2023, March 23). Normal distribution. In Wikipedia. Retrieved March 28, 2023, from https://en.wikipedia.org/wiki/Normal_distribution\n2. Pennsylvania State University. (n.d.). 4.2 - Bivariate normal distribution. In STAT 505: Applied multivariate statistical analysis. Retrieved March 28, 2023, from https://online.stat.psu.edu/stat505/lesson/4/4.2\n3. Visualize-ML. (n.d.). Book2_Beauty-of-Data-Visualization. GitHub. Retrieved March 28, 2023, from https://github.com/Visualize-ML/Book2_Beauty-of-Data-Visualization\n\n","slug":"Variables","published":1,"updated":"2023-04-07T02:43:50.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73hg0015ozpif05tcx35","content":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Uniform-distribution\"><a href=\"#Uniform-distribution\" class=\"headerlink\" title=\"Uniform distribution\"></a>Uniform distribution</h3><p>The probability density function (pdf) of the continuous uniform distribution is:</p>\n<script type=\"math/tex; mode=display\">\nf(x)= \\begin{cases}\\frac{1}{b-a} & \\text { for } a \\leq x \\leq b \\\\ 0 & \\text { for } x<a \\text { or } x>b\\end{cases}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 00:10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> cm</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">200</span>)  <span class=\"comment\"># define x range and number</span></span><br><span class=\"line\"></span><br><span class=\"line\">a_values = np.linspace(<span class=\"number\">1</span>, <span class=\"number\">5</span>, <span class=\"number\">10</span>)  <span class=\"comment\"># define a range and number</span></span><br><span class=\"line\"></span><br><span class=\"line\">colors = cm.RdYlBu(np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"built_in\">len</span>(a_values)))  <span class=\"comment\"># create a color map</span></span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> idx, a <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(a_values):</span><br><span class=\"line\">    pdf = np.where(np.<span class=\"built_in\">abs</span>(x) &lt;= a, <span class=\"number\">1</span> / (<span class=\"number\">2</span> * a), <span class=\"number\">0</span>)  <span class=\"comment\"># compute the pdf</span></span><br><span class=\"line\">    ax.plot(x, pdf, color=colors[idx], label=<span class=\"string\">f'a = <span class=\"subst\">{a:<span class=\"number\">.1</span>f}</span>'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax.legend()</span><br><span class=\"line\">ax.set_xlim(-<span class=\"number\">5</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_ylim(<span class=\"number\">0</span>, <span class=\"number\">0.6</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'PDF'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'uniform.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"uniform\" data-src=\"/2023/03/27/Variables/uniform.png\"></p>\n<h3 id=\"Normal-distribution\"><a href=\"#Normal-distribution\" class=\"headerlink\" title=\"Normal distribution\"></a>Normal distribution</h3><p>The probability density function (PDF) of a normal distribution with mean <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.489ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.364ex\" height=\"1.489ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 603 658\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D707\" d=\"M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z\"></path></g></g></g></svg></mjx-container> and standard deviation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.292ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 571 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D70E\" d=\"M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z\"></path></g></g></g></svg></mjx-container> is given by:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nf(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.294ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 572 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g></g></g></svg></mjx-container> is the random variable and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.299ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 1900 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(550,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(939,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1511,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container> is the probability density function at <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.294ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 572 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g></g></g></svg></mjx-container>. The mean <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.489ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.364ex\" height=\"1.489ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 603 658\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D707\" d=\"M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z\"></path></g></g></g></svg></mjx-container> determines the center of the distribution, while the standard deviation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.292ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 571 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D70E\" d=\"M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z\"></path></g></g></g></svg></mjx-container> determines the spread of the distribution.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/4/23 02:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.collections <span class=\"keyword\">import</span> LineCollection</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> cm  <span class=\"comment\"># import color map</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.stats <span class=\"keyword\">import</span> norm</span><br><span class=\"line\"></span><br><span class=\"line\">x_array = np.linspace(-<span class=\"number\">6</span>, <span class=\"number\">6</span>, <span class=\"number\">200</span>)</span><br><span class=\"line\">sigma_array = np.linspace(<span class=\"number\">0.5</span>, <span class=\"number\">5</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># generate x and sigma arrays</span></span><br><span class=\"line\"></span><br><span class=\"line\">num_lines = <span class=\"built_in\">len</span>(sigma_array)</span><br><span class=\"line\"><span class=\"comment\"># probability density function</span></span><br><span class=\"line\"></span><br><span class=\"line\">colors = cm.RdYlBu(np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, num_lines))</span><br><span class=\"line\"><span class=\"comment\"># color map</span></span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(figsize=(<span class=\"number\">5</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> idx, sigma_idx <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(sigma_array):</span><br><span class=\"line\">    pdf_idx = norm.pdf(x_array, scale=sigma_idx)</span><br><span class=\"line\">    legend_idx = <span class=\"string\">'$\\sigma$ = '</span> + <span class=\"built_in\">str</span>(sigma_idx)</span><br><span class=\"line\">    plt.plot(x_array, pdf_idx, color=colors[idx], label=legend_idx)</span><br><span class=\"line\">    <span class=\"comment\"># plot the pdf</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.xlim(<span class=\"built_in\">min</span>(x_array), <span class=\"built_in\">max</span>(x_array))</span><br><span class=\"line\">plt.ylim(<span class=\"number\">0</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'PDF'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fig.savefig(<span class=\"string\">'normal.png'</span>, dpi=<span class=\"number\">600</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"normal\" data-src=\"/2023/03/27/Variables/normal.png\"></p>\n<h3 id=\"Bivariate\"><a href=\"#Bivariate\" class=\"headerlink\" title=\"Bivariate\"></a>Bivariate</h3><p>The bivariate normal distribution is a probability distribution for two random variables that have a normal distribution.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/4/23 16:19</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.stats <span class=\"keyword\">import</span> multivariate_normal</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the mean and covariance of the distribution</span></span><br><span class=\"line\">mean = [<span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">cov = [[<span class=\"number\">1</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">1</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a grid of points to evaluate the distribution</span></span><br><span class=\"line\">x, y = np.mgrid[-<span class=\"number\">3</span>:<span class=\"number\">3</span>:<span class=\"number\">.01</span>, -<span class=\"number\">3</span>:<span class=\"number\">3</span>:<span class=\"number\">.01</span>]</span><br><span class=\"line\">pos = np.empty(x.shape + (<span class=\"number\">2</span>,))</span><br><span class=\"line\">pos[:, :, <span class=\"number\">0</span>] = x</span><br><span class=\"line\">pos[:, :, <span class=\"number\">1</span>] = y</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate the bivariate normal distribution</span></span><br><span class=\"line\">rv = multivariate_normal(mean, cov)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Evaluate the distribution at each point on the grid</span></span><br><span class=\"line\">z = rv.pdf(pos)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the distribution, like a mountain</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">121</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax.plot_surface(x, y, z, cmap=<span class=\"string\">\"RdBu_r\"</span>, linewidth=<span class=\"number\">0.1</span>, antialiased=<span class=\"literal\">True</span>)</span><br><span class=\"line\">ax.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\"><span class=\"comment\"># only leave the plot of the mountain</span></span><br><span class=\"line\">ax.set_axis_off()</span><br><span class=\"line\"></span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">122</span>)</span><br><span class=\"line\">ax.contourf(x, y, z, cmap=<span class=\"string\">\"RdBu_r\"</span>)</span><br><span class=\"line\">ax.set_aspect(<span class=\"string\">\"equal\"</span>)</span><br><span class=\"line\">ax.set_axis_off()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># save the figure</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"bivariate_normal.png\"</span>, dpi=<span class=\"number\">600</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"bivariate_normal\" data-src=\"/2023/03/27/Variables/bivariate_normal.png\"></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Wikipedia contributors. (2023, March 23). Normal distribution. In Wikipedia. Retrieved March 28, 2023, from <a href=\"https://en.wikipedia.org/wiki/Normal_distribution\">https://en.wikipedia.org/wiki/Normal_distribution</a></li>\n<li>Pennsylvania State University. (n.d.). 4.2 - Bivariate normal distribution. In STAT 505: Applied multivariate statistical analysis. Retrieved March 28, 2023, from <a href=\"https://online.stat.psu.edu/stat505/lesson/4/4.2\">https://online.stat.psu.edu/stat505/lesson/4/4.2</a></li>\n<li>Visualize-ML. (n.d.). Book2_Beauty-of-Data-Visualization. GitHub. Retrieved March 28, 2023, from <a href=\"https://github.com/Visualize-ML/Book2_Beauty-of-Data-Visualization\">https://github.com/Visualize-ML/Book2_Beauty-of-Data-Visualization</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/03/Functions/","2023/03/28/Functions-Plot/"],"length":587,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><h3 id=\"Uniform-distribution\"><a href=\"#Uniform-distribution\" class=\"headerlink\" title=\"Uniform distribution\"></a>Uniform distribution</h3><p>The probability density function (pdf) of the continuous uniform distribution is:</p>\n<script type=\"math/tex; mode=display\">\nf(x)= \\begin{cases}\\frac{1}{b-a} & \\text { for } a \\leq x \\leq b \\\\ 0 & \\text { for } x<a \\text { or } x>b\\end{cases}</script><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/28/23 00:10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> cm</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.linspace(-<span class=\"number\">5</span>, <span class=\"number\">5</span>, <span class=\"number\">200</span>)  <span class=\"comment\"># define x range and number</span></span><br><span class=\"line\"></span><br><span class=\"line\">a_values = np.linspace(<span class=\"number\">1</span>, <span class=\"number\">5</span>, <span class=\"number\">10</span>)  <span class=\"comment\"># define a range and number</span></span><br><span class=\"line\"></span><br><span class=\"line\">colors = cm.RdYlBu(np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"built_in\">len</span>(a_values)))  <span class=\"comment\"># create a color map</span></span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> idx, a <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(a_values):</span><br><span class=\"line\">    pdf = np.where(np.<span class=\"built_in\">abs</span>(x) &lt;= a, <span class=\"number\">1</span> / (<span class=\"number\">2</span> * a), <span class=\"number\">0</span>)  <span class=\"comment\"># compute the pdf</span></span><br><span class=\"line\">    ax.plot(x, pdf, color=colors[idx], label=<span class=\"string\">f'a = <span class=\"subst\">{a:<span class=\"number\">.1</span>f}</span>'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax.legend()</span><br><span class=\"line\">ax.set_xlim(-<span class=\"number\">5</span>, <span class=\"number\">5</span>)</span><br><span class=\"line\">ax.set_ylim(<span class=\"number\">0</span>, <span class=\"number\">0.6</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">'PDF'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.savefig(<span class=\"string\">'uniform.png'</span>, dpi=<span class=\"number\">300</span>, bbox_inches=<span class=\"string\">'tight'</span>, pad_inches=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"uniform\" data-src=\"/2023/03/27/Variables/uniform.png\"></p>\n<h3 id=\"Normal-distribution\"><a href=\"#Normal-distribution\" class=\"headerlink\" title=\"Normal distribution\"></a>Normal distribution</h3><p>The probability density function (PDF) of a normal distribution with mean <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.489ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.364ex\" height=\"1.489ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 603 658\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D707\" d=\"M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z\"></path></g></g></g></svg></mjx-container> and standard deviation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.292ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 571 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D70E\" d=\"M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z\"></path></g></g></g></svg></mjx-container> is given by:</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\nf(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\end{equation}</script><p>where <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.294ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 572 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g></g></g></svg></mjx-container> is the random variable and <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"4.299ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 1900 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D453\" d=\"M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(550,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(939,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1511,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container> is the probability density function at <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.294ex\" height=\"1.025ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 572 453\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g></g></g></svg></mjx-container>. The mean <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.489ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.364ex\" height=\"1.489ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 603 658\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D707\" d=\"M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z\"></path></g></g></g></svg></mjx-container> determines the center of the distribution, while the standard deviation <mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.292ex\" height=\"1ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -431 571 442\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D70E\" d=\"M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z\"></path></g></g></g></svg></mjx-container> determines the spread of the distribution.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/4/23 02:06</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.collections <span class=\"keyword\">import</span> LineCollection</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> cm  <span class=\"comment\"># import color map</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.stats <span class=\"keyword\">import</span> norm</span><br><span class=\"line\"></span><br><span class=\"line\">x_array = np.linspace(-<span class=\"number\">6</span>, <span class=\"number\">6</span>, <span class=\"number\">200</span>)</span><br><span class=\"line\">sigma_array = np.linspace(<span class=\"number\">0.5</span>, <span class=\"number\">5</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># generate x and sigma arrays</span></span><br><span class=\"line\"></span><br><span class=\"line\">num_lines = <span class=\"built_in\">len</span>(sigma_array)</span><br><span class=\"line\"><span class=\"comment\"># probability density function</span></span><br><span class=\"line\"></span><br><span class=\"line\">colors = cm.RdYlBu(np.linspace(<span class=\"number\">0</span>, <span class=\"number\">1</span>, num_lines))</span><br><span class=\"line\"><span class=\"comment\"># color map</span></span><br><span class=\"line\"></span><br><span class=\"line\">fig, ax = plt.subplots(figsize=(<span class=\"number\">5</span>, <span class=\"number\">4</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> idx, sigma_idx <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(sigma_array):</span><br><span class=\"line\">    pdf_idx = norm.pdf(x_array, scale=sigma_idx)</span><br><span class=\"line\">    legend_idx = <span class=\"string\">'$\\sigma$ = '</span> + <span class=\"built_in\">str</span>(sigma_idx)</span><br><span class=\"line\">    plt.plot(x_array, pdf_idx, color=colors[idx], label=legend_idx)</span><br><span class=\"line\">    <span class=\"comment\"># plot the pdf</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.xlim(<span class=\"built_in\">min</span>(x_array), <span class=\"built_in\">max</span>(x_array))</span><br><span class=\"line\">plt.ylim(<span class=\"number\">0</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'PDF'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fig.savefig(<span class=\"string\">'normal.png'</span>, dpi=<span class=\"number\">600</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"normal\" data-src=\"/2023/03/27/Variables/normal.png\"></p>\n<h3 id=\"Bivariate\"><a href=\"#Bivariate\" class=\"headerlink\" title=\"Bivariate\"></a>Bivariate</h3><p>The bivariate normal distribution is a probability distribution for two random variables that have a normal distribution.</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 3/4/23 16:19</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.stats <span class=\"keyword\">import</span> multivariate_normal</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the mean and covariance of the distribution</span></span><br><span class=\"line\">mean = [<span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">cov = [[<span class=\"number\">1</span>, <span class=\"number\">0</span>], [<span class=\"number\">0</span>, <span class=\"number\">1</span>]]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a grid of points to evaluate the distribution</span></span><br><span class=\"line\">x, y = np.mgrid[-<span class=\"number\">3</span>:<span class=\"number\">3</span>:<span class=\"number\">.01</span>, -<span class=\"number\">3</span>:<span class=\"number\">3</span>:<span class=\"number\">.01</span>]</span><br><span class=\"line\">pos = np.empty(x.shape + (<span class=\"number\">2</span>,))</span><br><span class=\"line\">pos[:, :, <span class=\"number\">0</span>] = x</span><br><span class=\"line\">pos[:, :, <span class=\"number\">1</span>] = y</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Generate the bivariate normal distribution</span></span><br><span class=\"line\">rv = multivariate_normal(mean, cov)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Evaluate the distribution at each point on the grid</span></span><br><span class=\"line\">z = rv.pdf(pos)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the distribution, like a mountain</span></span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">121</span>, projection=<span class=\"string\">'3d'</span>)</span><br><span class=\"line\">ax.plot_surface(x, y, z, cmap=<span class=\"string\">\"RdBu_r\"</span>, linewidth=<span class=\"number\">0.1</span>, antialiased=<span class=\"literal\">True</span>)</span><br><span class=\"line\">ax.grid(<span class=\"literal\">False</span>)</span><br><span class=\"line\"><span class=\"comment\"># only leave the plot of the mountain</span></span><br><span class=\"line\">ax.set_axis_off()</span><br><span class=\"line\"></span><br><span class=\"line\">ax = fig.add_subplot(<span class=\"number\">122</span>)</span><br><span class=\"line\">ax.contourf(x, y, z, cmap=<span class=\"string\">\"RdBu_r\"</span>)</span><br><span class=\"line\">ax.set_aspect(<span class=\"string\">\"equal\"</span>)</span><br><span class=\"line\">ax.set_axis_off()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># save the figure</span></span><br><span class=\"line\">plt.savefig(<span class=\"string\">\"bivariate_normal.png\"</span>, dpi=<span class=\"number\">600</span>, bbox_inches=<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></tbody></table></figure>\n<p><img alt=\"bivariate_normal\" data-src=\"/2023/03/27/Variables/bivariate_normal.png\"></p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Wikipedia contributors. (2023, March 23). Normal distribution. In Wikipedia. Retrieved March 28, 2023, from <a href=\"https://en.wikipedia.org/wiki/Normal_distribution\">https://en.wikipedia.org/wiki/Normal_distribution</a></li>\n<li>Pennsylvania State University. (n.d.). 4.2 - Bivariate normal distribution. In STAT 505: Applied multivariate statistical analysis. Retrieved March 28, 2023, from <a href=\"https://online.stat.psu.edu/stat505/lesson/4/4.2\">https://online.stat.psu.edu/stat505/lesson/4/4.2</a></li>\n<li>Visualize-ML. (n.d.). Book2_Beauty-of-Data-Visualization. GitHub. Retrieved March 28, 2023, from <a href=\"https://github.com/Visualize-ML/Book2_Beauty-of-Data-Visualization\">https://github.com/Visualize-ML/Book2_Beauty-of-Data-Visualization</a></li>\n</ol>\n</body></html>"},{"mathjax":true,"title":"Vehicle Detection and Counting Using OpenCV","date":"2023-04-01T13:29:31.000Z","_content":"\nThe code is a Python script that uses computer vision techniques to perform the following tasks:\n\n1. Load a video file and display it frame by frame using OpenCV.\n2. Remove the background from the video using a background subtraction algorithm.\n3. Identify and track vehicles in the video using morphological operations and contour detection techniques.\n4. Count the number of vehicles that pass a specified detection line in the video.\n\nThis type of technology can be used for various applications such as traffic monitoring, security surveillance, and vehicle tracking systems. It can help in detecting and preventing accidents, tracking stolen vehicles, and optimizing traffic flow.\n\n### Load the video\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/22 15:39\n\nimport cv2\nimport numpy as np\n\n# Create a VideoCapture object and open the video file\ncap = cv2.VideoCapture('./video.mp4')\n\n# Loop over the frames in the video\nwhile True:\n    # Read the current frame from the video\n    ret, frame = cap.read()\n\n    # If a frame was successfully read\n    if ret == True:\n        # Display the current frame in a window called \"video\"\n        cv2.imshow('video', frame)\n\n    # Wait for a key press for 1 millisecond\n    key = cv2.waitKey(1)\n\n    # If the user presses the \"esc\" key, break out of the loop\n    if key == 27:\n        break\n\n# Release the resources and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\"> <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155315817.png\" alt=\"image-20230401155315817\" style=\"zoom:20%;\" /> </p>\n\n### Background Subtraction in OpenCV\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/22 15:46\n\nimport cv2\nimport numpy as np\n\n# Create a VideoCapture object and open the video file\ncap = cv2.VideoCapture('./video.mp4')\n\n# Create a background subtractor object using the MOG method\nmog = cv2.createBackgroundSubtractorMOG2()\n\nwhile True:\n    # Read a frame from the video capture object\n    ret, frame = cap.read()\n\n    # If a frame was successfully read\n    if ret == True:\n        # Apply background subtraction to the frame\n        fgmask = mog.apply(frame)\n\n        # Display the resulting foreground mask in a window called \"video\"\n        cv2.imshow('video', fgmask)\n\n    # Wait for a key press for 1 millisecond\n    key = cv2.waitKey(1)\n\n    # If the user presses the \"esc\" key, break out of the loop\n    if key == 27:\n        break\n\n# Release the resources and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\"> <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155430619.png\" alt=\"image-20230401155430619\" style=\"zoom:20%;\" /> </p>\n\n### Detection and counting\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/22 15:57\n\nimport cv2\nprint(cv2.__version__)\n\nimport numpy as np\n\n# Open the video file for processing\ncap = cv2.VideoCapture('./video.mp4')\n\n# Create MOG object for background subtraction\nmog = cv2.createBackgroundSubtractorMOG2()\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n\n# Define minimum width and height for a detected car\nmin_w = 90\nmin_h = 90\n\n# Define the detection line position\nline_high = 600\n\n# Define the offset from the detection line for a car to be counted\noffset = 7\n\n# Initialize an empty list to store detected car positions\ncars = []\n\n# Initialize the car count to zero\ncarno = 0\n\n\n# Function to calculate the center point of a bounding rectangle\ndef center(x, y, w, h):\n    x1 = int(w / 2)\n    y1 = int(h / 2)\n    cx = int(x) + x1\n    cy = int(y) + y1\n    return cx, cy\n\n\n# Process each frame in the video\nwhile True:\n    ret, frame = cap.read()\n    if ret == True:\n        # Convert the frame to grayscale and apply Gaussian blur for noise reduction\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        blur = cv2.GaussianBlur(gray, (3, 3), 5)\n\n        # Apply MOG for background subtraction and morphological operations for noise reduction\n        mask = mog.apply(blur)\n        erode = cv2.erode(mask, kernel)\n        dialte = cv2.dilate(erode, kernel, iterations=2)\n        close = cv2.morphologyEx(dialte, cv2.MORPH_CLOSE, kernel)\n\n        # Find contours in the processed image\n        contours, h = cv2.findContours(close, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Draw the detection line on the frame\n        cv2.line(frame, (10, line_high), (1200, line_high), (255, 255, 0), 3)\n\n        # Process each detected contour\n        for contour in contours:\n            # Calculate the bounding rectangle of the contour\n            (x, y, w, h) = cv2.boundingRect(contour)\n            # Check if the bounding rectangle meets the minimum size requirement\n            is_valid = (w >= min_w) and (h >= min_h)\n            if not is_valid:\n                continue\n\n            # Draw a rectangle around the detected car and add its center point to the car list\n            cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 0, 255), 2)\n            cpoint = center(x, y, w, h)\n            cars.append(cpoint)\n            cv2.circle(frame, (cpoint), 5, (0, 0, 255), -1)\n\n            # Check if the car has crossed the detection line\n            for (x, y) in cars:\n                if (line_high - offset) < y < (line_high + offset):\n                    # Remove the car from the list and increment the car count\n                    carno += 1\n                    cars.remove((x, y))\n                    print(carno)\n\n        # Draw the car count on the frame and display it\n        cv2.putText(frame, 'Vehicle Count:' + str(carno), (500, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,\n        0, 255), 5)\n        cv2.imshow('frame', frame)\n\n    # Wait for the user to press a key, and exit if the key is \"esc\"\n    key = cv2.waitKey(1)\n    if key == 27:\n        break\n\n# Release the resources and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\"> <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401160906919.png\" alt=\"image-20230401160906919\" style=\"zoom:20%;\" /> </p>\n\nThe original video can be accessed at https://drive.google.com/file/d/1PQYkSYX-Hgd-CJ0kBhg-BxV_IJ0gOjje/view?usp=sharing. The results can be viewed at https://drive.google.com/file/d/1xG46InzwV0b1wVy7L4SEWSyYh-pEUclN/view?usp=sharing.\n\n### Improvements\n\nThe current issue with the program is that if multiple vehicles cross the line, the count may not be accurate. To improve the accuracy, two possible solutions are:\n\n1. Fine-tune the program parameters to better handle the situation where multiple vehicles cross the line simultaneously.\n2. Use deep learning to track the movement trajectories of vehicles and accurately count the number of vehicles crossing the line.\n\nBoth of these solutions can potentially improve the accuracy of the vehicle counting system.\n\n### Tracking and counting\n\nThe YOLOv7-DeepSORT-Object-Tracking is a computer vision project that utilizes the YOLOv7 object detection algorithm and DeepSORT object tracking algorithm to detect and track objects in real-time video streams.The project can be found on GitHub at https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking. \n\nI have tested it and the results can be viewed at https://drive.google.com/file/d/1ZtFjNEhHAxoEPQbjh0EN0TcsaVW2CTGZ/view?usp=sharing.\n\n<div style=\"text-align:center\">\n    <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230402154048465.png\" alt=\"image-20230402154048465\" style=\"margin:auto\">\n</div>\n\n### Reference\n\n1. Joshi, P. (2020, April 20). *Build your own Vehicle Detection Model using OpenCV and Python*. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2020/04/vehicle-detection-opencv-python/\n1. M. (2023, January 26). *GitHub - MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking: YOLOv7 Object Tracking using PyTorch, OpenCV and DeepSORT*. GitHub. https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Vehicle-Detection-and-Counting-Using-OpenCV.md","raw":"---\nmathjax: true\ntitle: Vehicle Detection and Counting Using OpenCV\ndate: 2023-04-01 13:29:31\ntags:\n  - Opencv\n  - Python\n  - Video processing\n  - Image processing\n  - Detection\n\n---\n\nThe code is a Python script that uses computer vision techniques to perform the following tasks:\n\n1. Load a video file and display it frame by frame using OpenCV.\n2. Remove the background from the video using a background subtraction algorithm.\n3. Identify and track vehicles in the video using morphological operations and contour detection techniques.\n4. Count the number of vehicles that pass a specified detection line in the video.\n\nThis type of technology can be used for various applications such as traffic monitoring, security surveillance, and vehicle tracking systems. It can help in detecting and preventing accidents, tracking stolen vehicles, and optimizing traffic flow.\n\n### Load the video\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/22 15:39\n\nimport cv2\nimport numpy as np\n\n# Create a VideoCapture object and open the video file\ncap = cv2.VideoCapture('./video.mp4')\n\n# Loop over the frames in the video\nwhile True:\n    # Read the current frame from the video\n    ret, frame = cap.read()\n\n    # If a frame was successfully read\n    if ret == True:\n        # Display the current frame in a window called \"video\"\n        cv2.imshow('video', frame)\n\n    # Wait for a key press for 1 millisecond\n    key = cv2.waitKey(1)\n\n    # If the user presses the \"esc\" key, break out of the loop\n    if key == 27:\n        break\n\n# Release the resources and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\"> <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155315817.png\" alt=\"image-20230401155315817\" style=\"zoom:20%;\" /> </p>\n\n### Background Subtraction in OpenCV\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/22 15:46\n\nimport cv2\nimport numpy as np\n\n# Create a VideoCapture object and open the video file\ncap = cv2.VideoCapture('./video.mp4')\n\n# Create a background subtractor object using the MOG method\nmog = cv2.createBackgroundSubtractorMOG2()\n\nwhile True:\n    # Read a frame from the video capture object\n    ret, frame = cap.read()\n\n    # If a frame was successfully read\n    if ret == True:\n        # Apply background subtraction to the frame\n        fgmask = mog.apply(frame)\n\n        # Display the resulting foreground mask in a window called \"video\"\n        cv2.imshow('video', fgmask)\n\n    # Wait for a key press for 1 millisecond\n    key = cv2.waitKey(1)\n\n    # If the user presses the \"esc\" key, break out of the loop\n    if key == 27:\n        break\n\n# Release the resources and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\"> <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155430619.png\" alt=\"image-20230401155430619\" style=\"zoom:20%;\" /> </p>\n\n### Detection and counting\n\n```python\n# Name: Mei Jiaojiao\n# Profession: Artificial Intelligence\n# Time and date: 4/1/22 15:57\n\nimport cv2\nprint(cv2.__version__)\n\nimport numpy as np\n\n# Open the video file for processing\ncap = cv2.VideoCapture('./video.mp4')\n\n# Create MOG object for background subtraction\nmog = cv2.createBackgroundSubtractorMOG2()\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n\n# Define minimum width and height for a detected car\nmin_w = 90\nmin_h = 90\n\n# Define the detection line position\nline_high = 600\n\n# Define the offset from the detection line for a car to be counted\noffset = 7\n\n# Initialize an empty list to store detected car positions\ncars = []\n\n# Initialize the car count to zero\ncarno = 0\n\n\n# Function to calculate the center point of a bounding rectangle\ndef center(x, y, w, h):\n    x1 = int(w / 2)\n    y1 = int(h / 2)\n    cx = int(x) + x1\n    cy = int(y) + y1\n    return cx, cy\n\n\n# Process each frame in the video\nwhile True:\n    ret, frame = cap.read()\n    if ret == True:\n        # Convert the frame to grayscale and apply Gaussian blur for noise reduction\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        blur = cv2.GaussianBlur(gray, (3, 3), 5)\n\n        # Apply MOG for background subtraction and morphological operations for noise reduction\n        mask = mog.apply(blur)\n        erode = cv2.erode(mask, kernel)\n        dialte = cv2.dilate(erode, kernel, iterations=2)\n        close = cv2.morphologyEx(dialte, cv2.MORPH_CLOSE, kernel)\n\n        # Find contours in the processed image\n        contours, h = cv2.findContours(close, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Draw the detection line on the frame\n        cv2.line(frame, (10, line_high), (1200, line_high), (255, 255, 0), 3)\n\n        # Process each detected contour\n        for contour in contours:\n            # Calculate the bounding rectangle of the contour\n            (x, y, w, h) = cv2.boundingRect(contour)\n            # Check if the bounding rectangle meets the minimum size requirement\n            is_valid = (w >= min_w) and (h >= min_h)\n            if not is_valid:\n                continue\n\n            # Draw a rectangle around the detected car and add its center point to the car list\n            cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 0, 255), 2)\n            cpoint = center(x, y, w, h)\n            cars.append(cpoint)\n            cv2.circle(frame, (cpoint), 5, (0, 0, 255), -1)\n\n            # Check if the car has crossed the detection line\n            for (x, y) in cars:\n                if (line_high - offset) < y < (line_high + offset):\n                    # Remove the car from the list and increment the car count\n                    carno += 1\n                    cars.remove((x, y))\n                    print(carno)\n\n        # Draw the car count on the frame and display it\n        cv2.putText(frame, 'Vehicle Count:' + str(carno), (500, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,\n        0, 255), 5)\n        cv2.imshow('frame', frame)\n\n    # Wait for the user to press a key, and exit if the key is \"esc\"\n    key = cv2.waitKey(1)\n    if key == 27:\n        break\n\n# Release the resources and close all windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n<p align=\"center\"> <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401160906919.png\" alt=\"image-20230401160906919\" style=\"zoom:20%;\" /> </p>\n\nThe original video can be accessed at https://drive.google.com/file/d/1PQYkSYX-Hgd-CJ0kBhg-BxV_IJ0gOjje/view?usp=sharing. The results can be viewed at https://drive.google.com/file/d/1xG46InzwV0b1wVy7L4SEWSyYh-pEUclN/view?usp=sharing.\n\n### Improvements\n\nThe current issue with the program is that if multiple vehicles cross the line, the count may not be accurate. To improve the accuracy, two possible solutions are:\n\n1. Fine-tune the program parameters to better handle the situation where multiple vehicles cross the line simultaneously.\n2. Use deep learning to track the movement trajectories of vehicles and accurately count the number of vehicles crossing the line.\n\nBoth of these solutions can potentially improve the accuracy of the vehicle counting system.\n\n### Tracking and counting\n\nThe YOLOv7-DeepSORT-Object-Tracking is a computer vision project that utilizes the YOLOv7 object detection algorithm and DeepSORT object tracking algorithm to detect and track objects in real-time video streams.The project can be found on GitHub at https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking. \n\nI have tested it and the results can be viewed at https://drive.google.com/file/d/1ZtFjNEhHAxoEPQbjh0EN0TcsaVW2CTGZ/view?usp=sharing.\n\n<div style=\"text-align:center\">\n    <img src=\"Vehicle-Detection-and-Counting-Using-OpenCV/image-20230402154048465.png\" alt=\"image-20230402154048465\" style=\"margin:auto\">\n</div>\n\n### Reference\n\n1. Joshi, P. (2020, April 20). *Build your own Vehicle Detection Model using OpenCV and Python*. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2020/04/vehicle-detection-opencv-python/\n1. M. (2023, January 26). *GitHub - MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking: YOLOv7 Object Tracking using PyTorch, OpenCV and DeepSORT*. GitHub. https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Vehicle-Detection-and-Counting-Using-OpenCV","published":1,"updated":"2023-04-07T02:43:50.920Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg7b73hi0017ozpifxqpdnyv","content":"<html><head></head><body></body></html><html><head></head><body><p>The code is a Python script that uses computer vision techniques to perform the following tasks:</p>\n<ol>\n<li>Load a video file and display it frame by frame using OpenCV.</li>\n<li>Remove the background from the video using a background subtraction algorithm.</li>\n<li>Identify and track vehicles in the video using morphological operations and contour detection techniques.</li>\n<li>Count the number of vehicles that pass a specified detection line in the video.</li>\n</ol>\n<p>This type of technology can be used for various applications such as traffic monitoring, security surveillance, and vehicle tracking systems. It can help in detecting and preventing accidents, tracking stolen vehicles, and optimizing traffic flow.</p>\n<h3 id=\"Load-the-video\"><a href=\"#Load-the-video\" class=\"headerlink\" title=\"Load the video\"></a>Load the video</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/22 15:39</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a VideoCapture object and open the video file</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"string\">'./video.mp4'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Loop over the frames in the video</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># Read the current frame from the video</span></span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If a frame was successfully read</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># Display the current frame in a window called \"video\"</span></span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">'video'</span>, frame)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Wait for a key press for 1 millisecond</span></span><br><span class=\"line\">    key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If the user presses the \"esc\" key, break out of the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Release the resources and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"image-20230401155315817\" style=\"zoom:20%;\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155315817.png\"> </p>\n\n<h3 id=\"Background-Subtraction-in-OpenCV\"><a href=\"#Background-Subtraction-in-OpenCV\" class=\"headerlink\" title=\"Background Subtraction in OpenCV\"></a>Background Subtraction in OpenCV</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/22 15:46</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a VideoCapture object and open the video file</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"string\">'./video.mp4'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a background subtractor object using the MOG method</span></span><br><span class=\"line\">mog = cv2.createBackgroundSubtractorMOG2()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># Read a frame from the video capture object</span></span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If a frame was successfully read</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># Apply background subtraction to the frame</span></span><br><span class=\"line\">        fgmask = mog.apply(frame)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Display the resulting foreground mask in a window called \"video\"</span></span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">'video'</span>, fgmask)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Wait for a key press for 1 millisecond</span></span><br><span class=\"line\">    key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If the user presses the \"esc\" key, break out of the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Release the resources and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"image-20230401155430619\" style=\"zoom:20%;\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155430619.png\"> </p>\n\n<h3 id=\"Detection-and-counting\"><a href=\"#Detection-and-counting\" class=\"headerlink\" title=\"Detection and counting\"></a>Detection and counting</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/22 15:57</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"built_in\">print</span>(cv2.__version__)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Open the video file for processing</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"string\">'./video.mp4'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create MOG object for background subtraction</span></span><br><span class=\"line\">mog = cv2.createBackgroundSubtractorMOG2()</span><br><span class=\"line\">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class=\"number\">5</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define minimum width and height for a detected car</span></span><br><span class=\"line\">min_w = <span class=\"number\">90</span></span><br><span class=\"line\">min_h = <span class=\"number\">90</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the detection line position</span></span><br><span class=\"line\">line_high = <span class=\"number\">600</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the offset from the detection line for a car to be counted</span></span><br><span class=\"line\">offset = <span class=\"number\">7</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize an empty list to store detected car positions</span></span><br><span class=\"line\">cars = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize the car count to zero</span></span><br><span class=\"line\">carno = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Function to calculate the center point of a bounding rectangle</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">center</span>(<span class=\"params\">x, y, w, h</span>):</span><br><span class=\"line\">    x1 = <span class=\"built_in\">int</span>(w / <span class=\"number\">2</span>)</span><br><span class=\"line\">    y1 = <span class=\"built_in\">int</span>(h / <span class=\"number\">2</span>)</span><br><span class=\"line\">    cx = <span class=\"built_in\">int</span>(x) + x1</span><br><span class=\"line\">    cy = <span class=\"built_in\">int</span>(y) + y1</span><br><span class=\"line\">    <span class=\"keyword\">return</span> cx, cy</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Process each frame in the video</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># Convert the frame to grayscale and apply Gaussian blur for noise reduction</span></span><br><span class=\"line\">        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">        blur = cv2.GaussianBlur(gray, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), <span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Apply MOG for background subtraction and morphological operations for noise reduction</span></span><br><span class=\"line\">        mask = mog.apply(blur)</span><br><span class=\"line\">        erode = cv2.erode(mask, kernel)</span><br><span class=\"line\">        dialte = cv2.dilate(erode, kernel, iterations=<span class=\"number\">2</span>)</span><br><span class=\"line\">        close = cv2.morphologyEx(dialte, cv2.MORPH_CLOSE, kernel)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Find contours in the processed image</span></span><br><span class=\"line\">        contours, h = cv2.findContours(close, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Draw the detection line on the frame</span></span><br><span class=\"line\">        cv2.line(frame, (<span class=\"number\">10</span>, line_high), (<span class=\"number\">1200</span>, line_high), (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Process each detected contour</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> contour <span class=\"keyword\">in</span> contours:</span><br><span class=\"line\">            <span class=\"comment\"># Calculate the bounding rectangle of the contour</span></span><br><span class=\"line\">            (x, y, w, h) = cv2.boundingRect(contour)</span><br><span class=\"line\">            <span class=\"comment\"># Check if the bounding rectangle meets the minimum size requirement</span></span><br><span class=\"line\">            is_valid = (w &gt;= min_w) <span class=\"keyword\">and</span> (h &gt;= min_h)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> is_valid:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Draw a rectangle around the detected car and add its center point to the car list</span></span><br><span class=\"line\">            cv2.rectangle(frame, (<span class=\"built_in\">int</span>(x), <span class=\"built_in\">int</span>(y)), (<span class=\"built_in\">int</span>(x + w), <span class=\"built_in\">int</span>(y + h)), (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">            cpoint = center(x, y, w, h)</span><br><span class=\"line\">            cars.append(cpoint)</span><br><span class=\"line\">            cv2.circle(frame, (cpoint), <span class=\"number\">5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Check if the car has crossed the detection line</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (x, y) <span class=\"keyword\">in</span> cars:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (line_high - offset) &lt; y &lt; (line_high + offset):</span><br><span class=\"line\">                    <span class=\"comment\"># Remove the car from the list and increment the car count</span></span><br><span class=\"line\">                    carno += <span class=\"number\">1</span></span><br><span class=\"line\">                    cars.remove((x, y))</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(carno)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Draw the car count on the frame and display it</span></span><br><span class=\"line\">        cv2.putText(frame, <span class=\"string\">'Vehicle Count:'</span> + <span class=\"built_in\">str</span>(carno), (<span class=\"number\">500</span>, <span class=\"number\">60</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">2</span>, (<span class=\"number\">0</span>,</span><br><span class=\"line\">        <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">5</span>)</span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">'frame'</span>, frame)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Wait for the user to press a key, and exit if the key is \"esc\"</span></span><br><span class=\"line\">    key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Release the resources and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"image-20230401160906919\" style=\"zoom:20%;\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401160906919.png\"> </p>\n\n<p>The original video can be accessed at <a href=\"https://drive.google.com/file/d/1PQYkSYX-Hgd-CJ0kBhg-BxV_IJ0gOjje/view?usp=sharing\">https://drive.google.com/file/d/1PQYkSYX-Hgd-CJ0kBhg-BxV_IJ0gOjje/view?usp=sharing</a>. The results can be viewed at <a href=\"https://drive.google.com/file/d/1xG46InzwV0b1wVy7L4SEWSyYh-pEUclN/view?usp=sharing\">https://drive.google.com/file/d/1xG46InzwV0b1wVy7L4SEWSyYh-pEUclN/view?usp=sharing</a>.</p>\n<h3 id=\"Improvements\"><a href=\"#Improvements\" class=\"headerlink\" title=\"Improvements\"></a>Improvements</h3><p>The current issue with the program is that if multiple vehicles cross the line, the count may not be accurate. To improve the accuracy, two possible solutions are:</p>\n<ol>\n<li>Fine-tune the program parameters to better handle the situation where multiple vehicles cross the line simultaneously.</li>\n<li>Use deep learning to track the movement trajectories of vehicles and accurately count the number of vehicles crossing the line.</li>\n</ol>\n<p>Both of these solutions can potentially improve the accuracy of the vehicle counting system.</p>\n<h3 id=\"Tracking-and-counting\"><a href=\"#Tracking-and-counting\" class=\"headerlink\" title=\"Tracking and counting\"></a>Tracking and counting</h3><p>The YOLOv7-DeepSORT-Object-Tracking is a computer vision project that utilizes the YOLOv7 object detection algorithm and DeepSORT object tracking algorithm to detect and track objects in real-time video streams.The project can be found on GitHub at <a href=\"https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking\">https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking</a>. </p>\n<p>I have tested it and the results can be viewed at <a href=\"https://drive.google.com/file/d/1ZtFjNEhHAxoEPQbjh0EN0TcsaVW2CTGZ/view?usp=sharing\">https://drive.google.com/file/d/1ZtFjNEhHAxoEPQbjh0EN0TcsaVW2CTGZ/view?usp=sharing</a>.</p>\n<div style=\"text-align:center\">\n    <img alt=\"image-20230402154048465\" style=\"margin:auto\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230402154048465.png\">\n</div>\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Joshi, P. (2020, April 20). <em>Build your own Vehicle Detection Model using OpenCV and Python</em>. Analytics Vidhya. <a href=\"https://www.analyticsvidhya.com/blog/2020/04/vehicle-detection-opencv-python/\">https://www.analyticsvidhya.com/blog/2020/04/vehicle-detection-opencv-python/</a></li>\n<li>M. (2023, January 26). <em>GitHub - MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking: YOLOv7 Object Tracking using PyTorch, OpenCV and DeepSORT</em>. GitHub. <a href=\"https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking\">https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking</a></li>\n</ol>\n</body></html>","site":{"data":{}},"related_posts":["2023/04/01/OpenCV-Hand-Tracking-to-Count-Fingers/","2023/04/02/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/"],"length":1116,"excerpt":"","more":"<html><head></head><body></body></html><html><head></head><body><p>The code is a Python script that uses computer vision techniques to perform the following tasks:</p>\n<ol>\n<li>Load a video file and display it frame by frame using OpenCV.</li>\n<li>Remove the background from the video using a background subtraction algorithm.</li>\n<li>Identify and track vehicles in the video using morphological operations and contour detection techniques.</li>\n<li>Count the number of vehicles that pass a specified detection line in the video.</li>\n</ol>\n<p>This type of technology can be used for various applications such as traffic monitoring, security surveillance, and vehicle tracking systems. It can help in detecting and preventing accidents, tracking stolen vehicles, and optimizing traffic flow.</p>\n<h3 id=\"Load-the-video\"><a href=\"#Load-the-video\" class=\"headerlink\" title=\"Load the video\"></a>Load the video</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/22 15:39</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a VideoCapture object and open the video file</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"string\">'./video.mp4'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Loop over the frames in the video</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># Read the current frame from the video</span></span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If a frame was successfully read</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># Display the current frame in a window called \"video\"</span></span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">'video'</span>, frame)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Wait for a key press for 1 millisecond</span></span><br><span class=\"line\">    key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If the user presses the \"esc\" key, break out of the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Release the resources and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"image-20230401155315817\" style=\"zoom:20%;\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155315817.png\"> </p>\n\n<h3 id=\"Background-Subtraction-in-OpenCV\"><a href=\"#Background-Subtraction-in-OpenCV\" class=\"headerlink\" title=\"Background Subtraction in OpenCV\"></a>Background Subtraction in OpenCV</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/22 15:46</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a VideoCapture object and open the video file</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"string\">'./video.mp4'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create a background subtractor object using the MOG method</span></span><br><span class=\"line\">mog = cv2.createBackgroundSubtractorMOG2()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># Read a frame from the video capture object</span></span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If a frame was successfully read</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># Apply background subtraction to the frame</span></span><br><span class=\"line\">        fgmask = mog.apply(frame)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Display the resulting foreground mask in a window called \"video\"</span></span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">'video'</span>, fgmask)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Wait for a key press for 1 millisecond</span></span><br><span class=\"line\">    key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># If the user presses the \"esc\" key, break out of the loop</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Release the resources and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"image-20230401155430619\" style=\"zoom:20%;\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155430619.png\"> </p>\n\n<h3 id=\"Detection-and-counting\"><a href=\"#Detection-and-counting\" class=\"headerlink\" title=\"Detection and counting\"></a>Detection and counting</h3><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Name: Mei Jiaojiao</span></span><br><span class=\"line\"><span class=\"comment\"># Profession: Artificial Intelligence</span></span><br><span class=\"line\"><span class=\"comment\"># Time and date: 4/1/22 15:57</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"built_in\">print</span>(cv2.__version__)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Open the video file for processing</span></span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"string\">'./video.mp4'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create MOG object for background subtraction</span></span><br><span class=\"line\">mog = cv2.createBackgroundSubtractorMOG2()</span><br><span class=\"line\">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class=\"number\">5</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define minimum width and height for a detected car</span></span><br><span class=\"line\">min_w = <span class=\"number\">90</span></span><br><span class=\"line\">min_h = <span class=\"number\">90</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the detection line position</span></span><br><span class=\"line\">line_high = <span class=\"number\">600</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Define the offset from the detection line for a car to be counted</span></span><br><span class=\"line\">offset = <span class=\"number\">7</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize an empty list to store detected car positions</span></span><br><span class=\"line\">cars = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize the car count to zero</span></span><br><span class=\"line\">carno = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Function to calculate the center point of a bounding rectangle</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">center</span>(<span class=\"params\">x, y, w, h</span>):</span><br><span class=\"line\">    x1 = <span class=\"built_in\">int</span>(w / <span class=\"number\">2</span>)</span><br><span class=\"line\">    y1 = <span class=\"built_in\">int</span>(h / <span class=\"number\">2</span>)</span><br><span class=\"line\">    cx = <span class=\"built_in\">int</span>(x) + x1</span><br><span class=\"line\">    cy = <span class=\"built_in\">int</span>(y) + y1</span><br><span class=\"line\">    <span class=\"keyword\">return</span> cx, cy</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Process each frame in the video</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">        <span class=\"comment\"># Convert the frame to grayscale and apply Gaussian blur for noise reduction</span></span><br><span class=\"line\">        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">        blur = cv2.GaussianBlur(gray, (<span class=\"number\">3</span>, <span class=\"number\">3</span>), <span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Apply MOG for background subtraction and morphological operations for noise reduction</span></span><br><span class=\"line\">        mask = mog.apply(blur)</span><br><span class=\"line\">        erode = cv2.erode(mask, kernel)</span><br><span class=\"line\">        dialte = cv2.dilate(erode, kernel, iterations=<span class=\"number\">2</span>)</span><br><span class=\"line\">        close = cv2.morphologyEx(dialte, cv2.MORPH_CLOSE, kernel)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Find contours in the processed image</span></span><br><span class=\"line\">        contours, h = cv2.findContours(close, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Draw the detection line on the frame</span></span><br><span class=\"line\">        cv2.line(frame, (<span class=\"number\">10</span>, line_high), (<span class=\"number\">1200</span>, line_high), (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Process each detected contour</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> contour <span class=\"keyword\">in</span> contours:</span><br><span class=\"line\">            <span class=\"comment\"># Calculate the bounding rectangle of the contour</span></span><br><span class=\"line\">            (x, y, w, h) = cv2.boundingRect(contour)</span><br><span class=\"line\">            <span class=\"comment\"># Check if the bounding rectangle meets the minimum size requirement</span></span><br><span class=\"line\">            is_valid = (w &gt;= min_w) <span class=\"keyword\">and</span> (h &gt;= min_h)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> is_valid:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Draw a rectangle around the detected car and add its center point to the car list</span></span><br><span class=\"line\">            cv2.rectangle(frame, (<span class=\"built_in\">int</span>(x), <span class=\"built_in\">int</span>(y)), (<span class=\"built_in\">int</span>(x + w), <span class=\"built_in\">int</span>(y + h)), (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">            cpoint = center(x, y, w, h)</span><br><span class=\"line\">            cars.append(cpoint)</span><br><span class=\"line\">            cv2.circle(frame, (cpoint), <span class=\"number\">5</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>), -<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\"># Check if the car has crossed the detection line</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (x, y) <span class=\"keyword\">in</span> cars:</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (line_high - offset) &lt; y &lt; (line_high + offset):</span><br><span class=\"line\">                    <span class=\"comment\"># Remove the car from the list and increment the car count</span></span><br><span class=\"line\">                    carno += <span class=\"number\">1</span></span><br><span class=\"line\">                    cars.remove((x, y))</span><br><span class=\"line\">                    <span class=\"built_in\">print</span>(carno)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Draw the car count on the frame and display it</span></span><br><span class=\"line\">        cv2.putText(frame, <span class=\"string\">'Vehicle Count:'</span> + <span class=\"built_in\">str</span>(carno), (<span class=\"number\">500</span>, <span class=\"number\">60</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class=\"number\">2</span>, (<span class=\"number\">0</span>,</span><br><span class=\"line\">        <span class=\"number\">0</span>, <span class=\"number\">255</span>), <span class=\"number\">5</span>)</span><br><span class=\"line\">        cv2.imshow(<span class=\"string\">'frame'</span>, frame)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Wait for the user to press a key, and exit if the key is \"esc\"</span></span><br><span class=\"line\">    key = cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> key == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Release the resources and close all windows</span></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure>\n<p align=\"center\"> <img alt=\"image-20230401160906919\" style=\"zoom:20%;\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401160906919.png\"> </p>\n\n<p>The original video can be accessed at <a href=\"https://drive.google.com/file/d/1PQYkSYX-Hgd-CJ0kBhg-BxV_IJ0gOjje/view?usp=sharing\">https://drive.google.com/file/d/1PQYkSYX-Hgd-CJ0kBhg-BxV_IJ0gOjje/view?usp=sharing</a>. The results can be viewed at <a href=\"https://drive.google.com/file/d/1xG46InzwV0b1wVy7L4SEWSyYh-pEUclN/view?usp=sharing\">https://drive.google.com/file/d/1xG46InzwV0b1wVy7L4SEWSyYh-pEUclN/view?usp=sharing</a>.</p>\n<h3 id=\"Improvements\"><a href=\"#Improvements\" class=\"headerlink\" title=\"Improvements\"></a>Improvements</h3><p>The current issue with the program is that if multiple vehicles cross the line, the count may not be accurate. To improve the accuracy, two possible solutions are:</p>\n<ol>\n<li>Fine-tune the program parameters to better handle the situation where multiple vehicles cross the line simultaneously.</li>\n<li>Use deep learning to track the movement trajectories of vehicles and accurately count the number of vehicles crossing the line.</li>\n</ol>\n<p>Both of these solutions can potentially improve the accuracy of the vehicle counting system.</p>\n<h3 id=\"Tracking-and-counting\"><a href=\"#Tracking-and-counting\" class=\"headerlink\" title=\"Tracking and counting\"></a>Tracking and counting</h3><p>The YOLOv7-DeepSORT-Object-Tracking is a computer vision project that utilizes the YOLOv7 object detection algorithm and DeepSORT object tracking algorithm to detect and track objects in real-time video streams.The project can be found on GitHub at <a href=\"https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking\">https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking</a>. </p>\n<p>I have tested it and the results can be viewed at <a href=\"https://drive.google.com/file/d/1ZtFjNEhHAxoEPQbjh0EN0TcsaVW2CTGZ/view?usp=sharing\">https://drive.google.com/file/d/1ZtFjNEhHAxoEPQbjh0EN0TcsaVW2CTGZ/view?usp=sharing</a>.</p>\n<div style=\"text-align:center\">\n    <img alt=\"image-20230402154048465\" style=\"margin:auto\" data-src=\"/2023/04/01/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230402154048465.png\">\n</div>\n\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><ol>\n<li>Joshi, P. (2020, April 20). <em>Build your own Vehicle Detection Model using OpenCV and Python</em>. Analytics Vidhya. <a href=\"https://www.analyticsvidhya.com/blog/2020/04/vehicle-detection-opencv-python/\">https://www.analyticsvidhya.com/blog/2020/04/vehicle-detection-opencv-python/</a></li>\n<li>M. (2023, January 26). <em>GitHub - MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking: YOLOv7 Object Tracking using PyTorch, OpenCV and DeepSORT</em>. GitHub. <a href=\"https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking\">https://github.com/MuhammadMoinFaisal/YOLOv7-DeepSORT-Object-Tracking</a></li>\n</ol>\n</body></html>"}],"PostAsset":[{"_id":"source/_posts/Differential-equations/Constrained_vs_Unconstrained_Optimization.png","post":"clg7b73ge0003ozpi3j0sczxr","slug":"Constrained_vs_Unconstrained_Optimization.png","modified":1,"renderable":1},{"_id":"source/_posts/Differential-equations/Exact_vs_Noisy_Cost_Functions.png","post":"clg7b73ge0003ozpi3j0sczxr","slug":"Exact_vs_Noisy_Cost_Functions.png","modified":1,"renderable":1},{"_id":"source/_posts/Differential-equations/Interpolation.png","post":"clg7b73ge0003ozpi3j0sczxr","slug":"Interpolation.png","modified":1,"renderable":1},{"_id":"source/_posts/Differential-equations/Local Minima.png","post":"clg7b73ge0003ozpi3j0sczxr","slug":"Local Minima.png","modified":1,"renderable":1},{"_id":"source/_posts/Differential-equations/Optimization with constraints.png","post":"clg7b73ge0003ozpi3j0sczxr","slug":"Optimization with constraints.png","modified":1,"renderable":1},{"_id":"source/_posts/Differential-equations/Optimization.png","post":"clg7b73ge0003ozpi3j0sczxr","slug":"Optimization.png","modified":1,"renderable":1},{"_id":"source/_posts/Differential-equations/smooth_non_smooth.png","post":"clg7b73ge0003ozpi3j0sczxr","slug":"smooth_non_smooth.png","modified":1,"renderable":1},{"_id":"source/_posts/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/predictions.png","post":"clg7b73gk0006ozpidupa93ld","slug":"predictions.png","modified":1,"renderable":1},{"_id":"source/_posts/FashionMNIST-Classification-with-PyTorch-Training-and-Testing-with-Loss-Plotting/train_test_loss.png","post":"clg7b73gk0006ozpidupa93ld","slug":"train_test_loss.png","modified":1,"renderable":1},{"_id":"source/_posts/From-linear-regression-to-binary-classification/binaryclass.png","post":"clg7b73gm0008ozpi2g202xwp","slug":"binaryclass.png","modified":1,"renderable":1},{"_id":"source/_posts/From-linear-regression-to-binary-classification/binaryclass1.png","post":"clg7b73gm0008ozpi2g202xwp","slug":"binaryclass1.png","modified":1,"renderable":1},{"_id":"source/_posts/From-linear-regression-to-binary-classification/binaryclass2.png","post":"clg7b73gm0008ozpi2g202xwp","slug":"binaryclass2.png","modified":1,"renderable":1},{"_id":"source/_posts/From-linear-regression-to-binary-classification/sigmoid.png","post":"clg7b73gm0008ozpi2g202xwp","slug":"sigmoid.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions-Plot/2d_functions.png","post":"clg7b73gn000aozpi070fdpd3","slug":"2d_functions.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions-Plot/3d_functions.png","post":"clg7b73gn000aozpi070fdpd3","slug":"3d_functions.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions/Even and old Function.png","post":"clg7b73gp000cozpi985p6hki","slug":"Even and old Function.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions/Function f(x) = x^2.png","post":"clg7b73gp000cozpi985p6hki","slug":"Function f(x) = x^2.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions/One-to-one Function.png","post":"clg7b73gp000cozpi985p6hki","slug":"One-to-one Function.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions/convexity.png","post":"clg7b73gp000cozpi985p6hki","slug":"convexity.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions/exponential_logarithmic.png","post":"clg7b73gp000cozpi985p6hki","slug":"exponential_logarithmic.png","modified":1,"renderable":1},{"_id":"source/_posts/Functions/floor_ceiling.png","post":"clg7b73gp000cozpi985p6hki","slug":"floor_ceiling.png","modified":1,"renderable":1},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient.png","post":"clg7b73gq000dozpi6wn0fucb","slug":"gradient.png","modified":1,"renderable":1},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient1.png","post":"clg7b73gq000dozpi6wn0fucb","slug":"gradient1.png","modified":1,"renderable":1},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient2.png","post":"clg7b73gq000dozpi6wn0fucb","slug":"gradient2.png","modified":1,"renderable":1},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient3-0040620.png","post":"clg7b73gq000dozpi6wn0fucb","slug":"gradient3-0040620.png","modified":1,"renderable":1},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient3.png","post":"clg7b73gq000dozpi6wn0fucb","slug":"gradient3.png","modified":1,"renderable":1},{"_id":"source/_posts/Gradient-descend-for-linear-regression/gradient4.png","post":"clg7b73gq000dozpi6wn0fucb","slug":"gradient4.png","modified":1,"renderable":1},{"_id":"source/_posts/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness.gif","post":"clg7b73gw000fozpigtdj8qlg","slug":"brightness.gif","modified":1,"renderable":1},{"_id":"source/_posts/Hand-Gesture-Controlled-Brightness-Adjustment-with-OpenCV-and-Mediapipe/brightness_control.gif","post":"clg7b73gw000fozpigtdj8qlg","slug":"brightness_control.gif","modified":1,"renderable":1},{"_id":"source/_posts/Hyperplane/binary_classification_problem_in_2d.png","post":"clg7b73gx000gozpi9xcb7s3s","slug":"binary_classification_problem_in_2d.png","modified":1,"renderable":1},{"_id":"source/_posts/Hyperplane/binary_classification_problem_in_3d.png","post":"clg7b73gx000gozpi9xcb7s3s","slug":"binary_classification_problem_in_3d.png","modified":1,"renderable":1},{"_id":"source/_posts/Image-processing-using-Numpy/rose_chanel_order.png","post":"clg7b73gz000iozpi50gu7ymx","slug":"rose_chanel_order.png","modified":1,"renderable":1},{"_id":"source/_posts/Image-processing-using-Numpy/rose_channels.png","post":"clg7b73gz000iozpi50gu7ymx","slug":"rose_channels.png","modified":1,"renderable":1},{"_id":"source/_posts/Linear-Algebra-Basics/2d_vector.png","post":"clg7b73h0000kozpig3zy1gp4","slug":"2d_vector.png","modified":1,"renderable":1},{"_id":"source/_posts/Norms/norm.png","post":"clg7b73h3000pozpi6dsu0x4s","slug":"norm.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV-Hand-Tracking-to-Count-Fingers/image-20230401192321128.png","post":"clg7b73h5000sozpi9r2fejj7","slug":"image-20230401192321128.png","modified":1,"renderable":1},{"_id":"source/_posts/Pandas-Basics/iris.png","post":"clg7b73h6000tozpi9haeb2gx","slug":"iris.png","modified":1,"renderable":1},{"_id":"source/_posts/RGB-color/rgb_colors.png","post":"clg7b73h9000vozpi9b5a8cgz","slug":"rgb_colors.png","modified":1,"renderable":1},{"_id":"source/_posts/RGB-color/rgb_cubic.png","post":"clg7b73h9000vozpi9b5a8cgz","slug":"rgb_cubic.png","modified":1,"renderable":1},{"_id":"source/_posts/Regression/Correlation coefficients.png","post":"clg7b73ha000xozpi243i79hn","slug":"Correlation coefficients.png","modified":1,"renderable":1},{"_id":"source/_posts/Regression/Linear Regression.png","post":"clg7b73ha000xozpi243i79hn","slug":"Linear Regression.png","modified":1,"renderable":1},{"_id":"source/_posts/Regression/Polynomial Regression of Sin(x).png","post":"clg7b73ha000xozpi243i79hn","slug":"Polynomial Regression of Sin(x).png","modified":1,"renderable":1},{"_id":"source/_posts/Relationships-between-two-Sets/Cartesian Product of A and B.png","post":"clg7b73hb0010ozpi4gnb5h6u","slug":"Cartesian Product of A and B.png","modified":1,"renderable":1},{"_id":"source/_posts/Relationships-between-two-Sets/Venn Diagrams for cardinality.png","post":"clg7b73hb0010ozpi4gnb5h6u","slug":"Venn Diagrams for cardinality.png","modified":1,"renderable":1},{"_id":"source/_posts/Relationships-between-two-Sets/Venn Diagrams for numbers.png","post":"clg7b73hb0010ozpi4gnb5h6u","slug":"Venn Diagrams for numbers.png","modified":1,"renderable":1},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock.png","post":"clg7b73hc0012ozpi2azc1a13","slug":"minimize_rosenbrock.png","modified":1,"renderable":1},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock_bfgs.png","post":"clg7b73hc0012ozpi2azc1a13","slug":"minimize_rosenbrock_bfgs.png","modified":1,"renderable":1},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock_methods.png","post":"clg7b73hc0012ozpi2azc1a13","slug":"minimize_rosenbrock_methods.png","modified":1,"renderable":1},{"_id":"source/_posts/Scipy-optimization/minimize_rosenbrock_newton.png","post":"clg7b73hc0012ozpi2azc1a13","slug":"minimize_rosenbrock_newton.png","modified":1,"renderable":1},{"_id":"source/_posts/Scipy-optimization/minimize_scalar.png","post":"clg7b73hc0012ozpi2azc1a13","slug":"minimize_scalar.png","modified":1,"renderable":1},{"_id":"source/_posts/Scipy-optimization/minimize_scalar1.png","post":"clg7b73hc0012ozpi2azc1a13","slug":"minimize_scalar1.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/AdaBoost.png","post":"clg7b73he0014ozpi17lf79un","slug":"AdaBoost.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Decision Tree.png","post":"clg7b73he0014ozpi17lf79un","slug":"Decision Tree.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/K-Nearest Neighbors.png","post":"clg7b73he0014ozpi17lf79un","slug":"K-Nearest Neighbors.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Logistic Regression.png","post":"clg7b73he0014ozpi17lf79un","slug":"Logistic Regression.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/MLP classifier model.png","post":"clg7b73he0014ozpi17lf79un","slug":"MLP classifier model.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Naive Bayes classifier model.png","post":"clg7b73he0014ozpi17lf79un","slug":"Naive Bayes classifier model.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/Random Forest.png","post":"clg7b73he0014ozpi17lf79un","slug":"Random Forest.png","modified":1,"renderable":1},{"_id":"source/_posts/Sentiment-Analysis-on-Product-Reviews/SVM.png","post":"clg7b73he0014ozpi17lf79un","slug":"SVM.png","modified":1,"renderable":1},{"_id":"source/_posts/Variables/bivariate_normal.png","post":"clg7b73hg0015ozpif05tcx35","slug":"bivariate_normal.png","modified":1,"renderable":1},{"_id":"source/_posts/Variables/normal.png","post":"clg7b73hg0015ozpif05tcx35","slug":"normal.png","modified":1,"renderable":1},{"_id":"source/_posts/Variables/uniform.png","post":"clg7b73hg0015ozpif05tcx35","slug":"uniform.png","modified":1,"renderable":1},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155315817.png","post":"clg7b73hi0017ozpifxqpdnyv","slug":"image-20230401155315817.png","modified":1,"renderable":1},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401155430619.png","post":"clg7b73hi0017ozpifxqpdnyv","slug":"image-20230401155430619.png","modified":1,"renderable":1},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230401160906919.png","post":"clg7b73hi0017ozpifxqpdnyv","slug":"image-20230401160906919.png","modified":1,"renderable":1},{"_id":"source/_posts/Vehicle-Detection-and-Counting-Using-OpenCV/image-20230402154048465.png","post":"clg7b73hi0017ozpifxqpdnyv","slug":"image-20230402154048465.png","modified":1,"renderable":1}],"PostCategory":[],"PostTag":[{"post_id":"clg7b73g70001ozpi1nzvcst6","tag_id":"clg7b73gh0004ozpiake151ol","_id":"clg7b73h0000jozpi4rz2cr3g"},{"post_id":"clg7b73g70001ozpi1nzvcst6","tag_id":"clg7b73go000bozpi176tfvcq","_id":"clg7b73h1000lozpih63p65l9"},{"post_id":"clg7b73g70001ozpi1nzvcst6","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73h3000oozpi4du0cr5w"},{"post_id":"clg7b73ge0003ozpi3j0sczxr","tag_id":"clg7b73gy000hozpi0fj97c5s","_id":"clg7b73ha000wozpicve99dg7"},{"post_id":"clg7b73ge0003ozpi3j0sczxr","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73hb000yozpieqjdfz57"},{"post_id":"clg7b73ge0003ozpi3j0sczxr","tag_id":"clg7b73h4000rozpifpvlgbq6","_id":"clg7b73hc0011ozpi4quk9uw1"},{"post_id":"clg7b73gk0006ozpidupa93ld","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73hj0018ozpialm0c3az"},{"post_id":"clg7b73gk0006ozpidupa93ld","tag_id":"clg7b73hb000zozpi1mqehnkk","_id":"clg7b73hj0019ozpiat309c7x"},{"post_id":"clg7b73gk0006ozpidupa93ld","tag_id":"clg7b73hd0013ozpiaw1h4xkx","_id":"clg7b73hk001bozpifvqnft14"},{"post_id":"clg7b73gm0008ozpi2g202xwp","tag_id":"clg7b73hh0016ozpifdc67dcc","_id":"clg7b73hl001gozpig7hd4h1c"},{"post_id":"clg7b73gm0008ozpi2g202xwp","tag_id":"clg7b73hj001aozpi72nr4hm7","_id":"clg7b73hl001hozpiegm9df59"},{"post_id":"clg7b73gm0008ozpi2g202xwp","tag_id":"clg7b73hk001cozpi9ln38clx","_id":"clg7b73hm001jozpi7nvnhf0e"},{"post_id":"clg7b73gm0008ozpi2g202xwp","tag_id":"clg7b73hk001dozpi43vx3nta","_id":"clg7b73hm001kozpiax8pb1de"},{"post_id":"clg7b73gm0008ozpi2g202xwp","tag_id":"clg7b73hk001eozpif6gqhzb0","_id":"clg7b73hn001mozpicref3s5w"},{"post_id":"clg7b73gn000aozpi070fdpd3","tag_id":"clg7b73hl001fozpiem1s2x00","_id":"clg7b73hn001pozpi54aybtvh"},{"post_id":"clg7b73gn000aozpi070fdpd3","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73ho001qozpi69is3kxp"},{"post_id":"clg7b73gn000aozpi070fdpd3","tag_id":"clg7b73hm001lozpi8ltxbmfa","_id":"clg7b73ho001sozpi1qqx7oi8"},{"post_id":"clg7b73gn000aozpi070fdpd3","tag_id":"clg7b73hn001nozpig68a8w2y","_id":"clg7b73ho001tozpigf6t1ucy"},{"post_id":"clg7b73gp000cozpi985p6hki","tag_id":"clg7b73hl001fozpiem1s2x00","_id":"clg7b73hw001yozpigwly77sx"},{"post_id":"clg7b73gp000cozpi985p6hki","tag_id":"clg7b73gy000hozpi0fj97c5s","_id":"clg7b73hw001zozpicjpy8150"},{"post_id":"clg7b73gp000cozpi985p6hki","tag_id":"clg7b73ho001uozpi5irqglcl","_id":"clg7b73hw0021ozpi351p7ljh"},{"post_id":"clg7b73gp000cozpi985p6hki","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73hw0022ozpiehm054en"},{"post_id":"clg7b73gp000cozpi985p6hki","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73hx0024ozpi11cv9bn9"},{"post_id":"clg7b73gq000dozpi6wn0fucb","tag_id":"clg7b73hv001xozpi7iy0fgj6","_id":"clg7b73i30029ozpietb08syy"},{"post_id":"clg7b73gq000dozpi6wn0fucb","tag_id":"clg7b73hh0016ozpifdc67dcc","_id":"clg7b73i3002aozpi64418b8v"},{"post_id":"clg7b73gq000dozpi6wn0fucb","tag_id":"clg7b73hx0023ozpi3y757iv0","_id":"clg7b73i9002cozpi6c9qfvtr"},{"post_id":"clg7b73gq000dozpi6wn0fucb","tag_id":"clg7b73hx0025ozpi5nlm7cpz","_id":"clg7b73ia002dozpi7donaqjx"},{"post_id":"clg7b73gq000dozpi6wn0fucb","tag_id":"clg7b73hx0026ozpi23yq7e6h","_id":"clg7b73ia002fozpi56ddeb70"},{"post_id":"clg7b73gq000dozpi6wn0fucb","tag_id":"clg7b73hy0027ozpi6v7kfnml","_id":"clg7b73ia002gozpi92e8hgio"},{"post_id":"clg7b73gw000fozpigtdj8qlg","tag_id":"clg7b73hy0028ozpia10rg3zm","_id":"clg7b73ic002lozpi06xy2n5w"},{"post_id":"clg7b73gw000fozpigtdj8qlg","tag_id":"clg7b73i9002bozpiag1p53ab","_id":"clg7b73ic002mozpi7wb57hyw"},{"post_id":"clg7b73gw000fozpigtdj8qlg","tag_id":"clg7b73ia002eozpi7pf88fgf","_id":"clg7b73ic002oozpi3mza9os2"},{"post_id":"clg7b73gw000fozpigtdj8qlg","tag_id":"clg7b73ia002hozpi27dk6kds","_id":"clg7b73ic002pozpi30ejd9wd"},{"post_id":"clg7b73gw000fozpigtdj8qlg","tag_id":"clg7b73ib002iozpi0vp6bfkr","_id":"clg7b73id002rozpi3eszbm9q"},{"post_id":"clg7b73gw000fozpigtdj8qlg","tag_id":"clg7b73ib002jozpi8nrr9osj","_id":"clg7b73id002sozpi1whchcel"},{"post_id":"clg7b73gx000gozpi9xcb7s3s","tag_id":"clg7b73hk001cozpi9ln38clx","_id":"clg7b73id002uozpi53aoaooz"},{"post_id":"clg7b73gx000gozpi9xcb7s3s","tag_id":"clg7b73hj001aozpi72nr4hm7","_id":"clg7b73ie002vozpi6qggfgcj"},{"post_id":"clg7b73gx000gozpi9xcb7s3s","tag_id":"clg7b73ic002qozpi063h63dx","_id":"clg7b73ie002xozpi4rpohkoq"},{"post_id":"clg7b73gz000iozpi50gu7ymx","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73ig0030ozpi6fqug9xx"},{"post_id":"clg7b73gz000iozpi50gu7ymx","tag_id":"clg7b73hm001lozpi8ltxbmfa","_id":"clg7b73ig0031ozpi3a1hby6l"},{"post_id":"clg7b73gz000iozpi50gu7ymx","tag_id":"clg7b73ib002iozpi0vp6bfkr","_id":"clg7b73ih0033ozpi8a8y7e8r"},{"post_id":"clg7b73h0000kozpig3zy1gp4","tag_id":"clg7b73hk001cozpi9ln38clx","_id":"clg7b73ih0035ozpi05yj60tw"},{"post_id":"clg7b73h0000kozpig3zy1gp4","tag_id":"clg7b73gh0004ozpiake151ol","_id":"clg7b73ih0036ozpico4z3l9k"},{"post_id":"clg7b73h0000kozpig3zy1gp4","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73ii0038ozpi1afqf60l"},{"post_id":"clg7b73h0000kozpig3zy1gp4","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73ii0039ozpi948522wh"},{"post_id":"clg7b73h2000nozpi668b2jet","tag_id":"clg7b73hk001cozpi9ln38clx","_id":"clg7b73ij003cozpi9ynoc0m0"},{"post_id":"clg7b73h2000nozpi668b2jet","tag_id":"clg7b73ih0037ozpif2lvg50p","_id":"clg7b73ij003dozpiafg465yk"},{"post_id":"clg7b73h2000nozpi668b2jet","tag_id":"clg7b73ii003aozpi13c850ps","_id":"clg7b73ij003fozpid31td6vf"},{"post_id":"clg7b73h3000pozpi6dsu0x4s","tag_id":"clg7b73gh0004ozpiake151ol","_id":"clg7b73ij003gozpifbfpe51s"},{"post_id":"clg7b73h3000pozpi6dsu0x4s","tag_id":"clg7b73ii003bozpi4ex438wq","_id":"clg7b73im003iozpic0ja4204"},{"post_id":"clg7b73h3000pozpi6dsu0x4s","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73im003jozpifoxvdcbs"},{"post_id":"clg7b73h4000qozpi9itdhuza","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73in003lozpiaxmdfyyd"},{"post_id":"clg7b73h4000qozpi9itdhuza","tag_id":"clg7b73hm001lozpi8ltxbmfa","_id":"clg7b73in003mozpi64ry7v8r"},{"post_id":"clg7b73h4000qozpi9itdhuza","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73in003oozpi0wtw6bcy"},{"post_id":"clg7b73h4000qozpi9itdhuza","tag_id":"clg7b73ik003hozpi66ycf01h","_id":"clg7b73in003pozpi0ier8tmp"},{"post_id":"clg7b73h5000sozpi9r2fejj7","tag_id":"clg7b73im003kozpi7kv146y0","_id":"clg7b73iq003tozpi2zozb5o2"},{"post_id":"clg7b73h5000sozpi9r2fejj7","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73iq003uozpidn8cdp50"},{"post_id":"clg7b73h5000sozpi9r2fejj7","tag_id":"clg7b73in003nozpi1v329v0i","_id":"clg7b73iq003wozpi72gw9byw"},{"post_id":"clg7b73h5000sozpi9r2fejj7","tag_id":"clg7b73ib002iozpi0vp6bfkr","_id":"clg7b73ir003xozpi1fpp7il2"},{"post_id":"clg7b73h5000sozpi9r2fejj7","tag_id":"clg7b73io003rozpihgzxa29o","_id":"clg7b73ir003zozpi11gmfv26"},{"post_id":"clg7b73h6000tozpi9haeb2gx","tag_id":"clg7b73io003sozpihs7d83hf","_id":"clg7b73ir0040ozpielog4928"},{"post_id":"clg7b73h6000tozpi9haeb2gx","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73is0042ozpibe6tan43"},{"post_id":"clg7b73h6000tozpi9haeb2gx","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73is0043ozpidrj2d44n"},{"post_id":"clg7b73h9000vozpi9b5a8cgz","tag_id":"clg7b73iq003vozpi4lisei7k","_id":"clg7b73is0045ozpicjeq36e0"},{"post_id":"clg7b73h9000vozpi9b5a8cgz","tag_id":"clg7b73ib002iozpi0vp6bfkr","_id":"clg7b73is0046ozpidwk682r1"},{"post_id":"clg7b73h9000vozpi9b5a8cgz","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73is0048ozpi18te9g6f"},{"post_id":"clg7b73ha000xozpi243i79hn","tag_id":"clg7b73hh0016ozpifdc67dcc","_id":"clg7b73iu004cozpi4fbr216y"},{"post_id":"clg7b73ha000xozpi243i79hn","tag_id":"clg7b73is0044ozpi3pecgy9r","_id":"clg7b73iu004dozpi52es6qhl"},{"post_id":"clg7b73ha000xozpi243i79hn","tag_id":"clg7b73hk001cozpi9ln38clx","_id":"clg7b73iu004fozpie1u54teq"},{"post_id":"clg7b73ha000xozpi243i79hn","tag_id":"clg7b73it0049ozpi4p077iyp","_id":"clg7b73iu004gozpi43zn5re6"},{"post_id":"clg7b73ha000xozpi243i79hn","tag_id":"clg7b73it004aozpi1wfz821w","_id":"clg7b73iv004iozpibc74hiqg"},{"post_id":"clg7b73hb0010ozpi4gnb5h6u","tag_id":"clg7b73it004bozpielh59ntp","_id":"clg7b73iv004jozpidczd4xr2"},{"post_id":"clg7b73hb0010ozpi4gnb5h6u","tag_id":"clg7b73gy000hozpi0fj97c5s","_id":"clg7b73iv004lozpi7xnk0zti"},{"post_id":"clg7b73hb0010ozpi4gnb5h6u","tag_id":"clg7b73ho001uozpi5irqglcl","_id":"clg7b73iw004mozpi7k150ke0"},{"post_id":"clg7b73hb0010ozpi4gnb5h6u","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73ix004oozpi5u7306ei"},{"post_id":"clg7b73hb0010ozpi4gnb5h6u","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73ix004pozpi9jjlc5fy"},{"post_id":"clg7b73hc0012ozpi2azc1a13","tag_id":"clg7b73h4000rozpifpvlgbq6","_id":"clg7b73ix004rozpi13jw3vfa"},{"post_id":"clg7b73hc0012ozpi2azc1a13","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73ix004sozpi27wud51f"},{"post_id":"clg7b73hc0012ozpi2azc1a13","tag_id":"clg7b73iu004hozpie3yebfu6","_id":"clg7b73ix004tozpi7e2808f3"},{"post_id":"clg7b73hc0012ozpi2azc1a13","tag_id":"clg7b73hx0023ozpi3y757iv0","_id":"clg7b73iy004vozpifiy85p42"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73iw004nozpicr16hejn","_id":"clg7b73j60054ozpib7yxbaxw"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73ix004qozpic0e6gvqk","_id":"clg7b73j60055ozpi0tjbbddw"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73ix004uozpi82461fo3","_id":"clg7b73j70057ozpi1v9ig61f"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73iy004wozpi10vr296v","_id":"clg7b73j70058ozpi2spp55io"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73iy004xozpi79f70sud","_id":"clg7b73j7005aozpia19a62pu"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73iz004yozpify74gf7u","_id":"clg7b73j7005bozpidggkabw9"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73iz004zozpi9065gfsu","_id":"clg7b73j8005dozpi3z3t5ult"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73iz0050ozpidbxk4f9k","_id":"clg7b73j8005eozpia3ysgr6e"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73iz0051ozpi2ouig65r","_id":"clg7b73j8005fozpibdyze9n3"},{"post_id":"clg7b73he0014ozpi17lf79un","tag_id":"clg7b73j00052ozpieg8qbt35","_id":"clg7b73j8005hozpi5ui89w4y"},{"post_id":"clg7b73hg0015ozpif05tcx35","tag_id":"clg7b73j00053ozpicxyyhp5g","_id":"clg7b73j9005iozpibwab1hjy"},{"post_id":"clg7b73hg0015ozpif05tcx35","tag_id":"clg7b73j70056ozpiallee8av","_id":"clg7b73j9005kozpi35x0dtpg"},{"post_id":"clg7b73hg0015ozpif05tcx35","tag_id":"clg7b73j70059ozpi8yb4d6pn","_id":"clg7b73j9005lozpi6ahe26e8"},{"post_id":"clg7b73hg0015ozpif05tcx35","tag_id":"clg7b73j7005cozpi0p3fgciy","_id":"clg7b73ja005nozpiazoedah0"},{"post_id":"clg7b73hg0015ozpif05tcx35","tag_id":"clg7b73gw000eozpi12j15m7f","_id":"clg7b73ja005oozpi0qbm6391"},{"post_id":"clg7b73hi0017ozpifxqpdnyv","tag_id":"clg7b73im003kozpi7kv146y0","_id":"clg7b73je005qozpictur0p9f"},{"post_id":"clg7b73hi0017ozpifxqpdnyv","tag_id":"clg7b73h1000mozpi7jjm7naj","_id":"clg7b73je005rozpifxwg9bw0"},{"post_id":"clg7b73hi0017ozpifxqpdnyv","tag_id":"clg7b73in003nozpi1v329v0i","_id":"clg7b73jf005sozpi3mxpgber"},{"post_id":"clg7b73hi0017ozpifxqpdnyv","tag_id":"clg7b73ib002iozpi0vp6bfkr","_id":"clg7b73jf005tozpi4qbe1b3r"},{"post_id":"clg7b73hi0017ozpifxqpdnyv","tag_id":"clg7b73io003rozpihgzxa29o","_id":"clg7b73jf005uozpi5z3w6sxi"}],"Tag":[{"name":"Matrix","_id":"clg7b73gh0004ozpiake151ol"},{"name":"Linear combination","_id":"clg7b73go000bozpi176tfvcq"},{"name":"Basics","_id":"clg7b73gw000eozpi12j15m7f"},{"name":"Math","_id":"clg7b73gy000hozpi0fj97c5s"},{"name":"Python","_id":"clg7b73h1000mozpi7jjm7naj"},{"name":"Scipy","_id":"clg7b73h4000rozpifpvlgbq6"},{"name":"Classification","_id":"clg7b73hb000zozpi1mqehnkk"},{"name":"Torch","_id":"clg7b73hd0013ozpiaw1h4xkx"},{"name":"Linear regression","_id":"clg7b73hh0016ozpifdc67dcc"},{"name":"Logistic regression","_id":"clg7b73hj001aozpi72nr4hm7"},{"name":"Linear algebra","_id":"clg7b73hk001cozpi9ln38clx"},{"name":"Binary classification","_id":"clg7b73hk001dozpi43vx3nta"},{"name":"Sigmoid","_id":"clg7b73hk001eozpif6gqhzb0"},{"name":"Functions","_id":"clg7b73hl001fozpiem1s2x00"},{"name":"Numpy","_id":"clg7b73hm001lozpi8ltxbmfa"},{"name":"Matplotlib","_id":"clg7b73hn001nozpig68a8w2y"},{"name":"Probability","_id":"clg7b73ho001uozpi5irqglcl"},{"name":"Gradient descend","_id":"clg7b73hv001xozpi7iy0fgj6"},{"name":"Optimization","_id":"clg7b73hx0023ozpi3y757iv0"},{"name":"Mean squared error","_id":"clg7b73hx0025ozpi5nlm7cpz"},{"name":"Loss function","_id":"clg7b73hx0026ozpi23yq7e6h"},{"name":"Machine learning","_id":"clg7b73hy0027ozpi6v7kfnml"},{"name":"Hand gesture","_id":"clg7b73hy0028ozpia10rg3zm"},{"name":"Mediapipe","_id":"clg7b73i9002bozpiag1p53ab"},{"name":"OpenCV","_id":"clg7b73ia002eozpi7pf88fgf"},{"name":"Computer vision","_id":"clg7b73ia002hozpi27dk6kds"},{"name":"Image processing","_id":"clg7b73ib002iozpi0vp6bfkr"},{"name":"Real-time tracking","_id":"clg7b73ib002jozpi8nrr9osj"},{"name":"Hyperplane","_id":"clg7b73ic002qozpi063h63dx"},{"name":"linear regression","_id":"clg7b73ih0037ozpif2lvg50p"},{"name":"Linear equations","_id":"clg7b73ii003aozpi13c850ps"},{"name":"Norm","_id":"clg7b73ii003bozpi4ex438wq"},{"name":"Array","_id":"clg7b73ik003hozpi66ycf01h"},{"name":"Opencv","_id":"clg7b73im003kozpi7kv146y0"},{"name":"Video processing","_id":"clg7b73in003nozpi1v329v0i"},{"name":"Detection","_id":"clg7b73io003rozpihgzxa29o"},{"name":"Pandas","_id":"clg7b73io003sozpihs7d83hf"},{"name":"Data visualization","_id":"clg7b73iq003vozpi4lisei7k"},{"name":"Polynomial regression","_id":"clg7b73is0044ozpi3pecgy9r"},{"name":"Span","_id":"clg7b73it0049ozpi4p077iyp"},{"name":"Rank","_id":"clg7b73it004aozpi1wfz821w"},{"name":"Set","_id":"clg7b73it004bozpielh59ntp"},{"name":"Gradient","_id":"clg7b73iu004hozpie3yebfu6"},{"name":"Sentiment analysis","_id":"clg7b73iw004nozpicr16hejn"},{"name":"MLP classifier","_id":"clg7b73ix004qozpic0e6gvqk"},{"name":"Naive Bayes classifier","_id":"clg7b73ix004uozpi82461fo3"},{"name":"SVM","_id":"clg7b73iy004wozpi10vr296v"},{"name":"Random Forest","_id":"clg7b73iy004xozpi79f70sud"},{"name":"Logistic Regression","_id":"clg7b73iz004yozpify74gf7u"},{"name":"K-Nearest Neighbors","_id":"clg7b73iz004zozpi9065gfsu"},{"name":"Decision Tree","_id":"clg7b73iz0050ozpidbxk4f9k"},{"name":"AdaBoost","_id":"clg7b73iz0051ozpi2ouig65r"},{"name":"Gradient Boosting","_id":"clg7b73j00052ozpieg8qbt35"},{"name":"Probabilities","_id":"clg7b73j00053ozpicxyyhp5g"},{"name":"Variables","_id":"clg7b73j70056ozpiallee8av"},{"name":"Uniform distribution","_id":"clg7b73j70059ozpi8yb4d6pn"},{"name":"Normal distribution","_id":"clg7b73j7005cozpi0p3fgciy"}]}}